<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[测试]]></title>
    <url>%2F2018%2F10%2F24%2F%E6%B5%8B%E8%AF%95%2F</url>
    <content type="text"><![CDATA[脑壳大]]></content>
      <tags>
        <tag>测试</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>%2F2018%2F09%2F03%2Fnetwork%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%2F</url>
    <content type="text"><![CDATA[概述交换技术电路交换 大致过程：端到端先建立好连接，整个端到端的链路就不能被其它访问，然后进行数据交换，最后释放连接，其它端才能访问，所以这种方式的传输效率会非常低 分组交换 大致过程：采用存储转发技术。我们把要发送的整个数据叫做报文；在发送之前，我们将报文划分成为一个个更小的等长的数据段并在每个数据段之前加上一些必要的控制信息组成的首部。每个分组独立的选择转发路由，对通信电路是逐段占用 报文交换 就是不进行划分的分组交换 计算机网络的性能指标 速率：在计算机网上的主机在数字信道上传送数据的速率 带宽：是指数字信道所能传送的最大数据率 吞吐量：表示在单位时间内通过某个网络的数据量 时延：是指数据从网络的一端传送到另一端所需要的时间 物理层基本概念 物理层考虑的是怎样才能在连接各种计算机的传输媒体上传输数据的比特流，而不是指具体的传输媒体 物理层的主要任务描述为确定与传输媒体的接口有关的特性： 机械特性、电气特性、功能特性、过程特性 网络层网络层概述网络层向上只提供简单灵活的、无连接的、近最大努力交付的数据报服务 ICMP概述 网际控制报文协议，目的是更有效的转发IP数据报和提高交付成功的机会；ICMP不是高层协议而是IP协议，作为IP层数据报的数据，加上数据报的首部，组成IP数据报发送出去 ICMP报文种类 差错报告报文 终点不可达 原点抑制 时间超过 参数问题 改变路由 询问报文 回送请求和回答(ping) 时间戳请求和回答(时钟同步和测量时间) VPN和NAT**VPN（virtual private network） 定义：虚拟专用网，目的是解决两个专用网的通信，在因特网上的传输过程中数据加密 NAT（network address translation） 定义：网络地址转换，由于全球ip地址紧缺，通过路由器形成一个专用网，路由器拥有全球专有ip地址且安装了NAT软件，动态的分配IP地址给上网的用户，然后通过路由器进行专用网内的计算机与因特网上的计算机进行通信；所以也不难理解专用网内的计算机不能作服务器 运输层运输层概述运输层为应用程序提供端到端的逻辑通信 UDP用户数据报协议 概述 UDP是无连接的 尽最大努力交付 面向报文 没有拥塞控制 支持一对一，一对多，多对一，多对多的交付通信 首部开销小 首部格式 源端口、目的端口、长度、检验和 TCP传输控制协议 概述 面向连接的传输层协议 提供可靠交付的服务 全双工通信 面向字节流 可靠传输的工作原理 停止等待协议 无差错：每次发送一个分组，等到收到收到分组的确认就再发送下一个分组 出现差错：发送一个分组后，超过一定时间没有收到确认，那么就会重传此分组 确认丢失和确认迟到 连续ARQ协议 由于停止等待协议的信道利用率低，就有了这种协议 TCP报文的首部格式 源端口和目的端口 序号:本报文段所发送的数据的第一个字节的序号 确认号：期望收到对方下一个报文段的第一个数据字节的序号 数据偏移：指出TCP报文段的数据起始处距离TCP报文段起始处有多远 保留 紧急URG 确认ACK：仅当ACK=1时确认号字段才有效；建立连接后所有报文首部ACK=1 推送PSH 复位RST 同步SYN：在连接建立时用来同步序号 终止FIN：用来释放连接 窗口：指的是发送本报文段的一方的接受窗口 检验和 TCP可靠传输的实现 滑动窗口实现 TCP的流量控制 通过响应报文中的rwnd实现 TCP拥塞控制 慢开始和拥塞避免 快重传和快恢复]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2018%2F08%2F27%2Fjavaweb%2FCookie%E5%92%8CSession%2F</url>
    <content type="text"><![CDATA[Cookie机制 定义 Cookie使服务器在本地机器上存储的小段文本并随每一个请求发送至同一服务器 产生流程 正统的cookie分发使通过扩展HTTP协议实现的，服务器通过在HTTP响应头中加一行特殊的指示以提示浏览器按照指示生成相应的cookie，一般这个时候就会把服务器产生的sessionId发送给浏览器保存在cookie中以便维持有状态。当浏览器发送请求时，会检查所有存储的cookie，如果某个cookie所声明的作用范围大于等于将要请求的资源所在位置，则把该cookie附在请求资源的HTTP请求头上发送给浏览器。 Session机制 定义 session机制是一种服务器端的机制，服务器使用一种类似于散列表的结构来保存信息 产生流程 当程序需要为某个客户端的请求创建一个session时，服务器首先会检查这个客户端的请求里是否已经包含了一个sessionId，如果有就将该session检索出来放在Request中来使用，如果没有就创建一个新的seesion放在Request来使用，产生的sessionId将被在本次响应中返回给客户端保存，一般保存方式就是cookie 两者的不同点 存取方式的不同 Cookie只能保存ASCII字符串，存储UNICODE字符需要先进行编码 Session能保存任何类型的数据甚至java类 隐私策略不同 Cookie对于客户端是可见的，Session是不可见的 有效期上的不同 Cookie可以设置一个较长时间的过期时间，但是Session关闭了阅读器该Session就会失效，因而不能长期有效，如果Session长时间有效会导致服务器内存溢出 服务器压力不同 Cookie存储在本地，Session存储在服务器 跨域的支持上的不同 Cookie支持跨域，但是Session不支持跨域，不同域名使用不同Session 关于Cookie和Session的跨域共享 正常情况下Cookie发送 现在我们有两个站点 12www.example.com/site1www.example.com/site2 这两个站点因为在同一个域名下，所以在访问这两个站点时，会发送相同的cookie，因为浏览器存储cookie域是www.example.com 我们想实现的是同一个域但是不同的子域如何进行单点登录 12sub1.onmpw.comsub2.onmpw.com 上面就是两个同一个域但是不同的子域的例子，我们可以采用以下的实现方式实现： 登录sub1.onmpw.com系统 登录成功以后，设置cookie信息。这里需要注意，我们可以将用户名和密码存到cookie中，但是在设置的时候必须将这cookie的所属域设置为顶级域 .onmpw.com。这里可以使用setcookie函数，该函数的第四个参数是用来设置cookie所述域的。 1cookie.setDomain(&quot;.onmpw.com&quot;); 访问sub2.onmpw.com系统，浏览器会将cookie中的信息username和password附带在请求中一块儿发送到sub2.onmpw.com系统。这时该系统会先检查session是否登录，如果没有登录则验证cookie中的username和password从而实现自动登录。 sub2.onmpw.com 登录成功以后再写session信息。以后的验证就用自己的session信息验证就可以了。 但是现在出现了一个问题 问题：当我们进入一个子域，要退出时我们可以删除自身的session信息和所属域为.onmpw.com的cookie，但是由于session时不跨域的不能删除另一个子域的session信息，也就是不能同时退出 解决方案：把第一登录生成的JSESSIONID，通过setDomain放到一个共享的自定义的cookie中。之后访问二级域名的时候，将自定义cookie中的值取出来，然后再放到JESSIONID的cookie值中 123Cookie c = new Cookie(&quot;JSESSIONID&quot;, session.getId()); c.setDomain(&quot;abc.com&quot;); resp.addCookie(c);]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2018%2F08%2F27%2Fjavaweb%2F%E8%B7%A8%E5%9F%9F%E8%AF%B7%E6%B1%82%2F</url>
    <content type="text"><![CDATA[什么是跨域请求跨域请求就是比如我们在浏览器中正在访问一个aaa.com的网站，它其中有一个链接是bbb.com，如果我们点击这个链接那么它就是一个跨域请求，但是我们如果访问以aaa.com开头的所有链接都不是跨域请求 CROSCORS即Cross-Origin Resource Sharing是一个新的W3C标准，它新增了一组HTTP首部字段，允许服务端其声明哪些源站有权限访问哪些资源 具体实现方式对于简单请求浏览器直接发送原请求，如果响应中没有相应的字段那么不会收到任何数据；如果是非简单请求，那么浏览器会使用Option方法发起一个预检请求，从而在响应中得知是否允许跨域，如果允许在发送原请求 至于具体的字段配置看下面的参考 参考https://www.jianshu.com/p/f880878c1398]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2018%2F08%2F14%2Fjavaweb%2FDocker%2F</url>
    <content type="text"><![CDATA[更换Docker镜像源编辑 /etc/docker/daemon.json 的文件，如果没有就添加，docker版本要大于1.12 1&#123;"registry-mirrors":[]&#125; [] 里面可以填一下的镜像源： Docker官方中国区：https://registry.docker-cn.com 网易： http://hub-mirror.c.163.com ustc：https://docker.mirrors.ustc.edu.cn 区DaoCloud获取地址]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2018%2F08%2F11%2Fjavaweb%2F%E8%87%AA%E5%8A%A8%E5%8C%96%E7%94%9F%E6%88%90Api%E6%96%87%E6%A1%A3%2F</url>
    <content type="text"><![CDATA[Swagger注解使用说明 @Api 这个注解用来生命此类为Swagger resource API ，只有被这个@Api注解的类才能被Swagger扫描到；但是我发现这个不是必要的，不要这个注解有其它条件也可以扫描到类下面的Api @ApiOperation 这个注解用来声明单个方法为一个Api接口，其中value是用来给这个Api作简短的介绍；notes 允许你给出重要的和更详细的该接口的信息；response和responseContainer主要是用来展示返回示例的，如果在此使用了这两个就会体现在Example Value上 @ApiResponses、@ApiResponse 这两个注解组合使用在类上，是为了展示方法返回状态码的含义 @ApiParam 此注解就是用来显示请求该接口需要哪些参数,这个用来GET方法上 @ApiImplicitParam、@ApiImplicitParam 此注解也是用来显示接口参数，但是是用在参数放在Body里面的参数 @ApiModel、@ApiModelProperty 这两个注解是用来在请求参数中如果有对象，可以用这两个注解来具体描述里面的参数]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2018%2F08%2F05%2Fjavaweb%2F%E9%AB%98%E6%80%A7%E8%83%BDMysql%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[Schema与数据类型优化 选择优化得数据类型原则： 更小的通常更好 简单就好 尽量避免NULL，因为可为NULL的列使得索引，索引统计和值比较都更为复杂 尽量不要使用Decimal，因为其会比DOUBLE或者FLOAT占用更大的空间且计算开销，除非你真的需要精确的小数计算比如存储财务数据 关于VARCHAR和CHAR VARCHAR 它比定长更节省空间，因为它仅使用必要的空间；所以在一下情况下最好使用该类型： 字符串列的长度比平均长度大很多 列的更新很少，所以碎片不是问题(因为VARCHAR的更新可能会导致原来的页剩余的空间不够而需要采取其它的技术手段) 使用了UTF-8这样复杂的字符集，每个字符使用不同的字节数进行存储 CHAR Mysql总是会根据定义的字符串长度分配足够的空间，它会删除末尾的空格 使用情况： 很短的字符串且定长 经常变更的数据 关于DATETIME和TIMESTAMP TIMESTAMP会比DATETIME是更好的选择，因为前者会使用比后者一半对的存储空间但是它前者能够存储的时间范围比后者小 创建高性能的索引B-Tree索引 可以使用B-tree索引的查询类型 全值匹配：指的是和索引中的所有列进行匹配 匹配最左前缀 匹配列前缀 匹配范围值 精确匹配某一列并范围匹配另外一列 只访问索引的查询 B-TREE索引的限制 如果不是按照索引的最左列开始查找，则无法使用索引 不能跳过索引中的列 如果查询中有某个列的范围查询，则右边所有列都无法使用索引优化查找 索引的优点 索引大大减少了服务器需要扫描的数据量 快速定位，所以不需要导入全部数据进行顺序查找 索引可以帮助服务器避免排序和临时表 顺序存储，便于ORDER BY、GROUP BY ；当需要排序时，不是顺序存储的如果数据表小的话就把数据导入内存不然就用磁盘然后建立一个临时表进行排序这是一个非常耗时间的过程 索引可以将随机IO变为顺序IO 因为数据在索引中顺序存放的 Innodb 页结构InnoDB数据页由以下七个部分组成，如图所示： File Header（文件头）。 Page Header（页头）。 Infimun+Supremum Records。 User Records（用户记录，即行记录）。 Free Space（空闲空间）。 Page Directory（页目录）。 File Trailer（文件结尾信息）。 我这里主要想说三四点： 非聚餐索引就是这种形式存储所有记录的；也就是说每个B+-Tree叶子结点都是一个页，存储了具体的记录；B+树索引本身并不能找到具体的一条记录，B+树索引能找到只是该记录所在的页。数据库把页载入内存，然后通过Page Directory再进行二叉查找。只不过二叉查找的时间复杂度很低，同时内存中的查找很快，因此通常我们忽略了这部分查找所用的时间。 高性能的索引策略独立的列如果查询中的列不是独立的，则Mysql就不会使用索引；”独立的列”是指索引列不能是表达式的一部分，也不能是函数的一部分 ex：select actor_id from actor where actor_id + 1 = 5 前缀索引和索引选择性前缀索引：索引开始的部分字符，这样可以大大节约索引空间，从而提高索引效率。但是这样也会降低索引的选择性 索引的选择性：不重复的索引值和数据表的记录总数(#T)的比值 怎样确定索引前多少个字符? 12345select count(distinct left(city,3))/count(*) as sel3,count(distinct left(city,4))/count(*) as sel4,count(distinct left(city,5))/count(*) as sel5,count(distinct left(city,6))/count(*) as sel6,count(distinct left(city,7))/count(*) as sel7 选择选择性增加幅度很小的情况，但是也要注意数据分布不均匀的情况，即最常出现的前缀次数比最常出现的城市次数大很多的情况 前缀索引的缺点：无法使用前缀索引做ORDER BY 和 GROUP BY 多列索引举个例子：select film_id,actor_id from actor where actor_id=’1’ and film_id=’1’；但是只有两个独立的分别是film_id的和actor_id的索引，那么mysql在查询时会使用”索引联合”策略，但是这个会有性能的问题，需要耗费大量CPU和内存资源在算法的缓存、排序和合并操作上；索引在EXPLAIN中有索引合并应该好好检查一下查询和表结构 选择合适的索引列顺序 将选择性最高的列索引放到最前列 根据那些运行频率最高的插叙来调整索引列的顺序 聚簇索引聚簇：表示数据行和相邻的键值紧凑地存储在一起 聚簇索引包含了一张表的全部数据，一张表只能一个聚簇索引 优点： 可以把相关数据保存在一起(通过索引我们只需读取少量有我们想要数据的数据页，而如果是MYISAM，就是通过索引得到想要数据的物理地址，读取一行就是一次磁盘IO) 数据访问很快 使用覆盖索引扫描的查询可以直接使用页结点中的主键值 缺点： 最大限度提高了IO密集型应用的性能，但如果数据在内存中就没有用了 插入速度严重依赖于插入顺序 更新聚簇索引代价很高 插入行可能有页分裂的问题 聚簇索引可能导致全表扫描变慢 二级索引可能比想象的要更大，因为二级索引的叶子结点包含了引用行的主键 二级索引访问需要二次索引查找，而不是一次(如果你select 的字段比二级索引多，然后过滤条件能使用此二级索引，第一次先用二级索引进行查找找到对应的主键，然后通过主键在聚簇索引中找到想要的数据) Innodb和MyISAM数据分布差异 MyISAM数据分布 主键索引和普通索引没有区别； 按照数据插入的顺序插入的顺序存储在磁盘上，在索引数据行的旁边显示行号，从0开始递增，索引形式如图： 即叶子结 Innodb数据分布 就用下面的图来标识吧，很清晰了 覆盖索引 定义：如果一个索引包含所有需要查询的字段值，我们就称之为”覆盖索引” 全表扫描和全索引扫描全表扫描：是指通过物理表获取数据，顺序读磁盘上的数据 全索引扫描：查询时，遍历索引树来获取数据行 使用索引扫描来做排序Mysql有两种方式生成有序结果：通过排序操作或者按索引顺序扫描；所以如果直接通过排序操作，就可能用到中间表用来存储获取的数据然后通过算法排序，这样效率比较低 使用索引排序的要求： 索引的列顺序和ORDER BY字句的顺序完全一致，并且所有列的排序方向都一样时。如果查询需要关联多张表，则只有当ORDER BY字句引用的字段全部为第一个表时，才能使用索引做排序 索引的第一列被只能为一个常数，也能使用索引排序 冗余和重复索引Mysql 需要单独维护重复的索引，并且优化器在优化查询的时候也需要逐个的进行考虑，这会影响性能 未使用的索引索引和锁Innodb只有在访问行的时候才会对其加锁，而索引能够减少Innodb访问的行数，从而减少锁的数量 查询性能优化为什么查询速度慢在每一个消耗大量时间的查询案例中，我们都能看到一些不必要的额外操作，某些操作被额外的重复了很多次、某些操作执行得太慢等。优化查询的目的就是减少和消除这些操作所花费的时间 慢查询基础：优化数据访问查询性能低下的最基本原因是访问的数据太多 确认应用程序是否在检索大量超过需要的数据 确认Mysql服务器层是否在分析大量超过需要的行 是否向数据库请求了不需要的数据 查询不需要的记录 多表关联时返回全部列 总是取出全部列 重复查询相同的数据 Mysql是否在扫描额外的记录 衡量查询开销的三个指标如下： 响应时间 扫描的行数 返回的行数 响应时间：等待时间和响应时间的总和 扫描的行数和返回的行数：理想情况下扫描的行数和返回的行数相同 扫描的行数和访问类型(type) 访问类型：扫描表、扫描索引、范围访问和单值访问 索引让Mysql以最高效、扫描行数最少的方式找到需要的记录 重构查询方式 一个复杂查询还是多个简单查询 切分查询 分解关联查询 查询执行的基础Mysql发送一个请求的时候，Mysql到底做了些什么： 客户端发送 一条查询给服务器 服务器先检查查询缓存，如果命中了缓存，则立刻返回存储在缓存中的结果。佛欧泽进入下一阶段 服务器进行SQL解析、预处理，再由优化器生成对应的执行计划 Mysql根据优化器生产的执行计划、调用存储引擎的API来执行查询 将结果返回给客户端 Mysql客户端/服务器通信协议 查询状态 Sleep 线程正在等待客户端 Query 线程正在执行查询或者正在将结果发送给客户端 Locked 在Mysql服务器层，该线程正在等待表锁 Analyzing and statistics 线程正在收集存储引擎的统计信息，并生成查询的执行计划 Copying to tem table 线程正在执行查询，并且将其结果集收集都复制到一个临时表中 Storing result 线程正在对结果集进行排序 Sending data 线程可能在多个状态之间传递数据，或者在生成结果集，或者在向客户端返回数据 优化特定类型的查询 优化COUNT()查询 COUNT()的作用：是它可以统计某个列值的数量，也可以统计行数，在统计值时要求列值是非空的 关于MyISAM的神话： MyISAM的COUNT()函数总是非常快，这是个误解，只有在没有任何WHERE条件的COUNT(*)才非常快 简单的优化 优化LIMIT分页 为什么单纯的LIMIT性能不好，因为mysql会扫描全部数据，丢弃前面无用数据，然后只返回LIMIT的数据量 把LIMIT更改为使用 BETWEEN … AND 记录上一次查询返回的id，下一次从该id开始查询 ex：select * from rental where rental_id &lt; 16030 order by rental_id limit 201 EXPLAIN 字段说明 type system：表中只有一行数据或者是空表，且只能用于myisam和memory表。如果是Innodb引擎表，type列在这个情况通常都是all或者index const：使用唯一索引或者主键，返回记录一定是1行记录的等值where条件时，通常type是const。 ex：select * from student where student_id = 1; eq_ref：出现在要连接过个表的查询计划中，驱动表只返回一行数据，且这行数据是第二个表的主键或者唯一索引，且必须为not null，唯一索引和主键是多列时，只有所有的列都用作比较时才会出现eq_ref ex：explain select * from book,student where student.id = book.id; ref：不像eq_ref那样要求连接顺序，也没有主键和唯一索引的要求，只要使用相等条件检索时就可能出现，常见与辅助索引的等值查找。或者多列主键、唯一索引中，使用第一个列之外的列作为等值查找也会出现，总之，返回数据不唯一的等值查找就可能出现。 ex：select * from student where name=”梅勇杰” and sex=”男” 二种情况：过滤条件都有索引；多列主键、唯一索引，使用第一个列之外的列作为等值查找； fulltext：全文索引检索，要注意，全文索引的优先级很高，若全文索引和普通索引同时存在时，mysql不管代价，优先选择使用全文索引 index_merge：表示查询使用了两个以上的索引，最后取交集或者并集，常见and ，or的条件使用了不同的索引，官方排序这个在ref_or_null之后，但是实际上由于要读取所有索引，性能可能大部分时间都不如range ex：select * from student where name=”梅勇杰” and sex=”男” unique_subquery：用于where中的in形式子查询，子查询返回不重复值唯一值 index_subquery：用于in形式子查询使用到了辅助索引或者in常数列表，子查询可能返回重复值，可以使用索引将子查询去重 range：索引范围扫描，常见于使用 =, &lt;&gt;, &gt;, &gt;=, &lt;, &lt;=, IS NULL, &lt;=&gt;, BETWEEN, IN()或者like等运算符的查询中 index：索引全表扫描，把索引从头到尾扫一遍，常见于使用索引列就可以处理不需要读取数据文件的查询、可以使用索引排序或者分组的查询 all：这个就是全表扫描数据文件，然后再在server层进行过滤返回符合要求的记录 partitions 该列显示的为分区表命中的分区情况。 possible_keys 查询可能使用到的索引都会在这里列出来 key 查询真正使用到的索引，select_type为index_merge时，这里可能出现两个以上的索引，其他的select_type这里只会出现一个 key_len 用于处理查询的索引长度，如果是单列索引，那就整个索引长度算进去，如果是多列索引，那么查询不一定都能使用到所有的列，具体使用到了多少个列的索引，这里就会计算进去，没有使用到的列，这里不会计算进去。留意下这个列的值，算一下你的多列索引总长度就知道有没有使用到所有的列了。要注意，mysql的ICP特性使用到的索引不会计入其中。另外，key_len只计算where条件用到的索引长度，而排序和分组就算用到了索引，也不会计算到key_len中。 ref 如果是使用的常数等值查询，这里会显示const，如果是连接查询，被驱动表的执行计划这里会显示驱动表的关联字段，如果是条件使用了表达式或者函数，或者条件列发生了内部隐式转换，这里可能显示为func rows 这里是执行计划中估算的扫描行数，不是精确值 extra 对于extra列，官网上有这样一段话： If you want to make your queries as fast as possible, look out for Extra column values of Using filesort and Using temporary, or, in JSON-formatted EXPLAINoutput, for using_filesort and using_temporary_table properties equal to true. 大概的意思就是说，如果你想要优化你的查询，那就要注意extra辅助信息中的using filesort和using temporary，这两项非常消耗性能，需要注意。 这个列可以显示的信息非常多，有几十种，常用的有： A：distinct：在select部分使用了distinc关键字 B：no tables used：不带from字句的查询或者From dual查询 C：使用not in()形式子查询或not exists运算符的连接查询，这种叫做反连接。即，一般连接查询是先查询内表，再查询外表，反连接就是先查询外表，再查询内表。 D：using filesort：排序时无法使用到索引时，就会出现这个。常见于order by和group by语句中 E：using index：查询时不需要回表查询，直接通过索引就可以获取查询的数据。 F：using join buffer（block nested loop），using join buffer（batched key accss）：5.6.x之后的版本优化关联查询的BNL，BKA特性。主要是减少内表的循环数量以及比较顺序地扫描查询。 G：using sort_union，using_union，using intersect，using sort_intersection： using intersect：表示使用and的各个索引的条件时，该信息表示是从处理结果获取交集 using union：表示使用or连接各个使用索引的条件时，该信息表示从处理结果获取并集 using sort_union和using sort_intersection：与前面两个对应的类似，只是他们是出现在用and和or查询信息量大时，先查询主键，然后进行排序合并后，才能读取记录并返回。 H：using temporary：表示使用了临时表存储中间结果。临时表可以是内存临时表和磁盘临时表，执行计划中看不出来，需要查看status变量，used_tmp_table，used_tmp_disk_table才能看出来。 I：using where：表示存储引擎返回的记录并不是所有的都满足查询条件，需要在server层进行过滤。查询条件中分为限制条件和检查条件，5.6之前，存储引擎只能根据限制条件扫描数据并返回，然后server层根据检查条件进行过滤再返回真正符合查询的数据。5.6.x之后支持ICP特性，可以把检查条件也下推到存储引擎层，不符合检查条件和限制条件的数据，直接不读取，这样就大大减少了存储引擎扫描的记录数量。extra列显示using index condition J：firstmatch(tb_name)：5.6.x开始引入的优化子查询的新特性之一，常见于where字句含有in()类型的子查询。如果内表的数据量比较大，就可能出现这个 K：loosescan(m..n)：5.6.x之后引入的优化子查询的新特性之一，在in()类型的子查询中，子查询返回的可能有重复记录时，就可能出现这个 除了这些之外，还有很多查询数据字典库，执行计划过程中就发现不可能存在结果的一些提示信息 filtered 使用explain extended时会出现这个列，5.7之后的版本默认就有这个字段，不需要使用explain extended了。这个字段表示存储引擎返回的数据在server层过滤后，剩下多少满足查询的记录数量的比例，注意是百分比，不是具体记录数。 参考explain字段说明：https://www.jianshu.com/p/73f2c8448722]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2018%2F07%2F23%2Fjava%2F%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%2FSpring%20%E6%BA%90%E7%A0%81%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[Spring IOCSpring IOC概述 依赖反转：把控制权从具体的业务对象手中转交到平台或者框架中，Spring IOC就是实现这个模式的载体 为什么要使用Spring IOC 因为在面向对象程序设计中，一个对象会包含其它的对象，如果合伙对象的引用或依赖关系的管理有具体对象来完成，会导致代码的高度耦合和可测试性降低；如果把对象的管理和对象的注入都 交给Spring IOC来处理，那么解耦代码的同时还提高了可测试性 GenericApplicationContext的类图 IOC容器的初始化过程 这里就会涉及到一个方法refresh，下面是它的源码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445 public void refresh() throws BeansException, IllegalStateException &#123; Object var1 = this.startupShutdownMonitor; synchronized(this.startupShutdownMonitor) &#123; //初始化IOC容器之前的准备工作 this.prepareRefresh(); //得到一个BeanFactory,并且调用refreshBeanFactory(),这个方法会进行Bean的定位 、载入和 //注册；但是在我看AnnotationConfigApplicationContext源码的时候，我没有发现它的载入和注 //册 ConfigurableListableBeanFactory beanFactory = this.obtainFreshBeanFactory(); //给BeanFactory设置一些属性 this.prepareBeanFactory(beanFactory); try &#123; //设置BeanFactory的后置处理 this.postProcessBeanFactory(beanFactory); //调用BeanFactory的后置处理器，这些处理器是在IOC容器中通过Bean注册的 this.invokeBeanFactoryPostProcessors(beanFactory); //注册Bean的后处理器，在Bena的创建过程中调用 this.registerBeanPostProcessors(beanFactory); //对上下文中的消息源进行初始化 this.initMessageSource(); //初始化上下文中的事件机制 this.initApplicationEventMulticaster(); //初始化其它特殊的Bean this.onRefresh(); //检查监听Bean并且将这些Bean向容器注册 this.registerListeners(); //实例化所有的单件 this.finishBeanFactoryInitialization(beanFactory); //发布容器事件，结束refresh过程 this.finishRefresh(); &#125; catch (BeansException var9) &#123; if (this.logger.isWarnEnabled()) &#123; this.logger.warn("Exception encountered during context initialization - cancelling refresh attempt: " + var9); &#125; //为防止Bean资源占用，在异常处理中销毁已经创建的单件Bean this.destroyBeans(); //重置'active'标志 this.cancelRefresh(var9); throw var9; &#125; finally &#123; this.resetCommonCaches(); &#125; &#125;&#125; 这个方法涉及到了BeanDefinition的定位、载入和注册三个基本过程 一下是我看完源码后的一些感受 context上下文的意义要了解，什么叫做上下文，其实所有的不管FilesystemXmlApplicationContext还是AnnotationConfigApplicationContext它们都不叫做真正的IOC容器，它们都拥有一个共同的属性DefaultListableBeanFactory，这个才是真正的IOC容器，实现了IOC容器的所有功能；但是它们却把这个IOC容器放在了不同的环境下，这个环境就叫做上下文；就比如说FileSystemXmlApplicationContext，它的环境就是Xml文件而AnnotationConfigApplicationContext的环境是注解；所以这个造成了它们不同的行为方式，一个通过解析xml文件，定位、载入和注册Bean而另外一个是通过解析注解定位、载入和注册Bean BeanDefinition的定位和载入是通过AnnotationConfigApplicationContext的AnnotatedBeanDefinitionReader和ClassPathBeanDefinitionScanner，所以定位和载入都是通过Context来完成的；注册是IOC容器的registerDefinition方法来完成的 IOC容器的依赖注入 涉及到的源码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141public &lt;T&gt; T getBean(String name, @Nullable Class&lt;T&gt; requiredType) throws BeansException &#123; return this.doGetBean(name, requiredType, (Object[])null, false);&#125; protected &lt;T&gt; T doGetBean(String name, @Nullable Class&lt;T&gt; requiredType, @Nullable Object[] args, boolean typeCheckOnly) throws BeansException &#123; String beanName = this.transformedBeanName(name); //从缓存中得到对象，避免重复创建 Object sharedInstance = this.getSingleton(beanName); Object bean; if (sharedInstance != null &amp;&amp; args == null) &#123; if (this.logger.isDebugEnabled()) &#123; if (this.isSingletonCurrentlyInCreation(beanName)) &#123; this.logger.debug("Returning eagerly cached instance of singleton bean '" + beanName + "' that is not fully initialized yet - a consequence of a circular reference"); &#125; else &#123; this.logger.debug("Returning cached instance of singleton bean '" + beanName + "'"); &#125; &#125; //因为IOC中有FactoryBean和普通Bean两种，所以这里就是如果这个Bean是FactoryBean， //就取得它的真实对象 bean = this.getObjectForBeanInstance(sharedInstance, name, beanName, (RootBeanDefinition)null); //下面就是从父级容器里面得到Bean &#125; else &#123; if (this.isPrototypeCurrentlyInCreation(beanName)) &#123; throw new BeanCurrentlyInCreationException(beanName); &#125; BeanFactory parentBeanFactory = this.getParentBeanFactory(); if (parentBeanFactory != null &amp;&amp; !this.containsBeanDefinition(beanName)) &#123; String nameToLookup = this.originalBeanName(name); if (parentBeanFactory instanceof AbstractBeanFactory) &#123; return ((AbstractBeanFactory)parentBeanFactory).doGetBean(nameToLookup, requiredType, args, typeCheckOnly); &#125; if (args != null) &#123; return parentBeanFactory.getBean(nameToLookup, args); &#125; return parentBeanFactory.getBean(nameToLookup, requiredType); &#125; if (!typeCheckOnly) &#123; this.markBeanAsCreated(beanName); &#125; //处理依赖，创建Bean try &#123; RootBeanDefinition mbd = this.getMergedLocalBeanDefinition(beanName); this.checkMergedBeanDefinition(mbd, beanName, args); String[] dependsOn = mbd.getDependsOn(); String[] var11; if (dependsOn != null) &#123; var11 = dependsOn; int var12 = dependsOn.length; for(int var13 = 0; var13 &lt; var12; ++var13) &#123; String dep = var11[var13]; if (this.isDependent(beanName, dep)) &#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, "Circular depends-on relationship between '" + beanName + "' and '" + dep + "'"); &#125; this.registerDependentBean(dep, beanName); try &#123; this.getBean(dep); &#125; catch (NoSuchBeanDefinitionException var24) &#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, "'" + beanName + "' depends on missing bean '" + dep + "'", var24); &#125; &#125; &#125; if (mbd.isSingleton()) &#123; sharedInstance = this.getSingleton(beanName, () -&gt; &#123; try &#123; return this.createBean(beanName, mbd, args); &#125; catch (BeansException var5) &#123; this.destroySingleton(beanName); throw var5; &#125; &#125;); bean = this.getObjectForBeanInstance(sharedInstance, name, beanName, mbd); &#125; else if (mbd.isPrototype()) &#123; var11 = null; Object prototypeInstance; try &#123; this.beforePrototypeCreation(beanName); prototypeInstance = this.createBean(beanName, mbd, args); &#125; finally &#123; this.afterPrototypeCreation(beanName); &#125; bean = this.getObjectForBeanInstance(prototypeInstance, name, beanName, mbd); &#125; else &#123; String scopeName = mbd.getScope(); Scope scope = (Scope)this.scopes.get(scopeName); if (scope == null) &#123; throw new IllegalStateException("No Scope registered for scope name '" + scopeName + "'"); &#125; try &#123; Object scopedInstance = scope.get(beanName, () -&gt; &#123; this.beforePrototypeCreation(beanName); Object var4; try &#123; var4 = this.createBean(beanName, mbd, args); &#125; finally &#123; this.afterPrototypeCreation(beanName); &#125; return var4; &#125;); bean = this.getObjectForBeanInstance(scopedInstance, name, beanName, mbd); &#125; catch (IllegalStateException var23) &#123; throw new BeanCreationException(beanName, "Scope '" + scopeName + "' is not active for the current thread; consider defining a scoped proxy for this bean if you intend to refer to it from a singleton", var23); &#125; &#125; &#125; catch (BeansException var26) &#123; this.cleanupAfterBeanCreationFailure(beanName); throw var26; &#125; &#125; if (requiredType != null &amp;&amp; !requiredType.isInstance(bean)) &#123; try &#123; T convertedBean = this.getTypeConverter().convertIfNecessary(bean, requiredType); if (convertedBean == null) &#123; throw new BeanNotOfRequiredTypeException(name, requiredType, bean.getClass()); &#125; else &#123; return convertedBean; &#125; &#125; catch (TypeMismatchException var25) &#123; if (this.logger.isDebugEnabled()) &#123; this.logger.debug("Failed to convert bean '" + name + "' to required type '" + ClassUtils.getQualifiedName(requiredType) + "'", var25); &#125; throw new BeanNotOfRequiredTypeException(name, requiredType, bean.getClass()); &#125; &#125; else &#123; return bean; &#125;&#125; doGetBean的流程图: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485protected Object doCreateBean(String beanName, RootBeanDefinition mbd, @Nullable Object[] args) throws BeanCreationException &#123; BeanWrapper instanceWrapper = null; if (mbd.isSingleton()) &#123; instanceWrapper = (BeanWrapper)this.factoryBeanInstanceCache.remove(beanName); &#125; if (instanceWrapper == null) &#123; instanceWrapper = this.createBeanInstance(beanName, mbd, args); &#125; Object bean = instanceWrapper.getWrappedInstance(); Class&lt;?&gt; beanType = instanceWrapper.getWrappedClass(); if (beanType != NullBean.class) &#123; mbd.resolvedTargetType = beanType; &#125; Object var7 = mbd.postProcessingLock; synchronized(mbd.postProcessingLock) &#123; if (!mbd.postProcessed) &#123; try &#123; this.applyMergedBeanDefinitionPostProcessors(mbd, beanType, beanName); &#125; catch (Throwable var17) &#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, "Post-processing of merged bean definition failed", var17); &#125; mbd.postProcessed = true; &#125; &#125; boolean earlySingletonExposure = mbd.isSingleton() &amp;&amp; this.allowCircularReferences &amp;&amp; this.isSingletonCurrentlyInCreation(beanName); if (earlySingletonExposure) &#123; if (this.logger.isDebugEnabled()) &#123; this.logger.debug("Eagerly caching bean '" + beanName + "' to allow for resolving potential circular references"); &#125; this.addSingletonFactory(beanName, () -&gt; &#123; return this.getEarlyBeanReference(beanName, mbd, bean); &#125;); &#125; Object exposedObject = bean; try &#123; this.populateBean(beanName, mbd, instanceWrapper); exposedObject = this.initializeBean(beanName, exposedObject, mbd); &#125; catch (Throwable var18) &#123; if (var18 instanceof BeanCreationException &amp;&amp; beanName.equals(((BeanCreationException)var18).getBeanName())) &#123; throw (BeanCreationException)var18; &#125; throw new BeanCreationException(mbd.getResourceDescription(), beanName, "Initialization of bean failed", var18); &#125; if (earlySingletonExposure) &#123; Object earlySingletonReference = this.getSingleton(beanName, false); if (earlySingletonReference != null) &#123; if (exposedObject == bean) &#123; exposedObject = earlySingletonReference; &#125; else if (!this.allowRawInjectionDespiteWrapping &amp;&amp; this.hasDependentBean(beanName)) &#123; String[] dependentBeans = this.getDependentBeans(beanName); Set&lt;String&gt; actualDependentBeans = new LinkedHashSet(dependentBeans.length); String[] var12 = dependentBeans; int var13 = dependentBeans.length; for(int var14 = 0; var14 &lt; var13; ++var14) &#123; String dependentBean = var12[var14]; if (!this.removeSingletonIfCreatedForTypeCheckOnly(dependentBean)) &#123; actualDependentBeans.add(dependentBean); &#125; &#125; if (!actualDependentBeans.isEmpty()) &#123; throw new BeanCurrentlyInCreationException(beanName, "Bean with name '" + beanName + "' has been injected into other beans [" + StringUtils.collectionToCommaDelimitedString(actualDependentBeans) + "] in its raw version as part of a circular reference, but has eventually been wrapped. This means that said other beans do not use the final version of the bean. This is often the result of over-eager type matching - consider using 'getBeanNamesOfType' with the 'allowEagerInit' flag turned off, for example."); &#125; &#125; &#125; &#125; try &#123; this.registerDisposableBeanIfNecessary(beanName, bean, mbd); return exposedObject; &#125; catch (BeanDefinitionValidationException var16) &#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, "Invalid destruction signature", var16); &#125; &#125; 这里有个BeanWapper，这个BeanWapper的作用是管理Bean的属性 容器相关特性的设计与实现ApplicationContext和Bean的初始化和销毁ApplicationContext初始化:prepareBeanFactory() ApplicationContext的销毁：doClose(); 容器的实现是通过IOC管理Bean生命周期来实现的： initailizeBean；doClose；destroy lazy-init属性和预实例化FactoryBean的实现其实在我看来FactoryBean其实就是Spring 帮我们封装一个简化的工厂方法，我们可以把这个FactoryBean放在IOC容器里面，然后通过这个工厂类生成我们想要的类 主要涉及到的源码： 1234567891011121314151617181920212223242526272829303132protected Object getObjectForBeanInstance(Object beanInstance, String name, String beanName, @Nullable RootBeanDefinition mbd) &#123; if (BeanFactoryUtils.isFactoryDereference(name)) &#123; if (beanInstance instanceof NullBean) &#123; return beanInstance; &#125; if (!(beanInstance instanceof FactoryBean)) &#123; throw new BeanIsNotAFactoryException(this.transformedBeanName(name), beanInstance.getClass()); &#125; &#125; if (beanInstance instanceof FactoryBean &amp;&amp; !BeanFactoryUtils.isFactoryDereference(name)) &#123; Object object = null; if (mbd == null) &#123; object = this.getCachedObjectForFactoryBean(beanName); &#125; if (object == null) &#123; FactoryBean&lt;?&gt; factory = (FactoryBean)beanInstance; if (mbd == null &amp;&amp; this.containsBeanDefinition(beanName)) &#123; mbd = this.getMergedLocalBeanDefinition(beanName); &#125; boolean synthetic = mbd != null &amp;&amp; mbd.isSynthetic(); object = this.getObjectFromFactoryBean(factory, beanName, !synthetic); &#125; return object; &#125; else &#123; return beanInstance; &#125; &#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647protected Object getObjectFromFactoryBean(FactoryBean&lt;?&gt; factory, String beanName, boolean shouldPostProcess) &#123; if (factory.isSingleton() &amp;&amp; this.containsSingleton(beanName)) &#123; synchronized(this.getSingletonMutex()) &#123; Object object = this.factoryBeanObjectCache.get(beanName); if (object == null) &#123; object = this.doGetObjectFromFactoryBean(factory, beanName); Object alreadyThere = this.factoryBeanObjectCache.get(beanName); if (alreadyThere != null) &#123; object = alreadyThere; &#125; else &#123; if (shouldPostProcess) &#123; if (this.isSingletonCurrentlyInCreation(beanName)) &#123; return object; &#125; this.beforeSingletonCreation(beanName); try &#123; object = this.postProcessObjectFromFactoryBean(object, beanName); &#125; catch (Throwable var14) &#123; throw new BeanCreationException(beanName, "Post-processing of FactoryBean's singleton object failed", var14); &#125; finally &#123; this.afterSingletonCreation(beanName); &#125; &#125; if (this.containsSingleton(beanName)) &#123; this.factoryBeanObjectCache.put(beanName, object); &#125; &#125; &#125; return object; &#125; &#125; else &#123; Object object = this.doGetObjectFromFactoryBean(factory, beanName); if (shouldPostProcess) &#123; try &#123; object = this.postProcessObjectFromFactoryBean(object, beanName); &#125; catch (Throwable var17) &#123; throw new BeanCreationException(beanName, "Post-processing of FactoryBean's object failed", var17); &#125; &#125; return object; &#125;&#125; 上面两个方法解释了从FactoryBean取得真实对象 BeanPostProcessor的实现这个我们看源码的initializeBean方法就行 1234567891011121314151617181920212223242526272829protected Object initializeBean(String beanName, Object bean, @Nullable RootBeanDefinition mbd) &#123; if (System.getSecurityManager() != null) &#123; AccessController.doPrivileged(() -&gt; &#123; this.invokeAwareMethods(beanName, bean); return null; &#125;, this.getAccessControlContext()); &#125; else &#123; this.invokeAwareMethods(beanName, bean); &#125; //得到的是一个BeanWapper Object wrappedBean = bean; if (mbd == null || !mbd.isSynthetic()) &#123; //这里就会一次调用所有Bean创建的前置处理器 wrappedBean = this.applyBeanPostProcessorsBeforeInitialization(bean, beanName); &#125; try &#123; //初始化Bean this.invokeInitMethods(beanName, wrappedBean, mbd); &#125; catch (Throwable var6) &#123; throw new BeanCreationException(mbd != null ? mbd.getResourceDescription() : null, beanName, "Invocation of init method failed", var6); &#125; if (mbd == null || !mbd.isSynthetic()) &#123; //调用所有Bean创建的后置处理器 wrappedBean = this.applyBeanPostProcessorsAfterInitialization(wrappedBean, beanName); &#125; return wrappedBean;&#125; 这个方法会在getBean -&gt;doGetBean() -&gt;createBean-&gt; doCreateBean中调用 autowiring 的实现123456789101112if (mbd.getResolvedAutowireMode() == 1 || mbd.getResolvedAutowireMode() == 2) &#123; MutablePropertyValues newPvs = new MutablePropertyValues((PropertyValues)pvs); if (mbd.getResolvedAutowireMode() == 1) &#123; this.autowireByName(beanName, mbd, bw, newPvs); &#125; if (mbd.getResolvedAutowireMode() == 2) &#123; this.autowireByType(beanName, mbd, bw, newPvs); &#125; pvs = newPvs;&#125; 这是自动装配的实现，在AbstractAutowireCapableBeanFactory的populateBean方法中，这个populateBean 会在调用doCreateBean中调用 Bean对IOC容器的感知Spring AOPSpring AOP 概述业务逻辑的代码中不再含有针对特定领域问题代码的调用，业务逻辑同特定领域问题的关系通过切面来封装和维护，这样原本分散在整个应用程序中的变动就可以很好的管理起来 基础：视为待增强对象或者说目标对象； 切面：通常包含对于基础的增强应用； 配置：可以看成是一种编织，把基础和切面结合起来从而实现切面对目标对象的编织实现 在Spring AOP中有三个与上面对应： Advice通知：定义在切入点做什么，为切面增强提供织入接口，相当于上面的切面 Pointcut切点：定义通知应该作用于哪个连接点，相当于上面的基础 Advisor通知器：将切面和连接点结合起来的设计，相当于上面的配置 增强对象功能的过程首先给出AOP应用相关类的继承关系图： 我们先以ProxyFactoryBean来讲解Aop 配置ProxyFactoryBean 12345678910&lt;bean id="testAdvisor" class="comabc.TestAdvisor"/&gt;&lt;bean id="testAop" class="org.springframework.aop.ProxyFactoryBean"&gt;&lt;property name="proxyInterfaces"&gt;&lt;value&gt;com.test.AbcInterface&lt;/value&gt;&lt;/property&gt;&lt;property name="target"&gt; &lt;bean class="com.abc.TestTarget"/&gt;&lt;/property&gt;&lt;property name="intercerptorNames"&gt; &lt;list&gt;&lt;value&gt;testAdvisor&lt;/value&gt;&lt;/list&gt;&lt;/property&gt;&lt;/bean&gt; testAdvisor是定义切面 testAop定义ProxyFactoryBean，target属性是基础即待增强的类 ProxyFactoryBean生成AopProxy代理对象 生成AopProxy代理对象的流程图 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899public Object getObject() throws BeansException &#123; //初始化通知器链 this.initializeAdvisorChain(); //这里是对singleton和prototype的类型进行区分，生成对应的proxy if (this.isSingleton()) &#123; return this.getSingletonInstance(); &#125; else &#123; if (this.targetName == null) &#123; this.logger.warn("Using non-singleton proxies with singleton targets is often undesirable. Enable prototype proxies by setting the 'targetName' property."); &#125; return this.newPrototypeInstance(); &#125;&#125; private synchronized void initializeAdvisorChain() throws AopConfigException, BeansException &#123; if (!this.advisorChainInitialized) &#123; if (!ObjectUtils.isEmpty(this.interceptorNames)) &#123; if (this.beanFactory == null) &#123; throw new IllegalStateException("No BeanFactory available anymore (probably due to serialization) - cannot resolve interceptor names " + Arrays.asList(this.interceptorNames)); &#125; if (this.interceptorNames[this.interceptorNames.length - 1].endsWith("*") &amp;&amp; this.targetName == null &amp;&amp; this.targetSource == EMPTY_TARGET_SOURCE) &#123; throw new AopConfigException("Target required after globals"); &#125; String[] var1 = this.interceptorNames; int var2 = var1.length; //这里是添加Advisor链的调用，是通过interceprotNames属性进行设置的 for(int var3 = 0; var3 &lt; var2; ++var3) &#123; String name = var1[var3]; if (this.logger.isTraceEnabled()) &#123; this.logger.trace("Configuring advisor or advice '" + name + "'"); &#125; if (name.endsWith("*")) &#123; if (!(this.beanFactory instanceof ListableBeanFactory)) &#123; throw new AopConfigException("Can only use global advisors or interceptors with a ListableBeanFactory"); &#125; this.addGlobalAdvisor((ListableBeanFactory)this.beanFactory, name.substring(0, name.length() - "*".length())); &#125; else &#123; Object advice; if (!this.singleton &amp;&amp; !this.beanFactory.isSingleton(name)) &#123; advice = new ProxyFactoryBean.PrototypePlaceholderAdvisor(name); &#125; else &#123; advice = this.beanFactory.getBean(name); &#125; this.addAdvisorOnChainCreation(advice, name); &#125; &#125; &#125; this.advisorChainInitialized = true; &#125; &#125;private synchronized Object getSingletonInstance() &#123; if (this.singletonInstance == null) &#123; this.targetSource = this.freshTargetSource(); if (this.autodetectInterfaces &amp;&amp; this.getProxiedInterfaces().length == 0 &amp;&amp; !this.isProxyTargetClass()) &#123; Class&lt;?&gt; targetClass = this.getTargetClass(); if (targetClass == null) &#123; throw new FactoryBeanNotInitializedException("Cannot determine target class for proxy"); &#125; this.setInterfaces(ClassUtils.getAllInterfacesForClass(targetClass, this.proxyClassLoader)); &#125; super.setFrozen(this.freezeProxy); this.singletonInstance = this.getProxy(this.createAopProxy()); &#125; return this.singletonInstance; &#125; protected final synchronized AopProxy createAopProxy() &#123; if (!this.active) &#123; this.activate(); &#125; return this.getAopProxyFactory().createAopProxy(this); &#125; public AopProxy createAopProxy(AdvisedSupport config) throws AopConfigException &#123; if (!config.isOptimize() &amp;&amp; !config.isProxyTargetClass() &amp;&amp; !this.hasNoUserSuppliedProxyInterfaces(config)) &#123; return new JdkDynamicAopProxy(config); &#125; else &#123; Class&lt;?&gt; targetClass = config.getTargetClass(); if (targetClass == null) &#123; throw new AopConfigException("TargetSource cannot determine target class: Either an interface or a target is required for proxy creation."); &#125; else &#123; //如果有接口使用JDK动态代理，没有接口使用CGLIB return (AopProxy)(!targetClass.isInterface() &amp;&amp; !Proxy.isProxyClass(targetClass) ? new ObjenesisCglibAopProxy(config) : new JdkDynamicAopProxy(config)); &#125; &#125; &#125; Spring Aop拦截器调用实现 我们就以JDK invoke方法讲解 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071@Nullablepublic Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; Object oldProxy = null; boolean setProxyContext = false; TargetSource targetSource = this.advised.targetSource; Object target = null; Boolean var9; try &#123; if (this.equalsDefined || !AopUtils.isEqualsMethod(method)) &#123; //如果目标对象没有Object类的equals、hashCode方法 if (!this.hashCodeDefined &amp;&amp; AopUtils.isHashCodeMethod(method)) &#123; Integer var19 = this.hashCode(); return var19; &#125; if (method.getDeclaringClass() == DecoratingProxy.class) &#123; Class var18 = AopProxyUtils.ultimateTargetClass(this.advised); return var18; &#125; Object retVal; if (!this.advised.opaque &amp;&amp; method.getDeclaringClass().isInterface() &amp;&amp; method.getDeclaringClass().isAssignableFrom(Advised.class)) &#123; //根据代理对象的配置(ProxyConfig)来调用服务 retVal = AopUtils.invokeJoinpointUsingReflection(this.advised, method, args); return retVal; &#125; if (this.advised.exposeProxy) &#123; oldProxy = AopContext.setCurrentProxy(proxy); setProxyContext = true; &#125; target = targetSource.getTarget(); Class&lt;?&gt; targetClass = target != null ? target.getClass() : null; //获得经过过滤这个方法的所有拦截器 List&lt;Object&gt; chain = this.advised.getInterceptorsAndDynamicInterceptionAdvice(method, targetClass); if (chain.isEmpty()) &#123; Object[] argsToUse = AopProxyUtils.adaptArgumentsIfNecessary(method, args); retVal = AopUtils.invokeJoinpointUsingReflection(target, method, argsToUse); &#125; else &#123; //沿着拦截器链执行方法 MethodInvocation invocation = new ReflectiveMethodInvocation(proxy, target, method, args, targetClass, chain); retVal = invocation.proceed(); &#125; Class&lt;?&gt; returnType = method.getReturnType(); if (retVal != null &amp;&amp; retVal == target &amp;&amp; returnType != Object.class &amp;&amp; returnType.isInstance(proxy) &amp;&amp; !RawTargetAccess.class.isAssignableFrom(method.getDeclaringClass())) &#123; retVal = proxy; &#125; else if (retVal == null &amp;&amp; returnType != Void.TYPE &amp;&amp; returnType.isPrimitive()) &#123; throw new AopInvocationException("Null return value from advice does not match primitive return type for: " + method); &#125; Object var13 = retVal; return var13; &#125; var9 = this.equals(args[0]); &#125; finally &#123; if (target != null &amp;&amp; !targetSource.isStatic()) &#123; targetSource.releaseTarget(target); &#125; if (setProxyContext) &#123; AopContext.setCurrentProxy(oldProxy); &#125; &#125; return var9;&#125; AOP 拦截器链的调用 123456789101112131415public Object proceed() throws Throwable &#123; if (this.currentInterceptorIndex ==this.interceptorsAndDynamicMethodMatchers.size() - 1) &#123; return this.invokeJoinpoint(); &#125; else &#123; Object interceptorOrInterceptionAdvice = this.interceptorsAndDynamicMethodMatchers.get(++this.currentInterceptorIndex); if (interceptorOrInterceptionAdvice instanceof InterceptorAndDynamicMethodMatcher) &#123; InterceptorAndDynamicMethodMatcher dm = (InterceptorAndDynamicMethodMatcher)interceptorOrInterceptionAdvice; //如果通知器和调用的方法匹配，那么调用拦截器链的所有方法，否则继续匹配 return dm.methodMatcher.matches(this.method, this.targetClass, this.arguments) ? dm.interceptor.invoke(this) : this.proceed(); &#125; else &#123; return ((MethodInterceptor)interceptorOrInterceptionAdvice).invoke(this); &#125; &#125; &#125; 拦截器链的产生 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697 private synchronized void initializeAdvisorChain() throws AopConfigException, BeansException &#123; if (!this.advisorChainInitialized) &#123; if (!ObjectUtils.isEmpty(this.interceptorNames)) &#123; if (this.beanFactory == null) &#123; throw new IllegalStateException("No BeanFactory available anymore (probably due to serialization) - cannot resolve interceptor names " + Arrays.asList(this.interceptorNames)); &#125; if (this.interceptorNames[this.interceptorNames.length - 1].endsWith("*") &amp;&amp; this.targetName == null &amp;&amp; this.targetSource == EMPTY_TARGET_SOURCE) &#123; throw new AopConfigException("Target required after globals"); &#125; String[] var1 = this.interceptorNames; int var2 = var1.length; //这里是添加Advisor链的调用，是通过interceprotNames属性进行设置的 for(int var3 = 0; var3 &lt; var2; ++var3) &#123; String name = var1[var3]; if (this.logger.isTraceEnabled()) &#123; this.logger.trace("Configuring advisor or advice '" + name + "'"); &#125; if (name.endsWith("*")) &#123; if (!(this.beanFactory instanceof ListableBeanFactory)) &#123; throw new AopConfigException("Can only use global advisors or interceptors with a ListableBeanFactory"); &#125; this.addGlobalAdvisor((ListableBeanFactory)this.beanFactory, name.substring(0, name.length() - "*".length())); &#125; else &#123; Object advice; if (!this.singleton &amp;&amp; !this.beanFactory.isSingleton(name)) &#123; advice = new ProxyFactoryBean.PrototypePlaceholderAdvisor(name); &#125; else &#123; //从IOC容器中获得通知器或者切面，因为在实现中不管是通知器还是切面都会最终 //变成通知器Advisor advice = this.beanFactory.getBean(name); &#125; //添加到通知器中 this.addAdvisorOnChainCreation(advice, name); &#125; &#125; &#125; this.advisorChainInitialized = true; &#125; &#125;//这个完成了从所有的通知器中得到拦截器链public List&lt;Object&gt; getInterceptorsAndDynamicInterceptionAdvice(Advised config, Method method, @Nullable Class&lt;?&gt; targetClass) &#123; List&lt;Object&gt; interceptorList = new ArrayList(config.getAdvisors().length); Class&lt;?&gt; actualClass = targetClass != null ? targetClass : method.getDeclaringClass(); boolean hasIntroductions = hasMatchingIntroductions(config, actualClass); AdvisorAdapterRegistry registry = GlobalAdvisorAdapterRegistry.getInstance(); //从config中得到实现从xml中获得的所有通知器 Advisor[] var8 = config.getAdvisors(); int var9 = var8.length; for(int var10 = 0; var10 &lt; var9; ++var10) &#123; Advisor advisor = var8[var10]; //拦截器链 MethodInterceptor[] interceptors; if (advisor instanceof PointcutAdvisor) &#123; PointcutAdvisor pointcutAdvisor = (PointcutAdvisor)advisor; if (config.isPreFiltered() || pointcutAdvisor.getPointcut().getClassFilter().matches(actualClass)) &#123; //全局的注册工厂获得一个通知器的拦截器(这里是同注册工厂里面的适配器将所有的) //advisor变成特定类型的拦截器(MethodBeforeAdvice、AfterReturningAdvice等等) interceptors = registry.getInterceptors(advisor); //如果编码实现通知器，通知器中会实现切入点，只不过我们不怎么使用硬编码的形式实现 //切入点，所以下面再检查是否方法是否符合切入点 MethodMatcher mm = pointcutAdvisor.getPointcut().getMethodMatcher(); //下面是对所有的拦截器进行过滤，剩下这个方法的拦截器 if (MethodMatchers.matches(mm, method, actualClass, hasIntroductions)) &#123; if (mm.isRuntime()) &#123; MethodInterceptor[] var15 = interceptors; int var16 = interceptors.length; for(int var17 = 0; var17 &lt; var16; ++var17) &#123; MethodInterceptor interceptor = var15[var17]; //将所有方法加入拦截器链 interceptorList.add(new InterceptorAndDynamicMethodMatcher(interceptor, mm)); &#125; &#125; else &#123; interceptorList.addAll(Arrays.asList(interceptors)); &#125; &#125; &#125; &#125; else if (advisor instanceof IntroductionAdvisor) &#123; IntroductionAdvisor ia = (IntroductionAdvisor)advisor; if (config.isPreFiltered() || ia.getClassFilter().matches(actualClass)) &#123; interceptors = registry.getInterceptors(advisor); interceptorList.addAll(Arrays.asList(interceptors)); &#125; &#125; else &#123; Interceptor[] interceptors = registry.getInterceptors(advisor); interceptorList.addAll(Arrays.asList(interceptors)); &#125; &#125; return interceptorList; &#125; 方法增强的实现 12345678910111213141516171819202122232425//这个方法的意图是借助DefaultAdvisorAdapterRegistry的适配器将所有的Advisor变成特定的interceptor//方便在调用拦截器链时的调用public MethodInterceptor[] getInterceptors(Advisor advisor) throws UnknownAdviceTypeException &#123; List&lt;MethodInterceptor&gt; interceptors = new ArrayList(3); Advice advice = advisor.getAdvice(); if (advice instanceof MethodInterceptor) &#123; interceptors.add((MethodInterceptor)advice); &#125; Iterator var4 = this.adapters.iterator(); //根据所有的适配器来适配得到拦截器 while(var4.hasNext()) &#123; AdvisorAdapter adapter = (AdvisorAdapter)var4.next(); if (adapter.supportsAdvice(advice)) &#123; interceptors.add(adapter.getInterceptor(advisor)); &#125; &#125; if (interceptors.isEmpty()) &#123; throw new UnknownAdviceTypeException(advisor.getAdvice()); &#125; else &#123; return (MethodInterceptor[])interceptors.toArray(new MethodInterceptor[0]); &#125; &#125; 123456789101112131415//我们就分析这个adapter，supportsAdvice用来适配判断能够通过这个适配器来得到特定的拦截器；//getInterceptor就是用来得到特定的拦截器class MethodBeforeAdviceAdapter implements AdvisorAdapter, Serializable &#123; MethodBeforeAdviceAdapter() &#123; &#125; public boolean supportsAdvice(Advice advice) &#123; return advice instanceof MethodBeforeAdvice; &#125; public MethodInterceptor getInterceptor(Advisor advisor) &#123; MethodBeforeAdvice advice = (MethodBeforeAdvice)advisor.getAdvice(); return new MethodBeforeAdviceInterceptor(advice); &#125;&#125; 1234567891011121314//这个就是一种拦截器，通过invoke方法，我们也可以知道，其实就是在调用方法之前先执行了增强的内容public class MethodBeforeAdviceInterceptor implements MethodInterceptor, Serializable &#123; private MethodBeforeAdvice advice; public MethodBeforeAdviceInterceptor(MethodBeforeAdvice advice) &#123; Assert.notNull(advice, "Advice must not be null"); this.advice = advice; &#125; public Object invoke(MethodInvocation mi) throws Throwable &#123; this.advice.before(mi.getMethod(), mi.getArguments(), mi.getThis()); return mi.proceed(); &#125;&#125; 大概讲述一个Spring AOP实现的过程 首先我们以getObject()为突破口，这个方法的目的是为了得到一个AopProxy，我认为这个AopProxy会传给动态代理参数来增强函数，然后用这个类的接口来接受这个代理类；getObject方法在创建代理类的之前通过initializeAdvisorChain方法将所有的通知器注册到ProxyFactoryBean的advisors中 然后就是触发增强动能的AopProxy的invoke方法，这个方法会从全局的advisors中匹配得到所有有关调用方法的拦截器，invocation.proceed()通过这个方法会触发拦截器的调用，在拦截器调用过程中会把所有拦截器调用完，也会区别它们的先后关系 关于Spring MVC 源码详解关于web.xmlweb.xml其实是对ServletContext的参数设置也就是Tomcat的环境设置，我觉得通俗点讲就是所有Servlet的上下文环境的设置，其实它也是Tomcat和Spring项目的耦合点，也就是说Tomcat启动后会去加载这个文件里面的内容；然后也是基于此内容Spring 会去创建一个WebApplicationContext也就是IOC容器，在这里具体的是XmlWebApplicationContext，下面会具体讲怎么创建的，也基于此在web.xml中有下面的一段配置： 1234&lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;&lt;/param-value&gt;&lt;/context-param&gt; XmlWebApplicationContext 会将具体路径的配置加载到IOC容器中 关于ContextLoaderListener这个是具体Tomcat和Spring的耦合点，通过这个监听器Tomcat在启动完成后传递ServletContext给Spring然后完成一系列Spring项目的启动 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980public class ContextLoaderListener extends ContextLoader implements ServletContextListener &#123; public ContextLoaderListener() &#123; &#125; public ContextLoaderListener(WebApplicationContext context) &#123; super(context); &#125; //Tomat会在启动后通过监听器调用这个方法 public void contextInitialized(ServletContextEvent event) &#123; this.initWebApplicationContext(event.getServletContext()); &#125; public void contextDestroyed(ServletContextEvent event) &#123; this.closeWebApplicationContext(event.getServletContext()); ContextCleanupListener.cleanupAttributes(event.getServletContext()); &#125;&#125; public WebApplicationContext initWebApplicationContext(ServletContext servletContext) &#123; if (servletContext.getAttribute(WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE) != null) &#123; throw new IllegalStateException("Cannot initialize context because there is already a root application context present - check whether you have multiple ContextLoader* definitions in your web.xml!"); &#125; else &#123; Log logger = LogFactory.getLog(ContextLoader.class); servletContext.log("Initializing Spring root WebApplicationContext"); if (logger.isInfoEnabled()) &#123; logger.info("Root WebApplicationContext: initialization started"); &#125; long startTime = System.currentTimeMillis(); try &#123; if (this.context == null) &#123; //ContextLoader会去读ContextLoader.properties中的Context的类型来创建具体是什么 //Context this.context = this.createWebApplicationContext(servletContext); &#125; if (this.context instanceof ConfigurableWebApplicationContext) &#123; ConfigurableWebApplicationContext cwac = (ConfigurableWebApplicationContext)this.context; if (!cwac.isActive()) &#123; if (cwac.getParent() == null) &#123; //这里是NULL，也就是说着个容器已经是顶级容器 ApplicationContext parent = this.loadParentContext(servletContext); cwac.setParent(parent); &#125; //设置和初始化该ROOT IOC 容器 this.configureAndRefreshWebApplicationContext(cwac, servletContext); &#125; &#125; servletContext.setAttribute(WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE, this.context); ClassLoader ccl = Thread.currentThread().getContextClassLoader(); if (ccl == ContextLoader.class.getClassLoader()) &#123; currentContext = this.context; &#125; else if (ccl != null) &#123; currentContextPerThread.put(ccl, this.context); &#125; if (logger.isDebugEnabled()) &#123; logger.debug("Published root WebApplicationContext as ServletContext attribute with name [" + WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE + "]"); &#125; if (logger.isInfoEnabled()) &#123; long elapsedTime = System.currentTimeMillis() - startTime; logger.info("Root WebApplicationContext: initialization completed in " + elapsedTime + " ms"); &#125; return this.context; &#125; catch (RuntimeException var8) &#123; logger.error("Context initialization failed", var8); servletContext.setAttribute(WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE, var8); throw var8; &#125; catch (Error var9) &#123; logger.error("Context initialization failed", var9); servletContext.setAttribute(WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE, var9); throw var9; &#125; &#125; &#125; 12345678910111213141516171819202122232425262728protected void configureAndRefreshWebApplicationContext(ConfigurableWebApplicationContext wac, ServletContext sc) &#123; String configLocationParam; if (ObjectUtils.identityToString(wac).equals(wac.getId())) &#123; configLocationParam = sc.getInitParameter("contextId"); if (configLocationParam != null) &#123; wac.setId(configLocationParam); &#125; else &#123; wac.setId(ConfigurableWebApplicationContext.APPLICATION_CONTEXT_ID_PREFIX + ObjectUtils.getDisplayString(sc.getContextPath())); &#125; &#125; wac.setServletContext(sc); //通过ServletContext读取web.xml文件中设置的contextConfigLocation并把它赋值给wac //方便在后IOC容器的加载 configLocationParam = sc.getInitParameter("contextConfigLocation"); if (configLocationParam != null) &#123; wac.setConfigLocation(configLocationParam); &#125; ConfigurableEnvironment env = wac.getEnvironment(); if (env instanceof ConfigurableWebEnvironment) &#123; ((ConfigurableWebEnvironment)env).initPropertySources(sc, (ServletConfig)null); &#125; this.customizeContext(sc, wac); //IOC 容器启动啦 wac.refresh(); &#125; 关于DispatchServletDispatchServlet因为其自身本来就是一个Servlet所以它的初始化的完成时依赖于Servlet的init方法 下面关于它的继承关系图 1234567891011121314151617181920212223242526272829public final void init() throws ServletException &#123; if (this.logger.isDebugEnabled()) &#123; this.logger.debug("Initializing servlet '" + this.getServletName() + "'"); &#125; PropertyValues pvs = new HttpServletBean.ServletConfigPropertyValues(this.getServletConfig(), this.requiredProperties); if (!pvs.isEmpty()) &#123; try &#123; BeanWrapper bw = PropertyAccessorFactory.forBeanPropertyAccess(this); ResourceLoader resourceLoader = new ServletContextResourceLoader(this.getServletContext()); bw.registerCustomEditor(Resource.class, new ResourceEditor(resourceLoader, this.getEnvironment())); this.initBeanWrapper(bw); bw.setPropertyValues(pvs, true); &#125; catch (BeansException var4) &#123; if (this.logger.isErrorEnabled()) &#123; this.logger.error("Failed to set bean properties on servlet '" + this.getServletName() + "'", var4); &#125; throw var4; &#125; &#125; //初始化FrameworkServlet中的属性，其中就初始化了IOC容器 this.initServletBean(); if (this.logger.isDebugEnabled()) &#123; this.logger.debug("Servlet '" + this.getServletName() + "' configured successfully"); &#125; &#125; 12345678910111213141516//在DispatchServlet初始化IOC容器过程中有完成了对基础设施的初始化 protected void onRefresh(ApplicationContext context) &#123; this.initStrategies(context); &#125; protected void initStrategies(ApplicationContext context) &#123; this.initMultipartResolver(context); this.initLocaleResolver(context); this.initThemeResolver(context); this.initHandlerMappings(context); this.initHandlerAdapters(context); this.initHandlerExceptionResolvers(context); this.initRequestToViewNameTranslator(context); this.initViewResolvers(context); this.initFlashMapManager(context); &#125; 分析Spring Boot启动源码123456789101112131415161718192021222324252627282930313233343536373839404142434445public ConfigurableApplicationContext run(String... args) &#123; //用来监听只能运行一个Spring boot StopWatch stopWatch = new StopWatch(); stopWatch.start(); ConfigurableApplicationContext context = null; Collection&lt;SpringBootExceptionReporter&gt; exceptionReporters = new ArrayList(); this.configureHeadlessProperty(); //这个是Spring Boot专有的监听器 SpringApplicationRunListeners listeners = this.getRunListeners(args); listeners.starting(); Collection exceptionReporters; try &#123; ApplicationArguments applicationArguments = new DefaultApplicationArguments(args); ConfigurableEnvironment environment = this.prepareEnvironment(listeners, applicationArguments); this.configureIgnoreBeanInfo(environment); Banner printedBanner = this.printBanner(environment); //初始化IOC容器实例 context = this.createApplicationContext(); exceptionReporters = this.getSpringFactoriesInstances(SpringBootExceptionReporter.class, new Class[]&#123;ConfigurableApplicationContext.class&#125;, context); //这里面完成了BeanDefinition的定位、载入、注册 this.prepareContext(context, environment, listeners, applicationArguments, printedBanner); //进行IOC容器的初始化 this.refreshContext(context); this.afterRefresh(context, applicationArguments); stopWatch.stop(); if (this.logStartupInfo) &#123; (new StartupInfoLogger(this.mainApplicationClass)).logStarted(this.getApplicationLog(), stopWatch); &#125; listeners.started(context); this.callRunners(context, applicationArguments); &#125; catch (Throwable var10) &#123; this.handleRunFailure(context, var10, exceptionReporters, listeners); throw new IllegalStateException(var10); &#125; try &#123; listeners.running(context); return context; &#125; catch (Throwable var9) &#123; this.handleRunFailure(context, var9, exceptionReporters, (SpringApplicationRunListeners)null); throw new IllegalStateException(var9); &#125;&#125; 1234567891011//这个方法比较有趣，在初始化完IOC容器后，注册了一个这个应用的shutdownhookprivate void refreshContext(ConfigurableApplicationContext context) &#123; this.refresh(context); if (this.registerShutdownHook) &#123; try &#123; context.registerShutdownHook(); &#125; catch (AccessControlException var3) &#123; ; &#125; &#125; &#125; Spring 内置Tomcat启动源码解读123456789protected void onRefresh() &#123; super.onRefresh(); try &#123; this.createWebServer(); &#125; catch (Throwable var2) &#123; throw new ApplicationContextException("Unable to start web server", var2); &#125;&#125; 首先在初始化IOC容器的时候，通过onRefresh方法，调用creatWebServer创建指定的Web容器并启动 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081private void createWebServer() &#123; WebServer webServer = this.webServer; ServletContext servletContext = this.getServletContext(); if (webServer == null &amp;&amp; servletContext == null) &#123; ServletWebServerFactory factory = this.getWebServerFactory(); this.webServer = factory.getWebServer(new ServletContextInitializer[]&#123;this.getSelfInitializer()&#125;); &#125; else if (servletContext != null) &#123; try &#123; this.getSelfInitializer().onStartup(servletContext); &#125; catch (ServletException var4) &#123; throw new ApplicationContextException("Cannot initialize servlet context", var4); &#125; &#125; this.initPropertySources(); &#125; public WebServer getWebServer(ServletContextInitializer... initializers) &#123; Tomcat tomcat = new Tomcat(); File baseDir = this.baseDirectory != null ? this.baseDirectory : this.createTempDir("tomcat"); tomcat.setBaseDir(baseDir.getAbsolutePath()); Connector connector = new Connector(this.protocol); tomcat.getService().addConnector(connector); this.customizeConnector(connector); tomcat.setConnector(connector); tomcat.getHost().setAutoDeploy(false); this.configureEngine(tomcat.getEngine()); Iterator var5 = this.additionalTomcatConnectors.iterator(); while(var5.hasNext()) &#123; Connector additionalConnector = (Connector)var5.next(); tomcat.getService().addConnector(additionalConnector); &#125; this.prepareContext(tomcat.getHost(), initializers); return this.getTomcatWebServer(tomcat); &#125; protected TomcatWebServer getTomcatWebServer(Tomcat tomcat) &#123; return new TomcatWebServer(tomcat, this.getPort() &gt;= 0); &#125; public TomcatWebServer(Tomcat tomcat, boolean autoStart) &#123; this.monitor = new Object(); this.serviceConnectors = new HashMap(); Assert.notNull(tomcat, "Tomcat Server must not be null"); this.tomcat = tomcat; this.autoStart = autoStart; this.initialize(); &#125; private void initialize() throws WebServerException &#123; logger.info("Tomcat initialized with port(s): " + this.getPortsDescription(false)); Object var1 = this.monitor; synchronized(this.monitor) &#123; try &#123; this.addInstanceIdToEngineName(); Context context = this.findContext(); context.addLifecycleListener((event) -&gt; &#123; if (context.equals(event.getSource()) &amp;&amp; "start".equals(event.getType())) &#123; this.removeServiceConnectors(); &#125; &#125;); this.tomcat.start(); this.rethrowDeferredStartupExceptions(); try &#123; ContextBindings.bindClassLoader(context, context.getNamingToken(), this.getClass().getClassLoader()); &#125; catch (NamingException var5) &#123; ; &#125; this.startDaemonAwaitThread(); &#125; catch (Exception var6) &#123; this.stopSilently(); throw new WebServerException("Unable to start embedded Tomcat", var6); &#125; &#125; &#125; 通过上面一步一步我们很容易发现Tomcat是怎么启动的 关于Tomcat源码 omcat的架构图 Container的组成 一些名词 Server：服务器，一个Tomcat只能有一个Server，可以看做就是Tomcat，用于控制Tomcat的生命周期 Service：服务，有了Service就可以对外提供服务了，一个Server可以拥有多个Service Connector：连接器，表示接受请求的端点，并返回回复；Servlet容器处理请求，是需要Connector进行调度和控制的，Connector是Tomcat处理请求的主干，因此Connector的配置和使用对Tomcat的性能有着重要的影响 Engine：引擎，Engine下可以配置多个虚拟主机Virtual Host，每个虚拟主机都有一个域名，当Engine获得一个请求时，它把该请求匹配到某个Host上，然后把该请求交给该Host来处理，Engine有一个默认虚拟主机，当请求无法匹配到任何一个Host上的时候，将交给该默认Host来处理 Host：虚拟主机，每个虚拟主机和某个网络域名Domain Name相匹配 ，每个虚拟主机下都可以部署(deploy)一个或者多个Web App ,每个Web App对应于一个Context，有一个Context path，当Host获得一个请求时，将把该请求匹配到某个Context上，然后把该请求交给该Context来处理，匹配的方法是“最长匹配”，所以一个path==””的Context将成为该Host的默认Context，所有无法和其它Context的路径名匹配的请求都将最终和该默认Context匹配 Context ：一个Context对应于一个Web Application，一个Web Application由一个或者多个Servlet组成，Context在创建的时候将根据配置文件CATALINA_HOME/conf/web.xml和WEBAPP_HOME/WEB-INF/web.xml载入Servlet类，当Context获得请求时，将在自己的映射表(mapping table)中寻找相匹配的Servlet类，如果找到，则执行该类，获得请求的回应，并返回。 一个Host可以有多个Context，就相当于多个Web Application；其中TomcatEmbeddedContext就相当于这个 Wrapper：最底层的容器，是对 Servlet 的封装，负责 Servlet 实例的创 建、执行和销毁 需要注意的是 Engine、Host、Context、Wrapper都是实现Container接口的类，所以里面的结构就像第三张图一样一个容器嵌套一个容器 Spring Boot源码之内置Servlet容器创建WebServer并且启动 12345678910111213141516171819202122232425262728 protected void onRefresh() &#123; super.onRefresh(); try &#123; this.createWebServer(); &#125; catch (Throwable var2) &#123; throw new ApplicationContextException("Unable to start web server", var2); &#125; &#125;private void createWebServer() &#123; WebServer webServer = this.webServer; ServletContext servletContext = this.getServletContext(); if (webServer == null &amp;&amp; servletContext == null) &#123; ServletWebServerFactory factory = this.getWebServerFactory(); //参数是一些ServletContextInitializer，Servlet容器启动的时候会遍历这些ServletContextInitializer，并调用onStartup方法 this.webServer = factory.getWebServer(new ServletContextInitializer[]&#123;this.getSelfInitializer()&#125;); &#125; else if (servletContext != null) &#123; try &#123; this.getSelfInitializer().onStartup(servletContext); &#125; catch (ServletException var4) &#123; throw new ApplicationContextException("Cannot initialize servlet context", var4); &#125; &#125; this.initPropertySources(); &#125; ServletContextInitializer的其中一个具体内容，目的是添加Servlet、Filter、Listener，包括那些自定义的，它们最终都会通过适配器变为ServletRegistrationBean 1234567891011121314151617181920private void selfInitialize(ServletContext servletContext) throws ServletException &#123; this.prepareWebApplicationContext(servletContext); //得到 IOC容器 ConfigurableListableBeanFactory beanFactory = this.getBeanFactory(); ServletWebServerApplicationContext.ExistingWebApplicationScopes existingScopes = new ServletWebServerApplicationContext.ExistingWebApplicationScopes(beanFactory); WebApplicationContextUtils.registerWebApplicationScopes(beanFactory, this.getServletContext()); existingScopes.restore(); //将ServletContext注册到IOC容器 WebApplicationContextUtils.registerEnvironmentBeans(beanFactory, this.getServletContext()); //得到ServletContextInitializerBean遍历器 Iterator var4 = this.getServletContextInitializerBeans().iterator(); while(var4.hasNext()) &#123; //遍历执行所有ServletContextInitializer ServletContextInitializer beans = (ServletContextInitializer)var4.next(); beans.onStartup(servletContext); &#125; &#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133//IOC容器初始化过程protected void finishRefresh() &#123; super.finishRefresh(); WebServer webServer = this.startWebServer(); if (webServer != null) &#123; this.publishEvent(new ServletWebServerInitializedEvent(webServer, this)); &#125; &#125;//这里的启动WebServer其实就是注册所有的 private WebServer startWebServer() &#123; WebServer webServer = this.webServer; if (webServer != null) &#123; webServer.start(); &#125; return webServer; &#125;//这里以Tomcat启动为例 public void start() throws WebServerException &#123; Object var1 = this.monitor; synchronized(this.monitor) &#123; if (!this.started) &#123; boolean var10 = false; try &#123; var10 = true; this.addPreviouslyRemovedConnectors(); Connector var2 = this.tomcat.getConnector(); if (var2 != null &amp;&amp; this.autoStart) &#123; this.performDeferredLoadOnStartup(); &#125; this.checkThatConnectorsHaveStarted(); this.started = true; logger.info("Tomcat started on port(s): " + this.getPortsDescription(true) + " with context path '" + this.getContextPath() + "'"); var10 = false; &#125; catch (ConnectorStartFailedException var11) &#123; this.stopSilently(); throw var11; &#125; catch (Exception var12) &#123; throw new WebServerException("Unable to start embedded Tomcat server", var12); &#125; finally &#123; if (var10) &#123; Context context = this.findContext(); ContextBindings.unbindClassLoader(context, context.getNamingToken(), this.getClass().getClassLoader()); &#125; &#125; Context context = this.findContext(); ContextBindings.unbindClassLoader(context, context.getNamingToken(), this.getClass().getClassLoader()); &#125; &#125; &#125; private void performDeferredLoadOnStartup() &#123; try &#123; //得到该虚拟主机下的所有Context也就是WebApplication上下文 Container[] var1 = this.tomcat.getHost().findChildren(); int var2 = var1.length; for(int var3 = 0; var3 &lt; var2; ++var3) &#123; Container child = var1[var3]; if (child instanceof TomcatEmbeddedContext) &#123; ((TomcatEmbeddedContext)child).deferredLoadOnStartup(); &#125; &#125; &#125; catch (Exception var5) &#123; logger.error("Cannot start connector: ", var5); throw new WebServerException("Unable to start embedded Tomcat connectors", var5); &#125; &#125; public void deferredLoadOnStartup() &#123; ClassLoader classLoader = this.getLoader().getClassLoader(); ClassLoader existingLoader = null; if (classLoader != null) &#123; existingLoader = ClassUtils.overrideThreadContextClassLoader(classLoader); &#125; if (this.overrideLoadOnStart) &#123; //加载该上下文下的所有Servlet super.loadOnStartup(this.findChildren()); &#125; if (existingLoader != null) &#123; ClassUtils.overrideThreadContextClassLoader(existingLoader); &#125; &#125; public boolean loadOnStartup(Container[] children) &#123; TreeMap&lt;Integer, ArrayList&lt;Wrapper&gt;&gt; map = new TreeMap(); for(int i = 0; i &lt; children.length; ++i) &#123; Wrapper wrapper = (Wrapper)children[i]; int loadOnStartup = wrapper.getLoadOnStartup(); if (loadOnStartup &gt;= 0) &#123; Integer key = loadOnStartup; ArrayList&lt;Wrapper&gt; list = (ArrayList)map.get(key); if (list == null) &#123; list = new ArrayList(); map.put(key, list); &#125; list.add(wrapper); &#125; &#125; Iterator i$ = map.values().iterator(); while(i$.hasNext()) &#123; ArrayList&lt;Wrapper&gt; list = (ArrayList)i$.next(); Iterator i$ = list.iterator(); while(i$.hasNext()) &#123; Wrapper wrapper = (Wrapper)i$.next(); try &#123; wrapper.load(); &#125; catch (ServletException var8) &#123; this.getLogger().error(sm.getString("standardContext.loadOnStartup.loadException", new Object[]&#123;this.getName(), wrapper.getName()&#125;), StandardWrapper.getRootCause(var8)); if (this.getComputedFailCtxIfServletStartFails()) &#123; return false; &#125; &#125; &#125; &#125; return true; &#125; 关于Spring AplicationContextEvent1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253//AbstractApplicationContext下的protected void publishEvent(Object event, @Nullable ResolvableType eventType) &#123; Assert.notNull(event, "Event must not be null"); if (this.logger.isTraceEnabled()) &#123; this.logger.trace("Publishing event in " + this.getDisplayName() + ": " + event); &#125; Object applicationEvent; if (event instanceof ApplicationEvent) &#123; applicationEvent = (ApplicationEvent)event; &#125; else &#123; applicationEvent = new PayloadApplicationEvent(this, event); if (eventType == null) &#123; eventType = ((PayloadApplicationEvent)applicationEvent).getResolvableType(); &#125; &#125; //如果有事件没有处理完，就加入earlyApplicationEvents里面等待被处理 if (this.earlyApplicationEvents != null) &#123; this.earlyApplicationEvents.add(applicationEvent); &#125; else &#123; //真正开始处理事件 this.getApplicationEventMulticaster().multicastEvent((ApplicationEvent)applicationEvent, eventType); &#125; if (this.parent != null) &#123; if (this.parent instanceof AbstractApplicationContext) &#123; ((AbstractApplicationContext)this.parent).publishEvent(event, eventType); &#125; else &#123; this.parent.publishEvent(event); &#125; &#125; &#125;//SimpleApplicationEventMulticaster public void multicastEvent(ApplicationEvent event, @Nullable ResolvableType eventType) &#123; ResolvableType type = eventType != null ? eventType : this.resolveDefaultEventType(event); //这里取得了所有注册的相关类型的事件，至于怎么得到的，我这里简单的说一下；AbstractApplicationEventMulticaster.ListenerRetriever 这个类就是专门用于存储所有的监听器的，而且在AbstractApplicationEventMulticaster这个类下会缓存最近取的相关key的所有监听器，所以就可以从这个类里面得到监听器了 Iterator var4 = this.getApplicationListeners(event, type).iterator(); while(var4.hasNext()) &#123; ApplicationListener&lt;?&gt; listener = (ApplicationListener)var4.next(); //如果有线程池，使用线程池完成所有的监听器里面的内容 Executor executor = this.getTaskExecutor(); if (executor != null) &#123; executor.execute(() -&gt; &#123; this.invokeListener(listener, event); &#125;); &#125; else &#123; this.invokeListener(listener, event); &#125; &#125; &#125; 相关面试题http://www.importnew.com/15851.html#ioc_di 其中值得学习的类 ResolveableType 这个类是为了解决获取泛型实际类型 这里具体使用方法 相关链接 Spring Boot源码分析 https://fangjian0423.github.io/2017/05/22/springboot-embedded-servlet-container/ Tomcat https://juejin.im/post/5af27c34f265da0b78687e14 http://www.importnew.com/27309.html https://juejin.im/post/58eb5fdda0bb9f00692a78fc]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2018%2F07%2F21%2Fjava%2F%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%2FThreadPoolExecutor%E6%BA%90%E7%A0%81%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[ThreadPoolExecutor源码详解一些属性 clt 1private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0)); 这个属性前三位存储的是线程池的状态，后面的29位存储的是线程池的工作线程数 线程池的状态： RUNNING(运行状态)：能接受新提交的任务，并且能处理阻塞队列中的任务 SHUTDOWN(关闭状态):不能接受新提交的任务，但却可以继续处理阻塞队列中已保存的任务 。 在线程池处于 RUNNING 状态时, 调用 shutdown()方法会使线程池进入到该状态. STOP:不能接受新提交的任务, 也不能处理阻塞队列中已保存的任务, 并且会中断正在处理中的任务. 在线程池处于 RUNNING 或 SHUTDOWN 状态时, 调用 shutdownNow() 方法会使线程池进入到该状态. TIDYING (清理状态): 所有的任务都已终止了, workerCount (有效线程数) 为0, 线程池进入该状态后会调用 当线程池处于 SHUTDOWN 状态时, 如果此后线程池内没有线程了并且阻塞队列内也没有待执行的任务了 (即: 二者都为空), 线程池就会进入到该状态. 当线程池处于 STOP 状态时, 如果此后线程池内没有线程了, 线程池就会进入到该状态. TERMINATED : terminated() 方法执行完后就进入该状态. corePoolSize 核心线程数，这个属性的意义是，当线程池里面的workerCount&lt;corePoolSize那么提交一个新的任务，都会新建一个线程去处理，然后这些核心线程处理完任务后及时处于空闲状态，也不会对它们消除。 maximumPoolSize 最大线程数，这个属性的意义是线程池最大拥有的线程数，当一个新的任务到达时先是考虑把它添加到阻塞队列里面，如果添加失败，也就是说阻塞队列满了，那么就会创建一个线程去执行任务。但是创建的线程数量加上核心线程的数量不能超过这个值，超过了就应该进行拒绝策略进行拒绝 keepAliveTime 非核心线程的空闲保活时间，当创建了一个非核心线程执行任务后，因为没有任务执行一直处理空闲状态，当这个状态的时间超过该属性的值，就会对该线程销毁 workQueue 是一个用于保存等待执行任务的阻塞队列，提交任务，对于任务的处理有三种方式，这三种方式其实上面的处理都提到了，这里我总结一下,就是excute()方法的逻辑： 如果线程池中的线程数小于核心线程数，那么就会创建新的线程执行任务 如果线程池中的数量大于核心线程数，那么就将任务添加到阻塞队列 如果队列满了或者其他情况，导致添加失败，就会创建新的线程用于执行任务 三种处理策略： 直接切换(使用SynchronizeQueue):当提交一个任务到包含这种 SynchronousQueue 队列的线程池以后, 线程池会去检测是否有可用的空闲线程来执行该任务, 如果没有就直接新建一个线程来执行该任务而不是将该任务先暂存在队列中. “直接切换”的意思就是, 处理方式由”将任务暂时存入队列”直接切换为”新建一个线程来处理该任务”. 这种策略适合用来处理多个有相互依赖关系的任务, 因为该策略可以避免这些任务因一个没有及时处理而导致依赖于该任务的其他任务也不能及时处理而造成的锁定效果. 因为这种策略的目的是要让几乎每一个新提交的任务都能得到立即处理, 所以这种策略通常要求最大线程数 maximumPoolSizes 是无界的(即: Integer.MAX_VALUE). 静态工厂方法 Executors.newCachedThreadPool() 使用了这个队列。 使用无界队列：使用无界队列将使得线程池中能够创建的最大线程数就等于核心线程数 corePoolSize, 这样线程池的 maximumPoolSize 的数值起不到任何作用. 当要处理的多个任务之间没有任何相互依赖关系时, 就适合使用这种队列策略来处理这些任务. 静态工厂方法 Executors.newFixedThreadPool() 使用了这个队列。 使用有界队列：需要合理的分配最大线程数和队列容量 threadFactory 线程构造工厂 handler 拒绝策略，拒绝的条件： 当线程池处于 SHUTDOWN (关闭) 状态时 (不论线程池和阻塞队列是否都已满) 当线程池中的所有线程都处于运行状态并且线程池中的阻塞队列已满时 具体的拒绝策略 AbortPolicy: 这是一种直接抛异常的处理方式, 抛出 RejectedExecutionException 异常. CallerRunsPolicy: 将新提交的任务放在 ThreadPoolExecutor.execute()方法所在的那个线程中执行. DiscardPolicy: 直接不执行新提交的任务. DiscardOldestPolicy: 当线程池未关闭时, 会将阻塞队列中处于队首 (head) 的那个任务从队列中移除, 然后再将这个新提交的任务加入到该阻塞队列的队尾 (tail) 等待执行. 线程调度 首先我们按照逻辑，把其中调度的重要的源码贴出来 execute 12345678910111213141516171819public void execute(Runnable command) &#123; if (command == null) throw new NullPointerException(); int c = ctl.get(); if (workerCountOf(c) &lt; corePoolSize) &#123; if (addWorker(command, true)) return; c = ctl.get(); &#125; if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; int recheck = ctl.get(); if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); else if (workerCountOf(recheck) == 0) addWorker(null, false); &#125; else if (!addWorker(command, false)) reject(command); &#125; 这个我在上面已经讲了，就是提交任务后对任务处理的三种情况 addWorker 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566private boolean addWorker(Runnable firstTask, boolean core) &#123; retry: for (;;) &#123; int c = ctl.get(); int rs = runStateOf(c); // Check if queue empty only if necessary. if (rs &gt;= SHUTDOWN &amp;&amp; ! (rs == SHUTDOWN &amp;&amp; firstTask == null &amp;&amp; ! workQueue.isEmpty())) return false; for (;;) &#123; int wc = workerCountOf(c); if (wc &gt;= CAPACITY || wc &gt;= (core ? corePoolSize : maximumPoolSize)) return false; if (compareAndIncrementWorkerCount(c)) break retry; c = ctl.get(); // Re-read ctl if (runStateOf(c) != rs) continue retry; // else CAS failed due to workerCount change; retry inner loop &#125; &#125; boolean workerStarted = false; boolean workerAdded = false; Worker w = null; try &#123; w = new Worker(firstTask); final Thread t = w.thread; if (t != null) &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; // Recheck while holding lock. // Back out on ThreadFactory failure or if // shut down before lock acquired. int rs = runStateOf(ctl.get()); if (rs &lt; SHUTDOWN || (rs == SHUTDOWN &amp;&amp; firstTask == null)) &#123; if (t.isAlive()) // precheck that t is startable throw new IllegalThreadStateException(); workers.add(w); int s = workers.size(); if (s &gt; largestPoolSize) largestPoolSize = s; workerAdded = true; &#125; &#125; finally &#123; mainLock.unlock(); &#125; if (workerAdded) &#123; t.start(); workerStarted = true; &#125; &#125; &#125; finally &#123; if (! workerStarted) addWorkerFailed(w); &#125; return workerStarted; &#125; 这个方法是根据线程池的状态和限制判断是否可以添加新线程，如果可以，改变workerCount并且以参数fisrtTask为任务，进行运行； Worker的run方法内容 12345678910111213141516171819202122232425262728293031323334353637383940414243final void runWorker(Worker w) &#123; Thread wt = Thread.currentThread(); Runnable task = w.firstTask; w.firstTask = null; w.unlock(); // allow interrupts boolean completedAbruptly = true; try &#123; while (task != null || (task = getTask()) != null) &#123; w.lock(); // If pool is stopping, ensure thread is interrupted; // if not, ensure thread is not interrupted. This // requires a recheck in second case to deal with // shutdownNow race while clearing interrupt if ((runStateAtLeast(ctl.get(), STOP) || (Thread.interrupted() &amp;&amp; runStateAtLeast(ctl.get(), STOP))) &amp;&amp; !wt.isInterrupted()) wt.interrupt(); try &#123; beforeExecute(wt, task); Throwable thrown = null; try &#123; task.run(); &#125; catch (RuntimeException x) &#123; thrown = x; throw x; &#125; catch (Error x) &#123; thrown = x; throw x; &#125; catch (Throwable x) &#123; thrown = x; throw new Error(x); &#125; finally &#123; afterExecute(task, thrown); &#125; &#125; finally &#123; task = null; w.completedTasks++; w.unlock(); &#125; &#125; completedAbruptly = false; &#125; finally &#123; processWorkerExit(w, completedAbruptly); &#125;&#125; 主worker循环执行这个内容，不断的从队列中获取并执行它们 讲解一下Executors工厂方法构建出来的线程池 newFixedThreadPool 123return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()); 根据名称我们知道目的是想构建一个拥有固定线程数的线程池，源码得出以下特点： 核心线程数和最大线程线程数相同 阻塞队列为无界队列 根据以上特点我们知道核心线程数和最大线程数相同那么这个线程池只会创建nThreads的线程，然后根据第第二个特点我们知道这个线程池也不会拒绝任务，所有的任务都会加入无界队列 newCachedThreadPool 123return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;()); 根据方法名目的是想创建一个根据需求创建线程的线程池，源码得出以下特点： 没有核心线程 最大线程数无穷大 阻塞队列为SynchronousQueue 根据这几个特点我们知道这个线程池会为所有新来的任务创建新的线程，而且线程数不受限制 newSingleThreadPool 1234return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;())); 根据方法名目的是想创建一个只有一个线程的线程池，源码得出以下特点： 最大线程数和核心线程数都为1 阻塞队列为LinkedBlockingQueue 这个线程池只有用一个线程来完成所有任务，所有任务都添加到阻塞队列里面]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2018%2F07%2F18%2Freading%2F%E5%85%B3%E4%BA%8Ejava8%20%E5%AE%9E%E6%88%98%2F</url>
    <content type="text"><![CDATA[关于java8 实战并行数据处理与性能 在使用前必须确保，需要并行化的数据没有数据相关性，也就是说，多个并行流之间不存在对共享数据进行操作 留意装箱和拆箱，这个比较消耗性能 与流中元素顺序相关的操作比顺序无关的操作性能差 设N是要处理的元素的总数，Q是一个元素通过 流水线的大致处理成本，则N*Q就是这个对成本的一个粗略的定性估计。Q值较高就意味 着使用并行流时性能好的可能性比较大。 少量的数据不用并行流 要考虑流背后的数据结构是否易于分解 ；根据ArrayList和LinkedList的拆分器我们就可以看得出来，ArrayList的拆分直接把自己拥有的元素数组赋值给拆分器的数组元素，然后对这个数组元素进行拆分；但是LInkedList是把自己的引用传给拆分器的collection属性，拆分的时候是通过遍历添加进新建的数组，然后又传给新建的数组拆分器 关于默认方法 怎么使用默认方法： 由于API 版本的迭代，我们发现实现一个接口缺少了某些必要的方法；但是如果直接向接口中添加方法就会发现没有实现这个方法而发生编译错误；但是使用默认方法，我们就可以避免这个问题，接口提供了一个默认实现，用户可以覆盖这个方法而有自己的实现。 实现一个接口，但是并不是所有实现的类都需要其中的所有方法，以前我们的解决方式是实现一个空方法，有了默认方法，我们就可以在接口中以以下方式实现这个方法 123default void method()&#123; throw new UnsupportedOperationException();&#125; 行为的多继承 解决多实现冲突的规则： 类或父类中声明的方法优先级高于任何声明为默认方法的优先级(也就是说默认方法如果被覆盖了就以被覆盖的方法为准) 如果无法根据第一条进行判断，那么子接口的优先级更高：函数签名相同时，优先选择拥有最具体实现的默认方法的接口，即如果B继承了A，那么B就比A具体 最后，如果还无法判断，继承了多个接口的类必须通过显示覆盖和调用期望方法]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2018%2F07%2F15%2Fjava%2F%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%2F%E9%98%BB%E5%A1%9E%E9%98%9F%E5%88%97%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[阻塞队列详解BlockingQueue add() 这个方法是向阻塞队列中添加一个元素，添加元素时如果队列满了不会等待，会直接抛出异常，添加成功就会返回true offer() 这个方法时向阻塞队列中添加一个元素，添加元素时如果队列满了不会等待，但是不会抛异常，而是返回false，添加成功返回true put() 这个方法是向阻塞队列中添加一个元素，添加元素时如果队列满了会进行阻塞等待，所以不会返回什么 offer(e, timeout, unit) 添加元素时，会进行timeout的时间等待，其它就跟offer()方法一样了 take() 这个跟put方法对应，进行阻塞的取元素 poll(timeout, unit) 等待timeout的时间取元素，如果超时就返回null SynchronizeQueue该队列大概的结构如下 TransferStack这是非公平的，想对于公平来说，这个实现的区别是每次添加元素时，公平的实现是如果不能够匹配直接将结点加入到最后，但是非公平的方式是帮助前一个正在传递数据的两个节点完成交易，然后放在栈首；它主要想要达到的是线程局部性，以此来提高性能 SNode 一些属性 12345678910//连接下一个结点volatile SNode next; // next node in stack//如果有与当前节点匹配的节点，就把该节点赋值给这个属性volatile SNode match; // the node matched to this//该节点控制的线程volatile Thread waiter; // to control park/unpark//该节点拥有的数据Object item; // data; or null for REQUESTs//该节点的模式，有三种模式 REQUEST、DATA、FULFILLINGint mode; 一些栈元素的操作 这里对的参数中的timed和nanos是与算法的第二点又关的，timed、nanos是实现的一个过期机制， 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576E transfer(E e, boolean timed, long nanos) &#123; /* * Basic algorithm is to loop trying one of three actions: * * 1. If apparently empty or already containing nodes of same * mode, try to push node on stack and wait for a match, * returning it, or null if cancelled. * * 2. If apparently containing node of complementary mode, * try to push a fulfilling node on to stack, match * with corresponding waiting node, pop both from * stack, and return matched item. The matching or * unlinking might not actually be necessary because of * other threads performing action 3: * * 3. If top of stack already holds another fulfilling node, * help it out by doing its match and/or pop * operations, and then continue. The code for helping * is essentially the same as for fulfilling, except * that it doesn't return the item. */ SNode s = null; // constructed/reused as needed int mode = (e == null) ? REQUEST : DATA; for (;;) &#123; SNode h = head; if (h == null || h.mode == mode) &#123; // empty or same-mode if (timed &amp;&amp; nanos &lt;= 0) &#123; // can't wait if (h != null &amp;&amp; h.isCancelled()) casHead(h, h.next); // pop cancelled node else return null; &#125; else if (casHead(h, s = snode(s, e, h, mode))) &#123; SNode m = awaitFulfill(s, timed, nanos); if (m == s) &#123; // wait was cancelled clean(s); return null; &#125; if ((h = head) != null &amp;&amp; h.next == s) casHead(h, s.next); // help s's fulfiller return (E) ((mode == REQUEST) ? m.item : s.item); &#125; &#125; else if (!isFulfilling(h.mode)) &#123; // try to fulfill if (h.isCancelled()) // already cancelled casHead(h, h.next); // pop and retry else if (casHead(h, s=snode(s, e, h, FULFILLING|mode))) &#123; for (;;) &#123; // loop until matched or waiters disappear SNode m = s.next; // m is s's match if (m == null) &#123; // all waiters are gone casHead(s, null); // pop fulfill node s = null; // use new node next time break; // restart main loop &#125; SNode mn = m.next; if (m.tryMatch(s)) &#123; casHead(s, mn); // pop both s and m return (E) ((mode == REQUEST) ? m.item : s.item); &#125; else // lost match s.casNext(m, mn); // help unlink &#125; &#125; &#125; else &#123; // help a fulfiller SNode m = h.next; // m is h's match if (m == null) // waiter is gone casHead(h, null); // pop fulfilling node else &#123; SNode mn = m.next; if (m.tryMatch(h)) // help match casHead(h, mn); // pop both h and m else // lost match h.casNext(m, mn); // help unlink &#125; &#125; &#125; &#125; 这个就是实现的算法： 当栈为空或者栈中的首元素的模式与匹配的结点的模式相同，那么就会把结点推入栈等待匹配，这里的等待需要注意的是会调用awaitFulfill，这个方法会不会直接将线程阻塞进行等待，而是先进行自旋，自旋后没能够够成功匹配才进行阻塞等待； 如果当前栈顶的结点与请求交易的结点互补，那么将这个请求交易的节点的模式变为FULFILLING，然后将其压入栈中，和互补的节点进行匹配，完成交易之后将两个节点一起弹出，并且返回交易的数据。 如果栈顶已经存在一个模式为FULFILLING的节点，说明栈顶的节点正在进行匹配，那么就帮助这个栈顶节点快速完成交易，然后继续交易。我想要说一下这里的帮助，其实就是把正在进行数据传递的两个节点从栈中移除。 123456789101112boolean tryMatch(SNode s) &#123; if (match == null &amp;&amp; UNSAFE.compareAndSwapObject(this, matchOffset, null, s)) &#123; Thread w = waiter; if (w != null) &#123; // waiters need at most one unpark waiter = null; LockSupport.unpark(w); &#125; return true; &#125; return match == s;&#125; 这个方法是在进入栈中的时候尝试去匹配互补模式的节点，匹配成功就会使栈中节点拥有的线程唤醒 TransferQueue123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384E transfer(E e, boolean timed, long nanos) &#123; /* Basic algorithm is to loop trying to take either of * two actions: * * 1. If queue apparently empty or holding same-mode nodes, * try to add node to queue of waiters, wait to be * fulfilled (or cancelled) and return matching item. * * 2. If queue apparently contains waiting items, and this * call is of complementary mode, try to fulfill by CAS'ing * item field of waiting node and dequeuing it, and then * returning matching item. * * In each case, along the way, check for and try to help * advance head and tail on behalf of other stalled/slow * threads. * * The loop starts off with a null check guarding against * seeing uninitialized head or tail values. This never * happens in current SynchronousQueue, but could if * callers held non-volatile/final ref to the * transferer. The check is here anyway because it places * null checks at top of loop, which is usually faster * than having them implicitly interspersed. */ QNode s = null; // constructed/reused as needed boolean isData = (e != null); for (;;) &#123; QNode t = tail; QNode h = head; if (t == null || h == null) // saw uninitialized value continue; // spin if (h == t || t.isData == isData) &#123; // empty or same-mode QNode tn = t.next; if (t != tail) // inconsistent read continue; if (tn != null) &#123; // lagging tail advanceTail(t, tn); continue; &#125; if (timed &amp;&amp; nanos &lt;= 0) // can't wait return null; if (s == null) s = new QNode(e, isData); if (!t.casNext(null, s)) // failed to link in continue; advanceTail(t, s); // swing tail and wait Object x = awaitFulfill(s, e, timed, nanos); if (x == s) &#123; // wait was cancelled clean(t, s); return null; &#125; if (!s.isOffList()) &#123; // not already unlinked advanceHead(t, s); // unlink if head if (x != null) // and forget fields s.item = s; s.waiter = null; &#125; return (x != null) ? (E)x : e; &#125; else &#123; // complementary-mode QNode m = h.next; // node to fulfill if (t != tail || m == null || h != head) continue; // inconsistent read Object x = m.item; if (isData == (x != null) || // m already fulfilled x == m || // m cancelled !m.casItem(x, e)) &#123; // lost CAS advanceHead(h, m); // dequeue and retry continue; &#125; advanceHead(h, m); // successfully fulfilled LockSupport.unpark(m.waiter); return (x != null) ? (E)x : e; &#125; &#125; &#125; 算法设计思路： 如果队列为空，或者请求交易的节点和队列中的节点具有相同的交易类型，那么就将该请求交易的节点添加到队列尾部等待交易，直到被匹配或者被取消 如果队列中包含了等待的节点，并且请求的节点和等待的节点是互补的，那么进行匹配并且进行交易 关于awaitfulfill方法12345678910111213141516171819202122232425262728293031SNode awaitFulfill(SNode s, boolean timed, long nanos) &#123;final long deadline = timed ? System.nanoTime() + nanos : 0L; Thread w = Thread.currentThread(); int spins = (shouldSpin(s) ? (timed ? maxTimedSpins : maxUntimedSpins) : 0); for (;;) &#123; if (w.isInterrupted()) s.tryCancel(); SNode m = s.match; if (m != null) return m; //实现过期机制 if (timed) &#123; nanos = deadline - System.nanoTime(); if (nanos &lt;= 0L) &#123; s.tryCancel(); continue; &#125; &#125; //实现自旋等待 if (spins &gt; 0) spins = shouldSpin(s) ? (spins-1) : 0; else if (s.waiter == null) s.waiter = w; // establish waiter so can park next iter //这里就是线程会不会过期，不会过期直接阻塞；会过期就调用parkNanos然后重新执行循环，就会重新检查nanos，这个时候nanos会&lt;=0就会cancel这个结点 else if (!timed) LockSupport.park(this); else if (nanos &gt; spinForTimeoutThreshold) LockSupport.parkNanos(this, nanos); &#125; &#125; spins = shouldSpin(s) ? (spins-1) : 0; 这里实现了自旋等待；timed和nanos是给结点设置过期时间，time out了就会s.tryCancel();如果在自旋的时间内没有找到匹配的结点，那么进行阻塞等待，然后等到有匹配的线程到来，通过SNode的waiter属性占到当前线程进行唤醒；这里需要知道有了过期时间就不会有线程阻塞。 关于公平和非公平的区别12345* The (Lifo) stack is used for non-fair mode, and the (Fifo) * queue for fair mode. The performance of the two is generally * similar. Fifo usually supports higher throughput under * contention but Lifo maintains higher thread locality in common * applications. （Lifo）堆栈用于非公平模式，而（Fifo）队列用于公平模式。 两者的表现大致相似。 Fifo通常支持更高的吞吐量，但Lifo在常见应用程序中维护更高的线程局部性。 流程图展示整个大概的流程 ArrayBlockingQueue这个容器没有什么好讲的，我们看一下它的变量就差不多知道它的实现方式 12345678final Object[] items;int takeIndex;int putIndex;int count;final ReentrantLock lock;private final Condition notEmpty;private final Condition notFull;transient Itrs itrs = null; 1234567891011121314151617181920//这里需要讲的是，这里也设置了一个过期时间，这里的实现方式是当一个元素添加到容器里面时，如果容器满了，就等待一段时间，如果等待一段时间后，还是不可以添加，就添加失败 public boolean offer(E e, long timeout, TimeUnit unit) throws InterruptedException &#123; checkNotNull(e); long nanos = unit.toNanos(timeout); final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try &#123; while (count == items.length) &#123; if (nanos &lt;= 0) return false; nanos = notFull.awaitNanos(nanos); &#125; enqueue(e); return true; &#125; finally &#123; lock.unlock(); &#125; &#125; LinkedBlockingQueue变量 12345678private final int capacity;private final AtomicInteger count = new AtomicInteger();transient Node&lt;E&gt; head;private transient Node&lt;E&gt; last; private final ReentrantLock takeLock = new ReentrantLock(); private final Condition notEmpty = takeLock.newCondition();private final ReentrantLock putLock = new ReentrantLock();private final Condition notFull = putLock.newCondition(); 1234567891011private E dequeue() &#123; // assert takeLock.isHeldByCurrentThread(); // assert head.item == null; Node&lt;E&gt; h = head; Node&lt;E&gt; first = h.next; h.next = h; // help GC head = first; E x = first.item; first.item = null; return x;&#125; 这个方法需要注意的是，h.next = h;这里是通过自己的属性指向自己形成一个环， GC就会认为它是无用的]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2018%2F07%2F11%2Fjava%2F%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%2FThreadLocal%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[关于ThreadLocal 每个线程保存的是ThreadLocal.ThreadLocalMap ThreadLocalMap跟HashMap类似，我们接下来就具体看看它的重要的一些源码 12345678910111213//在ThreadLocal中保存的就是这个Entry数组，这个entry数组就是保存的我们的数据，Entry特殊的是它是一个弱引用，根据构造函数我们也知道它是让一个ThreadLocal 与一个我们要保存的数据进行绑定private Entry[] table; static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123; /** The value associated with this ThreadLocal. */ Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; super(k); value = v; &#125; &#125; 其它方面就跟HashMap非常类似，也有扩容机制，而且跟HashMap的扩容机制差不多]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2018%2F06%2F25%2Freading%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[存储器管理存储器的层次结构多级存储器结构 操作系统的存储管理，负责对可执行存储器的分配、回收以及提供在存储层次间数据移动的管理机制 主要分三层：CPU寄存器（寄存器），主存（高速缓存、主存、磁盘缓存）、辅存（磁盘、可移动介质） 程序的装入和链接程序的装入 绝对装入方式：程序员需要知道程序将驻留在什么位置 可重定位装入方式：程序指定程序驻留内存的相对位置 动态运行时装入方式：并不立即把装入模块中的相对无位置转换为绝对位置，而是把这种地址转换推迟到程序真正要执行时才运行 程序的链接 静态链接方式：在程序运行前，先将各目标模块及它们所需的库函数，链接成一个完整的装配模块，以后不再拆开 装入时动态链接：装入一个模块时，若发生一个外部模块调用事件，将引起装入程序去找对应的外部目标模块，并将它装入内存。 运行时动态链接：在程序运行时，将目标模块装入内存 连续分配方式单一连续分配固定分区分配 划分分区方法：将内存的用户空间划分为若干个固定大小的分区（有分区大小相等和不相等两种方式） 内存分配：使用一张分区使用表来进行分区的使用 动态分区分配 分配方式：根据进程的需要，动态的为之分配内存空间 分区分配中的数据结构： 空闲分区表 空闲分区链 分区分配算法 首次适应算法 定义：空闲分区链以地址递增的次序链接，在分配内存时从链首开始顺序查找 缺点：倾向于分配低地址部分，会留下许多难以利用的、很小的空闲分区，且查找是从头开始，会消耗多余的时间 循环首次适应算法 定义：对首次适应算法的改进，下次查找是从上一次分配的空间开始 缺点：缺乏大的空闲分区 最佳适应算法 定义：在所有的空闲分区按其容量有小到大的顺序形成一空闲分区链，在其中找到能满足要求的最小的空间 缺点：每次分配的是所切割下来的剩余部分总是最小的，在存储器中会留下许多难以利用的小空闲区 最坏适应算法 定义：从顺序空闲分区链中，找最大的空间分配 缺点：虽然可以减少碎片空间，但是缺少大的空闲分区 以上都是顺序搜索法 快速适应算法（分类搜索算法） 定义：将空闲分区根据其容量大小进行分类，对于没一类相同容量的所有空闲分区，单独设立一个空闲分区链表，寻找到能容纳它的最小空间区链表，取第一个 缺点：分区归还主存时算法复杂，系统开销大 分区分配操作 分配内存 回收内存 伙伴系统 定义：在系统运行过程中，由于不断的划分，可能会形成若干个不连续的空闲分区，将这些空闲分区根据分区的大小进行分类，在此基础上进行分配 可重定位分区分配 原因：在分区分配过程中会产生许多小空间，我们需要整合这些小空间，就需要移动原有程序 实现：动态运行时装入方式，利用硬件地址变换机构，即需在系统中增设一个重定位寄存器，用它来存放程序在内存中的起始地址 算法： 对换 定义：是指把内存中暂时不能运行的进程或者暂时不用的程序和数据调出到处到外存上，以便腾出足够的内存空间，再把已具备运行条件的进程或进程所需要的程序和数据调入到内存 对换空间的管理：通常是把外存分为文件区和对换区，文件去使用离散分配方式，对换区使用连续分配方式便于查找 基本分页存储管理方式 定义：前面都是连续分配方式，基于分页存储管理方式是离散分配方式 基本概念： 页面 将一个进程的逻辑地址空间分成若干个大小相等的片，称为页面 内存分为与页面相等大小的若干个存储块，称为物理块或者页框 页面大小 地址结构：20位页号12位位移量 即每页大小2^12 = 4K 页表：记录页面与物理块之间关系的表 地址变换机构 基本分段存储管理方式虚拟存储器 定义：仅需将那些当前要运行的少数页面或段先装入内存便可运行，在程序运行时再将没有调入的页面进行调入 特征： 多次性：一个程序被分成多次调用内存 对换性：作业在运行过程中换入换出 虚拟性：逻辑上对内存进行扩容 请求分页存储管理方式 硬件支持 页表机制 缺页中断机构 地址变换机构 页面置换算法 最佳置换算法：选择的被淘汰页面，将是以后永不使用的，这个是无法实现的 先进先出页面算法 LRU置换算法：硬件支持（寄存器或栈） Clock置换算法：根据访问位和修改位来判断置换的页面 请求分段存储管理方式进程管理进程的基本概念 进程顺序执行的基本特征：顺序性、封闭性、可再现性 进程并发执行的基本特征：间断性、失去封闭性、不可再现性 进程可能会有的所有状态：创建状态、就绪状态、执行状态、阻塞状态、挂起状态、终止状态 进程控制块（PCB）：一种数据结构，用于描述进程的当前情况以及控制进程运行的全部信息，PCB常驻内存。 其中有主要一下信息： 进程标识符 处理机状态 进程调度信息 进程控制信息 进程控制块组织方式： 链接方式 索引方式 进程控制 进程的创建 申请空白PCB 为新进程分配资源 初始化PCB 将PCB插入就绪队列 进程终止 进程的阻塞 改变PCB中的进程调度信息 插入阻塞队列 进程唤醒 改变PCB中的进程调度信息 插入就绪队列 进程的挂起 进程的激活 进程同步 基本概念 两种形式的制约关系 临界资源 临界区 信号量机制 整型信号量 记录型信息量 AND型信号量 信号量集 管程 定义：共享资源的数据结构，以及由对该数据结构实施操作的一组过程所组成的资源管理程序，共同构成了一个操作系统的资源管理模块 线程 线程与进程的比较 调度：同一进程的不同线程的切换不切换进程 并发性 拥有资源：访问隶属进程的资源，拥有很少量自己的自己的资源 系统开销：系统开销小 线程属性： 轻型实体 独立调度和分派的基本单位 可并发执行 共享进程资源 线程状态 线程的实现方式 内核支持线程 缺点：对于用户线程切换而言，开销很大 用户级线程 缺点：系统调用阻塞问题；多线程不能利用多处理机进行多重处理 组合方式 线程的实现 内核支持线程的实现：就类似于进程了 用户级线程的实现 运行时系统：用于管理和控制线程的函数集合 内核控制线程：每个进程拥有多个LWP，一个LWP连接多个用户进程，克服了内核线程的切换线程系统 开销大的问题，也克服了用户线程系统调用阻塞所有其它线程问题 处理机调度和死锁处理机调度层次 高级调度：根据某种算法，把外存上处理后备队列中的那些作业调入内存，调度的对象是作业 低级调度：调度的对象是进程 低级调度的功能： 保存处理机的现场信息，即进程运行时保存在各种寄存器里面的数据到PCB中 按某种算法选取下一个运行的进程 把处理器分配给下一个进程 低级调度的机制： 排队器：就绪进程队列 分派器：分派器就是由进程调度程序选定的进程，切换的进程首先把处理机切换到分派进程，然后分派进程再指定下一个进程并切换到下一个进程 上下文切换机制 进程调度方式 非抢占式调度：一个进程总是尝试运行完自己所有程序，除非遇到阻塞或异常而退出，再把处理机交给其它进程 抢占式调度：基于一定的优先原则，当优先级大的进程进入系统，会将当前运行的进程切换到优先级高的进程 中级调度：使那些暂时不能运行的进程调至外存上 调度队列模型和准则调度队列模型 仅有低级调度 低级调度和高级调度：从外存的后备队列上选择一个作业，然后封装为一个进程进行运行，进程运行有服从低级调度 三级调度都有：前面就像低级和高级调度的形式，然后在进程需要创建子进程内存空间不够的时候，就会换出暂时不会运行的线程到外存，变成外存就绪状态 调度算法的准则 面向用户准则 周期时间短 响应时间快 截止时间保证 优先权准则 面向系统准则 系统吞吐量：就是在一定的时间里能够完成的作业 处理机利用率 资源平衡利用 资源利用平衡 调度算法 高级调度和低级调度都适用的： 先来先服务调度算法：缺点是有利于长作业，不利于短作业；有利于CPU繁忙型作业，因为可以长时间占用处理机，导致其带权周转时间小 短作业调度优先：缺点是不利于长作业 高优先权优先调度算法：抢占式，非抢占式；静态优先权，动态优先权 高响应比优先调度算法：利用动态优先权，进程的优先权随着时间的改变而改变：响应时间/服务时间 低级调度适用的： 时间片轮转调度算法：在给定的时间片内，对按照先来先服务形成的就绪进程队列进程时间片周期轮转执行 多级反馈队列调度算法：设置多个就绪进程就绪队列，队列优先级依次降低，会首先执行优先级高的队列里面的进程且每一个低优先级都是其上一个优先级队列的分配时间片大一倍；创建一个进程时，先放到第一优先级队列，如果第一个时间片没有执行完在放到下一个优先级队列，依次类推；也仅有上一优先级队列为空时下一优先级队列才有机会执行，所以当有第一优先级队列有进程时，在执行第二优先级队列里面的进程时会被抢占 实时调度算法： 最早截止时间调度算法：有较早截止时间的进程有较高的优先级去执行 最低松弛度优先：在形成的松弛度有小到大的队列中选取第一个执行，松弛度=必须完成的时间-其本身时间-当前时间 产生死锁的原因和条件 产生死锁的原因： 竞争资源 竞争非剥夺性资源 竞争临时性资源 进程间推进顺序非法 产生死锁的必要条件 互斥条件 请求和保持条件 不剥夺条件 环路等待条件 设备管理IO控制方式 程序IO方式 中断驱动方式 口述一下就是IO程序发出读命令，然后检测IO设备是否空闲，空闲的话读取一个字到数据寄存器，然后发出中断信号，CPU检查输入过程是否有错，没有错再将字写到内存 直接存储器访问方式(DMA)控制方式 产生的原因：虽然产生了中断驱动IO控制方式，但是我们从上面的流程图可以得知，我们只能节省等待IO设备可用的时间，还有大量的IO传输速度与cpu不匹配所产生的cpu等待IO设备的时间会浪费，DMA方式成百倍的减少了CPU对IO的干预 DMA的特点： 每次传输一个数据块 DMA存在一个缓存区，即内存中的一块地方，所以DMA通过这个缓冲区与CPU进行数据传递，当CPU发送读命令时，从IO设备读取数据到这个缓存区，写命令时CPU右将数据发送到这个缓冲区 仅在一个数据块操作完成才需CPU干预，取下一个命令 关于设备控制器(DMA) 组成： DMA与CPU的接口：主要涉及数据线、地址线和控制线，这个三个线与命令/状态寄存器(CR)、内存地址寄存器(MDR)、数据寄存器(DR)、数据计数器(DR)进行数据传递； DMA与IO设备的接口 IO逻辑：实现对设备控制，通过一组控制线与处理机交互，处理机利用该逻辑向控制器发送IO命令；IO逻辑对收到的命令进行译码 DMA工作过程 IO通道控制方式 IO通道 定义：是一种特殊的处理机，但是它只能运行IO命令，且与处理机共享内存 产生的原因：DMA只能一次读取一个数据块的数据，IO通道则是DMA方式的发展，可以一次实现多个数据块的传送 执行过程：当CPU要完成一个读操作时，只需向IO通道发送一条IO指令，IO指令包括所要执行通道程序的首址和要访问的IO设备 中断处理程序 主要有以下几个步骤 唤醒被阻塞的驱动进程(这里唤醒的原因是需要中断处理程序处理IO完成后的工作) 保护被中断进程的CPU环境：我觉得这里需要注意的是与进程进行上下文切换机制不同，后者是将处理机现场信息保存到PCB中，但是这里是吧处理机状态字PSW和程序计数器保存在中断保留区，把被中断进程CPU现场信息压入中断栈中 转入相应设备处理程序 中断处理 恢复被中断进程现场 设备驱动程序 定义：他是IO进程与设备控制器之间的通信程序 产生原因：由于对不同硬件设备进行IO操作需要不同的指令代码，也即不同的硬件需要不同的驱动程序，所以在我们看来IO程序简单发出一个read或者write命令，但是如果设备控制器直接发给IO设备它是不认识的因为不同的硬件的内部结构是不一样的，所以这个时候就需要设备驱动程序对这个read或者write命令基于不同硬件解析为硬件认识的程序代码然后让设备控制器直接发给IO设备 操作系统接口系统调用 系统态和用户态：在现在的我看来是对处理机两种状态的标志，当处理机是系统态时可以使用所有指令和数据；而用户态只能使用非特权指令，不能使用系统态的空间和数据；这两个状态的切换时通过改变处理机状态字PSW 系统调用实现 主要是靠中断和陷入机制来完成的；当CPU执行到一条需要系统调用的指令时发生中断并将有关信号送给中断和陷入硬件机构，该机构收到信号后，启动相关的中断和陷入处理程序进行处理]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2018%2F06%2F20%2Fjava%2FJava%20%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%8F%82%E6%95%B0%2F</url>
    <content type="text"><![CDATA[Java 虚拟机参数-Xms 设置初始堆大小 -Xmx 设置最大堆大小 -XX:ReservedCodeCacheSize=240m 这个参数主要用来设置codecache大小，比如我们jit编译的代码都是放在codecache里的，所以codecache如果满了的话，那带来的问题就是无法再jit编译了，而且还会去优化。 因此大家可能碰到这样的问题：cpu一直高，然后发现是编译线程一直高（系统运行到一定时期），这个很大可能是codecache满了，一直去做优化。 -XX:+PrintGCDetails 打印GC日志 -Verbose:gc 用于垃圾收集时的信息打印 -XX:+PrintGCDateStamps 打印GC时间戳 -Xloggc:C:\Users\ligj\Downloads\gc.log GC 把GC日志输出的地方 虚拟机默认参数在命令行输入一下内容直接查看： 1java -XX:+PrintFlagsInitail 查看虚拟机使用的虚拟机1234public static void main(String[] args)&#123; List&lt;GarbageCollectorMXBean&gt; l = ManagementFactory.getGarbageCollectorMXBeans(); l.forEach(b -&gt; System.out.println(b.getName())); &#125;]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2018%2F06%2F15%2Fjava%2F%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%2FHashTable%2F</url>
    <content type="text"><![CDATA[根据jdk类注释中可以得到的一些信息 HashTable是线程安全的，但是如果不要求线程安全推荐使用HashMap来代替HashTable， 要求线程安全那么就使用HashTable 要求键值不能为空 如果会用较多的元素使用，那么最好设置足够的容量来减少添加元素时扩容的浪费的时间 关于modCount：在HashTable被创建完成后，除了使用iterator自己的remove方法，其他任何对于它结构性改变的方法都会抛出ConcurrentModificationException；因此在面对同步更改的情况下iterator能够失败得快而干净。但是这并不能对于非同步的同时更改带来硬性保证不会出现问题。 我们在iterator中看到这个也就明白了，在得到自己的遍历器的时候就会自己期望的更改次数值为当前的已经的更改次数值。 1expectedModCount = modCount; 当一个对象得到它的遍历器的时候也就是准备遍历它的所有元素，那么在这个遍历过程中我也就不想其中有元素会有所改变，所以在这个时候如果我们通过直接调用容器的删除添加元素等方法就会造成。 HashTable处理哈希冲突的方法也是使用了链式存储法 其实其他的大多就跟HashMap一样，最大不一样也就是进行了共享资源的同步。]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2018%2F06%2F15%2Fjava%2F%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%2FHashMap%E6%BA%90%E7%A0%81%2F</url>
    <content type="text"><![CDATA[为什么hashMap的capacity要选取2的幂，因为这样(数组长度-1)正好相当于一个低位掩码，这样也正好对应了数组的长度，可以得到数组的一个下标 1234 10100101 11000100 00100101 &amp; 00000000 00000000 00001111-------------------------------- 00000000 00000000 00000101 //高位全部归零，只保留末四位 hashCode 方法的原因 (h&gt;&gt;&gt;16)因为Object.hashCode是返回int型的散列值也就是32位，这里右移了16位得到了hash值得高16位，前16位用0填充这样高位的信息被变相的保留了下来，再进行(h^(h&gt;&gt;&gt;16))也就增加了低位的随机性下面使用的地方会使用 (n-1) &amp; hash(key)就会随机得到一个Node数组的一个下标，随机性增强了那么碰撞的可能也就减少了 threshold = size * loadFoactor 也就是说是node数组扩容的一个标志 loadFactor 用法如上就是用来确定容量在总容量什么程度下扩容 HashMap是使用Hash表来存储键值对，采用的解决哈希冲突的方法是使用链地址法，在采用链地址的同时如果某条链中的元素个数超过了8个就会使用 putVal 和 resize方法 tableSizeFor方法 putVal方法的流程图 为什么hashMap是非线程安全的 这里只说明一个例子：现在有两个线程同时操作一个HashMap，他们现在同时取得了插入哈希表的同一个地址，现在第一个线程插入进去把next指针指向了它，但是第二个线程对此一无所知，依然进行了同样的操作，最后也就覆盖了第一个线程的操作。 还有个什么死循环看不怎么懂 ….. 为什么在一个哈希桶里面添加元素个数在8的时候需要树形化而等于6的时候又要去树形化 因为红黑树的平均查找长度是log(n),长度为8时平均查找长度为3，如果继续使用链表平均查找长度为8/2 = 4；链表长度如果是小于等于6，6/2=3，虽然速度也很快的，但是转化为树结构和生成树的时间并不会太短。不选址直接是6或者8的原因是可以有效防止链表和树频繁转换 参考自具体这里 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798991001011021031041051061071081091101111121131141151161171181191201211221231241251261271281291301311321331341351361371381391401411421431441451461471481491501511521531541551561571581591601611621631641651661671681691701711721731741751761771781791801811821831841851861871881891901911921931941951961971981992002012022032042052062072082092102112122132142152162172182192202212222232242252262272282292302312322332342352362372382392402412422432442452462472482492502512522532542552562572582592602612622632642652662672682692702712722732742752762772782792802812822832842852862872882892902912922932942952962972982993003013023033043053063073083093103113123133143153163173183193203213223233243253263273283293303313323333343353363373383393403413423433443453463473483493503513523533543553563573583593603613623633643653663673683693703713723733743753763773783793803813823833843853863873883893903913923933943953963973983994004014024034044054064074084094104114124134144154164174184194204214224234244254264274284294304314324334344354364374384394404414424434444454464474484494504514524534544554564574584594604614624634644654664674684694704714724734744754764774784794804814824834844854864874884894904914924934944954964974984995005015025035045055065075085095105115125135145155165175185195205215225235245255265275285295305315325335345355365375385395405415425435445455465475485495505515525535545555565575585595605615625635645655665675685695705715725735745755765775785795805815825835845855865875885895905915925935945955965975985996006016026036046056066076086096106116126136146156166176186196206216226236246256266276286296306316326336346356366376386396406416426436446456466476486496506516526536546556566576586596606616626636646656666676686696706716726736746756766776786796806816826836846856866876886896906916926936946956966976986997007017027037047057067077087097107117127137147157167177187197207217227237247257267277287297307317327337347357367377387397407417427437447457467477487497507517527537547557567577587597607617627637647657667677687697707717727737747757767777787797807817827837847857867877887897907917927937947957967977987998008018028038048058068078088098108118128138148158168178188198208218228238248258268278288298308318328338348358368378388398408418428438448458468478488498508518528538548558568578588598608618628638648658668678688698708718728738748758768778788798808818828838848858868878888898908918928938948958968978988999009019029039049059069079089099109119129139149159169179189199209219229239249259269279289299309319329339349359369379389399409419429439449459469479489499509519529539549559569579589599609619629639649659669679689699709719729739749759769779789799809819829839849859869879889899909919929939949959969979989991000100110021003100410051006100710081009101010111012101310141015101610171018101910201021102210231024102510261027102810291030103110321033103410351036103710381039104010411042104310441045104610471048104910501051105210531054105510561057105810591060106110621063106410651066106710681069107010711072107310741075107610771078107910801081108210831084108510861087108810891090109110921093109410951096109710981099110011011102110311041105110611071108110911101111111211131114111511161117111811191120112111221123112411251126112711281129113011311132113311341135113611371138113911401141114211431144114511461147114811491150115111521153115411551156115711581159116011611162116311641165116611671168116911701171117211731174117511761177117811791180118111821183118411851186118711881189119011911192119311941195119611971198119912001201120212031204120512061207120812091210121112121213121412151216121712181219122012211222122312241225122612271228122912301231123212331234123512361237123812391240124112421243124412451246124712481249125012511252125312541255125612571258125912601261126212631264126512661267126812691270127112721273127412751276127712781279128012811282128312841285128612871288128912901291129212931294129512961297129812991300130113021303130413051306130713081309131013111312131313141315131613171318131913201321132213231324132513261327132813291330133113321333133413351336133713381339134013411342134313441345134613471348134913501351135213531354135513561357135813591360136113621363136413651366136713681369137013711372137313741375137613771378137913801381138213831384138513861387138813891390139113921393139413951396139713981399140014011402140314041405140614071408140914101411141214131414141514161417141814191420142114221423142414251426142714281429143014311432143314341435143614371438143914401441144214431444144514461447144814491450145114521453145414551456145714581459146014611462146314641465146614671468146914701471147214731474147514761477147814791480148114821483148414851486148714881489149014911492149314941495149614971498149915001501150215031504150515061507150815091510151115121513151415151516151715181519152015211522152315241525152615271528152915301531153215331534153515361537153815391540154115421543154415451546154715481549155015511552155315541555155615571558155915601561156215631564156515661567156815691570157115721573157415751576157715781579158015811582158315841585158615871588158915901591159215931594159515961597159815991600160116021603160416051606160716081609161016111612161316141615161616171618161916201621162216231624162516261627162816291630163116321633163416351636163716381639164016411642164316441645164616471648164916501651165216531654165516561657165816591660166116621663166416651666166716681669167016711672167316741675167616771678167916801681168216831684168516861687168816891690169116921693169416951696169716981699170017011702170317041705170617071708170917101711171217131714171517161717171817191720172117221723172417251726172717281729173017311732173317341735173617371738173917401741174217431744174517461747174817491750175117521753175417551756175717581759176017611762176317641765176617671768176917701771177217731774177517761777177817791780178117821783178417851786178717881789179017911792179317941795179617971798179918001801180218031804180518061807180818091810181118121813181418151816181718181819182018211822182318241825182618271828182918301831183218331834183518361837183818391840184118421843184418451846184718481849185018511852185318541855185618571858185918601861186218631864186518661867186818691870187118721873187418751876187718781879188018811882188318841885188618871888188918901891189218931894189518961897189818991900190119021903190419051906190719081909191019111912191319141915191619171918191919201921192219231924192519261927192819291930193119321933193419351936193719381939194019411942194319441945194619471948194919501951195219531954195519561957195819591960196119621963196419651966196719681969197019711972197319741975197619771978197919801981198219831984198519861987198819891990199119921993199419951996199719981999package java.util;import java.io.IOException;import java.io.InvalidObjectException;import java.io.Serializable;import java.lang.reflect.ParameterizedType;import java.lang.reflect.Type;import java.util.function.BiConsumer;import java.util.function.BiFunction;import java.util.function.Consumer;import java.util.function.Function;import sun.misc.SharedSecrets;public class HashMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements Map&lt;K,V&gt;, Cloneable, Serializable &#123; private static final long serialVersionUID = 362498820763181265L； static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // aka 16 static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30; static final float DEFAULT_LOAD_FACTOR = 0.75f; static final int TREEIFY_THRESHOLD = 8; static final int UNTREEIFY_THRESHOLD = 6; static final int MIN_TREEIFY_CAPACITY = 64; static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; final K key; V value; Node&lt;K,V&gt; next; Node(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; this.hash = hash; this.key = key; this.value = value; this.next = next; &#125; public final K getKey() &#123; return key; &#125; public final V getValue() &#123; return value; &#125; public final String toString() &#123; return key + "=" + value; &#125; public final int hashCode() &#123; return Objects.hashCode(key) ^ Objects.hashCode(value); &#125; public final V setValue(V newValue) &#123; V oldValue = value; value = newValue; return oldValue; &#125; public final boolean equals(Object o) &#123; if (o == this) return true; if (o instanceof Map.Entry) &#123; Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;)o; if (Objects.equals(key, e.getKey()) &amp;&amp; Objects.equals(value, e.getValue())) return true; &#125; return false; &#125; &#125; static final int hash(Object key) &#123; int h; /*(h&gt;&gt;&gt;16)因为Object.hashCode是返回int型的散列值也就是32位，这里右移了16位得到了hash值得高16 位，前16位用0填充这样高位的信息被变相的保留了下来，再进行(h^(h&gt;&gt;&gt;16))也就增加了低位的随机性 下面使用的地方会使用 (n-1) &amp; hash(key)就会随机得到一个Node数组的一个下标，随机性增强了那么 碰撞的可能也就减少了 */ return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16); &#125; /** 返回x的类如果x的类实现了Comparable接口 */ static Class&lt;?&gt; comparableClassFor(Object x) &#123; if (x instanceof Comparable) &#123; Class&lt;?&gt; c; Type[] ts, as; Type t; ParameterizedType p; if ((c = x.getClass()) == String.class) // bypass checks return c; if ((ts = c.getGenericInterfaces()) != null) &#123; for (int i = 0; i &lt; ts.length; ++i) &#123; if (((t = ts[i]) instanceof ParameterizedType) &amp;&amp; ((p = (ParameterizedType)t).getRawType() == Comparable.class) &amp;&amp; (as = p.getActualTypeArguments()) != null &amp;&amp; as.length == 1 &amp;&amp; as[0] == c) // type arg is c return c; &#125; &#125; &#125; return null; &#125; /** * Returns k.compareTo(x) if x matches kc (k's screened comparable * class), else 0. */ @SuppressWarnings(&#123;"rawtypes","unchecked"&#125;) // for cast to Comparable static int compareComparables(Class&lt;?&gt; kc, Object k, Object x) &#123; return (x == null || x.getClass() != kc ? 0 : ((Comparable)k).compareTo(x)); &#125; /** * 返回一个2的次幂的size根据给定的容量.（就是必须是2的次幂，否则这里会调整为2的次幂） */ static final int tableSizeFor(int cap) &#123; int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1; &#125; /* ---------------- Fields -------------- */ /** 我们需要的表，在第一次使用的时候初始化，在必要时调整大小。当调整大小的时候总是2的次幂。 */ transient Node&lt;K,V&gt;[] table; transient Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet; /** * 这个map中键值对的数量 */ transient int size; transient int modCount; int threshold; final float loadFactor; /* ---------------- Public operations -------------- */ /** 检验了初始容量和负载因子的正确性，赋值了负载因子，并根据指定的容量转换为2 的次幂的容量并且赋值 */ public HashMap(int initialCapacity, float loadFactor) &#123; if (initialCapacity &lt; 0) throw new IllegalArgumentException("Illegal initial capacity: " + initialCapacity); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException("Illegal load factor: " + loadFactor); this.loadFactor = loadFactor; this.threshold = tableSizeFor(initialCapacity); &#125; public HashMap(int initialCapacity) &#123; this(initialCapacity, DEFAULT_LOAD_FACTOR); &#125; public HashMap() &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted &#125; public HashMap(Map&lt;? extends K, ? extends V&gt; m) &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; putMapEntries(m, false); &#125;// 这里的evict在putVal中使用，意思是否table中有重复元素 final void putMapEntries(Map&lt;? extends K, ? extends V&gt; m, boolean evict) &#123; int s = m.size(); if (s &gt; 0) &#123; if (table == null) &#123; // pre-size float ft = ((float)s / loadFactor) + 1.0F; int t = ((ft &lt; (float)MAXIMUM_CAPACITY) ? (int)ft : MAXIMUM_CAPACITY); if (t &gt; threshold) threshold = tableSizeFor(t); &#125; else if (s &gt; threshold) resize(); for (Map.Entry&lt;? extends K, ? extends V&gt; e : m.entrySet()) &#123; K key = e.getKey(); V value = e.getValue(); putVal(hash(key), key, value, false, evict); &#125; &#125; &#125; public int size() &#123; return size; &#125; public boolean isEmpty() &#123; return size == 0; &#125; public V get(Object key) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value; &#125; final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; // 根据hash值找到对应的node赋值给first if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; //确定没有产生hash冲突 if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; //如果产生了hash冲突，如果是树形结构就用红黑树查找，是普通链表就用顺序查找。 if ((e = first.next) != null) &#123; if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; return null; &#125; public boolean containsKey(Object key) &#123; return getNode(hash(key), key) != null; &#125; public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true); &#125; final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; if ((tab = table) == null || (n = tab.length) == 0) //懒加载，在这里进行初始化 n = (tab = resize()).length; // 在哈希表里面如果找到的地址为空那么直接放进去 //并且把该地址上的首元素取出来给p if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else &#123; Node&lt;K,V&gt; e; K k; //该哈希表中该地址上的第一个元素与想要存放的元素相同，不进行存储 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; //该哈希表中该地址上所用元素已经使用红黑树进行存储，那么就用红黑树的规则进行存储 else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); //该哈希表中该地址上有元素但是右没有使用红黑树，就采用普通的方式进行链表添加， //但是如果添加了元素过后达到了TREEIFY_THRESHOLD就会对这里的链表序列进行红黑树化； else &#123; for (int binCount = 0; ; ++binCount) &#123; if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st //对哈希表中的指定地址进行红黑树排序 treeifyBin(tab, hash); break; &#125; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; ++modCount; //size大于阈值就会扩容 if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null; &#125; final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; if (oldCap &gt; 0) &#123; if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; // 给Node数组扩容1倍，阈值也扩大一倍 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold &#125; else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; else &#123; // zero initial threshold signifies using defaults // 这里是hashmap的懒加载，只有在第一次使用的时候才会初始化它的table newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; threshold = newThr; @SuppressWarnings(&#123;"rawtypes","unchecked"&#125;) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; //将以前表的值转移到新的表里面 if (oldTab != null) &#123; for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123; oldTab[j] = null; if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else &#123; // preserve order Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; next = e.next; if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab; &#125; /** * Replaces all linked nodes in bin at index for given hash unless * table is too small, in which case resizes instead. */ final void treeifyBin(Node&lt;K,V&gt;[] tab, int hash) &#123; int n, index; Node&lt;K,V&gt; e; if (tab == null || (n = tab.length) &lt; MIN_TREEIFY_CAPACITY) resize(); //将所有的普通结点转换为红黑树结点 else if ((e = tab[index = (n - 1) &amp; hash]) != null) &#123; TreeNode&lt;K,V&gt; hd = null, tl = null; do &#123; TreeNode&lt;K,V&gt; p = replacementTreeNode(e, null); if (tl == null) hd = p; else &#123; p.prev = tl; tl.next = p; &#125; tl = p; &#125; while ((e = e.next) != null); if ((tab[index] = hd) != null) hd.treeify(tab); &#125; &#125; /** * Copies all of the mappings from the specified map to this map. * These mappings will replace any mappings that this map had for * any of the keys currently in the specified map. * * @param m mappings to be stored in this map * @throws NullPointerException if the specified map is null */ public void putAll(Map&lt;? extends K, ? extends V&gt; m) &#123; putMapEntries(m, true); &#125; /** * Removes the mapping for the specified key from this map if present. * * @param key key whose mapping is to be removed from the map * @return the previous value associated with &lt;tt&gt;key&lt;/tt&gt;, or * &lt;tt&gt;null&lt;/tt&gt; if there was no mapping for &lt;tt&gt;key&lt;/tt&gt;. * (A &lt;tt&gt;null&lt;/tt&gt; return can also indicate that the map * previously associated &lt;tt&gt;null&lt;/tt&gt; with &lt;tt&gt;key&lt;/tt&gt;.) */ public V remove(Object key) &#123; Node&lt;K,V&gt; e; return (e = removeNode(hash(key), key, null, false, true)) == null ? null : e.value; &#125; /** * Implements Map.remove and related methods * * @param hash hash for key * @param key the key * @param value the value to match if matchValue, else ignored * @param matchValue if true only remove if value is equal * @param movable if false do not move other nodes while removing * @return the node, or null if none */ final Node&lt;K,V&gt; removeNode(int hash, Object key, Object value, boolean matchValue, boolean movable) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, index; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (p = tab[index = (n - 1) &amp; hash]) != null) &#123; Node&lt;K,V&gt; node = null, e; K k; V v; if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) node = p; else if ((e = p.next) != null) &#123; if (p instanceof TreeNode) node = ((TreeNode&lt;K,V&gt;)p).getTreeNode(hash, key); else &#123; do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) &#123; node = e; break; &#125; p = e; &#125; while ((e = e.next) != null); &#125; &#125; if (node != null &amp;&amp; (!matchValue || (v = node.value) == value || (value != null &amp;&amp; value.equals(v)))) &#123; if (node instanceof TreeNode) ((TreeNode&lt;K,V&gt;)node).removeTreeNode(this, tab, movable); else if (node == p) tab[index] = node.next; else p.next = node.next; ++modCount; --size; afterNodeRemoval(node); return node; &#125; &#125; return null; &#125; /** * Removes all of the mappings from this map. * The map will be empty after this call returns. */ public void clear() &#123; Node&lt;K,V&gt;[] tab; modCount++; if ((tab = table) != null &amp;&amp; size &gt; 0) &#123; size = 0; for (int i = 0; i &lt; tab.length; ++i) tab[i] = null; &#125; &#125; /** * Returns &lt;tt&gt;true&lt;/tt&gt; if this map maps one or more keys to the * specified value. * * @param value value whose presence in this map is to be tested * @return &lt;tt&gt;true&lt;/tt&gt; if this map maps one or more keys to the * specified value */ public boolean containsValue(Object value) &#123; Node&lt;K,V&gt;[] tab; V v; if ((tab = table) != null &amp;&amp; size &gt; 0) &#123; for (int i = 0; i &lt; tab.length; ++i) &#123; for (Node&lt;K,V&gt; e = tab[i]; e != null; e = e.next) &#123; if ((v = e.value) == value || (value != null &amp;&amp; value.equals(v))) return true; &#125; &#125; &#125; return false; &#125; /** * Returns a &#123;@link Set&#125; view of the keys contained in this map. * The set is backed by the map, so changes to the map are * reflected in the set, and vice-versa. If the map is modified * while an iteration over the set is in progress (except through * the iterator's own &lt;tt&gt;remove&lt;/tt&gt; operation), the results of * the iteration are undefined. The set supports element removal, * which removes the corresponding mapping from the map, via the * &lt;tt&gt;Iterator.remove&lt;/tt&gt;, &lt;tt&gt;Set.remove&lt;/tt&gt;, * &lt;tt&gt;removeAll&lt;/tt&gt;, &lt;tt&gt;retainAll&lt;/tt&gt;, and &lt;tt&gt;clear&lt;/tt&gt; * operations. It does not support the &lt;tt&gt;add&lt;/tt&gt; or &lt;tt&gt;addAll&lt;/tt&gt; * operations. * * @return a set view of the keys contained in this map */ public Set&lt;K&gt; keySet() &#123; Set&lt;K&gt; ks = keySet; if (ks == null) &#123; ks = new KeySet(); keySet = ks; &#125; return ks; &#125; final class KeySet extends AbstractSet&lt;K&gt; &#123; public final int size() &#123; return size; &#125; public final void clear() &#123; HashMap.this.clear(); &#125; public final Iterator&lt;K&gt; iterator() &#123; return new KeyIterator(); &#125; public final boolean contains(Object o) &#123; return containsKey(o); &#125; public final boolean remove(Object key) &#123; return removeNode(hash(key), key, null, false, true) != null; &#125; public final Spliterator&lt;K&gt; spliterator() &#123; return new KeySpliterator&lt;&gt;(HashMap.this, 0, -1, 0, 0); &#125; public final void forEach(Consumer&lt;? super K&gt; action) &#123; Node&lt;K,V&gt;[] tab; if (action == null) throw new NullPointerException(); if (size &gt; 0 &amp;&amp; (tab = table) != null) &#123; int mc = modCount; for (int i = 0; i &lt; tab.length; ++i) &#123; for (Node&lt;K,V&gt; e = tab[i]; e != null; e = e.next) action.accept(e.key); &#125; if (modCount != mc) throw new ConcurrentModificationException(); &#125; &#125; &#125; /** * Returns a &#123;@link Collection&#125; view of the values contained in this map. * The collection is backed by the map, so changes to the map are * reflected in the collection, and vice-versa. If the map is * modified while an iteration over the collection is in progress * (except through the iterator's own &lt;tt&gt;remove&lt;/tt&gt; operation), * the results of the iteration are undefined. The collection * supports element removal, which removes the corresponding * mapping from the map, via the &lt;tt&gt;Iterator.remove&lt;/tt&gt;, * &lt;tt&gt;Collection.remove&lt;/tt&gt;, &lt;tt&gt;removeAll&lt;/tt&gt;, * &lt;tt&gt;retainAll&lt;/tt&gt; and &lt;tt&gt;clear&lt;/tt&gt; operations. It does not * support the &lt;tt&gt;add&lt;/tt&gt; or &lt;tt&gt;addAll&lt;/tt&gt; operations. * * @return a view of the values contained in this map */ public Collection&lt;V&gt; values() &#123; Collection&lt;V&gt; vs = values; if (vs == null) &#123; vs = new Values(); values = vs; &#125; return vs; &#125; final class Values extends AbstractCollection&lt;V&gt; &#123; public final int size() &#123; return size; &#125; public final void clear() &#123; HashMap.this.clear(); &#125; public final Iterator&lt;V&gt; iterator() &#123; return new ValueIterator(); &#125; public final boolean contains(Object o) &#123; return containsValue(o); &#125; public final Spliterator&lt;V&gt; spliterator() &#123; return new ValueSpliterator&lt;&gt;(HashMap.this, 0, -1, 0, 0); &#125; public final void forEach(Consumer&lt;? super V&gt; action) &#123; Node&lt;K,V&gt;[] tab; if (action == null) throw new NullPointerException(); if (size &gt; 0 &amp;&amp; (tab = table) != null) &#123; int mc = modCount; for (int i = 0; i &lt; tab.length; ++i) &#123; for (Node&lt;K,V&gt; e = tab[i]; e != null; e = e.next) action.accept(e.value); &#125; if (modCount != mc) throw new ConcurrentModificationException(); &#125; &#125; &#125; /** * Returns a &#123;@link Set&#125; view of the mappings contained in this map. * The set is backed by the map, so changes to the map are * reflected in the set, and vice-versa. If the map is modified * while an iteration over the set is in progress (except through * the iterator's own &lt;tt&gt;remove&lt;/tt&gt; operation, or through the * &lt;tt&gt;setValue&lt;/tt&gt; operation on a map entry returned by the * iterator) the results of the iteration are undefined. The set * supports element removal, which removes the corresponding * mapping from the map, via the &lt;tt&gt;Iterator.remove&lt;/tt&gt;, * &lt;tt&gt;Set.remove&lt;/tt&gt;, &lt;tt&gt;removeAll&lt;/tt&gt;, &lt;tt&gt;retainAll&lt;/tt&gt; and * &lt;tt&gt;clear&lt;/tt&gt; operations. It does not support the * &lt;tt&gt;add&lt;/tt&gt; or &lt;tt&gt;addAll&lt;/tt&gt; operations. * * @return a set view of the mappings contained in this map */ public Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet() &#123; Set&lt;Map.Entry&lt;K,V&gt;&gt; es; return (es = entrySet) == null ? (entrySet = new EntrySet()) : es; &#125; final class EntrySet extends AbstractSet&lt;Map.Entry&lt;K,V&gt;&gt; &#123; public final int size() &#123; return size; &#125; public final void clear() &#123; HashMap.this.clear(); &#125; public final Iterator&lt;Map.Entry&lt;K,V&gt;&gt; iterator() &#123; return new EntryIterator(); &#125; public final boolean contains(Object o) &#123; if (!(o instanceof Map.Entry)) return false; Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;) o; Object key = e.getKey(); Node&lt;K,V&gt; candidate = getNode(hash(key), key); return candidate != null &amp;&amp; candidate.equals(e); &#125; public final boolean remove(Object o) &#123; if (o instanceof Map.Entry) &#123; Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;) o; Object key = e.getKey(); Object value = e.getValue(); return removeNode(hash(key), key, value, true, true) != null; &#125; return false; &#125; public final Spliterator&lt;Map.Entry&lt;K,V&gt;&gt; spliterator() &#123; return new EntrySpliterator&lt;&gt;(HashMap.this, 0, -1, 0, 0); &#125; public final void forEach(Consumer&lt;? super Map.Entry&lt;K,V&gt;&gt; action) &#123; Node&lt;K,V&gt;[] tab; if (action == null) throw new NullPointerException(); if (size &gt; 0 &amp;&amp; (tab = table) != null) &#123; int mc = modCount; for (int i = 0; i &lt; tab.length; ++i) &#123; for (Node&lt;K,V&gt; e = tab[i]; e != null; e = e.next) action.accept(e); &#125; if (modCount != mc) throw new ConcurrentModificationException(); &#125; &#125; &#125; // Overrides of JDK8 Map extension methods @Override public V getOrDefault(Object key, V defaultValue) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? defaultValue : e.value; &#125; @Override public V putIfAbsent(K key, V value) &#123; return putVal(hash(key), key, value, true, true); &#125; @Override public boolean remove(Object key, Object value) &#123; return removeNode(hash(key), key, value, true, true) != null; &#125; @Override public boolean replace(K key, V oldValue, V newValue) &#123; Node&lt;K,V&gt; e; V v; if ((e = getNode(hash(key), key)) != null &amp;&amp; ((v = e.value) == oldValue || (v != null &amp;&amp; v.equals(oldValue)))) &#123; e.value = newValue; afterNodeAccess(e); return true; &#125; return false; &#125; @Override public V replace(K key, V value) &#123; Node&lt;K,V&gt; e; if ((e = getNode(hash(key), key)) != null) &#123; V oldValue = e.value; e.value = value; afterNodeAccess(e); return oldValue; &#125; return null; &#125; @Override public V computeIfAbsent(K key, Function&lt;? super K, ? extends V&gt; mappingFunction) &#123; if (mappingFunction == null) throw new NullPointerException(); int hash = hash(key); Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first; int n, i; int binCount = 0; TreeNode&lt;K,V&gt; t = null; Node&lt;K,V&gt; old = null; if (size &gt; threshold || (tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; if ((first = tab[i = (n - 1) &amp; hash]) != null) &#123; if (first instanceof TreeNode) old = (t = (TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); else &#123; Node&lt;K,V&gt; e = first; K k; do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) &#123; old = e; break; &#125; ++binCount; &#125; while ((e = e.next) != null); &#125; V oldValue; if (old != null &amp;&amp; (oldValue = old.value) != null) &#123; afterNodeAccess(old); return oldValue; &#125; &#125; V v = mappingFunction.apply(key); if (v == null) &#123; return null; &#125; else if (old != null) &#123; old.value = v; afterNodeAccess(old); return v; &#125; else if (t != null) t.putTreeVal(this, tab, hash, key, v); else &#123; tab[i] = newNode(hash, key, v, first); if (binCount &gt;= TREEIFY_THRESHOLD - 1) treeifyBin(tab, hash); &#125; ++modCount; ++size; afterNodeInsertion(true); return v; &#125; public V computeIfPresent(K key, BiFunction&lt;? super K, ? super V, ? extends V&gt; remappingFunction) &#123; if (remappingFunction == null) throw new NullPointerException(); Node&lt;K,V&gt; e; V oldValue; int hash = hash(key); if ((e = getNode(hash, key)) != null &amp;&amp; (oldValue = e.value) != null) &#123; V v = remappingFunction.apply(key, oldValue); if (v != null) &#123; e.value = v; afterNodeAccess(e); return v; &#125; else removeNode(hash, key, null, false, true); &#125; return null; &#125; @Override public V compute(K key, BiFunction&lt;? super K, ? super V, ? extends V&gt; remappingFunction) &#123; if (remappingFunction == null) throw new NullPointerException(); int hash = hash(key); Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first; int n, i; int binCount = 0; TreeNode&lt;K,V&gt; t = null; Node&lt;K,V&gt; old = null; if (size &gt; threshold || (tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; if ((first = tab[i = (n - 1) &amp; hash]) != null) &#123; if (first instanceof TreeNode) old = (t = (TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); else &#123; Node&lt;K,V&gt; e = first; K k; do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) &#123; old = e; break; &#125; ++binCount; &#125; while ((e = e.next) != null); &#125; &#125; V oldValue = (old == null) ? null : old.value; V v = remappingFunction.apply(key, oldValue); if (old != null) &#123; if (v != null) &#123; old.value = v; afterNodeAccess(old); &#125; else removeNode(hash, key, null, false, true); &#125; else if (v != null) &#123; if (t != null) t.putTreeVal(this, tab, hash, key, v); else &#123; tab[i] = newNode(hash, key, v, first); if (binCount &gt;= TREEIFY_THRESHOLD - 1) treeifyBin(tab, hash); &#125; ++modCount; ++size; afterNodeInsertion(true); &#125; return v; &#125; @Override public V merge(K key, V value, BiFunction&lt;? super V, ? super V, ? extends V&gt; remappingFunction) &#123; if (value == null) throw new NullPointerException(); if (remappingFunction == null) throw new NullPointerException(); int hash = hash(key); Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first; int n, i; int binCount = 0; TreeNode&lt;K,V&gt; t = null; Node&lt;K,V&gt; old = null; if (size &gt; threshold || (tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; if ((first = tab[i = (n - 1) &amp; hash]) != null) &#123; if (first instanceof TreeNode) old = (t = (TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); else &#123; Node&lt;K,V&gt; e = first; K k; do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) &#123; old = e; break; &#125; ++binCount; &#125; while ((e = e.next) != null); &#125; &#125; if (old != null) &#123; V v; if (old.value != null) v = remappingFunction.apply(old.value, value); else v = value; if (v != null) &#123; old.value = v; afterNodeAccess(old); &#125; else removeNode(hash, key, null, false, true); return v; &#125; if (value != null) &#123; if (t != null) t.putTreeVal(this, tab, hash, key, value); else &#123; tab[i] = newNode(hash, key, value, first); if (binCount &gt;= TREEIFY_THRESHOLD - 1) treeifyBin(tab, hash); &#125; ++modCount; ++size; afterNodeInsertion(true); &#125; return value; &#125; @Override public void forEach(BiConsumer&lt;? super K, ? super V&gt; action) &#123; Node&lt;K,V&gt;[] tab; if (action == null) throw new NullPointerException(); if (size &gt; 0 &amp;&amp; (tab = table) != null) &#123; int mc = modCount; for (int i = 0; i &lt; tab.length; ++i) &#123; for (Node&lt;K,V&gt; e = tab[i]; e != null; e = e.next) action.accept(e.key, e.value); &#125; if (modCount != mc) throw new ConcurrentModificationException(); &#125; &#125; @Override public void replaceAll(BiFunction&lt;? super K, ? super V, ? extends V&gt; function) &#123; Node&lt;K,V&gt;[] tab; if (function == null) throw new NullPointerException(); if (size &gt; 0 &amp;&amp; (tab = table) != null) &#123; int mc = modCount; for (int i = 0; i &lt; tab.length; ++i) &#123; for (Node&lt;K,V&gt; e = tab[i]; e != null; e = e.next) &#123; e.value = function.apply(e.key, e.value); &#125; &#125; if (modCount != mc) throw new ConcurrentModificationException(); &#125; &#125; /* ------------------------------------------------------------ */ // Cloning and serialization /** * Returns a shallow copy of this &lt;tt&gt;HashMap&lt;/tt&gt; instance: the keys and * values themselves are not cloned. * * @return a shallow copy of this map */ @SuppressWarnings("unchecked") @Override public Object clone() &#123; HashMap&lt;K,V&gt; result; try &#123; result = (HashMap&lt;K,V&gt;)super.clone(); &#125; catch (CloneNotSupportedException e) &#123; // this shouldn't happen, since we are Cloneable throw new InternalError(e); &#125; result.reinitialize(); result.putMapEntries(this, false); return result; &#125; // These methods are also used when serializing HashSets final float loadFactor() &#123; return loadFactor; &#125; final int capacity() &#123; return (table != null) ? table.length : (threshold &gt; 0) ? threshold : DEFAULT_INITIAL_CAPACITY; &#125; /** * Save the state of the &lt;tt&gt;HashMap&lt;/tt&gt; instance to a stream (i.e., * serialize it). * * @serialData The &lt;i&gt;capacity&lt;/i&gt; of the HashMap (the length of the * bucket array) is emitted (int), followed by the * &lt;i&gt;size&lt;/i&gt; (an int, the number of key-value * mappings), followed by the key (Object) and value (Object) * for each key-value mapping. The key-value mappings are * emitted in no particular order. */ private void writeObject(java.io.ObjectOutputStream s) throws IOException &#123; int buckets = capacity(); // Write out the threshold, loadfactor, and any hidden stuff s.defaultWriteObject(); s.writeInt(buckets); s.writeInt(size); internalWriteEntries(s); &#125; /** * Reconstitute the &#123;@code HashMap&#125; instance from a stream (i.e., * deserialize it). */ private void readObject(java.io.ObjectInputStream s) throws IOException, ClassNotFoundException &#123; // Read in the threshold (ignored), loadfactor, and any hidden stuff s.defaultReadObject(); reinitialize(); if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new InvalidObjectException("Illegal load factor: " + loadFactor); s.readInt(); // Read and ignore number of buckets int mappings = s.readInt(); // Read number of mappings (size) if (mappings &lt; 0) throw new InvalidObjectException("Illegal mappings count: " + mappings); else if (mappings &gt; 0) &#123; // (if zero, use defaults) // Size the table using given load factor only if within // range of 0.25...4.0 float lf = Math.min(Math.max(0.25f, loadFactor), 4.0f); float fc = (float)mappings / lf + 1.0f; int cap = ((fc &lt; DEFAULT_INITIAL_CAPACITY) ? DEFAULT_INITIAL_CAPACITY : (fc &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : tableSizeFor((int)fc)); float ft = (float)cap * lf; threshold = ((cap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; MAXIMUM_CAPACITY) ? (int)ft : Integer.MAX_VALUE); // Check Map.Entry[].class since it's the nearest public type to // what we're actually creating. SharedSecrets.getJavaOISAccess().checkArray(s, Map.Entry[].class, cap); @SuppressWarnings(&#123;"rawtypes","unchecked"&#125;) Node&lt;K,V&gt;[] tab = (Node&lt;K,V&gt;[])new Node[cap]; table = tab; // Read the keys and values, and put the mappings in the HashMap for (int i = 0; i &lt; mappings; i++) &#123; @SuppressWarnings("unchecked") K key = (K) s.readObject(); @SuppressWarnings("unchecked") V value = (V) s.readObject(); putVal(hash(key), key, value, false, false); &#125; &#125; &#125; /* ------------------------------------------------------------ */ // iterators abstract class HashIterator &#123; Node&lt;K,V&gt; next; // next entry to return Node&lt;K,V&gt; current; // current entry int expectedModCount; // for fast-fail int index; // current slot HashIterator() &#123; expectedModCount = modCount; Node&lt;K,V&gt;[] t = table; current = next = null; index = 0; if (t != null &amp;&amp; size &gt; 0) &#123; // advance to first entry do &#123;&#125; while (index &lt; t.length &amp;&amp; (next = t[index++]) == null); &#125; &#125; public final boolean hasNext() &#123; return next != null; &#125; final Node&lt;K,V&gt; nextNode() &#123; Node&lt;K,V&gt;[] t; Node&lt;K,V&gt; e = next; if (modCount != expectedModCount) throw new ConcurrentModificationException(); if (e == null) throw new NoSuchElementException(); if ((next = (current = e).next) == null &amp;&amp; (t = table) != null) &#123; do &#123;&#125; while (index &lt; t.length &amp;&amp; (next = t[index++]) == null); &#125; return e; &#125; public final void remove() &#123; Node&lt;K,V&gt; p = current; if (p == null) throw new IllegalStateException(); if (modCount != expectedModCount) throw new ConcurrentModificationException(); current = null; K key = p.key; removeNode(hash(key), key, null, false, false); expectedModCount = modCount; &#125; &#125; final class KeyIterator extends HashIterator implements Iterator&lt;K&gt; &#123; public final K next() &#123; return nextNode().key; &#125; &#125; final class ValueIterator extends HashIterator implements Iterator&lt;V&gt; &#123; public final V next() &#123; return nextNode().value; &#125; &#125; final class EntryIterator extends HashIterator implements Iterator&lt;Map.Entry&lt;K,V&gt;&gt; &#123; public final Map.Entry&lt;K,V&gt; next() &#123; return nextNode(); &#125; &#125; /* ------------------------------------------------------------ */ // spliterators static class HashMapSpliterator&lt;K,V&gt; &#123; final HashMap&lt;K,V&gt; map; Node&lt;K,V&gt; current; // current node int index; // current index, modified on advance/split int fence; // one past last index int est; // size estimate int expectedModCount; // for comodification checks HashMapSpliterator(HashMap&lt;K,V&gt; m, int origin, int fence, int est, int expectedModCount) &#123; this.map = m; this.index = origin; this.fence = fence; this.est = est; this.expectedModCount = expectedModCount; &#125; final int getFence() &#123; // initialize fence and size on first use int hi; if ((hi = fence) &lt; 0) &#123; HashMap&lt;K,V&gt; m = map; est = m.size; expectedModCount = m.modCount; Node&lt;K,V&gt;[] tab = m.table; hi = fence = (tab == null) ? 0 : tab.length; &#125; return hi; &#125; public final long estimateSize() &#123; getFence(); // force init return (long) est; &#125; &#125; static final class KeySpliterator&lt;K,V&gt; extends HashMapSpliterator&lt;K,V&gt; implements Spliterator&lt;K&gt; &#123; KeySpliterator(HashMap&lt;K,V&gt; m, int origin, int fence, int est, int expectedModCount) &#123; super(m, origin, fence, est, expectedModCount); &#125; public KeySpliterator&lt;K,V&gt; trySplit() &#123; int hi = getFence(), lo = index, mid = (lo + hi) &gt;&gt;&gt; 1; return (lo &gt;= mid || current != null) ? null : new KeySpliterator&lt;&gt;(map, lo, index = mid, est &gt;&gt;&gt;= 1, expectedModCount); &#125; public void forEachRemaining(Consumer&lt;? super K&gt; action) &#123; int i, hi, mc; if (action == null) throw new NullPointerException(); HashMap&lt;K,V&gt; m = map; Node&lt;K,V&gt;[] tab = m.table; if ((hi = fence) &lt; 0) &#123; mc = expectedModCount = m.modCount; hi = fence = (tab == null) ? 0 : tab.length; &#125; else mc = expectedModCount; if (tab != null &amp;&amp; tab.length &gt;= hi &amp;&amp; (i = index) &gt;= 0 &amp;&amp; (i &lt; (index = hi) || current != null)) &#123; Node&lt;K,V&gt; p = current; current = null; do &#123; if (p == null) p = tab[i++]; else &#123; action.accept(p.key); p = p.next; &#125; &#125; while (p != null || i &lt; hi); if (m.modCount != mc) throw new ConcurrentModificationException(); &#125; &#125; public boolean tryAdvance(Consumer&lt;? super K&gt; action) &#123; int hi; if (action == null) throw new NullPointerException(); Node&lt;K,V&gt;[] tab = map.table; if (tab != null &amp;&amp; tab.length &gt;= (hi = getFence()) &amp;&amp; index &gt;= 0) &#123; while (current != null || index &lt; hi) &#123; if (current == null) current = tab[index++]; else &#123; K k = current.key; current = current.next; action.accept(k); if (map.modCount != expectedModCount) throw new ConcurrentModificationException(); return true; &#125; &#125; &#125; return false; &#125; public int characteristics() &#123; return (fence &lt; 0 || est == map.size ? Spliterator.SIZED : 0) | Spliterator.DISTINCT; &#125; &#125; static final class ValueSpliterator&lt;K,V&gt; extends HashMapSpliterator&lt;K,V&gt; implements Spliterator&lt;V&gt; &#123; ValueSpliterator(HashMap&lt;K,V&gt; m, int origin, int fence, int est, int expectedModCount) &#123; super(m, origin, fence, est, expectedModCount); &#125; public ValueSpliterator&lt;K,V&gt; trySplit() &#123; int hi = getFence(), lo = index, mid = (lo + hi) &gt;&gt;&gt; 1; return (lo &gt;= mid || current != null) ? null : new ValueSpliterator&lt;&gt;(map, lo, index = mid, est &gt;&gt;&gt;= 1, expectedModCount); &#125; public void forEachRemaining(Consumer&lt;? super V&gt; action) &#123; int i, hi, mc; if (action == null) throw new NullPointerException(); HashMap&lt;K,V&gt; m = map; Node&lt;K,V&gt;[] tab = m.table; if ((hi = fence) &lt; 0) &#123; mc = expectedModCount = m.modCount; hi = fence = (tab == null) ? 0 : tab.length; &#125; else mc = expectedModCount; if (tab != null &amp;&amp; tab.length &gt;= hi &amp;&amp; (i = index) &gt;= 0 &amp;&amp; (i &lt; (index = hi) || current != null)) &#123; Node&lt;K,V&gt; p = current; current = null; do &#123; if (p == null) p = tab[i++]; else &#123; action.accept(p.value); p = p.next; &#125; &#125; while (p != null || i &lt; hi); if (m.modCount != mc) throw new ConcurrentModificationException(); &#125; &#125; public boolean tryAdvance(Consumer&lt;? super V&gt; action) &#123; int hi; if (action == null) throw new NullPointerException(); Node&lt;K,V&gt;[] tab = map.table; if (tab != null &amp;&amp; tab.length &gt;= (hi = getFence()) &amp;&amp; index &gt;= 0) &#123; while (current != null || index &lt; hi) &#123; if (current == null) current = tab[index++]; else &#123; V v = current.value; current = current.next; action.accept(v); if (map.modCount != expectedModCount) throw new ConcurrentModificationException(); return true; &#125; &#125; &#125; return false; &#125; public int characteristics() &#123; return (fence &lt; 0 || est == map.size ? Spliterator.SIZED : 0); &#125; &#125; static final class EntrySpliterator&lt;K,V&gt; extends HashMapSpliterator&lt;K,V&gt; implements Spliterator&lt;Map.Entry&lt;K,V&gt;&gt; &#123; EntrySpliterator(HashMap&lt;K,V&gt; m, int origin, int fence, int est, int expectedModCount) &#123; super(m, origin, fence, est, expectedModCount); &#125; public EntrySpliterator&lt;K,V&gt; trySplit() &#123; int hi = getFence(), lo = index, mid = (lo + hi) &gt;&gt;&gt; 1; return (lo &gt;= mid || current != null) ? null : new EntrySpliterator&lt;&gt;(map, lo, index = mid, est &gt;&gt;&gt;= 1, expectedModCount); &#125; public void forEachRemaining(Consumer&lt;? super Map.Entry&lt;K,V&gt;&gt; action) &#123; int i, hi, mc; if (action == null) throw new NullPointerException(); HashMap&lt;K,V&gt; m = map; Node&lt;K,V&gt;[] tab = m.table; if ((hi = fence) &lt; 0) &#123; mc = expectedModCount = m.modCount; hi = fence = (tab == null) ? 0 : tab.length; &#125; else mc = expectedModCount; if (tab != null &amp;&amp; tab.length &gt;= hi &amp;&amp; (i = index) &gt;= 0 &amp;&amp; (i &lt; (index = hi) || current != null)) &#123; Node&lt;K,V&gt; p = current; current = null; do &#123; if (p == null) p = tab[i++]; else &#123; action.accept(p); p = p.next; &#125; &#125; while (p != null || i &lt; hi); if (m.modCount != mc) throw new ConcurrentModificationException(); &#125; &#125; public boolean tryAdvance(Consumer&lt;? super Map.Entry&lt;K,V&gt;&gt; action) &#123; int hi; if (action == null) throw new NullPointerException(); Node&lt;K,V&gt;[] tab = map.table; if (tab != null &amp;&amp; tab.length &gt;= (hi = getFence()) &amp;&amp; index &gt;= 0) &#123; while (current != null || index &lt; hi) &#123; if (current == null) current = tab[index++]; else &#123; Node&lt;K,V&gt; e = current; current = current.next; action.accept(e); if (map.modCount != expectedModCount) throw new ConcurrentModificationException(); return true; &#125; &#125; &#125; return false; &#125; public int characteristics() &#123; return (fence &lt; 0 || est == map.size ? Spliterator.SIZED : 0) | Spliterator.DISTINCT; &#125; &#125; /* ------------------------------------------------------------ */ // LinkedHashMap support /* * The following package-protected methods are designed to be * overridden by LinkedHashMap, but not by any other subclass. * Nearly all other internal methods are also package-protected * but are declared final, so can be used by LinkedHashMap, view * classes, and HashSet. */ // Create a regular (non-tree) node Node&lt;K,V&gt; newNode(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; return new Node&lt;&gt;(hash, key, value, next); &#125; // For conversion from TreeNodes to plain nodes Node&lt;K,V&gt; replacementNode(Node&lt;K,V&gt; p, Node&lt;K,V&gt; next) &#123; return new Node&lt;&gt;(p.hash, p.key, p.value, next); &#125; // Create a tree bin node TreeNode&lt;K,V&gt; newTreeNode(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; return new TreeNode&lt;&gt;(hash, key, value, next); &#125; // For treeifyBin TreeNode&lt;K,V&gt; replacementTreeNode(Node&lt;K,V&gt; p, Node&lt;K,V&gt; next) &#123; return new TreeNode&lt;&gt;(p.hash, p.key, p.value, next); &#125; /** * Reset to initial default state. Called by clone and readObject. */ void reinitialize() &#123; table = null; entrySet = null; keySet = null; values = null; modCount = 0; threshold = 0; size = 0; &#125; // Callbacks to allow LinkedHashMap post-actions void afterNodeAccess(Node&lt;K,V&gt; p) &#123; &#125; void afterNodeInsertion(boolean evict) &#123; &#125; void afterNodeRemoval(Node&lt;K,V&gt; p) &#123; &#125; // Called only from writeObject, to ensure compatible ordering. void internalWriteEntries(java.io.ObjectOutputStream s) throws IOException &#123; Node&lt;K,V&gt;[] tab; if (size &gt; 0 &amp;&amp; (tab = table) != null) &#123; for (int i = 0; i &lt; tab.length; ++i) &#123; for (Node&lt;K,V&gt; e = tab[i]; e != null; e = e.next) &#123; s.writeObject(e.key); s.writeObject(e.value); &#125; &#125; &#125; &#125; /* ------------------------------------------------------------ */ // Tree bins /** * Entry for Tree bins. Extends LinkedHashMap.Entry (which in turn * extends Node) so can be used as extension of either regular or * linked node. */ static final class TreeNode&lt;K,V&gt; extends LinkedHashMap.Entry&lt;K,V&gt; &#123; TreeNode&lt;K,V&gt; parent; // red-black tree links TreeNode&lt;K,V&gt; left; TreeNode&lt;K,V&gt; right; TreeNode&lt;K,V&gt; prev; // needed to unlink next upon deletion boolean red; TreeNode(int hash, K key, V val, Node&lt;K,V&gt; next) &#123; super(hash, key, val, next); &#125; /** * Returns root of tree containing this node. */ final TreeNode&lt;K,V&gt; root() &#123; for (TreeNode&lt;K,V&gt; r = this, p;;) &#123; if ((p = r.parent) == null) return r; r = p; &#125; &#125; /** * Ensures that the given root is the first node of its bin. */ static &lt;K,V&gt; void moveRootToFront(Node&lt;K,V&gt;[] tab, TreeNode&lt;K,V&gt; root) &#123; int n; if (root != null &amp;&amp; tab != null &amp;&amp; (n = tab.length) &gt; 0) &#123; int index = (n - 1) &amp; root.hash; TreeNode&lt;K,V&gt; first = (TreeNode&lt;K,V&gt;)tab[index]; if (root != first) &#123; Node&lt;K,V&gt; rn; tab[index] = root; TreeNode&lt;K,V&gt; rp = root.prev; if ((rn = root.next) != null) ((TreeNode&lt;K,V&gt;)rn).prev = rp; if (rp != null) rp.next = rn; if (first != null) first.prev = root; root.next = first; root.prev = null; &#125; assert checkInvariants(root); &#125; &#125; /** * Finds the node starting at root p with the given hash and key. * The kc argument caches comparableClassFor(key) upon first use * comparing keys. */ final TreeNode&lt;K,V&gt; find(int h, Object k, Class&lt;?&gt; kc) &#123; TreeNode&lt;K,V&gt; p = this; do &#123; int ph, dir; K pk; TreeNode&lt;K,V&gt; pl = p.left, pr = p.right, q; if ((ph = p.hash) &gt; h) p = pl; else if (ph &lt; h) p = pr; else if ((pk = p.key) == k || (k != null &amp;&amp; k.equals(pk))) return p; else if (pl == null) p = pr; else if (pr == null) p = pl; else if ((kc != null || (kc = comparableClassFor(k)) != null) &amp;&amp; (dir = compareComparables(kc, k, pk)) != 0) p = (dir &lt; 0) ? pl : pr; else if ((q = pr.find(h, k, kc)) != null) return q; else p = pl; &#125; while (p != null); return null; &#125; /** * Calls find for root node. */ final TreeNode&lt;K,V&gt; getTreeNode(int h, Object k) &#123; return ((parent != null) ? root() : this).find(h, k, null); &#125; /** * Tie-breaking utility for ordering insertions when equal * hashCodes and non-comparable. We don't require a total * order, just a consistent insertion rule to maintain * equivalence across rebalancings. Tie-breaking further than * necessary simplifies testing a bit. */ static int tieBreakOrder(Object a, Object b) &#123; int d; if (a == null || b == null || (d = a.getClass().getName(). compareTo(b.getClass().getName())) == 0) d = (System.identityHashCode(a) &lt;= System.identityHashCode(b) ? -1 : 1); return d; &#125; /** * Forms tree of the nodes linked from this node. * @return root of tree */ final void treeify(Node&lt;K,V&gt;[] tab) &#123; TreeNode&lt;K,V&gt; root = null; for (TreeNode&lt;K,V&gt; x = this, next; x != null; x = next) &#123; next = (TreeNode&lt;K,V&gt;)x.next; x.left = x.right = null; if (root == null) &#123; x.parent = null; x.red = false; root = x; &#125; else &#123; K k = x.key; int h = x.hash; Class&lt;?&gt; kc = null; for (TreeNode&lt;K,V&gt; p = root;;) &#123; int dir, ph; K pk = p.key; if ((ph = p.hash) &gt; h) dir = -1; else if (ph &lt; h) dir = 1; else if ((kc == null &amp;&amp; (kc = comparableClassFor(k)) == null) || (dir = compareComparables(kc, k, pk)) == 0) dir = tieBreakOrder(k, pk); TreeNode&lt;K,V&gt; xp = p; if ((p = (dir &lt;= 0) ? p.left : p.right) == null) &#123; x.parent = xp; if (dir &lt;= 0) xp.left = x; else xp.right = x; root = balanceInsertion(root, x); break; &#125; &#125; &#125; &#125; moveRootToFront(tab, root); &#125; /** * Returns a list of non-TreeNodes replacing those linked from * this node. */ final Node&lt;K,V&gt; untreeify(HashMap&lt;K,V&gt; map) &#123; Node&lt;K,V&gt; hd = null, tl = null; for (Node&lt;K,V&gt; q = this; q != null; q = q.next) &#123; Node&lt;K,V&gt; p = map.replacementNode(q, null); if (tl == null) hd = p; else tl.next = p; tl = p; &#125; return hd; &#125; /** * Tree version of putVal. */ final TreeNode&lt;K,V&gt; putTreeVal(HashMap&lt;K,V&gt; map, Node&lt;K,V&gt;[] tab, int h, K k, V v) &#123; Class&lt;?&gt; kc = null; boolean searched = false; TreeNode&lt;K,V&gt; root = (parent != null) ? root() : this; for (TreeNode&lt;K,V&gt; p = root;;) &#123; int dir, ph; K pk; if ((ph = p.hash) &gt; h) dir = -1; else if (ph &lt; h) dir = 1; else if ((pk = p.key) == k || (k != null &amp;&amp; k.equals(pk))) return p; else if ((kc == null &amp;&amp; (kc = comparableClassFor(k)) == null) || (dir = compareComparables(kc, k, pk)) == 0) &#123; if (!searched) &#123; TreeNode&lt;K,V&gt; q, ch; searched = true; if (((ch = p.left) != null &amp;&amp; (q = ch.find(h, k, kc)) != null) || ((ch = p.right) != null &amp;&amp; (q = ch.find(h, k, kc)) != null)) return q; &#125; dir = tieBreakOrder(k, pk); &#125; TreeNode&lt;K,V&gt; xp = p; if ((p = (dir &lt;= 0) ? p.left : p.right) == null) &#123; Node&lt;K,V&gt; xpn = xp.next; TreeNode&lt;K,V&gt; x = map.newTreeNode(h, k, v, xpn); if (dir &lt;= 0) xp.left = x; else xp.right = x; xp.next = x; x.parent = x.prev = xp; if (xpn != null) ((TreeNode&lt;K,V&gt;)xpn).prev = x; moveRootToFront(tab, balanceInsertion(root, x)); return null; &#125; &#125; &#125; /** * Removes the given node, that must be present before this call. * This is messier than typical red-black deletion code because we * cannot swap the contents of an interior node with a leaf * successor that is pinned by "next" pointers that are accessible * independently during traversal. So instead we swap the tree * linkages. If the current tree appears to have too few nodes, * the bin is converted back to a plain bin. (The test triggers * somewhere between 2 and 6 nodes, depending on tree structure). */ final void removeTreeNode(HashMap&lt;K,V&gt; map, Node&lt;K,V&gt;[] tab, boolean movable) &#123; int n; if (tab == null || (n = tab.length) == 0) return; int index = (n - 1) &amp; hash; TreeNode&lt;K,V&gt; first = (TreeNode&lt;K,V&gt;)tab[index], root = first, rl; TreeNode&lt;K,V&gt; succ = (TreeNode&lt;K,V&gt;)next, pred = prev; if (pred == null) tab[index] = first = succ; else pred.next = succ; if (succ != null) succ.prev = pred; if (first == null) return; if (root.parent != null) root = root.root(); if (root == null || root.right == null || (rl = root.left) == null || rl.left == null) &#123; tab[index] = first.untreeify(map); // too small return; &#125; TreeNode&lt;K,V&gt; p = this, pl = left, pr = right, replacement; if (pl != null &amp;&amp; pr != null) &#123; TreeNode&lt;K,V&gt; s = pr, sl; while ((sl = s.left) != null) // find successor s = sl; boolean c = s.red; s.red = p.red; p.red = c; // swap colors TreeNode&lt;K,V&gt; sr = s.right; TreeNode&lt;K,V&gt; pp = p.parent; if (s == pr) &#123; // p was s's direct parent p.parent = s; s.right = p; &#125; else &#123; TreeNode&lt;K,V&gt; sp = s.parent; if ((p.parent = sp) != null) &#123; if (s == sp.left) sp.left = p; else sp.right = p; &#125; if ((s.right = pr) != null) pr.parent = s; &#125; p.left = null; if ((p.right = sr) != null) sr.parent = p; if ((s.left = pl) != null) pl.parent = s; if ((s.parent = pp) == null) root = s; else if (p == pp.left) pp.left = s; else pp.right = s; if (sr != null) replacement = sr; else replacement = p; &#125; else if (pl != null) replacement = pl; else if (pr != null) replacement = pr; else replacement = p; if (replacement != p) &#123; TreeNode&lt;K,V&gt; pp = replacement.parent = p.parent; if (pp == null) root = replacement; else if (p == pp.left) pp.left = replacement; else pp.right = replacement; p.left = p.right = p.parent = null; &#125; TreeNode&lt;K,V&gt; r = p.red ? root : balanceDeletion(root, replacement); if (replacement == p) &#123; // detach TreeNode&lt;K,V&gt; pp = p.parent; p.parent = null; if (pp != null) &#123; if (p == pp.left) pp.left = null; else if (p == pp.right) pp.right = null; &#125; &#125; if (movable) moveRootToFront(tab, r); &#125; /** * Splits nodes in a tree bin into lower and upper tree bins, * or untreeifies if now too small. Called only from resize; * see above discussion about split bits and indices. * * @param map the map * @param tab the table for recording bin heads * @param index the index of the table being split * @param bit the bit of hash to split on */ final void split(HashMap&lt;K,V&gt; map, Node&lt;K,V&gt;[] tab, int index, int bit) &#123; TreeNode&lt;K,V&gt; b = this; // Relink into lo and hi lists, preserving order TreeNode&lt;K,V&gt; loHead = null, loTail = null; TreeNode&lt;K,V&gt; hiHead = null, hiTail = null; int lc = 0, hc = 0; for (TreeNode&lt;K,V&gt; e = b, next; e != null; e = next) &#123; next = (TreeNode&lt;K,V&gt;)e.next; e.next = null; if ((e.hash &amp; bit) == 0) &#123; if ((e.prev = loTail) == null) loHead = e; else loTail.next = e; loTail = e; ++lc; &#125; else &#123; if ((e.prev = hiTail) == null) hiHead = e; else hiTail.next = e; hiTail = e; ++hc; &#125; &#125; if (loHead != null) &#123; if (lc &lt;= UNTREEIFY_THRESHOLD) tab[index] = loHead.untreeify(map); else &#123; tab[index] = loHead; if (hiHead != null) // (else is already treeified) loHead.treeify(tab); &#125; &#125; if (hiHead != null) &#123; if (hc &lt;= UNTREEIFY_THRESHOLD) tab[index + bit] = hiHead.untreeify(map); else &#123; tab[index + bit] = hiHead; if (loHead != null) hiHead.treeify(tab); &#125; &#125; &#125; /* ------------------------------------------------------------ */ // Red-black tree methods, all adapted from CLR static &lt;K,V&gt; TreeNode&lt;K,V&gt; rotateLeft(TreeNode&lt;K,V&gt; root, TreeNode&lt;K,V&gt; p) &#123; TreeNode&lt;K,V&gt; r, pp, rl; if (p != null &amp;&amp; (r = p.right) != null) &#123; if ((rl = p.right = r.left) != null) rl.parent = p; if ((pp = r.parent = p.parent) == null) (root = r).red = false; else if (pp.left == p) pp.left = r; else pp.right = r; r.left = p; p.parent = r; &#125; return root; &#125; static &lt;K,V&gt; TreeNode&lt;K,V&gt; rotateRight(TreeNode&lt;K,V&gt; root, TreeNode&lt;K,V&gt; p) &#123; TreeNode&lt;K,V&gt; l, pp, lr; if (p != null &amp;&amp; (l = p.left) != null) &#123; if ((lr = p.left = l.right) != null) lr.parent = p; if ((pp = l.parent = p.parent) == null) (root = l).red = false; else if (pp.right == p) pp.right = l; else pp.left = l; l.right = p; p.parent = l; &#125; return root; &#125; static &lt;K,V&gt; TreeNode&lt;K,V&gt; balanceInsertion(TreeNode&lt;K,V&gt; root, TreeNode&lt;K,V&gt; x) &#123; x.red = true; for (TreeNode&lt;K,V&gt; xp, xpp, xppl, xppr;;) &#123; if ((xp = x.parent) == null) &#123; x.red = false; return x; &#125; else if (!xp.red || (xpp = xp.parent) == null) return root; if (xp == (xppl = xpp.left)) &#123; if ((xppr = xpp.right) != null &amp;&amp; xppr.red) &#123; xppr.red = false; xp.red = false; xpp.red = true; x = xpp; &#125; else &#123; if (x == xp.right) &#123; root = rotateLeft(root, x = xp); xpp = (xp = x.parent) == null ? null : xp.parent; &#125; if (xp != null) &#123; xp.red = false; if (xpp != null) &#123; xpp.red = true; root = rotateRight(root, xpp); &#125; &#125; &#125; &#125; else &#123; if (xppl != null &amp;&amp; xppl.red) &#123; xppl.red = false; xp.red = false; xpp.red = true; x = xpp; &#125; else &#123; if (x == xp.left) &#123; root = rotateRight(root, x = xp); xpp = (xp = x.parent) == null ? null : xp.parent; &#125; if (xp != null) &#123; xp.red = false; if (xpp != null) &#123; xpp.red = true; root = rotateLeft(root, xpp); &#125; &#125; &#125; &#125; &#125; &#125; static &lt;K,V&gt; TreeNode&lt;K,V&gt; balanceDeletion(TreeNode&lt;K,V&gt; root, TreeNode&lt;K,V&gt; x) &#123; for (TreeNode&lt;K,V&gt; xp, xpl, xpr;;) &#123; if (x == null || x == root) return root; else if ((xp = x.parent) == null) &#123; x.red = false; return x; &#125; else if (x.red) &#123; x.red = false; return root; &#125; else if ((xpl = xp.left) == x) &#123; if ((xpr = xp.right) != null &amp;&amp; xpr.red) &#123; xpr.red = false; xp.red = true; root = rotateLeft(root, xp); xpr = (xp = x.parent) == null ? null : xp.right; &#125; if (xpr == null) x = xp; else &#123; TreeNode&lt;K,V&gt; sl = xpr.left, sr = xpr.right; if ((sr == null || !sr.red) &amp;&amp; (sl == null || !sl.red)) &#123; xpr.red = true; x = xp; &#125; else &#123; if (sr == null || !sr.red) &#123; if (sl != null) sl.red = false; xpr.red = true; root = rotateRight(root, xpr); xpr = (xp = x.parent) == null ? null : xp.right; &#125; if (xpr != null) &#123; xpr.red = (xp == null) ? false : xp.red; if ((sr = xpr.right) != null) sr.red = false; &#125; if (xp != null) &#123; xp.red = false; root = rotateLeft(root, xp); &#125; x = root; &#125; &#125; &#125; else &#123; // symmetric if (xpl != null &amp;&amp; xpl.red) &#123; xpl.red = false; xp.red = true; root = rotateRight(root, xp); xpl = (xp = x.parent) == null ? null : xp.left; &#125; if (xpl == null) x = xp; else &#123; TreeNode&lt;K,V&gt; sl = xpl.left, sr = xpl.right; if ((sl == null || !sl.red) &amp;&amp; (sr == null || !sr.red)) &#123; xpl.red = true; x = xp; &#125; else &#123; if (sl == null || !sl.red) &#123; if (sr != null) sr.red = false; xpl.red = true; root = rotateLeft(root, xpl); xpl = (xp = x.parent) == null ? null : xp.left; &#125; if (xpl != null) &#123; xpl.red = (xp == null) ? false : xp.red; if ((sl = xpl.left) != null) sl.red = false; &#125; if (xp != null) &#123; xp.red = false; root = rotateRight(root, xp); &#125; x = root; &#125; &#125; &#125; &#125; &#125; /** * Recursive invariant check */ static &lt;K,V&gt; boolean checkInvariants(TreeNode&lt;K,V&gt; t) &#123; TreeNode&lt;K,V&gt; tp = t.parent, tl = t.left, tr = t.right, tb = t.prev, tn = (TreeNode&lt;K,V&gt;)t.next; if (tb != null &amp;&amp; tb.next != t) return false; if (tn != null &amp;&amp; tn.prev != t) return false; if (tp != null &amp;&amp; t != tp.left &amp;&amp; t != tp.right) return false; if (tl != null &amp;&amp; (tl.parent != t || tl.hash &gt; t.hash)) return false; if (tr != null &amp;&amp; (tr.parent != t || tr.hash &lt; t.hash)) return false; if (t.red &amp;&amp; tl != null &amp;&amp; tl.red &amp;&amp; tr != null &amp;&amp; tr.red) return false; if (tl != null &amp;&amp; !checkInvariants(tl)) return false; if (tr != null &amp;&amp; !checkInvariants(tr)) return false; return true; &#125; &#125;&#125;]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2018%2F06%2F14%2Freading%2FHashMap%E6%BA%90%E7%A0%81%2F</url>
    <content type="text"><![CDATA[1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798991001011021031041051061071081091101111121131141151161171181191201211221231241251261271281291301311321331341351361371381391401411421431441451461471481491501511521531541551561571581591601611621631641651661671681691701711721731741751761771781791801811821831841851861871881891901911921931941951961971981992002012022032042052062072082092102112122132142152162172182192202212222232242252262272282292302312322332342352362372382392402412422432442452462472482492502512522532542552562572582592602612622632642652662672682692702712722732742752762772782792802812822832842852862872882892902912922932942952962972982993003013023033043053063073083093103113123133143153163173183193203213223233243253263273283293303313323333343353363373383393403413423433443453463473483493503513523533543553563573583593603613623633643653663673683693703713723733743753763773783793803813823833843853863873883893903913923933943953963973983994004014024034044054064074084094104114124134144154164174184194204214224234244254264274284294304314324334344354364374384394404414424434444454464474484494504514524534544554564574584594604614624634644654664674684694704714724734744754764774784794804814824834844854864874884894904914924934944954964974984995005015025035045055065075085095105115125135145155165175185195205215225235245255265275285295305315325335345355365375385395405415425435445455465475485495505515525535545555565575585595605615625635645655665675685695705715725735745755765775785795805815825835845855865875885895905915925935945955965975985996006016026036046056066076086096106116126136146156166176186196206216226236246256266276286296306316326336346356366376386396406416426436446456466476486496506516526536546556566576586596606616626636646656666676686696706716726736746756766776786796806816826836846856866876886896906916926936946956966976986997007017027037047057067077087097107117127137147157167177187197207217227237247257267277287297307317327337347357367377387397407417427437447457467477487497507517527537547557567577587597607617627637647657667677687697707717727737747757767777787797807817827837847857867877887897907917927937947957967977987998008018028038048058068078088098108118128138148158168178188198208218228238248258268278288298308318328338348358368378388398408418428438448458468478488498508518528538548558568578588598608618628638648658668678688698708718728738748758768778788798808818828838848858868878888898908918928938948958968978988999009019029039049059069079089099109119129139149159169179189199209219229239249259269279289299309319329339349359369379389399409419429439449459469479489499509519529539549559569579589599609619629639649659669679689699709719729739749759769779789799809819829839849859869879889899909919929939949959969979989991000100110021003100410051006100710081009101010111012101310141015101610171018101910201021102210231024102510261027102810291030103110321033103410351036103710381039104010411042104310441045104610471048104910501051105210531054105510561057105810591060106110621063106410651066106710681069107010711072107310741075107610771078107910801081108210831084108510861087108810891090109110921093109410951096109710981099110011011102110311041105110611071108110911101111111211131114111511161117111811191120112111221123112411251126112711281129113011311132113311341135113611371138113911401141114211431144114511461147114811491150115111521153115411551156115711581159116011611162116311641165116611671168116911701171117211731174117511761177117811791180118111821183118411851186118711881189119011911192119311941195119611971198119912001201120212031204120512061207120812091210121112121213121412151216121712181219122012211222122312241225122612271228122912301231123212331234123512361237123812391240124112421243124412451246124712481249125012511252125312541255125612571258125912601261126212631264126512661267126812691270127112721273127412751276127712781279128012811282128312841285128612871288128912901291129212931294129512961297129812991300130113021303130413051306130713081309131013111312131313141315131613171318131913201321132213231324132513261327132813291330133113321333133413351336133713381339134013411342134313441345134613471348134913501351135213531354135513561357135813591360136113621363136413651366136713681369137013711372137313741375137613771378137913801381138213831384138513861387138813891390139113921393139413951396139713981399140014011402140314041405140614071408140914101411141214131414141514161417141814191420142114221423142414251426142714281429143014311432143314341435143614371438143914401441144214431444144514461447144814491450145114521453145414551456145714581459146014611462146314641465146614671468146914701471147214731474147514761477147814791480148114821483148414851486148714881489149014911492149314941495149614971498149915001501150215031504150515061507150815091510151115121513151415151516151715181519152015211522152315241525152615271528152915301531153215331534153515361537153815391540154115421543154415451546154715481549155015511552155315541555155615571558155915601561156215631564156515661567156815691570157115721573157415751576157715781579158015811582158315841585158615871588158915901591159215931594159515961597159815991600160116021603160416051606160716081609161016111612161316141615161616171618161916201621162216231624162516261627162816291630163116321633163416351636163716381639164016411642164316441645164616471648164916501651165216531654165516561657165816591660166116621663166416651666166716681669167016711672167316741675167616771678167916801681168216831684168516861687168816891690169116921693169416951696169716981699170017011702170317041705170617071708170917101711171217131714171517161717171817191720172117221723172417251726172717281729173017311732173317341735173617371738173917401741174217431744174517461747174817491750175117521753175417551756175717581759176017611762176317641765176617671768176917701771177217731774177517761777177817791780178117821783178417851786178717881789179017911792179317941795179617971798179918001801180218031804180518061807180818091810181118121813181418151816181718181819182018211822182318241825182618271828182918301831183218331834183518361837183818391840184118421843184418451846184718481849185018511852185318541855185618571858185918601861186218631864186518661867186818691870187118721873187418751876187718781879188018811882188318841885188618871888188918901891189218931894189518961897189818991900190119021903190419051906190719081909191019111912191319141915191619171918191919201921192219231924192519261927192819291930193119321933193419351936193719381939194019411942194319441945194619471948194919501951195219531954195519561957195819591960196119621963196419651966196719681969197019711972197319741975197619771978197919801981198219831984198519861987198819891990199119921993199419951996199719981999200020012002200320042005200620072008200920102011201220132014201520162017201820192020202120222023202420252026202720282029203020312032203320342035203620372038203920402041204220432044204520462047204820492050205120522053205420552056205720582059206020612062206320642065206620672068206920702071207220732074207520762077207820792080208120822083208420852086208720882089209020912092209320942095209620972098209921002101210221032104210521062107210821092110211121122113211421152116211721182119212021212122212321242125212621272128212921302131213221332134213521362137213821392140214121422143214421452146214721482149215021512152215321542155215621572158215921602161216221632164216521662167216821692170217121722173217421752176217721782179218021812182218321842185218621872188218921902191219221932194219521962197219821992200220122022203220422052206220722082209221022112212221322142215221622172218221922202221222222232224222522262227222822292230223122322233223422352236223722382239224022412242224322442245224622472248224922502251225222532254225522562257225822592260226122622263226422652266226722682269227022712272227322742275227622772278227922802281228222832284228522862287228822892290229122922293229422952296package java.util;import java.io.IOException;import java.io.InvalidObjectException;import java.io.Serializable;import java.lang.reflect.ParameterizedType;import java.lang.reflect.Type;import java.util.function.BiConsumer;import java.util.function.BiFunction;import java.util.function.Consumer;import java.util.function.Function;import sun.misc.SharedSecrets;/** *这是基于哈希表Map接口的实现。这个实现提供了所有Map的方法还允许键值为空。(HashMap类 *大致的和HashTable类一致，除了HashMap是非同步的和可以允许为空)HashMap是非稳定性的 *所以它不会保证它的顺序不会改变。 * * &lt;p&gt;This implementation provides constant-time performance for the basic * operations (&lt;tt&gt;get&lt;/tt&gt; and &lt;tt&gt;put&lt;/tt&gt;), assuming the hash function * disperses the elements properly among the buckets. Iteration over * collection views requires time proportional to the "capacity" of the * &lt;tt&gt;HashMap&lt;/tt&gt; instance (the number of buckets) plus its size (the number * of key-value mappings). Thus, it's very important not to set the initial * capacity too high (or the load factor too low) if iteration performance is * important. * * &lt;p&gt;An instance of &lt;tt&gt;HashMap&lt;/tt&gt; has two parameters that affect its * performance: &lt;i&gt;initial capacity&lt;/i&gt; and &lt;i&gt;load factor&lt;/i&gt;. The * &lt;i&gt;capacity&lt;/i&gt; is the number of buckets in the hash table, and the initial * capacity is simply the capacity at the time the hash table is created. The * &lt;i&gt;load factor&lt;/i&gt; is a measure of how full the hash table is allowed to * get before its capacity is automatically increased. When the number of * entries in the hash table exceeds the product of the load factor and the * current capacity, the hash table is &lt;i&gt;rehashed&lt;/i&gt; (that is, internal data * structures are rebuilt) so that the hash table has approximately twice the * number of buckets. * * &lt;p&gt;As a general rule, the default load factor (.75) offers a good * tradeoff between time and space costs. Higher values decrease the * space overhead but increase the lookup cost (reflected in most of * the operations of the &lt;tt&gt;HashMap&lt;/tt&gt; class, including * &lt;tt&gt;get&lt;/tt&gt; and &lt;tt&gt;put&lt;/tt&gt;). The expected number of entries in * the map and its load factor should be taken into account when * setting its initial capacity, so as to minimize the number of * rehash operations. If the initial capacity is greater than the * maximum number of entries divided by the load factor, no rehash * operations will ever occur. * * &lt;p&gt;If many mappings are to be stored in a &lt;tt&gt;HashMap&lt;/tt&gt; * instance, creating it with a sufficiently large capacity will allow * the mappings to be stored more efficiently than letting it perform * automatic rehashing as needed to grow the table. Note that using * many keys with the same &#123;@code hashCode()&#125; is a sure way to slow * down performance of any hash table. To ameliorate impact, when keys * are &#123;@link Comparable&#125;, this class may use comparison order among * keys to help break ties. * * &lt;p&gt;&lt;strong&gt;Note that this implementation is not synchronized.&lt;/strong&gt; * If multiple threads access a hash map concurrently, and at least one of * the threads modifies the map structurally, it &lt;i&gt;must&lt;/i&gt; be * synchronized externally. (A structural modification is any operation * that adds or deletes one or more mappings; merely changing the value * associated with a key that an instance already contains is not a * structural modification.) This is typically accomplished by * synchronizing on some object that naturally encapsulates the map. * * If no such object exists, the map should be "wrapped" using the * &#123;@link Collections#synchronizedMap Collections.synchronizedMap&#125; * method. This is best done at creation time, to prevent accidental * unsynchronized access to the map:&lt;pre&gt; * Map m = Collections.synchronizedMap(new HashMap(...));&lt;/pre&gt; * * &lt;p&gt;The iterators returned by all of this class's "collection view methods" * are &lt;i&gt;fail-fast&lt;/i&gt;: if the map is structurally modified at any time after * the iterator is created, in any way except through the iterator's own * &lt;tt&gt;remove&lt;/tt&gt; method, the iterator will throw a * &#123;@link ConcurrentModificationException&#125;. Thus, in the face of concurrent * modification, the iterator fails quickly and cleanly, rather than risking * arbitrary, non-deterministic behavior at an undetermined time in the * future. * * &lt;p&gt;Note that the fail-fast behavior of an iterator cannot be guaranteed * as it is, generally speaking, impossible to make any hard guarantees in the * presence of unsynchronized concurrent modification. Fail-fast iterators * throw &lt;tt&gt;ConcurrentModificationException&lt;/tt&gt; on a best-effort basis. * Therefore, it would be wrong to write a program that depended on this * exception for its correctness: &lt;i&gt;the fail-fast behavior of iterators * should be used only to detect bugs.&lt;/i&gt; * * &lt;p&gt;This class is a member of the * &lt;a href="&#123;@docRoot&#125;/../technotes/guides/collections/index.html"&gt; * Java Collections Framework&lt;/a&gt;. * * @param &lt;K&gt; the type of keys maintained by this map * @param &lt;V&gt; the type of mapped values */public class HashMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements Map&lt;K,V&gt;, Cloneable, Serializable &#123; private static final long serialVersionUID = 362498820763181265L; /* * 实施说明。 这个映射通常作为一个binned（bucketed）哈希表，但是当bin变得太大时，它们被转换成TreeNodes的仓，每个仓都与java.util.TreeMap中的结构类似。大多数方法都尝试使用正常的bin，但在适用时转发给TreeNode方法（仅通过检查节点的instanceof）。 TreeNodes的bin可以像任何其他的一样遍历和使用，但是当人口过多时还支持更快的查找。然而，由于绝大多数正常使用的垃圾箱没有人口过多，因此在表格方法过程中可能会延迟检查树木垃圾箱的存在。 树元素（即元素都是TreeNode的元素）主要由hashCode来排序，但在关系的情况下，如果两个元素具有相同的“类C实现Comparable &lt;C&gt;”，则键入它们的compareTo方法用于排序。 （我们通过反射保守地检查泛型来验证这一点 - 请参阅可比较的类格式）。当密钥具有不同的哈希值或可订购时，提供最坏情况下的O（log n）操作是增值的，因此，在意外或恶意使用情况下，hashCode（）方法返回的值不佳分布式以及许多密钥共享一个hashCode，只要它们也是Comparable。 （如果这些都不适用，那么与没有采取预防措施相比，我们可能会浪费大约两倍的时间和空间，但唯一已知的情况来自不良用户编程实践，这些实践已经非常缓慢，几乎没有什么区别。） 由于TreeNodes大约是常规节点大小的两倍，因此我们仅在容器包含足够的节点以保证使用时才使用它们（请参阅TREEIFY_THRESHOLD）。当它们变得太小（由于去除或调整大小），它们被转换回普通箱。在具有分布良好的用户散列码的用法中，很少使用树形容器。理想情况下，在随机hashCodes下，bin中节点的频率遵循Poisson分布（http：en.wikipedia.org wiki Poisson_distribution），平均默认调整大小阈值为0.75，参数平均为0.5，但由于调整粒度。忽略方差，列表大小k的预期发生是（exp（-0.5）pow（0.5，k）阶乘（k））。第一个值是： 0：0.60653066 1：0.30326533 2：0.07581633 3：0.01263606 4：0.00157952 5：0.00015795 6：0.00001316 7：0.00000094 8：0.00000006 更多：千万不到1 树仓的根通常是其第一个节点。但是，有时（目前仅在Iterator.remove上），根可能在别处，但可以在父链接（方法TreeNode.root（））后恢复。 所有适用的内部方法都接受一个散列码作为参数（通常由公共方法提供），允许它们互相呼叫而不用重新计算用户散列码。大多数内部方法也接受一个“标签”参数，通常是当前表格，但在调整大小或转换时可能是新的或旧的。 当bin列表被树化，分裂或者未被指定时，我们使它们保持相同的相对访问遍历顺序（即字段Node.next）以更好地保持局部性，并略微简化调用iterator.remove的分割和遍历的处理。在插入时使用比较器时，为了保持整个rebalancings中的总体排序（或尽可能接近此处），我们将类和identityHashCodes作为比较搭配断路器。 由于存在子类LinkedHashMap，在普通模式和树模式之间的使用和转换变得复杂了。请参阅下面的钩子方法，这些钩子方法被定义为在插入，移除和访问时被调用，以允许LinkedHashMap内部部件保持独立于这些机制。 （这也要求映射实例被传递给可能创建新节点的一些实用方法。） 类似于并发编程的基于SSA的编码风格有助于避免所有扭曲的指针操作中的别名错误。 */ /** * The default initial capacity - MUST be a power of two. */ static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // aka 16 /** * The maximum capacity, used if a higher value is implicitly specified * by either of the constructors with arguments. * MUST be a power of two &lt;= 1&lt;&lt;30. */ static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30; /** * The load factor used when none specified in constructor. */ static final float DEFAULT_LOAD_FACTOR = 0.75f; /** * The bin count threshold for using a tree rather than list for a * bin. Bins are converted to trees when adding an element to a * bin with at least this many nodes. The value must be greater * than 2 and should be at least 8 to mesh with assumptions in * tree removal about conversion back to plain bins upon * shrinkage. */ static final int TREEIFY_THRESHOLD = 8; /** * The bin count threshold for untreeifying a (split) bin during a * resize operation. Should be less than TREEIFY_THRESHOLD, and at * most 6 to mesh with shrinkage detection under removal. */ static final int UNTREEIFY_THRESHOLD = 6; /** * The smallest table capacity for which bins may be treeified. * (Otherwise the table is resized if too many nodes in a bin.) * Should be at least 4 * TREEIFY_THRESHOLD to avoid conflicts * between resizing and treeification thresholds. */ static final int MIN_TREEIFY_CAPACITY = 64; /** * Basic hash bin node, used for most entries. (See below for * TreeNode subclass, and in LinkedHashMap for its Entry subclass.) */ static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; final K key; V value; Node&lt;K,V&gt; next; Node(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; this.hash = hash; this.key = key; this.value = value; this.next = next; &#125; public final K getKey() &#123; return key; &#125; public final V getValue() &#123; return value; &#125; public final String toString() &#123; return key + "=" + value; &#125; public final int hashCode() &#123; return Objects.hashCode(key) ^ Objects.hashCode(value); &#125; public final V setValue(V newValue) &#123; V oldValue = value; value = newValue; return oldValue; &#125; public final boolean equals(Object o) &#123; if (o == this) return true; if (o instanceof Map.Entry) &#123; Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;)o; if (Objects.equals(key, e.getKey()) &amp;&amp; Objects.equals(value, e.getValue())) return true; &#125; return false; &#125; &#125; /* ---------------- Static utilities -------------- */ /** * Computes key.hashCode() and spreads (XORs) higher bits of hash * to lower. Because the table uses power-of-two masking, sets of * hashes that vary only in bits above the current mask will * always collide. (Among known examples are sets of Float keys * holding consecutive whole numbers in small tables.) So we * apply a transform that spreads the impact of higher bits * downward. There is a tradeoff between speed, utility, and * quality of bit-spreading. Because many common sets of hashes * are already reasonably distributed (so don't benefit from * spreading), and because we use trees to handle large sets of * collisions in bins, we just XOR some shifted bits in the * cheapest possible way to reduce systematic lossage, as well as * to incorporate impact of the highest bits that would otherwise * never be used in index calculations because of table bounds. */ static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16); &#125; /** * Returns x's Class if it is of the form "class C implements * Comparable&lt;C&gt;", else null. */ static Class&lt;?&gt; comparableClassFor(Object x) &#123; if (x instanceof Comparable) &#123; Class&lt;?&gt; c; Type[] ts, as; Type t; ParameterizedType p; if ((c = x.getClass()) == String.class) // bypass checks return c; if ((ts = c.getGenericInterfaces()) != null) &#123; for (int i = 0; i &lt; ts.length; ++i) &#123; if (((t = ts[i]) instanceof ParameterizedType) &amp;&amp; ((p = (ParameterizedType)t).getRawType() == Comparable.class) &amp;&amp; (as = p.getActualTypeArguments()) != null &amp;&amp; as.length == 1 &amp;&amp; as[0] == c) // type arg is c return c; &#125; &#125; &#125; return null; &#125; /** * Returns k.compareTo(x) if x matches kc (k's screened comparable * class), else 0. */ @SuppressWarnings(&#123;"rawtypes","unchecked"&#125;) // for cast to Comparable static int compareComparables(Class&lt;?&gt; kc, Object k, Object x) &#123; return (x == null || x.getClass() != kc ? 0 : ((Comparable)k).compareTo(x)); &#125; /** * Returns a power of two size for the given target capacity. */ static final int tableSizeFor(int cap) &#123; int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1; &#125; /* ---------------- Fields -------------- */ /** * The table, initialized on first use, and resized as * necessary. When allocated, length is always a power of two. * (We also tolerate length zero in some operations to allow * bootstrapping mechanics that are currently not needed.) */ transient Node&lt;K,V&gt;[] table; /** * Holds cached entrySet(). Note that AbstractMap fields are used * for keySet() and values(). */ transient Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet; /** * The number of key-value mappings contained in this map. */ transient int size; /** * The number of times this HashMap has been structurally modified * Structural modifications are those that change the number of mappings in * the HashMap or otherwise modify its internal structure (e.g., * rehash). This field is used to make iterators on Collection-views of * the HashMap fail-fast. (See ConcurrentModificationException). */ transient int modCount; /** * The next size value at which to resize (capacity * load factor). * * @serial */ // (The javadoc description is true upon serialization. // Additionally, if the table array has not been allocated, this // field holds the initial array capacity, or zero signifying // DEFAULT_INITIAL_CAPACITY.) int threshold; /** * The load factor for the hash table. * * @serial */ final float loadFactor; /* ---------------- Public operations -------------- */ /** * Constructs an empty &lt;tt&gt;HashMap&lt;/tt&gt; with the specified initial * capacity and load factor. * * @param initialCapacity the initial capacity * @param loadFactor the load factor * @throws IllegalArgumentException if the initial capacity is negative * or the load factor is nonpositive */ public HashMap(int initialCapacity, float loadFactor) &#123; if (initialCapacity &lt; 0) throw new IllegalArgumentException("Illegal initial capacity: " + initialCapacity); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException("Illegal load factor: " + loadFactor); this.loadFactor = loadFactor; this.threshold = tableSizeFor(initialCapacity); &#125; /** * Constructs an empty &lt;tt&gt;HashMap&lt;/tt&gt; with the specified initial * capacity and the default load factor (0.75). * * @param initialCapacity the initial capacity. * @throws IllegalArgumentException if the initial capacity is negative. */ public HashMap(int initialCapacity) &#123; this(initialCapacity, DEFAULT_LOAD_FACTOR); &#125; /** * Constructs an empty &lt;tt&gt;HashMap&lt;/tt&gt; with the default initial capacity * (16) and the default load factor (0.75). */ public HashMap() &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted &#125; /** * Constructs a new &lt;tt&gt;HashMap&lt;/tt&gt; with the same mappings as the * specified &lt;tt&gt;Map&lt;/tt&gt;. The &lt;tt&gt;HashMap&lt;/tt&gt; is created with * default load factor (0.75) and an initial capacity sufficient to * hold the mappings in the specified &lt;tt&gt;Map&lt;/tt&gt;. * * @param m the map whose mappings are to be placed in this map * @throws NullPointerException if the specified map is null */ public HashMap(Map&lt;? extends K, ? extends V&gt; m) &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; putMapEntries(m, false); &#125; /** * Implements Map.putAll and Map constructor * * @param m the map * @param evict false when initially constructing this map, else * true (relayed to method afterNodeInsertion). */ final void putMapEntries(Map&lt;? extends K, ? extends V&gt; m, boolean evict) &#123; int s = m.size(); if (s &gt; 0) &#123; if (table == null) &#123; // pre-size float ft = ((float)s / loadFactor) + 1.0F; int t = ((ft &lt; (float)MAXIMUM_CAPACITY) ? (int)ft : MAXIMUM_CAPACITY); if (t &gt; threshold) threshold = tableSizeFor(t); &#125; else if (s &gt; threshold) resize(); for (Map.Entry&lt;? extends K, ? extends V&gt; e : m.entrySet()) &#123; K key = e.getKey(); V value = e.getValue(); putVal(hash(key), key, value, false, evict); &#125; &#125; &#125; /** * Returns the number of key-value mappings in this map. * * @return the number of key-value mappings in this map */ public int size() &#123; return size; &#125; /** * Returns &lt;tt&gt;true&lt;/tt&gt; if this map contains no key-value mappings. * * @return &lt;tt&gt;true&lt;/tt&gt; if this map contains no key-value mappings */ public boolean isEmpty() &#123; return size == 0; &#125; /** * Returns the value to which the specified key is mapped, * or &#123;@code null&#125; if this map contains no mapping for the key. * * &lt;p&gt;More formally, if this map contains a mapping from a key * &#123;@code k&#125; to a value &#123;@code v&#125; such that &#123;@code (key==null ? k==null : * key.equals(k))&#125;, then this method returns &#123;@code v&#125;; otherwise * it returns &#123;@code null&#125;. (There can be at most one such mapping.) * * &lt;p&gt;A return value of &#123;@code null&#125; does not &lt;i&gt;necessarily&lt;/i&gt; * indicate that the map contains no mapping for the key; it's also * possible that the map explicitly maps the key to &#123;@code null&#125;. * The &#123;@link #containsKey containsKey&#125; operation may be used to * distinguish these two cases. * * @see #put(Object, Object) */ public V get(Object key) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value; &#125; /** * Implements Map.get and related methods * * @param hash hash for key * @param key the key * @return the node, or null if none */ final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; if ((e = first.next) != null) &#123; if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; return null; &#125; /** * Returns &lt;tt&gt;true&lt;/tt&gt; if this map contains a mapping for the * specified key. * * @param key The key whose presence in this map is to be tested * @return &lt;tt&gt;true&lt;/tt&gt; if this map contains a mapping for the specified * key. */ public boolean containsKey(Object key) &#123; return getNode(hash(key), key) != null; &#125; /** * Associates the specified value with the specified key in this map. * If the map previously contained a mapping for the key, the old * value is replaced. * * @param key key with which the specified value is to be associated * @param value value to be associated with the specified key * @return the previous value associated with &lt;tt&gt;key&lt;/tt&gt;, or * &lt;tt&gt;null&lt;/tt&gt; if there was no mapping for &lt;tt&gt;key&lt;/tt&gt;. * (A &lt;tt&gt;null&lt;/tt&gt; return can also indicate that the map * previously associated &lt;tt&gt;null&lt;/tt&gt; with &lt;tt&gt;key&lt;/tt&gt;.) */ public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true); &#125; /** * Implements Map.put and related methods * * @param hash hash for key * @param key the key * @param value the value to put * @param onlyIfAbsent if true, don't change existing value * @param evict if false, the table is in creation mode. * @return previous value, or null if none */ final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else &#123; Node&lt;K,V&gt; e; K k; if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else &#123; for (int binCount = 0; ; ++binCount) &#123; if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; ++modCount; if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null; &#125; /** * Initializes or doubles table size. If null, allocates in * accord with initial capacity target held in field threshold. * Otherwise, because we are using power-of-two expansion, the * elements from each bin must either stay at same index, or move * with a power of two offset in the new table. * * @return the table */ final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; if (oldCap &gt; 0) &#123; if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold &#125; else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; else &#123; // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; threshold = newThr; @SuppressWarnings(&#123;"rawtypes","unchecked"&#125;) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; if (oldTab != null) &#123; for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123; oldTab[j] = null; if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else &#123; // preserve order Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; next = e.next; if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab; &#125; /** * Replaces all linked nodes in bin at index for given hash unless * table is too small, in which case resizes instead. */ final void treeifyBin(Node&lt;K,V&gt;[] tab, int hash) &#123; int n, index; Node&lt;K,V&gt; e; if (tab == null || (n = tab.length) &lt; MIN_TREEIFY_CAPACITY) resize(); else if ((e = tab[index = (n - 1) &amp; hash]) != null) &#123; TreeNode&lt;K,V&gt; hd = null, tl = null; do &#123; TreeNode&lt;K,V&gt; p = replacementTreeNode(e, null); if (tl == null) hd = p; else &#123; p.prev = tl; tl.next = p; &#125; tl = p; &#125; while ((e = e.next) != null); if ((tab[index] = hd) != null) hd.treeify(tab); &#125; &#125; /** * Copies all of the mappings from the specified map to this map. * These mappings will replace any mappings that this map had for * any of the keys currently in the specified map. * * @param m mappings to be stored in this map * @throws NullPointerException if the specified map is null */ public void putAll(Map&lt;? extends K, ? extends V&gt; m) &#123; putMapEntries(m, true); &#125; /** * Removes the mapping for the specified key from this map if present. * * @param key key whose mapping is to be removed from the map * @return the previous value associated with &lt;tt&gt;key&lt;/tt&gt;, or * &lt;tt&gt;null&lt;/tt&gt; if there was no mapping for &lt;tt&gt;key&lt;/tt&gt;. * (A &lt;tt&gt;null&lt;/tt&gt; return can also indicate that the map * previously associated &lt;tt&gt;null&lt;/tt&gt; with &lt;tt&gt;key&lt;/tt&gt;.) */ public V remove(Object key) &#123; Node&lt;K,V&gt; e; return (e = removeNode(hash(key), key, null, false, true)) == null ? null : e.value; &#125; /** * Implements Map.remove and related methods * * @param hash hash for key * @param key the key * @param value the value to match if matchValue, else ignored * @param matchValue if true only remove if value is equal * @param movable if false do not move other nodes while removing * @return the node, or null if none */ final Node&lt;K,V&gt; removeNode(int hash, Object key, Object value, boolean matchValue, boolean movable) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, index; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (p = tab[index = (n - 1) &amp; hash]) != null) &#123; Node&lt;K,V&gt; node = null, e; K k; V v; if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) node = p; else if ((e = p.next) != null) &#123; if (p instanceof TreeNode) node = ((TreeNode&lt;K,V&gt;)p).getTreeNode(hash, key); else &#123; do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) &#123; node = e; break; &#125; p = e; &#125; while ((e = e.next) != null); &#125; &#125; if (node != null &amp;&amp; (!matchValue || (v = node.value) == value || (value != null &amp;&amp; value.equals(v)))) &#123; if (node instanceof TreeNode) ((TreeNode&lt;K,V&gt;)node).removeTreeNode(this, tab, movable); else if (node == p) tab[index] = node.next; else p.next = node.next; ++modCount; --size; afterNodeRemoval(node); return node; &#125; &#125; return null; &#125; /** * Removes all of the mappings from this map. * The map will be empty after this call returns. */ public void clear() &#123; Node&lt;K,V&gt;[] tab; modCount++; if ((tab = table) != null &amp;&amp; size &gt; 0) &#123; size = 0; for (int i = 0; i &lt; tab.length; ++i) tab[i] = null; &#125; &#125; /** * Returns &lt;tt&gt;true&lt;/tt&gt; if this map maps one or more keys to the * specified value. * * @param value value whose presence in this map is to be tested * @return &lt;tt&gt;true&lt;/tt&gt; if this map maps one or more keys to the * specified value */ public boolean containsValue(Object value) &#123; Node&lt;K,V&gt;[] tab; V v; if ((tab = table) != null &amp;&amp; size &gt; 0) &#123; for (int i = 0; i &lt; tab.length; ++i) &#123; for (Node&lt;K,V&gt; e = tab[i]; e != null; e = e.next) &#123; if ((v = e.value) == value || (value != null &amp;&amp; value.equals(v))) return true; &#125; &#125; &#125; return false; &#125; /** * Returns a &#123;@link Set&#125; view of the keys contained in this map. * The set is backed by the map, so changes to the map are * reflected in the set, and vice-versa. If the map is modified * while an iteration over the set is in progress (except through * the iterator's own &lt;tt&gt;remove&lt;/tt&gt; operation), the results of * the iteration are undefined. The set supports element removal, * which removes the corresponding mapping from the map, via the * &lt;tt&gt;Iterator.remove&lt;/tt&gt;, &lt;tt&gt;Set.remove&lt;/tt&gt;, * &lt;tt&gt;removeAll&lt;/tt&gt;, &lt;tt&gt;retainAll&lt;/tt&gt;, and &lt;tt&gt;clear&lt;/tt&gt; * operations. It does not support the &lt;tt&gt;add&lt;/tt&gt; or &lt;tt&gt;addAll&lt;/tt&gt; * operations. * * @return a set view of the keys contained in this map */ public Set&lt;K&gt; keySet() &#123; Set&lt;K&gt; ks = keySet; if (ks == null) &#123; ks = new KeySet(); keySet = ks; &#125; return ks; &#125; final class KeySet extends AbstractSet&lt;K&gt; &#123; public final int size() &#123; return size; &#125; public final void clear() &#123; HashMap.this.clear(); &#125; public final Iterator&lt;K&gt; iterator() &#123; return new KeyIterator(); &#125; public final boolean contains(Object o) &#123; return containsKey(o); &#125; public final boolean remove(Object key) &#123; return removeNode(hash(key), key, null, false, true) != null; &#125; public final Spliterator&lt;K&gt; spliterator() &#123; return new KeySpliterator&lt;&gt;(HashMap.this, 0, -1, 0, 0); &#125; public final void forEach(Consumer&lt;? super K&gt; action) &#123; Node&lt;K,V&gt;[] tab; if (action == null) throw new NullPointerException(); if (size &gt; 0 &amp;&amp; (tab = table) != null) &#123; int mc = modCount; for (int i = 0; i &lt; tab.length; ++i) &#123; for (Node&lt;K,V&gt; e = tab[i]; e != null; e = e.next) action.accept(e.key); &#125; if (modCount != mc) throw new ConcurrentModificationException(); &#125; &#125; &#125; /** * Returns a &#123;@link Collection&#125; view of the values contained in this map. * The collection is backed by the map, so changes to the map are * reflected in the collection, and vice-versa. If the map is * modified while an iteration over the collection is in progress * (except through the iterator's own &lt;tt&gt;remove&lt;/tt&gt; operation), * the results of the iteration are undefined. The collection * supports element removal, which removes the corresponding * mapping from the map, via the &lt;tt&gt;Iterator.remove&lt;/tt&gt;, * &lt;tt&gt;Collection.remove&lt;/tt&gt;, &lt;tt&gt;removeAll&lt;/tt&gt;, * &lt;tt&gt;retainAll&lt;/tt&gt; and &lt;tt&gt;clear&lt;/tt&gt; operations. It does not * support the &lt;tt&gt;add&lt;/tt&gt; or &lt;tt&gt;addAll&lt;/tt&gt; operations. * * @return a view of the values contained in this map */ public Collection&lt;V&gt; values() &#123; Collection&lt;V&gt; vs = values; if (vs == null) &#123; vs = new Values(); values = vs; &#125; return vs; &#125; final class Values extends AbstractCollection&lt;V&gt; &#123; public final int size() &#123; return size; &#125; public final void clear() &#123; HashMap.this.clear(); &#125; public final Iterator&lt;V&gt; iterator() &#123; return new ValueIterator(); &#125; public final boolean contains(Object o) &#123; return containsValue(o); &#125; public final Spliterator&lt;V&gt; spliterator() &#123; return new ValueSpliterator&lt;&gt;(HashMap.this, 0, -1, 0, 0); &#125; public final void forEach(Consumer&lt;? super V&gt; action) &#123; Node&lt;K,V&gt;[] tab; if (action == null) throw new NullPointerException(); if (size &gt; 0 &amp;&amp; (tab = table) != null) &#123; int mc = modCount; for (int i = 0; i &lt; tab.length; ++i) &#123; for (Node&lt;K,V&gt; e = tab[i]; e != null; e = e.next) action.accept(e.value); &#125; if (modCount != mc) throw new ConcurrentModificationException(); &#125; &#125; &#125; /** * Returns a &#123;@link Set&#125; view of the mappings contained in this map. * The set is backed by the map, so changes to the map are * reflected in the set, and vice-versa. If the map is modified * while an iteration over the set is in progress (except through * the iterator's own &lt;tt&gt;remove&lt;/tt&gt; operation, or through the * &lt;tt&gt;setValue&lt;/tt&gt; operation on a map entry returned by the * iterator) the results of the iteration are undefined. The set * supports element removal, which removes the corresponding * mapping from the map, via the &lt;tt&gt;Iterator.remove&lt;/tt&gt;, * &lt;tt&gt;Set.remove&lt;/tt&gt;, &lt;tt&gt;removeAll&lt;/tt&gt;, &lt;tt&gt;retainAll&lt;/tt&gt; and * &lt;tt&gt;clear&lt;/tt&gt; operations. It does not support the * &lt;tt&gt;add&lt;/tt&gt; or &lt;tt&gt;addAll&lt;/tt&gt; operations. * * @return a set view of the mappings contained in this map */ public Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet() &#123; Set&lt;Map.Entry&lt;K,V&gt;&gt; es; return (es = entrySet) == null ? (entrySet = new EntrySet()) : es; &#125; final class EntrySet extends AbstractSet&lt;Map.Entry&lt;K,V&gt;&gt; &#123; public final int size() &#123; return size; &#125; public final void clear() &#123; HashMap.this.clear(); &#125; public final Iterator&lt;Map.Entry&lt;K,V&gt;&gt; iterator() &#123; return new EntryIterator(); &#125; public final boolean contains(Object o) &#123; if (!(o instanceof Map.Entry)) return false; Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;) o; Object key = e.getKey(); Node&lt;K,V&gt; candidate = getNode(hash(key), key); return candidate != null &amp;&amp; candidate.equals(e); &#125; public final boolean remove(Object o) &#123; if (o instanceof Map.Entry) &#123; Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;) o; Object key = e.getKey(); Object value = e.getValue(); return removeNode(hash(key), key, value, true, true) != null; &#125; return false; &#125; public final Spliterator&lt;Map.Entry&lt;K,V&gt;&gt; spliterator() &#123; return new EntrySpliterator&lt;&gt;(HashMap.this, 0, -1, 0, 0); &#125; public final void forEach(Consumer&lt;? super Map.Entry&lt;K,V&gt;&gt; action) &#123; Node&lt;K,V&gt;[] tab; if (action == null) throw new NullPointerException(); if (size &gt; 0 &amp;&amp; (tab = table) != null) &#123; int mc = modCount; for (int i = 0; i &lt; tab.length; ++i) &#123; for (Node&lt;K,V&gt; e = tab[i]; e != null; e = e.next) action.accept(e); &#125; if (modCount != mc) throw new ConcurrentModificationException(); &#125; &#125; &#125; // Overrides of JDK8 Map extension methods @Override public V getOrDefault(Object key, V defaultValue) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? defaultValue : e.value; &#125; @Override public V putIfAbsent(K key, V value) &#123; return putVal(hash(key), key, value, true, true); &#125; @Override public boolean remove(Object key, Object value) &#123; return removeNode(hash(key), key, value, true, true) != null; &#125; @Override public boolean replace(K key, V oldValue, V newValue) &#123; Node&lt;K,V&gt; e; V v; if ((e = getNode(hash(key), key)) != null &amp;&amp; ((v = e.value) == oldValue || (v != null &amp;&amp; v.equals(oldValue)))) &#123; e.value = newValue; afterNodeAccess(e); return true; &#125; return false; &#125; @Override public V replace(K key, V value) &#123; Node&lt;K,V&gt; e; if ((e = getNode(hash(key), key)) != null) &#123; V oldValue = e.value; e.value = value; afterNodeAccess(e); return oldValue; &#125; return null; &#125; @Override public V computeIfAbsent(K key, Function&lt;? super K, ? extends V&gt; mappingFunction) &#123; if (mappingFunction == null) throw new NullPointerException(); int hash = hash(key); Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first; int n, i; int binCount = 0; TreeNode&lt;K,V&gt; t = null; Node&lt;K,V&gt; old = null; if (size &gt; threshold || (tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; if ((first = tab[i = (n - 1) &amp; hash]) != null) &#123; if (first instanceof TreeNode) old = (t = (TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); else &#123; Node&lt;K,V&gt; e = first; K k; do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) &#123; old = e; break; &#125; ++binCount; &#125; while ((e = e.next) != null); &#125; V oldValue; if (old != null &amp;&amp; (oldValue = old.value) != null) &#123; afterNodeAccess(old); return oldValue; &#125; &#125; V v = mappingFunction.apply(key); if (v == null) &#123; return null; &#125; else if (old != null) &#123; old.value = v; afterNodeAccess(old); return v; &#125; else if (t != null) t.putTreeVal(this, tab, hash, key, v); else &#123; tab[i] = newNode(hash, key, v, first); if (binCount &gt;= TREEIFY_THRESHOLD - 1) treeifyBin(tab, hash); &#125; ++modCount; ++size; afterNodeInsertion(true); return v; &#125; public V computeIfPresent(K key, BiFunction&lt;? super K, ? super V, ? extends V&gt; remappingFunction) &#123; if (remappingFunction == null) throw new NullPointerException(); Node&lt;K,V&gt; e; V oldValue; int hash = hash(key); if ((e = getNode(hash, key)) != null &amp;&amp; (oldValue = e.value) != null) &#123; V v = remappingFunction.apply(key, oldValue); if (v != null) &#123; e.value = v; afterNodeAccess(e); return v; &#125; else removeNode(hash, key, null, false, true); &#125; return null; &#125; @Override public V compute(K key, BiFunction&lt;? super K, ? super V, ? extends V&gt; remappingFunction) &#123; if (remappingFunction == null) throw new NullPointerException(); int hash = hash(key); Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first; int n, i; int binCount = 0; TreeNode&lt;K,V&gt; t = null; Node&lt;K,V&gt; old = null; if (size &gt; threshold || (tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; if ((first = tab[i = (n - 1) &amp; hash]) != null) &#123; if (first instanceof TreeNode) old = (t = (TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); else &#123; Node&lt;K,V&gt; e = first; K k; do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) &#123; old = e; break; &#125; ++binCount; &#125; while ((e = e.next) != null); &#125; &#125; V oldValue = (old == null) ? null : old.value; V v = remappingFunction.apply(key, oldValue); if (old != null) &#123; if (v != null) &#123; old.value = v; afterNodeAccess(old); &#125; else removeNode(hash, key, null, false, true); &#125; else if (v != null) &#123; if (t != null) t.putTreeVal(this, tab, hash, key, v); else &#123; tab[i] = newNode(hash, key, v, first); if (binCount &gt;= TREEIFY_THRESHOLD - 1) treeifyBin(tab, hash); &#125; ++modCount; ++size; afterNodeInsertion(true); &#125; return v; &#125; @Override public V merge(K key, V value, BiFunction&lt;? super V, ? super V, ? extends V&gt; remappingFunction) &#123; if (value == null) throw new NullPointerException(); if (remappingFunction == null) throw new NullPointerException(); int hash = hash(key); Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first; int n, i; int binCount = 0; TreeNode&lt;K,V&gt; t = null; Node&lt;K,V&gt; old = null; if (size &gt; threshold || (tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; if ((first = tab[i = (n - 1) &amp; hash]) != null) &#123; if (first instanceof TreeNode) old = (t = (TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); else &#123; Node&lt;K,V&gt; e = first; K k; do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) &#123; old = e; break; &#125; ++binCount; &#125; while ((e = e.next) != null); &#125; &#125; if (old != null) &#123; V v; if (old.value != null) v = remappingFunction.apply(old.value, value); else v = value; if (v != null) &#123; old.value = v; afterNodeAccess(old); &#125; else removeNode(hash, key, null, false, true); return v; &#125; if (value != null) &#123; if (t != null) t.putTreeVal(this, tab, hash, key, value); else &#123; tab[i] = newNode(hash, key, value, first); if (binCount &gt;= TREEIFY_THRESHOLD - 1) treeifyBin(tab, hash); &#125; ++modCount; ++size; afterNodeInsertion(true); &#125; return value; &#125; @Override public void forEach(BiConsumer&lt;? super K, ? super V&gt; action) &#123; Node&lt;K,V&gt;[] tab; if (action == null) throw new NullPointerException(); if (size &gt; 0 &amp;&amp; (tab = table) != null) &#123; int mc = modCount; for (int i = 0; i &lt; tab.length; ++i) &#123; for (Node&lt;K,V&gt; e = tab[i]; e != null; e = e.next) action.accept(e.key, e.value); &#125; if (modCount != mc) throw new ConcurrentModificationException(); &#125; &#125; @Override public void replaceAll(BiFunction&lt;? super K, ? super V, ? extends V&gt; function) &#123; Node&lt;K,V&gt;[] tab; if (function == null) throw new NullPointerException(); if (size &gt; 0 &amp;&amp; (tab = table) != null) &#123; int mc = modCount; for (int i = 0; i &lt; tab.length; ++i) &#123; for (Node&lt;K,V&gt; e = tab[i]; e != null; e = e.next) &#123; e.value = function.apply(e.key, e.value); &#125; &#125; if (modCount != mc) throw new ConcurrentModificationException(); &#125; &#125; /* ------------------------------------------------------------ */ // Cloning and serialization /** * Returns a shallow copy of this &lt;tt&gt;HashMap&lt;/tt&gt; instance: the keys and * values themselves are not cloned. * * @return a shallow copy of this map */ @SuppressWarnings("unchecked") @Override public Object clone() &#123; HashMap&lt;K,V&gt; result; try &#123; result = (HashMap&lt;K,V&gt;)super.clone(); &#125; catch (CloneNotSupportedException e) &#123; // this shouldn't happen, since we are Cloneable throw new InternalError(e); &#125; result.reinitialize(); result.putMapEntries(this, false); return result; &#125; // These methods are also used when serializing HashSets final float loadFactor() &#123; return loadFactor; &#125; final int capacity() &#123; return (table != null) ? table.length : (threshold &gt; 0) ? threshold : DEFAULT_INITIAL_CAPACITY; &#125; /** * Save the state of the &lt;tt&gt;HashMap&lt;/tt&gt; instance to a stream (i.e., * serialize it). * * @serialData The &lt;i&gt;capacity&lt;/i&gt; of the HashMap (the length of the * bucket array) is emitted (int), followed by the * &lt;i&gt;size&lt;/i&gt; (an int, the number of key-value * mappings), followed by the key (Object) and value (Object) * for each key-value mapping. The key-value mappings are * emitted in no particular order. */ private void writeObject(java.io.ObjectOutputStream s) throws IOException &#123; int buckets = capacity(); // Write out the threshold, loadfactor, and any hidden stuff s.defaultWriteObject(); s.writeInt(buckets); s.writeInt(size); internalWriteEntries(s); &#125; /** * Reconstitute the &#123;@code HashMap&#125; instance from a stream (i.e., * deserialize it). */ private void readObject(java.io.ObjectInputStream s) throws IOException, ClassNotFoundException &#123; // Read in the threshold (ignored), loadfactor, and any hidden stuff s.defaultReadObject(); reinitialize(); if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new InvalidObjectException("Illegal load factor: " + loadFactor); s.readInt(); // Read and ignore number of buckets int mappings = s.readInt(); // Read number of mappings (size) if (mappings &lt; 0) throw new InvalidObjectException("Illegal mappings count: " + mappings); else if (mappings &gt; 0) &#123; // (if zero, use defaults) // Size the table using given load factor only if within // range of 0.25...4.0 float lf = Math.min(Math.max(0.25f, loadFactor), 4.0f); float fc = (float)mappings / lf + 1.0f; int cap = ((fc &lt; DEFAULT_INITIAL_CAPACITY) ? DEFAULT_INITIAL_CAPACITY : (fc &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : tableSizeFor((int)fc)); float ft = (float)cap * lf; threshold = ((cap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; MAXIMUM_CAPACITY) ? (int)ft : Integer.MAX_VALUE); // Check Map.Entry[].class since it's the nearest public type to // what we're actually creating. SharedSecrets.getJavaOISAccess().checkArray(s, Map.Entry[].class, cap); @SuppressWarnings(&#123;"rawtypes","unchecked"&#125;) Node&lt;K,V&gt;[] tab = (Node&lt;K,V&gt;[])new Node[cap]; table = tab; // Read the keys and values, and put the mappings in the HashMap for (int i = 0; i &lt; mappings; i++) &#123; @SuppressWarnings("unchecked") K key = (K) s.readObject(); @SuppressWarnings("unchecked") V value = (V) s.readObject(); putVal(hash(key), key, value, false, false); &#125; &#125; &#125; /* ------------------------------------------------------------ */ // iterators abstract class HashIterator &#123; Node&lt;K,V&gt; next; // next entry to return Node&lt;K,V&gt; current; // current entry int expectedModCount; // for fast-fail int index; // current slot HashIterator() &#123; expectedModCount = modCount; Node&lt;K,V&gt;[] t = table; current = next = null; index = 0; if (t != null &amp;&amp; size &gt; 0) &#123; // advance to first entry do &#123;&#125; while (index &lt; t.length &amp;&amp; (next = t[index++]) == null); &#125; &#125; public final boolean hasNext() &#123; return next != null; &#125; final Node&lt;K,V&gt; nextNode() &#123; Node&lt;K,V&gt;[] t; Node&lt;K,V&gt; e = next; if (modCount != expectedModCount) throw new ConcurrentModificationException(); if (e == null) throw new NoSuchElementException(); if ((next = (current = e).next) == null &amp;&amp; (t = table) != null) &#123; do &#123;&#125; while (index &lt; t.length &amp;&amp; (next = t[index++]) == null); &#125; return e; &#125; public final void remove() &#123; Node&lt;K,V&gt; p = current; if (p == null) throw new IllegalStateException(); if (modCount != expectedModCount) throw new ConcurrentModificationException(); current = null; K key = p.key; removeNode(hash(key), key, null, false, false); expectedModCount = modCount; &#125; &#125; final class KeyIterator extends HashIterator implements Iterator&lt;K&gt; &#123; public final K next() &#123; return nextNode().key; &#125; &#125; final class ValueIterator extends HashIterator implements Iterator&lt;V&gt; &#123; public final V next() &#123; return nextNode().value; &#125; &#125; final class EntryIterator extends HashIterator implements Iterator&lt;Map.Entry&lt;K,V&gt;&gt; &#123; public final Map.Entry&lt;K,V&gt; next() &#123; return nextNode(); &#125; &#125; /* ------------------------------------------------------------ */ // spliterators static class HashMapSpliterator&lt;K,V&gt; &#123; final HashMap&lt;K,V&gt; map; Node&lt;K,V&gt; current; // current node int index; // current index, modified on advance/split int fence; // one past last index int est; // size estimate int expectedModCount; // for comodification checks HashMapSpliterator(HashMap&lt;K,V&gt; m, int origin, int fence, int est, int expectedModCount) &#123; this.map = m; this.index = origin; this.fence = fence; this.est = est; this.expectedModCount = expectedModCount; &#125; final int getFence() &#123; // initialize fence and size on first use int hi; if ((hi = fence) &lt; 0) &#123; HashMap&lt;K,V&gt; m = map; est = m.size; expectedModCount = m.modCount; Node&lt;K,V&gt;[] tab = m.table; hi = fence = (tab == null) ? 0 : tab.length; &#125; return hi; &#125; public final long estimateSize() &#123; getFence(); // force init return (long) est; &#125; &#125; static final class KeySpliterator&lt;K,V&gt; extends HashMapSpliterator&lt;K,V&gt; implements Spliterator&lt;K&gt; &#123; KeySpliterator(HashMap&lt;K,V&gt; m, int origin, int fence, int est, int expectedModCount) &#123; super(m, origin, fence, est, expectedModCount); &#125; public KeySpliterator&lt;K,V&gt; trySplit() &#123; int hi = getFence(), lo = index, mid = (lo + hi) &gt;&gt;&gt; 1; return (lo &gt;= mid || current != null) ? null : new KeySpliterator&lt;&gt;(map, lo, index = mid, est &gt;&gt;&gt;= 1, expectedModCount); &#125; public void forEachRemaining(Consumer&lt;? super K&gt; action) &#123; int i, hi, mc; if (action == null) throw new NullPointerException(); HashMap&lt;K,V&gt; m = map; Node&lt;K,V&gt;[] tab = m.table; if ((hi = fence) &lt; 0) &#123; mc = expectedModCount = m.modCount; hi = fence = (tab == null) ? 0 : tab.length; &#125; else mc = expectedModCount; if (tab != null &amp;&amp; tab.length &gt;= hi &amp;&amp; (i = index) &gt;= 0 &amp;&amp; (i &lt; (index = hi) || current != null)) &#123; Node&lt;K,V&gt; p = current; current = null; do &#123; if (p == null) p = tab[i++]; else &#123; action.accept(p.key); p = p.next; &#125; &#125; while (p != null || i &lt; hi); if (m.modCount != mc) throw new ConcurrentModificationException(); &#125; &#125; public boolean tryAdvance(Consumer&lt;? super K&gt; action) &#123; int hi; if (action == null) throw new NullPointerException(); Node&lt;K,V&gt;[] tab = map.table; if (tab != null &amp;&amp; tab.length &gt;= (hi = getFence()) &amp;&amp; index &gt;= 0) &#123; while (current != null || index &lt; hi) &#123; if (current == null) current = tab[index++]; else &#123; K k = current.key; current = current.next; action.accept(k); if (map.modCount != expectedModCount) throw new ConcurrentModificationException(); return true; &#125; &#125; &#125; return false; &#125; public int characteristics() &#123; return (fence &lt; 0 || est == map.size ? Spliterator.SIZED : 0) | Spliterator.DISTINCT; &#125; &#125; static final class ValueSpliterator&lt;K,V&gt; extends HashMapSpliterator&lt;K,V&gt; implements Spliterator&lt;V&gt; &#123; ValueSpliterator(HashMap&lt;K,V&gt; m, int origin, int fence, int est, int expectedModCount) &#123; super(m, origin, fence, est, expectedModCount); &#125; public ValueSpliterator&lt;K,V&gt; trySplit() &#123; int hi = getFence(), lo = index, mid = (lo + hi) &gt;&gt;&gt; 1; return (lo &gt;= mid || current != null) ? null : new ValueSpliterator&lt;&gt;(map, lo, index = mid, est &gt;&gt;&gt;= 1, expectedModCount); &#125; public void forEachRemaining(Consumer&lt;? super V&gt; action) &#123; int i, hi, mc; if (action == null) throw new NullPointerException(); HashMap&lt;K,V&gt; m = map; Node&lt;K,V&gt;[] tab = m.table; if ((hi = fence) &lt; 0) &#123; mc = expectedModCount = m.modCount; hi = fence = (tab == null) ? 0 : tab.length; &#125; else mc = expectedModCount; if (tab != null &amp;&amp; tab.length &gt;= hi &amp;&amp; (i = index) &gt;= 0 &amp;&amp; (i &lt; (index = hi) || current != null)) &#123; Node&lt;K,V&gt; p = current; current = null; do &#123; if (p == null) p = tab[i++]; else &#123; action.accept(p.value); p = p.next; &#125; &#125; while (p != null || i &lt; hi); if (m.modCount != mc) throw new ConcurrentModificationException(); &#125; &#125; public boolean tryAdvance(Consumer&lt;? super V&gt; action) &#123; int hi; if (action == null) throw new NullPointerException(); Node&lt;K,V&gt;[] tab = map.table; if (tab != null &amp;&amp; tab.length &gt;= (hi = getFence()) &amp;&amp; index &gt;= 0) &#123; while (current != null || index &lt; hi) &#123; if (current == null) current = tab[index++]; else &#123; V v = current.value; current = current.next; action.accept(v); if (map.modCount != expectedModCount) throw new ConcurrentModificationException(); return true; &#125; &#125; &#125; return false; &#125; public int characteristics() &#123; return (fence &lt; 0 || est == map.size ? Spliterator.SIZED : 0); &#125; &#125; static final class EntrySpliterator&lt;K,V&gt; extends HashMapSpliterator&lt;K,V&gt; implements Spliterator&lt;Map.Entry&lt;K,V&gt;&gt; &#123; EntrySpliterator(HashMap&lt;K,V&gt; m, int origin, int fence, int est, int expectedModCount) &#123; super(m, origin, fence, est, expectedModCount); &#125; public EntrySpliterator&lt;K,V&gt; trySplit() &#123; int hi = getFence(), lo = index, mid = (lo + hi) &gt;&gt;&gt; 1; return (lo &gt;= mid || current != null) ? null : new EntrySpliterator&lt;&gt;(map, lo, index = mid, est &gt;&gt;&gt;= 1, expectedModCount); &#125; public void forEachRemaining(Consumer&lt;? super Map.Entry&lt;K,V&gt;&gt; action) &#123; int i, hi, mc; if (action == null) throw new NullPointerException(); HashMap&lt;K,V&gt; m = map; Node&lt;K,V&gt;[] tab = m.table; if ((hi = fence) &lt; 0) &#123; mc = expectedModCount = m.modCount; hi = fence = (tab == null) ? 0 : tab.length; &#125; else mc = expectedModCount; if (tab != null &amp;&amp; tab.length &gt;= hi &amp;&amp; (i = index) &gt;= 0 &amp;&amp; (i &lt; (index = hi) || current != null)) &#123; Node&lt;K,V&gt; p = current; current = null; do &#123; if (p == null) p = tab[i++]; else &#123; action.accept(p); p = p.next; &#125; &#125; while (p != null || i &lt; hi); if (m.modCount != mc) throw new ConcurrentModificationException(); &#125; &#125; public boolean tryAdvance(Consumer&lt;? super Map.Entry&lt;K,V&gt;&gt; action) &#123; int hi; if (action == null) throw new NullPointerException(); Node&lt;K,V&gt;[] tab = map.table; if (tab != null &amp;&amp; tab.length &gt;= (hi = getFence()) &amp;&amp; index &gt;= 0) &#123; while (current != null || index &lt; hi) &#123; if (current == null) current = tab[index++]; else &#123; Node&lt;K,V&gt; e = current; current = current.next; action.accept(e); if (map.modCount != expectedModCount) throw new ConcurrentModificationException(); return true; &#125; &#125; &#125; return false; &#125; public int characteristics() &#123; return (fence &lt; 0 || est == map.size ? Spliterator.SIZED : 0) | Spliterator.DISTINCT; &#125; &#125; /* ------------------------------------------------------------ */ // LinkedHashMap support /* * The following package-protected methods are designed to be * overridden by LinkedHashMap, but not by any other subclass. * Nearly all other internal methods are also package-protected * but are declared final, so can be used by LinkedHashMap, view * classes, and HashSet. */ // Create a regular (non-tree) node Node&lt;K,V&gt; newNode(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; return new Node&lt;&gt;(hash, key, value, next); &#125; // For conversion from TreeNodes to plain nodes Node&lt;K,V&gt; replacementNode(Node&lt;K,V&gt; p, Node&lt;K,V&gt; next) &#123; return new Node&lt;&gt;(p.hash, p.key, p.value, next); &#125; // Create a tree bin node TreeNode&lt;K,V&gt; newTreeNode(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; return new TreeNode&lt;&gt;(hash, key, value, next); &#125; // For treeifyBin TreeNode&lt;K,V&gt; replacementTreeNode(Node&lt;K,V&gt; p, Node&lt;K,V&gt; next) &#123; return new TreeNode&lt;&gt;(p.hash, p.key, p.value, next); &#125; /** * Reset to initial default state. Called by clone and readObject. */ void reinitialize() &#123; table = null; entrySet = null; keySet = null; values = null; modCount = 0; threshold = 0; size = 0; &#125; // Callbacks to allow LinkedHashMap post-actions void afterNodeAccess(Node&lt;K,V&gt; p) &#123; &#125; void afterNodeInsertion(boolean evict) &#123; &#125; void afterNodeRemoval(Node&lt;K,V&gt; p) &#123; &#125; // Called only from writeObject, to ensure compatible ordering. void internalWriteEntries(java.io.ObjectOutputStream s) throws IOException &#123; Node&lt;K,V&gt;[] tab; if (size &gt; 0 &amp;&amp; (tab = table) != null) &#123; for (int i = 0; i &lt; tab.length; ++i) &#123; for (Node&lt;K,V&gt; e = tab[i]; e != null; e = e.next) &#123; s.writeObject(e.key); s.writeObject(e.value); &#125; &#125; &#125; &#125; /* ------------------------------------------------------------ */ // Tree bins /** * Entry for Tree bins. Extends LinkedHashMap.Entry (which in turn * extends Node) so can be used as extension of either regular or * linked node. */ static final class TreeNode&lt;K,V&gt; extends LinkedHashMap.Entry&lt;K,V&gt; &#123; TreeNode&lt;K,V&gt; parent; // red-black tree links TreeNode&lt;K,V&gt; left; TreeNode&lt;K,V&gt; right; TreeNode&lt;K,V&gt; prev; // needed to unlink next upon deletion boolean red; TreeNode(int hash, K key, V val, Node&lt;K,V&gt; next) &#123; super(hash, key, val, next); &#125; /** * Returns root of tree containing this node. */ final TreeNode&lt;K,V&gt; root() &#123; for (TreeNode&lt;K,V&gt; r = this, p;;) &#123; if ((p = r.parent) == null) return r; r = p; &#125; &#125; /** * Ensures that the given root is the first node of its bin. */ static &lt;K,V&gt; void moveRootToFront(Node&lt;K,V&gt;[] tab, TreeNode&lt;K,V&gt; root) &#123; int n; if (root != null &amp;&amp; tab != null &amp;&amp; (n = tab.length) &gt; 0) &#123; int index = (n - 1) &amp; root.hash; TreeNode&lt;K,V&gt; first = (TreeNode&lt;K,V&gt;)tab[index]; if (root != first) &#123; Node&lt;K,V&gt; rn; tab[index] = root; TreeNode&lt;K,V&gt; rp = root.prev; if ((rn = root.next) != null) ((TreeNode&lt;K,V&gt;)rn).prev = rp; if (rp != null) rp.next = rn; if (first != null) first.prev = root; root.next = first; root.prev = null; &#125; assert checkInvariants(root); &#125; &#125; /** * Finds the node starting at root p with the given hash and key. * The kc argument caches comparableClassFor(key) upon first use * comparing keys. */ final TreeNode&lt;K,V&gt; find(int h, Object k, Class&lt;?&gt; kc) &#123; TreeNode&lt;K,V&gt; p = this; do &#123; int ph, dir; K pk; TreeNode&lt;K,V&gt; pl = p.left, pr = p.right, q; if ((ph = p.hash) &gt; h) p = pl; else if (ph &lt; h) p = pr; else if ((pk = p.key) == k || (k != null &amp;&amp; k.equals(pk))) return p; else if (pl == null) p = pr; else if (pr == null) p = pl; else if ((kc != null || (kc = comparableClassFor(k)) != null) &amp;&amp; (dir = compareComparables(kc, k, pk)) != 0) p = (dir &lt; 0) ? pl : pr; else if ((q = pr.find(h, k, kc)) != null) return q; else p = pl; &#125; while (p != null); return null; &#125; /** * Calls find for root node. */ final TreeNode&lt;K,V&gt; getTreeNode(int h, Object k) &#123; return ((parent != null) ? root() : this).find(h, k, null); &#125; /** * Tie-breaking utility for ordering insertions when equal * hashCodes and non-comparable. We don't require a total * order, just a consistent insertion rule to maintain * equivalence across rebalancings. Tie-breaking further than * necessary simplifies testing a bit. */ static int tieBreakOrder(Object a, Object b) &#123; int d; if (a == null || b == null || (d = a.getClass().getName(). compareTo(b.getClass().getName())) == 0) d = (System.identityHashCode(a) &lt;= System.identityHashCode(b) ? -1 : 1); return d; &#125; /** * Forms tree of the nodes linked from this node. * @return root of tree */ final void treeify(Node&lt;K,V&gt;[] tab) &#123; TreeNode&lt;K,V&gt; root = null; for (TreeNode&lt;K,V&gt; x = this, next; x != null; x = next) &#123; next = (TreeNode&lt;K,V&gt;)x.next; x.left = x.right = null; if (root == null) &#123; x.parent = null; x.red = false; root = x; &#125; else &#123; K k = x.key; int h = x.hash; Class&lt;?&gt; kc = null; for (TreeNode&lt;K,V&gt; p = root;;) &#123; int dir, ph; K pk = p.key; if ((ph = p.hash) &gt; h) dir = -1; else if (ph &lt; h) dir = 1; else if ((kc == null &amp;&amp; (kc = comparableClassFor(k)) == null) || (dir = compareComparables(kc, k, pk)) == 0) dir = tieBreakOrder(k, pk); TreeNode&lt;K,V&gt; xp = p; if ((p = (dir &lt;= 0) ? p.left : p.right) == null) &#123; x.parent = xp; if (dir &lt;= 0) xp.left = x; else xp.right = x; root = balanceInsertion(root, x); break; &#125; &#125; &#125; &#125; moveRootToFront(tab, root); &#125; /** * Returns a list of non-TreeNodes replacing those linked from * this node. */ final Node&lt;K,V&gt; untreeify(HashMap&lt;K,V&gt; map) &#123; Node&lt;K,V&gt; hd = null, tl = null; for (Node&lt;K,V&gt; q = this; q != null; q = q.next) &#123; Node&lt;K,V&gt; p = map.replacementNode(q, null); if (tl == null) hd = p; else tl.next = p; tl = p; &#125; return hd; &#125; /** * Tree version of putVal. */ final TreeNode&lt;K,V&gt; putTreeVal(HashMap&lt;K,V&gt; map, Node&lt;K,V&gt;[] tab, int h, K k, V v) &#123; Class&lt;?&gt; kc = null; boolean searched = false; TreeNode&lt;K,V&gt; root = (parent != null) ? root() : this; for (TreeNode&lt;K,V&gt; p = root;;) &#123; int dir, ph; K pk; if ((ph = p.hash) &gt; h) dir = -1; else if (ph &lt; h) dir = 1; else if ((pk = p.key) == k || (k != null &amp;&amp; k.equals(pk))) return p; else if ((kc == null &amp;&amp; (kc = comparableClassFor(k)) == null) || (dir = compareComparables(kc, k, pk)) == 0) &#123; if (!searched) &#123; TreeNode&lt;K,V&gt; q, ch; searched = true; if (((ch = p.left) != null &amp;&amp; (q = ch.find(h, k, kc)) != null) || ((ch = p.right) != null &amp;&amp; (q = ch.find(h, k, kc)) != null)) return q; &#125; dir = tieBreakOrder(k, pk); &#125; TreeNode&lt;K,V&gt; xp = p; if ((p = (dir &lt;= 0) ? p.left : p.right) == null) &#123; Node&lt;K,V&gt; xpn = xp.next; TreeNode&lt;K,V&gt; x = map.newTreeNode(h, k, v, xpn); if (dir &lt;= 0) xp.left = x; else xp.right = x; xp.next = x; x.parent = x.prev = xp; if (xpn != null) ((TreeNode&lt;K,V&gt;)xpn).prev = x; moveRootToFront(tab, balanceInsertion(root, x)); return null; &#125; &#125; &#125; /** * Removes the given node, that must be present before this call. * This is messier than typical red-black deletion code because we * cannot swap the contents of an interior node with a leaf * successor that is pinned by "next" pointers that are accessible * independently during traversal. So instead we swap the tree * linkages. If the current tree appears to have too few nodes, * the bin is converted back to a plain bin. (The test triggers * somewhere between 2 and 6 nodes, depending on tree structure). */ final void removeTreeNode(HashMap&lt;K,V&gt; map, Node&lt;K,V&gt;[] tab, boolean movable) &#123; int n; if (tab == null || (n = tab.length) == 0) return; int index = (n - 1) &amp; hash; TreeNode&lt;K,V&gt; first = (TreeNode&lt;K,V&gt;)tab[index], root = first, rl; TreeNode&lt;K,V&gt; succ = (TreeNode&lt;K,V&gt;)next, pred = prev; if (pred == null) tab[index] = first = succ; else pred.next = succ; if (succ != null) succ.prev = pred; if (first == null) return; if (root.parent != null) root = root.root(); if (root == null || root.right == null || (rl = root.left) == null || rl.left == null) &#123; tab[index] = first.untreeify(map); // too small return; &#125; TreeNode&lt;K,V&gt; p = this, pl = left, pr = right, replacement; if (pl != null &amp;&amp; pr != null) &#123; TreeNode&lt;K,V&gt; s = pr, sl; while ((sl = s.left) != null) // find successor s = sl; boolean c = s.red; s.red = p.red; p.red = c; // swap colors TreeNode&lt;K,V&gt; sr = s.right; TreeNode&lt;K,V&gt; pp = p.parent; if (s == pr) &#123; // p was s's direct parent p.parent = s; s.right = p; &#125; else &#123; TreeNode&lt;K,V&gt; sp = s.parent; if ((p.parent = sp) != null) &#123; if (s == sp.left) sp.left = p; else sp.right = p; &#125; if ((s.right = pr) != null) pr.parent = s; &#125; p.left = null; if ((p.right = sr) != null) sr.parent = p; if ((s.left = pl) != null) pl.parent = s; if ((s.parent = pp) == null) root = s; else if (p == pp.left) pp.left = s; else pp.right = s; if (sr != null) replacement = sr; else replacement = p; &#125; else if (pl != null) replacement = pl; else if (pr != null) replacement = pr; else replacement = p; if (replacement != p) &#123; TreeNode&lt;K,V&gt; pp = replacement.parent = p.parent; if (pp == null) root = replacement; else if (p == pp.left) pp.left = replacement; else pp.right = replacement; p.left = p.right = p.parent = null; &#125; TreeNode&lt;K,V&gt; r = p.red ? root : balanceDeletion(root, replacement); if (replacement == p) &#123; // detach TreeNode&lt;K,V&gt; pp = p.parent; p.parent = null; if (pp != null) &#123; if (p == pp.left) pp.left = null; else if (p == pp.right) pp.right = null; &#125; &#125; if (movable) moveRootToFront(tab, r); &#125; /** * Splits nodes in a tree bin into lower and upper tree bins, * or untreeifies if now too small. Called only from resize; * see above discussion about split bits and indices. * * @param map the map * @param tab the table for recording bin heads * @param index the index of the table being split * @param bit the bit of hash to split on */ final void split(HashMap&lt;K,V&gt; map, Node&lt;K,V&gt;[] tab, int index, int bit) &#123; TreeNode&lt;K,V&gt; b = this; // Relink into lo and hi lists, preserving order TreeNode&lt;K,V&gt; loHead = null, loTail = null; TreeNode&lt;K,V&gt; hiHead = null, hiTail = null; int lc = 0, hc = 0; for (TreeNode&lt;K,V&gt; e = b, next; e != null; e = next) &#123; next = (TreeNode&lt;K,V&gt;)e.next; e.next = null; if ((e.hash &amp; bit) == 0) &#123; if ((e.prev = loTail) == null) loHead = e; else loTail.next = e; loTail = e; ++lc; &#125; else &#123; if ((e.prev = hiTail) == null) hiHead = e; else hiTail.next = e; hiTail = e; ++hc; &#125; &#125; if (loHead != null) &#123; if (lc &lt;= UNTREEIFY_THRESHOLD) tab[index] = loHead.untreeify(map); else &#123; tab[index] = loHead; if (hiHead != null) // (else is already treeified) loHead.treeify(tab); &#125; &#125; if (hiHead != null) &#123; if (hc &lt;= UNTREEIFY_THRESHOLD) tab[index + bit] = hiHead.untreeify(map); else &#123; tab[index + bit] = hiHead; if (loHead != null) hiHead.treeify(tab); &#125; &#125; &#125; /* ------------------------------------------------------------ */ // Red-black tree methods, all adapted from CLR static &lt;K,V&gt; TreeNode&lt;K,V&gt; rotateLeft(TreeNode&lt;K,V&gt; root, TreeNode&lt;K,V&gt; p) &#123; TreeNode&lt;K,V&gt; r, pp, rl; if (p != null &amp;&amp; (r = p.right) != null) &#123; if ((rl = p.right = r.left) != null) rl.parent = p; if ((pp = r.parent = p.parent) == null) (root = r).red = false; else if (pp.left == p) pp.left = r; else pp.right = r; r.left = p; p.parent = r; &#125; return root; &#125; static &lt;K,V&gt; TreeNode&lt;K,V&gt; rotateRight(TreeNode&lt;K,V&gt; root, TreeNode&lt;K,V&gt; p) &#123; TreeNode&lt;K,V&gt; l, pp, lr; if (p != null &amp;&amp; (l = p.left) != null) &#123; if ((lr = p.left = l.right) != null) lr.parent = p; if ((pp = l.parent = p.parent) == null) (root = l).red = false; else if (pp.right == p) pp.right = l; else pp.left = l; l.right = p; p.parent = l; &#125; return root; &#125; static &lt;K,V&gt; TreeNode&lt;K,V&gt; balanceInsertion(TreeNode&lt;K,V&gt; root, TreeNode&lt;K,V&gt; x) &#123; x.red = true; for (TreeNode&lt;K,V&gt; xp, xpp, xppl, xppr;;) &#123; if ((xp = x.parent) == null) &#123; x.red = false; return x; &#125; else if (!xp.red || (xpp = xp.parent) == null) return root; if (xp == (xppl = xpp.left)) &#123; if ((xppr = xpp.right) != null &amp;&amp; xppr.red) &#123; xppr.red = false; xp.red = false; xpp.red = true; x = xpp; &#125; else &#123; if (x == xp.right) &#123; root = rotateLeft(root, x = xp); xpp = (xp = x.parent) == null ? null : xp.parent; &#125; if (xp != null) &#123; xp.red = false; if (xpp != null) &#123; xpp.red = true; root = rotateRight(root, xpp); &#125; &#125; &#125; &#125; else &#123; if (xppl != null &amp;&amp; xppl.red) &#123; xppl.red = false; xp.red = false; xpp.red = true; x = xpp; &#125; else &#123; if (x == xp.left) &#123; root = rotateRight(root, x = xp); xpp = (xp = x.parent) == null ? null : xp.parent; &#125; if (xp != null) &#123; xp.red = false; if (xpp != null) &#123; xpp.red = true; root = rotateLeft(root, xpp); &#125; &#125; &#125; &#125; &#125; &#125; static &lt;K,V&gt; TreeNode&lt;K,V&gt; balanceDeletion(TreeNode&lt;K,V&gt; root, TreeNode&lt;K,V&gt; x) &#123; for (TreeNode&lt;K,V&gt; xp, xpl, xpr;;) &#123; if (x == null || x == root) return root; else if ((xp = x.parent) == null) &#123; x.red = false; return x; &#125; else if (x.red) &#123; x.red = false; return root; &#125; else if ((xpl = xp.left) == x) &#123; if ((xpr = xp.right) != null &amp;&amp; xpr.red) &#123; xpr.red = false; xp.red = true; root = rotateLeft(root, xp); xpr = (xp = x.parent) == null ? null : xp.right; &#125; if (xpr == null) x = xp; else &#123; TreeNode&lt;K,V&gt; sl = xpr.left, sr = xpr.right; if ((sr == null || !sr.red) &amp;&amp; (sl == null || !sl.red)) &#123; xpr.red = true; x = xp; &#125; else &#123; if (sr == null || !sr.red) &#123; if (sl != null) sl.red = false; xpr.red = true; root = rotateRight(root, xpr); xpr = (xp = x.parent) == null ? null : xp.right; &#125; if (xpr != null) &#123; xpr.red = (xp == null) ? false : xp.red; if ((sr = xpr.right) != null) sr.red = false; &#125; if (xp != null) &#123; xp.red = false; root = rotateLeft(root, xp); &#125; x = root; &#125; &#125; &#125; else &#123; // symmetric if (xpl != null &amp;&amp; xpl.red) &#123; xpl.red = false; xp.red = true; root = rotateRight(root, xp); xpl = (xp = x.parent) == null ? null : xp.left; &#125; if (xpl == null) x = xp; else &#123; TreeNode&lt;K,V&gt; sl = xpl.left, sr = xpl.right; if ((sl == null || !sl.red) &amp;&amp; (sr == null || !sr.red)) &#123; xpl.red = true; x = xp; &#125; else &#123; if (sl == null || !sl.red) &#123; if (sr != null) sr.red = false; xpl.red = true; root = rotateLeft(root, xpl); xpl = (xp = x.parent) == null ? null : xp.left; &#125; if (xpl != null) &#123; xpl.red = (xp == null) ? false : xp.red; if ((sl = xpl.left) != null) sl.red = false; &#125; if (xp != null) &#123; xp.red = false; root = rotateRight(root, xp); &#125; x = root; &#125; &#125; &#125; &#125; &#125; /** * Recursive invariant check */ static &lt;K,V&gt; boolean checkInvariants(TreeNode&lt;K,V&gt; t) &#123; TreeNode&lt;K,V&gt; tp = t.parent, tl = t.left, tr = t.right, tb = t.prev, tn = (TreeNode&lt;K,V&gt;)t.next; if (tb != null &amp;&amp; tb.next != t) return false; if (tn != null &amp;&amp; tn.prev != t) return false; if (tp != null &amp;&amp; t != tp.left &amp;&amp; t != tp.right) return false; if (tl != null &amp;&amp; (tl.parent != t || tl.hash &gt; t.hash)) return false; if (tr != null &amp;&amp; (tr.parent != t || tr.hash &lt; t.hash)) return false; if (t.red &amp;&amp; tl != null &amp;&amp; tl.red &amp;&amp; tr != null &amp;&amp; tr.red) return false; if (tl != null &amp;&amp; !checkInvariants(tl)) return false; if (tr != null &amp;&amp; !checkInvariants(tr)) return false; return true; &#125; &#125;&#125;]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2018%2F06%2F13%2Falgorithm%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[线性表顺序存储方式 定义 用一段地址连续的存储空间存储线性表的元素 存储结构 1234typedef struct&#123; Elemtype data[MAX_SIZE]; int length;&#125;SqList 添加元素实现方式 实现原理 将要插入的位置以后的元素全部向后移一位，然后将插入的元素添加进去 算法 12345678Status insertElem(SqList *l, int i, Elemtype e)&#123; int k; for(k=l-&gt;length;k&gt;=i-1; k++)&#123; l-&gt;data[k]=l-&gt;data[k-1]; &#125; l-&gt;data[i-1] = e; return OK;&#125; 删除元素实现方式 实现原理 将要删除元素以后的所有元素向前移一位 算法 1234567Status deleteElem(SqList *l, int i)&#123; int k; for(k=i-1; k &lt; l-&gt;length; k++)&#123; l-&gt;data[k] = l-&gt;data[k+1]; &#125; return OK;&#125; 链式存储方式 存储结构 12345typedef struct Node&#123; ElemType data; struct Node *next;&#125;typedef struct Node *LinkList; 添加元素算法 1234567891011121314Status insertElem(LinkList *l, int i, ElemType e)&#123; int j = 1; LinkList p,q; p = *l; while(p &amp;&amp; j&lt;i)&#123; p=p-&gt;next; j++; &#125; q = (LinkList)malloc(sizeof(Node)); q-&gt;data = e; q-&gt;next = p-&gt;next; p-next = q; return OK;&#125; 删除元素算法 1234567891011121314Status deleteElem(LinkList *l, int i)&#123; int j = 1; LinkList p,q; p = *l; while(p &amp;&amp; j&lt;i)&#123; p=p-&gt;next; j++; &#125; q = p-&gt;next; p-next = q-&gt;next; free(q); l-&gt;length = l-&gt;length - 1; return OK;&#125; 循环链表 定义 如果从链表中间一个元素开始遍历链表，如果使用传统的方式会比较麻烦，这个时候如果使用循环链表就比较方便，即在尾节点上存储头节点的地址，而不是存储空； 双向链表 定义 在使用传统链表的时候如果需要查看当前节点的上一个节点会显得比较麻烦，这个时候如果有前驱后后继两个节点之分就会方便很多 存储结构 12345typedef struct Node&#123; Elemtype data; Node *previous; Node *next;&#125; 栈顺序存储方式 存储结构 1234typedef struct Stack&#123; Elemtype data[MAX_SIZE]; int top;&#125; 添加元素算法 1234567Status push(Stack *s, Elemtype e)&#123; if(top + 1 &gt; MAX_SEZE)&#123; return ERROE; &#125; s-&gt;data[++s-&gt;top] = e; return OK;&#125; 删除元素实现算法 1234567Status pop(Stack *s)&#123; if(top == 0)&#123; return ERROE; &#125; --s-&gt;top; return OK;&#125; 链式存储方式 存储结构 123456789typedef struct Node&#123; Elemtype data; Node *next;&#125;Node, *LinkStackPtr;typedef struct LinkStack&#123; LinkStackPtr top; int count;&#125; 添加元素算法 123456789101112Status push(LinkStatck *s, Elemtype e)&#123; Node *node = (LinkStatckPtr)malloc(sizeof(Node)); if(node)&#123; return ERROE; &#125; node-&gt;data = e; LinkStatckPtr top = s-&gt;top; node-&gt;next = top; s-&gt;top = node; ++s-&gt;count; return OK;&#125; 删除元素算法 1234567Status pop(LinkStatck *s)&#123; LinkStackPtr p = s-&gt;top; s-&gt;top = p-&gt;next; free(p); s-&gt;count--; return OK;&#125; 队列链队列 存储结构 12345678typedef struct QNode&#123; Elemtype data; QNode *next;&#125;QNode, *QueuePtr;typedef struct LinkQuene&#123; QueuePtr front, rear;&#125; 添加元素算法 12345678910Status enQueue(LinkQueue *q, Elemtype e)&#123; QueuePtr s = (QueuePtr)malloc(sizeof(QNode)); if(!q)&#123; exit(OVERFLOW); &#125; s-&gt;data = e; q-&gt;rear-&gt;next = s; q-&gt;rear = s; return OK;&#125; 删除元素算法 123456Status deQueue(LinkQueue *q)&#123; QueuePtr s = q-&gt;front; q-&gt;front = s-&gt;next; free(s); return OK;&#125; 循环队列 存储结构 12345typedef struct Queue&#123; Elemtype data[MAX_SIZE]; int front; int rear;&#125; 添加元素算法 1234567Status enQueue(Queue *q, Elemtype e)&#123; if((q-&gt;rear + 1)%MAX_SIZE == q-&gt;front)&#123; return OVERFLOW; &#125; data[++front] = e; return OK;&#125; 删除元素算法 1234567Status deQueue(Queue *q)&#123; if(q-&gt;front == q-&gt;rear)&#123; return ERROR; &#125; q-&gt;front--; return OK;&#125; 二叉树 定义 是n个节点的集合，该集合或者是空集，或者由一个根节点和两棵互不相交的、分别称为根节点的左子树和右子树的二叉树组成。 特殊二叉树 满二叉树：在一棵二叉树中，如果所有分支节点都存在左子树和右子树，并且所有叶子都在同一层上，这样的二叉树称为满二叉树。 完全二叉树：在一棵具有n个节点的二叉树按层序编号，如果编号为i的节点与同样深度的满二叉树中国编号为i的点在在二叉树中位置相同，则这棵二叉树就是完全二叉树。 性质 在二叉树的第i层上之多有2^i-1 个结点 深度为k的二叉树至多有(2^k)-1个结点 对于任何一棵二叉树T，如果其终端结点数为n0，度为2的结点数n2，则n0 = n2 +1 具有n个结点的完全二叉树的深度为（log2n）+ 1；(如果log2n不为整数，那么其为不大于log2n的整数) 如果对一棵有n个结点的完全二叉树的结点按层序编号，对任一结点i有 如果i=1，则结点i是二叉树的根，无双亲；如果i&gt;1则其双亲是结点(i/2) (不大于其的最大整数) 如果2i&gt;n则结点i无左孩子 如果2i+1&gt;n则结点无右孩子 存储结构 1234typedef struct BiTNode&#123; ElemType data; struct BiTNode *lChild, rChild;&#125;BiTNode, *BiTree; 遍历二叉树 前序遍历 方式: 先访问根节点，再访问左子树，最后右子树 算法： 12345678void preOrderTraverse(BiTree t, void (*visit)(BiTree))&#123; if(t == NULL)&#123; return ; &#125; visit(t); preOrderTraverse(t-&gt;lChild, visit); preOrderTraverse(t-&gt;rChild, visit);&#125; 中序遍历 方式:先方位右子树，再访问根结点，最有是右子树 算法 12345678void inOrderTraverse(BiTree t, void (*visit)(BiTree))&#123; if(t == null)&#123; return; &#125; preOrderTraverse(t-&gt;lChild, visit); visit(t); preOrderTraverse(t-&gt;rChild, visit);&#125; 后序遍历 方式:先访问右子树，再访问根结点，最后是左子树 算法 12345678void inOrderTraverse(BiTree t, void (*visit)(BiTree))&#123; if(t == null)&#123; return; &#125; preOrderTraverse(t-&gt;lChild, visit); preOrderTraverse(t-&gt;rChild, visit); visit(t);&#125; 一些方法用的遍历方式 在创建链二叉树的时候要使用前序遍历 在销毁链二叉树的时候要使用后序遍历 赫夫曼树 最优二叉树 实现原理： 根据给定的n个权值{w1,w2……wn}构成n颗二叉树集合F={T1,T2…..Tn},其中每颗二叉树Ti中只有一个带权为Wi根结点，其左右子树为空。 在F中选取两棵根结点的权值最小的树作为左右子树构造一棵新的二叉树，且置新的二叉树的根结点的权值为其左右子树上根结点的权值之和 在F中删除这两棵树，同时将新得到的二叉树加入F中 重复2 、3步骤，直到F中只含一棵树为止。 查找静态查找顺序查找 算法 12345678// 其中n为数组个数，key为要查找的值int sequential_Search(int *a, int n, int key)&#123; a[0] key; while(!a[n] == key)&#123; n--; &#125; return n;&#125; 有序表的查找 折半查找 算法 1234567891011121314151617// 其中n为数组个数，key为要查找的值int binary_Search(int *a, int n, int key)&#123; int low = 1; int high = n; int mid; while(low &lt;= hign)&#123; mid = (low + hign)/2; if(a[mid] &lt; key)&#123; low = mid+1; &#125;else if(a[mid] &gt; key)&#123; hign = mid + 1; &#125;else if(a[mid] = key)&#123; return mid; &#125; &#125; return 0;&#125; 插值查找 优点 对于分布比较均匀的数据来说，查找性能会更加的好，但是对于不均匀的数据查找性能还不如折半查找 算法 1234567891011121314151617// 其中n为数组个数，key为要查找的值int binary_Search(int *a, int n, int key)&#123; int low = 1; int high = n; int mid; while(low &lt;= hign)&#123; mid = low + (key-a[low])/(a[hign]- a[low])*(hign -low); if(a[mid] &lt; key)&#123; low = mid+1; &#125;else if(a[mid] &gt; key)&#123; hign = mid + 1; &#125;else if(a[mid] = key)&#123; return mid; &#125; &#125; return 0;&#125; 线性索引查找 稠密索引 实现原理：是指在线性索引中，将数据集的每个记录对应一个索引项。 缺点：如果数据集比较大，意味着索引也得同样的数据集长度规模，对于内存有限的计算机来说，可能就需要反复的访问磁盘，查找性能反而大大下降。 分块索引 实现原理：就是用分块有序(块内无序，块间有序)的方式，把数据集的记录分成了若干块，将每块对应一个索引，这种索引方法就是分块索引。 倒排索引 实现原理：就像在通过关键字搜索文章时，我们记录一张表，第一列是关键字，第二列是文章的编号；这里就是倒排索引通用的索引项结构，关键字是次关键码，文章编号为记录号表；其中记录号表存储具有相同次关键字的所有记录的记录号。这样的实现方式就是倒排索引。 动态查找二叉排序树 定义：它或者是一棵空树，或者具有以下性质： 若它的左子树不空，则左子树上所有结点的值均小于它的根结点的值。 若它的右子树不空，则右子树上所有结点的值均小于它的根结点的值。 它的左右子树也分别为二叉排序树。 查找操作 算法： 1234567891011121314151617//f 指向T的双亲结点，其初始值为NULL//若查找成功p指向该数据元素结点，否则指向查找路径上最后访问的结点Status searchBST(BiTree t, int key, BiTree f, BiTree *p)&#123; if(!t)&#123; *p=f; return false; &#125; else if(key == t-&gt;data)&#123; *p = t; return TRUE; &#125; else if(key &lt; t-&gt;data)&#123; return searchBST(t-&gt;lChild, key, t, p) &#125; else return searchBST(t-&gt;rChild, key, t, p);&#125; 插入操作 算法： 12345678910111213141516171819Status insertBST(BiTree *T, int key)&#123; BiTree p,s; if(!searchBST(T, key, NULL, &amp;p))&#123; s = (BiTree)malloc(sizeof(BiTNode)); s-&gt;data = key; s-&gt;lChild = s-&gt;rChild = NULL; if(!p)&#123; *T = s; &#125; else if(p-&gt;data &gt; key)&#123; p-&gt;lChild = s; &#125; else if(p-&gt;data &lt; key)&#123; p-&gt;rChild = s; &#125; return TRUEE; &#125; return FALSE;&#125; 删除操作 算法 123456789101112131415161718192021222324252627282930Status delete(BiTree p)&#123; BiTree q,s; if(p-&gt;rChild == NULL)&#123; q = p; p = p-&gt;lChild; free(q); &#125;else if(p-&gt;lChild == NULL)&#123; q = p; p = p-&gt;rChild; free(q); &#125;else&#123; s = p-&gt;lChild; while(s-&gt;rChild)&#123; q = s; s= s-&gt;rChild; &#125; p-&gt;data = s-&gt;data; //有可能被删除结点的左子树没有右子树 if(s == p-&gt;lChild)&#123; q = p; p = s; free(q); &#125; else&#123; //连接由于s被换走后空下来的位置 q-&gt;rChild = s-&gt;lChild; free(s); &#125; &#125;&#125; 平衡二叉树 定义:是一种特殊的二叉排序树，其中每一个节点的左子树和右子树的高度差之多为1 实现原理: 失去平衡后进行调整的规律有以下四种情况: 单向右旋平衡处理：由于在*a的左子树根结点的左子树上插入结点，致使其平衡因子由1变为2，则需要一次向右的顺时针旋转操作 单向左旋平衡处理：由于*a的右子树的根结点的右子树上插入结点，致使其不平衡，则需要一次左旋处理 双向旋转(先左后右)平衡处理:由于在*a的左子树根结点的右子树上插入结点，就需要先左旋处理再右旋处理 双向旋转(先有后左)平衡处理:由于在*a的右子树根结点的左子树上插入结点，就需要先右旋处理再左旋处理 多路查找树2-3 树 定义:2-3树是这样一棵多路查找树：其中的每一个结点都具有两个孩子(2结点)或三个孩子(3结点)；一个2结点包含一个元素和两个孩子，一个3结点包含一小一大两个元素和三个孩子 B树 定义:2-3树，2-3-4树是B树的特例。结点最大的孩子数目称为B树的阶。每一个结点和它的子树就可以覆盖一个范围，联合起来那么就是所有的结果。这样的方式可以让我们很快的定位出我们需要的结果。 B+树 实现原理：由于B树如果需要遍历的话比较麻烦，在遍历完一个子节点又需要回到双亲结点，然后找到下一个遍历的子节点，所以B+树就是在B树的基础上给每个子节点存储了一个指向后一叶子结点的指针。 哈希查找 定义：散列技术是在记录的存储位置和它的关键字之间建立一个确定的对应关系f，使得每个关键字key对应一个存储位置f(key). 散列函数构造方法 直接地址法:取关键字的某个线性函数值为散列地址 除留余数法：取模 处理哈希冲突 开放地址法：一旦发生了冲突，就去寻找下一个空的散列地址，只要散列表足够大，空的散列地址总能够找到。它的公式是：fi(key) = (f(key) + di) MOD m 链地址法:将所有关键字为同义词的记录存储在一个单链表中，在散列表中只存储所有同义词字表的头指针。当然这个也就带来了遍历链表的性能损耗。 再散列函数法：预备另一个散列函数，当发生冲突的时候使用这个散列函数来进行散列。 排序冒泡排序 算法实现 12345678910void bubbleSort(SqList *l)&#123; int i，j; for(i = 1; i&lt;l-&gt;length; i++)&#123; for(j=l-&gt;length-1; j&gt;=i; j--)&#123; if(l-&gt;r[j]&lt;l-&gt;r[j-1])&#123; swap(l,j,j-1); &#125; &#125; &#125;&#125; 简单选择排序法 算法实现 1234567891011121314void selectSort(SqList *l)&#123; int i, j, min, k; for(i = 1; i&lt;l-&gt;length; i++)&#123; k = i; for(j = i; j&lt;l-&gt;length; j++)&#123; if(l-&gt;r[j]&lt;l-&gt;r[i])&#123; k = j; &#125; &#125; if(i!=k)&#123; swap(l, i, k); &#125; &#125;&#125; 直接插入排序 算法 123456789101112void insertSort(SqList *l)&#123; int i,j; for(i = 2; i &lt; l-&gt;length; i++)&#123; if(l-&gt;r[i]&gt;l-&gt;[i-1])&#123; l-&gt;r[0] = l-&gt;r[i]; for(j=i-1;l-&gt;r[j]&gt;l-&gt;r[0]; j--)&#123; l-&gt;r[j+1] = l-&gt;r[j]; &#125; l-&gt;r[j] = l-&gt;r[0]; &#125; &#125;&#125; 希尔排序 实现原理:根据由大到小的增量将两个数从小到大的排序，在增量变小的过程中序列已经变为基本有序，最后元素交换的次数会越来越少。 堆排序 堆：堆是具有以下性质的完全二叉树：每个结点的值都大于或等于其左右孩子结点的值，称为大顶堆，相反则是小顶堆。 实现原理：将待排序的序列造成一个大顶堆。此时，整个序列的最大值就是堆顶的根结点。将它移走(其实就是将其与堆数组的末尾元素交换，此时末尾元素就是最大值)，然后将剩余的n-1个序列重新构造成一个大顶堆，这样就会得到n个元素中的次大元素。如此反复执行，便能够得到一个有序序列了。 归并排序快速排序]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2018%2F05%2F28%2Fjava%2F%E5%85%B3%E4%BA%8E%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E7%9A%84%E6%80%9D%E8%80%83%2F</url>
    <content type="text"><![CDATA[byte b = (byte) 0xaa 引发的思考 为什么这样的强制类型转换时被允许的 我们知道0xaa 的二进制数是 1010 1010，因为byte的存储范围是-128-127，这场来说是不可能把 0xaa 赋值给byte 数据类型的，但是这里不同的是进行了一次强制类型转换，这里我的理解是其实在计算机里面所有数据都是二进制数 包括这里的0xaa，因为byte数据类型 第一位要存储符号位，所以后面只有七位用于存储数据；但是现在我们 （10101010） 这组数用一个byte的指针指向它并把这个指针给了b引用，所以导致了刚好没有超过byte数据类型的八位二进制数；但是我们可以看到输出b会是 -86 是因为java定义的byte 第一位是符号位 这里是“1”，而“86”是“0101010”的十进制数]]></content>
  </entry>
  <entry>
    <title><![CDATA[设计模式]]></title>
    <url>%2F2018%2F05%2F12%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[代理模式静态代理所谓静态代理也就是在程序运行前就已经存在代理类的字节码文件，代理类和委托类的关系在运行前就确定了。 通过继承实现静态代理直接贴代码：1234567891011121314151617181920212223public interface MoveAble &#123; void move() throws InterruptedException;&#125;public class Car implements MoveAble &#123; @Override public void move() throws InterruptedException &#123; System.out.println(&quot;汽车正在行驶....&quot;); &#125;&#125;public class ExCar extends Car &#123; @Override public void move() throws InterruptedException &#123; long startTime = System.currentTimeMillis(); super.move(); Thread.sleep(1000); long endTime = System.currentTimeMillis(); System.out.println(&quot;行驶了&quot;+ (endTime - startTime) + &quot;时间....&quot; ); &#125;&#125; 通过继承被代理类，然后在代理类里面实现方法调用被代理类的被代理方法，在这个方法前后我们就可以我们自己想做的事情。 通过聚合实现静态代理1234567891011121314151617181920212223242526public interface MoveAble &#123; void move() throws InterruptedException;&#125;public class Car implements MoveAble &#123; @Override public void move() throws InterruptedException &#123; System.out.println(&quot;汽车正在行驶....&quot;); &#125;&#125;public class ImCar &#123; private MoveAble m; public ImCar(MoveAble m)&#123; this.m = m; &#125; public void move() throws InterruptedException &#123; long startTime = System.currentTimeMillis(); m.move(); long endTime = System.currentTimeMillis(); System.out.println(&quot;行驶了&quot;+ (endTime - startTime) + &quot;时间....&quot; ); &#125;&#125; 将被代理类作代理类的属性成员，然后在代理方法中调用被代理方法，也就可以在被代理方法调用前后进行自己的操作。 两种静态代理模式的比较聚合方式的静态代理比继承方式的静态代理更加的好因为聚合方式的静态代理的可扩展性更好；如果我们使用继承方式的静态代理当我们需要给对象添加一个代理功能时，有一个需求就添加一个代理类，这样就会非常麻烦；但是如果我们使用聚合方式的静态代理模式，那么我们就可以将不同的需要代理的功能分离出来，然后实现同一个接口，那么就可以实现代理功能，而且还可以像装饰者模式一样实现功能的叠加，即可插拔性更好。 动态代理如果都用静态代理的话会发现会产生很多动态代理的类，一个类加一个代理功能就需要一个动态代理类，那么动态代理就解决了这个问题。 jdk动态代理（被代理类必须实现了接口）public class Car implements MoveAble { @Override public void move() throws InterruptedException { System.out.println(“汽车正在行驶….”); }} public class TimeHandler implements InvocationHandler { Object target; public TimeHandler(Object target){ this.target = target; } @Override public Object invoke(Object o, Method method, Object[] objects) throws Throwable { long startTime = System.currentTimeMillis(); method.invoke(target); Thread.sleep(1000); long endTime = System.currentTimeMillis(); System.out.println(&quot;汽车行驶了&quot; + (endTime - startTime) + &quot;ms 时间...&quot; ); return null; } } public class TestJdkProxy { public static void main(String[] args) throws InterruptedException { Car car = new Car(); TimeHandler timeHandler = new TimeHandler(car); MoveAble m = (MoveAble) Proxy.newProxyInstance(ClassLoader.getSystemClassLoader(), car.getClass().getInterfaces(), timeHandler); m.move(); } }1下面是动态代理newProxyInstance的源码： @CallerSensitivepublic static Object newProxyInstance(ClassLoader loader, Class&lt;?&gt;[] interfaces, InvocationHandler h) { Objects.requireNonNull(h); Class&lt;?&gt; caller = System.getSecurityManager() == null ? null : Reflection.getCallerClass(); Constructor&lt;?&gt; cons = getProxyConstructor(caller, loader, interfaces); return newProxyInstance(caller, cons, h);}123结合聚合方式的静态代理我个人理解为，首先getProxyConstructor(caller, loader, interfaces);创建了代理类的含interfaces引用的构造器；newProxyInstance(caller, cons, h)，然后根据InvocationHandler实现所有方法。##### cglib动态代理（代理类不能为final类，因为是靠继承类来实现的） 单例模式双重检锁实现代码：1234567891011121314public class Singleton &#123; private volatile static Singleton singleton; private Singleton ()&#123;&#125; public static Singleton getSingleton() &#123; if (singleton == null) &#123; synchronized (Singleton.class) &#123; if (singleton == null) &#123; singleton = new Singleton(); &#125; &#125; &#125; return singleton; &#125; &#125; 第一重检锁：直接判断singleton是否为空，这个时候会直接调用字节码指令：getstatic，避免进行过多的同步浪费，提升性能；第二重检锁：在调用getstatic字节码指令把singleton对象取出来之后再判断它是否为空并不是一个原子操作；所以存在其它线程已经完成了此实例化过程；所以就需要第二次判断这个singleton是否为空。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java序列化]]></title>
    <url>%2F2018%2F05%2F12%2Fjava%2Fjava%E5%BA%8F%E5%88%97%E5%8C%96%2F</url>
    <content type="text"><![CDATA[为什么要序列化当我们创建一个对象后，如果程序终止那么对象就会销毁，但是存在我们需要对对象进行持久化的需求，以便在将来我们取出对象进行再次利用。序列化就是把对象变成字节码序列来实现轻量级持久化，也方便我们对其在网络上进行传输。 怎么序列化123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class Stu implements Serializable&#123; private String name; private int age; private transient String password; public Stu(String name, int age, String password) &#123; this.name = name; this.age = age; this.password = password; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125; public String getPassword() &#123; return password; &#125; public void setPassword(String password) &#123; this.password = password; &#125; public String getName() &#123; return name; &#125;&#125;public class TestSerializable &#123; public static void main(String[] args) throws IOException, ClassNotFoundException &#123; Stu stu = new Stu(&quot;May&quot;,20, &quot;123456&quot;); ObjectOutputStream ops = new ObjectOutputStream(new FileOutputStream(&quot;/home/may/Documents/temp.txt&quot;)); ops.writeObject(stu); ops.close(); ObjectInputStream ois = new ObjectInputStream(new FileInputStream(&quot;/home/may/Documents/temp.txt&quot;)); Stu stu1 = (Stu) ois.readObject(); System.out.println(stu1.getPassword()); &#125;&#125; 以上便是简单的实现对象的序列化，只需要在类上添加Serializable标记接口，然后就可以直接使用ObjectOutputStream和ObjecInputStream对对象进行序列化和反序列化。 transient关键字在序列化的时候，有些字段我们不想默认序列化，比如说用户的密码等；这个时候我们就可以使用这个关键字，对标记的字段屏蔽默认序列化。 寻找类在我们进行反序列化的时候，被序列化对象的java文件应该在同一个目录下，而且版本相同即在序列化后没有进过修改，不然在反序列化的时候会抛出ClassNotFoundException。 序列化的控制有些时候我们不想按照默认的序列化方式进行，我们想定义自己对一个对象的序列化的方式，当然上面transient是一个方式。我们还可以使用Externalizable接口，重载writeExternal和readExternal方法。 12345678910111213141516171819202122232425262728293031323334353637383940414243public class Stu implements Externalizable&#123; private String name; private int age; private transient String password; public Stu(String name, int age, String password) &#123; this.name = name; this.age = age; this.password = password; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125; public String getPassword() &#123; return password; &#125; public void setPassword(String password) &#123; this.password = password; &#125; public String getName() &#123; return name; &#125; public void writeObject(ObjectOutputStream oos) throws IOException &#123; oos.defaultWriteObject(); &#125; public void readObject(ObjectInputStream ois) throws IOException, ClassNotFoundException &#123; ois.defaultReadObject(); &#125;&#125; 这里的defaultReadObject方法就是会采用默认的对象的序列化方式。 Externalizable的替代方案直接在实现了Serialization类里面实现下面两个方法123private void WriterObject()private void readObject() 在序列化和反序列化的时候在调用ObjectOutputStream.writeObject()和ObjectInputStream.readObject()的时候会检查object是不是有自己的writeObject和readObject方法。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>序列化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nio]]></title>
    <url>%2F2018%2F05%2F05%2Fjava%2Fjava%20nio%2F</url>
    <content type="text"><![CDATA[总的同步IO用户进程发起read操作之后，立刻就可以开始去做其它的事。而另一方面，从kernel的角度，当它受到一个asynchronous read之后，首先它会立刻返回，所以不会对用户进程产生任何block。然后，kernel会等待数据准备完成，然后将数据拷贝到用户内存，当这一切都完成之后，kernel会给用户进程发送一个signal，告诉它read操作完成了。 阻塞和非阻塞 阻塞 在等待数据就绪和复制数据阶段均阻塞。 非阻塞 在等待数据就绪阶段，如果数据未就绪 read 会立刻返回 error，不阻塞；用户需要轮询以确认数据就绪；当就绪后则复制数据，该过程阻塞。 多路复用实现非阻塞 这个概念稍有不同，它是在执行 select() 的时候，同时阻塞多个 fd 然后等到监测到某些 fd 就绪时返回。此时进程两阶段均被阻塞，但等待数据就绪阶段由 select() 阻塞，复制数据阶段由 read() 阻塞。 在BIO模型中，我们要实现非阻塞，由于不能知道什么时候可以从内核缓冲区中取数据又不想去浪费CPU资源，那么我们只能创建一个新的线程，然后使用新的线程去做接下来的事件然后等到可以取数据的时候，我们再去取。但是创建线程也是很消耗资源，而且当线程多了后切换线程也是很耗CPU资源的。所以在单线程下的IO多路复用的优点就凸显数来了，没有线程切换，只有拼命的读、写、选择事件，如果再利用好多核心进行IO那么效率还会有更大的提升 Unix五种IO模型 阻塞IO 非阻塞IO IO复用（select、poll、epoll） 信号驱动IO 异步IO Reactor和Proactor模式其实java中Selector就是Reactor模式的实现，java中的AIO就是Proactor模式的实现；它们都要实现IO的多路复用，但是在事件分发者分发给事件处理者后（内核缓冲区数据准备好了）处理事件方式不一样；前者是同步的即在当前线程下处理IO任务（将内核缓冲区数据复制到用户空间），如果这个IO任务比较耗时就会比较浪费CPU资源；后者采用的方式的创建一个新的线程给事件处理者 NIOjava nio基本概念nio就是new io，是相对于传统的io模型来说的；java nio是一种基于多路复用模型的同步非阻塞的io模型 。相对于传统就一个io流就需要一个线程来进行连接处理，nio的处理方式更加的节约资源，增加系统的吞吐量。 java nio的实现 上面就是java nio的一种基本模型；一个线程对应一个selector，一个selector可以绑定多个Channel，一个Channel对应着一个Buffer。当然这只是通常的做法，一个Channel也可以对应多个Selector，一个Channel对应着多个Buffer。 selectorselector就是java nio实现多路复用的关键；在传统io中，一个socket我们必须用一个线程去管理；而在这里我们在io流和线程中间抽象出一个selector出来，selector就可以去管理多个io流连接从而实现多路链接。 channel通道是java nio的第二个主要创新。它们既不是一个扩展也不是一项增强,而是全新、极好的 Java I/O 示例,提供与 I/O 服务的直接连接。Channel 用于在字节缓冲区和位于通道另一侧的实体(通常是一个文件或套接字)之间有效地传输数据。通道是一种途径,借助该途径,可以用最小的总开销来访问操作系统本身的 I/O 服务。 Buffer一个Buffer对象是固定数量的数据的容器。其作用是一个存储器,或者分段运输区,在这里数据可被存储并在之后用于检索。缓冲区的工作与通道紧密联系。通道是 I/O 传输发生时通过的入口,而缓冲区是这些数据传输的来源或目标。对于离开缓冲区的传输,您想传递出去的数据被置于一个缓冲区,被传送到通道。 下面是一段怎么将ByteBuffer里面的数据转换为utf-8数据 12345678910111213141516171819private static String getBufferString(ByteBuffer buffer)&#123; Charset charset = null; CharsetDecoder decoder = null; CharBuffer charBuffer = null; try &#123; charset = Charset.forName("UTF-8"); decoder = charset.newDecoder(); // charBuffer = decoder.decode(buffer);//用这个的话，只能输出来一次结果，第二次显示为空 charBuffer = decoder.decode(buffer.asReadOnlyBuffer()); return charBuffer.toString(); &#125; catch (Exception ex) &#123; ex.printStackTrace(); return ""; &#125;&#125; 在java nio中同步非阻塞的实现方式因为java nio是在传统io中包装过来的，所以它的本质还是同步的，而它的非阻塞就是通过channel是实现的。在代码中我们通常通过 循环selector.select()来得到连接或者待读取的通道，这里都是同步的；当得到一个连接准备写入或者读取数据的时候也就是channel的write和read方法会异步的进行，也就是在执行write方法时在还没有进行数据写进buffer之前就返回了，read同理在没有读数据到Buffer的时候就已经返回，而是通过开启一个新的线程来完成写入和读取操作。 简单的nio服务器代码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151import java.net.InetSocketAddress;import java.net.ServerSocket;import java.nio.ByteBuffer;import java.nio.channels.SelectableChannel;import java.nio.channels.SelectionKey;import java.nio.channels.Selector;import java.nio.channels.ServerSocketChannel;import java.nio.channels.SocketChannel; import javax.swing.text.html.HTMLDocument.Iterator; /*** Simple echo-back server which listens for incoming stream connections and* echoes back whatever it reads. A single Selector object is used to listen to* the server socket (to accept new connections) and all the active socket* channels.* @author zale (zalezone.cn)*/public class SelectSockets &#123; public static int PORT_NUMBER = 1234; public static void main(String[] argv) throws Exception &#123; new SelectSockets().go(argv); &#125; public void go(String[] argv) throws Exception &#123; int port = PORT_NUMBER; if (argv.length &gt; 0) &#123; // 覆盖默认的监听端口 port = Integer.parseInt(argv[0]); &#125; System.out.println("Listening on port " + port); ServerSocketChannel serverChannel = ServerSocketChannel.open();// 打开一个未绑定的serversocketchannel ServerSocket serverSocket = serverChannel.socket();// 得到一个ServerSocket去和它绑定 Selector selector = Selector.open();// 创建一个Selector供下面使用 serverSocket.bind(new InetSocketAddress(port));//设置server channel将会监听的端口 serverChannel.configureBlocking(false);//设置非阻塞模式 serverChannel.register(selector, SelectionKey.OP_ACCEPT);//将ServerSocketChannel注册到Selector while (true) &#123; // This may block for a long time. Upon returning, the // selected set contains keys of the ready channels. int n = selector.select(); if (n == 0) &#123; continue; // nothing to do &#125; java.util.Iterator&lt;SelectionKey&gt; it = selector.selectedKeys().iterator();// Get an iterator over the set of selected keys //在被选择的set中遍历全部的key while (it.hasNext()) &#123; SelectionKey key = (SelectionKey) it.next(); // 判断是否是一个连接到来 if (key.isAcceptable()) &#123; ServerSocketChannel server =(ServerSocketChannel) key.channel(); SocketChannel channel = server.accept(); registerChannel(selector, channel,SelectionKey.OP_READ);//注册读事件 sayHello(channel);//对连接进行处理 &#125; //判断这个channel上是否有数据要读 if (key.isReadable()) &#123; readDataFromSocket(key); &#125; //从selected set中移除这个key，因为它已经被处理过了 it.remove(); &#125; &#125; &#125; /** * Register the given channel with the given selector for the given * operations of interest */ protected void registerChannel(Selector selector,SelectableChannel channel, int ops) throws Exception &#123; if (channel == null) &#123; return; // 可能会发生 &#125; // 设置通道为非阻塞 channel.configureBlocking(false); // 将通道注册到选择器上 channel.register(selector, ops); &#125; // ---------------------------------------------------------- // Use the same byte buffer for all channels. A single thread is // servicing all the channels, so no danger of concurrent acccess. //对所有的通道使用相同的缓冲区。单线程为所有的通道进行服务，所以并发访问没有风险 // 就是说这里因为只有一个selector 也就是 private ByteBuffer buffer = ByteBuffer.allocateDirect(1024); * Sample data handler method for a channel with data ready to read. * 对于一个准备读入数据的通道的简单的数据处理方法 * @param key * A SelectionKey object associated with a channel determined by the selector to be ready for reading. If the channel returns an EOF condition, it is closed here, which automatically invalidates the associated key. The selector will then de-register the channel on the next select call. 一个选择器决定了和通道关联的SelectionKey object是准备读状态。如果通道返回EOF，通道将被关闭。 并且会自动使相关的key失效，选择器然后会在下一次的select call时取消掉通道的注册 protected void readDataFromSocket(SelectionKey key) throws Exception &#123; SocketChannel socketChannel = (SocketChannel) key.channel(); int count; buffer.clear(); // 清空Buffer // Loop while data is available; channel is nonblocking //当可以读到数据时一直循环，通道为非阻塞 while ((count = socketChannel.read(buffer)) &gt; 0) &#123; buffer.flip(); // 将缓冲区置为可读 // Send the data; don't assume it goes all at once //发送数据，不要期望能一次将数据发送完 while (buffer.hasRemaining()) &#123; socketChannel.write(buffer); &#125; // WARNING: the above loop is evil. Because // it's writing back to the same nonblocking // channel it read the data from, this code can // potentially spin in a busy loop. In real life // you'd do something more useful than this. //这里的循环是无意义的，具体按实际情况而定 buffer.clear(); // Empty buffer &#125; if (count &lt; 0) &#123; // Close channel on EOF, invalidates the key //读取结束后关闭通道，使key失效 socketChannel.close(); &#125; &#125; // ---------------------------------------------------------- /** * Spew a greeting to the incoming client connection. * * @param channel * The newly connected SocketChannel to say hello to. */ private void sayHello(SocketChannel channel) throws Exception &#123; buffer.clear(); buffer.put("Hi there!\r\n".getBytes()); buffer.flip(); channel.write(buffer); &#125;&#125; 线程池的通道实现代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224import java.io.IOException;import java.nio.ByteBuffer;import java.nio.channels.SelectionKey;import java.nio.channels.SocketChannel;import java.util.LinkedList;import java.util.List; /*** Specialization of the SelectSockets class which uses a thread pool to service* channels. The thread pool is an ad-hoc implementation quicky lashed togther* in a few hours for demonstration purposes. It's definitely not production* quality.** @author Ron Hitchens (ron@ronsoft.com)*/public class SelectSocketsThreadPool extends SelectSockets &#123; private static final int MAX_THREADS = 5; private ThreadPool pool = new ThreadPool(MAX_THREADS); // ------------------------------------------------------------- public static void main(String[] argv) throws Exception &#123; new SelectSocketsThreadPool().go(argv); &#125; // ------------------------------------------------------------- /** * Sample data handler method for a channel with data ready to read. This * method is invoked from(被调用) the go( ) method in the parent class. This handler * delegates（委托） to a worker thread in a thread pool to service the channel, * then returns immediately. * * @param key * A SelectionKey object representing a channel determined by the * selector to be ready for reading. If the channel returns an * EOF condition, it is closed here, which automatically * invalidates the associated key. The selector will then * de-register the channel on the next select call. */ protected void readDataFromSocket(SelectionKey key) throws Exception &#123; WorkerThread worker = pool.getWorker(); if (worker == null) &#123; // No threads available. Do nothing. The selection // loop will keep calling this method until a // thread becomes available. This design could // be improved. return; &#125; // Invoking this wakes up the worker thread, then returns worker.serviceChannel(key); &#125; // --------------------------------------------------------------- /** * A very simple thread pool class. The pool size is set at construction * time and remains fixed. Threads are cycled through a FIFO idle queue. */ private class ThreadPool &#123; List idle = new LinkedList(); ThreadPool(int poolSize) &#123; // Fill up the pool with worker threads for (int i = 0; i &lt; poolSize; i++) &#123; WorkerThread thread = new WorkerThread(this); // Set thread name for debugging. Start it. thread.setName("Worker" + (i + 1)); thread.start(); idle.add(thread); &#125; &#125; /** * Find an idle worker thread, if any. Could return null. */ WorkerThread getWorker() &#123; WorkerThread worker = null; synchronized (idle) &#123; if (idle.size() &gt; 0) &#123; worker = (WorkerThread) idle.remove(0); &#125; &#125; return (worker); &#125; /** * Called by the worker thread to return itself to the idle pool. */ void returnWorker(WorkerThread worker) &#123; synchronized (idle) &#123; idle.add(worker); &#125; &#125; &#125; /** * A worker thread class which can drain（排空） channels and echo-back（回显） the input. * Each instance is constructed with a reference（参考） to the owning thread pool * object. When started, the thread loops forever waiting to be awakened to * service the channel associated with a SelectionKey object. The worker is * tasked by calling its serviceChannel( ) method with a SelectionKey * object. The serviceChannel( ) method stores the key reference in the * thread object then calls notify( ) to wake it up. When the channel has * been drained, the worker thread returns itself to its parent pool. */ private class WorkerThread extends Thread &#123; private ByteBuffer buffer = ByteBuffer.allocate(1024); private ThreadPool pool; private SelectionKey key; WorkerThread(ThreadPool pool) &#123; this.pool = pool; &#125; // Loop forever waiting for work to do public synchronized void run() &#123; System.out.println(this.getName() + " is ready"); while (true) &#123; try &#123; // Sleep and release object lock //休眠并且释放掉对象锁 this.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); // Clear interrupt status this.interrupted(); &#125; if (key == null) &#123; continue; // just in case &#125; System.out.println(this.getName() + " has been awakened"); try &#123; drainChannel(key); &#125; catch (Exception e) &#123; System.out.println("Caught '" + e + "' closing channel"); // Close channel and nudge selector try &#123; key.channel().close(); &#125; catch (IOException ex) &#123; ex.printStackTrace(); &#125; key.selector().wakeup(); &#125; key = null; // Done. Ready for more. Return to pool this.pool.returnWorker(this); &#125; &#125; /** * Called to initiate a unit of work by this worker thread on the * provided SelectionKey object. This method is synchronized, as is the * run( ) method, so only one key can be serviced at a given time. * Before waking the worker thread, and before returning to the main * selection loop, this key's interest set is updated to remove OP_READ. * This will cause the selector to ignore read-readiness for this * channel while the worker thread is servicing it. * 通过一个被提供SelectionKey对象的工作线程来初始化一个工作集合，这个方法是同步的，所以 * 里面的run方法只有一个key能被服务在同一个时间，在唤醒工作线程和返回到主循环之前，这个key的 * 感兴趣的集合被更新来删除OP_READ，这将会引起工作线程在提供服务的时候选择器会忽略读就绪的通道 */ synchronized void serviceChannel(SelectionKey key) &#123; this.key = key; key.interestOps(key.interestOps() &amp; (~SelectionKey.OP_READ)); this.notify(); // Awaken the thread &#125; /** * The actual code which drains the channel associated with the given * key. This method assumes the key has been modified prior to * invocation to turn off selection interest in OP_READ. When this * method completes it re-enables OP_READ and calls wakeup( ) on the * selector so the selector will resume watching this channel. */ void drainChannel(SelectionKey key) throws Exception &#123; SocketChannel channel = (SocketChannel) key.channel(); int count; buffer.clear(); // 清空buffer // Loop while data is available; channel is nonblocking while ((count = channel.read(buffer)) &gt; 0) &#123; buffer.flip(); // make buffer readable // Send the data; may not go all at once while (buffer.hasRemaining()) &#123; channel.write(buffer); &#125; // WARNING: the above loop is evil. // See comments in superclass. buffer.clear(); // Empty buffer &#125; if (count &lt; 0) &#123; // Close channel on EOF; invalidates the key channel.close(); return; &#125; // Resume interest in OP_READ key.interestOps(key.interestOps() | SelectionKey.OP_READ); // Cycle the selector so this key is active again key.selector().wakeup(); &#125; &#125;&#125; select、poll、epoll这三者都是IO多路复用的机制。I/O多路复用就是通过一种机制，一个进程可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。 select 1int select (int n, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout); select 函数监视的文件描述符分3类，分别是writefds、readfds、和exceptfds。调用后select函数会阻塞，直到有描述副就绪（有数据 可读、可写、或者有except），或者超时（timeout指定等待时间，如果立即返回设为null即可），函数返回。当select函数返回后，可以 通过遍历fdset，来找到就绪的描述符。 poll 1int poll (struct pollfd *fds, unsigned int nfds, int timeout); 不同与select使用三个位图来表示三个fdset的方式，poll使用一个 pollfd的指针实现。 12345struct pollfd &#123; int fd; /* file descriptor */ short events; /* requested events to watch */ short revents; /* returned events witnessed */&#125;; pollfd结构包含了要监视的event和发生的event，不再使用select“参数-值”传递的方式。同时，pollfd并没有最大数量限制（但是数量过大后性能也是会下降）。 和select函数一样，poll返回后，需要轮询pollfd来获取就绪的描述符。 epoll 12345678910111213141516171819202122int epoll_create(int size)；//创建一个epoll的句柄，size用来告诉内核这个监听的数目一共有多大，调用这个方法就会产生一个如下的结构体struct eventpoll&#123; .... /*红黑树的根节点，这颗树中存储着所有添加到epoll中的需要监控的事件*/ struct rb_root rbr; /*双链表中则存放着将要通过epoll_wait返回给用户的满足条件的事件*/ struct list_head rdlist; ....&#125;;//我觉得rbr是在用户注册完需要监听的端口的所有事件后，系统在接受到一个请求后就会把此事件与这个红黑树rbr中的所有事件进行比较，如果有的话就会加入到rdlist，所以在用户不用遍历所有监听的端口而是只用遍历rdlist就可以得到所有可以读取的流int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)//创建需要监听的事件epfd epoll的句柄idop 操作即是要对fd即端口删除、增加还是修改event，所有op对应 添加EPOLL_CTL_ADD，删除EPOLL_CTL_DEL，修改EPOLL_CTL_MODfd 监听的端口对应的句柄event 进行op操作的所有事件int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout);//从内核得到事件集合，返回需要处理的事件数目 以上我们可以得出epoll相对于select和poll的优点： 没有注册描述符的限制，也就是没有监听端口的限制，也不会因为监听端口的增加而性能降低 不用去遍历所有流得到能读或者写的流，epoll已经把哪个流产生了怎样的IO事件通知了我们，我们直接取出来即可 AIO在我看来一下的两种方式其实都是通过一种方式来进行异步的：先是通过多路复用也就是Nio来实现非阻塞，然后再通过创建线程做其它事情的方式避免等待从内核缓冲区向用户空间复制数据 所以它们有一个共同点就是要先在用户空间创建buffer Future方式 12345678910111213141516171819 Path path = Paths.get("/data/code/github/java_practice/src/main/resources/1log4j.properties"); AsynchronousFileChannel channel = AsynchronousFileChannel.open(path); ByteBuffer buffer = ByteBuffer.allocate(1024); Future future = channel.read(buffer,0);// while (!future.isDone())&#123;// System.out.println("I'm idle");// &#125;//我们可以在这里做其它事情 Integer readNumber = future.get(); buffer.flip(); CharBuffer charBuffer = CharBuffer.allocate(1024); CharsetDecoder decoder = Charset.defaultCharset().newDecoder(); decoder.decode(buffer,charBuffer,false); charBuffer.flip(); String data = new String(charBuffer.array(),0, charBuffer.limit()); System.out.println("read number:" + readNumber); System.out.println(data); 因为Future的本质就是直接返回而创建新的线程运算得到结果，运算结束后自己去取结果 回调方式 12345678910111213141516171819Path path = Paths.get("/data/code/github/java_practice/src/main/resources/1log4j.properties");AsynchronousFileChannel channel = AsynchronousFileChannel.open(path);ByteBuffer buffer = ByteBuffer.allocate(1024);channel.read(buffer, 0, buffer, new CompletionHandler() &#123; @Override public void completed(Integer result, ByteBuffer attachment) &#123; System.out.println(Thread.currentThread().getName() + " read success!"); &#125; @Override public void failed(Throwable exc, ByteBuffer attachment) &#123; System.out.println("read error"); &#125;&#125;);while (true)&#123; System.out.println(Thread.currentThread().getName() + " sleep"); Thread.sleep(1000);&#125; 创建新的线程从内核取数据，所以completed方法也是在新线程上完成的 参考Linux io模式、select、poll、epoll https://segmentfault.com/a/1190000003063859 https://blog.csdn.net/tianjing0805/article/details/76021440 Aio https://juejin.im/entry/583ec2e3128fe1006bfa6c83]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[transient关键字]]></title>
    <url>%2F2018%2F03%2F13%2Fjava%2Ftransient%E5%85%B3%E9%94%AE%E5%AD%97%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[深克隆和浅克隆]]></title>
    <url>%2F2018%2F03%2F13%2Fjava%2F%E6%B7%B1%E5%85%8B%E9%9A%86%E5%92%8C%E6%B5%85%E5%85%8B%E9%9A%86%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[ArrayList源码解析]]></title>
    <url>%2F2018%2F03%2F13%2Fjava%2F%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%2FArrayList%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[####Arrays.copyof 12345public static &lt;T, U&gt; T[] copyOf(U[] original, int newLength, Class&lt;? extends T[]&gt; newType) &#123; T[] copy = newType == Object[].class ? new Object[newLength] : (Object[])Array.newInstance(newType.getComponentType(), newLength); System.arraycopy(original, 0, copy, 0, Math.min(original.length, newLength)); return copy; &#125; 函数解释：返回一个元素original数组一样的但是引用不一样的数组。 ####System.arraycopy 123public static native void arraycopy(Object src, int srcPos, Object dest, int destPos, int length); 函数解释：从指定的源数组复制数组，从指定位置，到目标数组的制定位置。源数组为src，目标数组为dest，复制的组件数量为length，从源数组复制的位置从下标srcPos到srcPos+length-1(源数组要复制的结尾的下标)，被复制到dest数组从下标destPos到destPos+length-1(目标数组要复制的结尾的下标)的位置。 ####变量 123456private static final int DEFAULT_CAPACITY = 10; //默认的数组容量private static final Object[] EMPTY_ELEMENTDATA = new Object[0]; //临时实例化private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = new Object[0];transient Object[] elementData; //缓存private int size;//数组大小private static final int MAX_ARRAY_SIZE = 2147483639; //MAX_ARRAY_SIZE=Integer.MAX_VALNE-8;是因为虚拟机在数组数组类型数据中保留head word字段，其会占用空间。 ####构造器 无参构造函数 123public ArrayList() &#123; this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA;&#125; 构造时是将空数组赋值给elementData ，但是在随后的第一个add元素的时候，会先新创建一个容量为10的初始数组。 指定容量构造函数 123456789101112public ArrayList(int initialCapacity) &#123; if (initialCapacity &gt; 0) &#123; this.elementData = new Object[initialCapacity]; &#125; else &#123; if (initialCapacity != 0) &#123; throw new IllegalArgumentException("Illegal Capacity: " + initialCapacity); &#125; this.elementData = EMPTY_ELEMENTDATA; &#125;&#125; 集合构造函数 1234567891011public ArrayList(Collection&lt;? extends E&gt; c) &#123; this.elementData = c.toArray(); if ((this.size = this.elementData.length) != 0) &#123; if (this.elementData.getClass() != Object[].class) &#123; this.elementData = Arrays.copyOf(this.elementData, this.size, Object[].class); &#125; &#125; else &#123; this.elementData = EMPTY_ELEMENTDATA; &#125;&#125; ####Method add12345678private void add(E e, Object[] elementData, int s) &#123; if (s == elementData.length) &#123; elementData = this.grow(); &#125; elementData[s] = e; this.size = s + 1;&#125; 每一次添加元素的时候都会检查缓存数组的长度是否不够，不够就会加1 grow1234567private Object[] grow() &#123; return this.grow(this.size + 1);&#125; private Object[] grow(int minCapacity) &#123; return this.elementData = Arrays.copyOf(this.elementData,this.newCapacity(minCapacity));&#125; newCapacity123456789101112131415private int newCapacity(int minCapacity) &#123; int oldCapacity = this.elementData.length; int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1);// if (newCapacity - minCapacity &lt;= 0) &#123; if (this.elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) &#123; return Math.max(10, minCapacity); &#125; else if (minCapacity &lt; 0) &#123; throw new OutOfMemoryError(); &#125; else &#123; return minCapacity; &#125; &#125; else &#123; return newCapacity - 2147483639 &lt;= 0 ? newCapacity : hugeCapacity(minCapacity); &#125;&#125; 如果指定容量大于初始容量的1.5倍，且容量为空的话就初始化容量为10，不然就是指定容量的大小；所以这里当一个空的ArrayList添加一个元素后容量都会变为10. remove123456789101112public E remove(int index) &#123; Objects.checkIndex(index, this.size); ++this.modCount; E oldValue = this.elementData(index); int numMoved = this.size - index - 1; if (numMoved &gt; 0) &#123; System.arraycopy(this.elementData, index + 1, this.elementData, index, numMoved); &#125; this.elementData[--this.size] = null; return oldValue;&#125; 把从要移除元素的下标位置开始每个元素向前移动一个位置，然后另最后一个元素为null； addAll12345678910111213141516171819202122232425public boolean addAll(int index, Collection&lt;? extends E&gt; c) &#123; this.rangeCheckForAdd(index); Object[] a = c.toArray(); ++this.modCount; int numNew = a.length; if (numNew == 0) &#123; return false; &#125; else &#123; Object[] elementData = this.elementData; int var10001 = this.elementData.length; int s = this.size; if (numNew &gt; var10001 - this.size) &#123; elementData = this.grow(s + numNew); &#125; int numMoved = s - index; if (numMoved &gt; 0) &#123; System.arraycopy(elementData, index, elementData, index + numNew, numMoved); &#125; System.arraycopy(a, 0, elementData, index, numNew); this.size = s + numNew; return true; &#125;&#125; 先扩大数组容量，然后从指定位置开始把所有元素向后面移动要添加元素数量的位置，然后再将要添加元素的从指定位置开始插入。 removeRange12345678protected void removeRange(int fromIndex, int toIndex) &#123; if (fromIndex &gt; toIndex) &#123; throw new IndexOutOfBoundsException(outOfBoundsMsg(fromIndex, toIndex)); &#125; else &#123; ++this.modCount; this.shiftTailOverGap(this.elementData, fromIndex, toIndex); &#125;&#125; 从toIndex+1以后的所有元素移动到fromIndex的位置以后，然后再另length-1-（toIndex-fromIndex）位置后的所有元素为null 一些内部类ArrayListSpliteratorjava8 并行迭代 Spliterator接口 Spliterator 是Java8 引入的新接口，顾名思义，Spliterator可以理解为Iterator的Split版本，对于Java的流API，进行并行分割迭代计算，充分利用多核CPU的优势，并行计算具有极大的辅助作用。在使用Iterator的时候，我们一般都是单线程地去顺序遍历集合的元素，但是使用Spliterator可以将集合元素分割成多份，使用多个线程 同时进行迭代，大大地提高了执行效率。 SubList相当于ArrayList的一个子视图，所以对它的操作也会反应到ArrayList上，它的工作原理就是依赖于下面三个变量 123private final ArrayList&lt;E&gt; root; // 从root里面获得子listprivate final int offset; //SubList的开始，root截断的起点private int size;//subList的大小 ItrArrayList自定义实现的容器，实现了fail-fast机制（在遍历过程中如果modCount与expectedModCount不相等，则抛出ConcurrentModificationException异常） ListItr继承自ArrayList.Itr，扩展了ListIterator的方法，能够在遍历过程中进行更多的操作。 三种元素访问 随机访问 12345String value = null;int size = list.size();for (int i=0; i&lt;size; i++) &#123; value = (String )list.get(i); &#125; 此方法是直接在缓冲数组上的通过索引访问的，速度最快 foreach访问 1234String value = null;for(String a : list)&#123; value = a;&#125; foreach访问也比随机访问要慢，但是要快于迭代器的方式（foreach是一种语法糖，在编译期间需要进行语法解析，插入额外的辅助访问的代码，会有一定的消耗） 迭代器访问 12345String value = null;Iterator iter = list.iterator();while (iter.hasNext()) &#123; value = (String )iter.next();&#125; 速度最慢，由于要保存迭代器的状态，所以性能受到损耗 一些需要注意的点 底层通过System.arraycopy将原来ArrayList的缓冲数组elementData拷贝给新的ArrayList的缓冲数组，这里是一个深克隆，操作新的数组并不会改变原来的数组的状态。 每一次影响集合结构的修改（包括增加、删除、扩容、移动元素位置，不包括修改set）ArrayList的时候都要使得modCount自增，确保感知在使用迭代器和进行序列化过程中是否发生并发修改ArrayList的情况 在子列表上的操作（如add、remove等）都会反映到原来的ArrayList上面（共用elementData），即子列表只是提供一种在原列表上的一种视图。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>ArrayList</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java位运算符]]></title>
    <url>%2F2018%2F03%2F12%2Fjava%2Fjava%E4%BD%8D%E8%BF%90%E7%AE%97%E7%AC%A6%2F</url>
    <content type="text"><![CDATA[binary 二进制 octal 八进制 decimal 十进制 hexaddecimal 十六进制 a = D(60) = B(001111100) b = D(13) = B(00001101) 按位右移运算符(&gt;&gt;)左操作数按位右移右操作数指定的位数 a&gt;&gt;2 = D(15) = B(1111) 对于十进制来说就是 ａ= a / 2^2 按位左移运算符(&lt;&lt;)左操作数按位左移右操作数指定的位数 a&lt;&lt;2 = D(240) = H(11110000) 对于十进制来说就是 ａ = a* 2^2 按位右移补零运算符(&gt;&gt;&gt;)a&gt;&gt;&gt;2 = D(15) = B(00001111) 与运算符(&amp;)如果相对应位都是1，则结果为1，否则为0 a&amp;b = D(12) = B(00001100) 或运算符(|)如果相对应位都是0，则结果为0，否则为1 (a|b) = D(61) = B(00111101) ##### ^运算符 如果相对应位值相同，则结果为0，否则为1 (a ^ b) = D(49) = B(00110001) ~运算符按位补运算符翻转操作数的每一位，即0变成1，1变成0。 ~a = D(-61) = B(11000011)]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>位运算</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[String源码解析]]></title>
    <url>%2F2018%2F03%2F12%2Fjava%2F%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%2FString%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[####变化 在JDK 8之前，String的源码实现都是通过使用char数组接收字符串，但是每个char字符是由两个字符组成，因为java内部使用UTF-16实现；如果一个字符串含有英文字符，那么这些英文字符的前 8 比特都将为 0，因为一个ASCII字符都能被单个字节来表示。然而我们在使用字符串的时候只需8bit的情况占大多数。由于这种情况jvm堆空间通常很大一部分被字符串占据。 在java1.6时候引入了一个新的虚拟机参数 UseCompressedStrings；字符串将以byte数组的形式存储，代替原来的char。然而在JDK 7中被移除，主要原因在于它将带来一些如法预料的性能问题。 JDK 9中String对象的实现#####实现方式 1private final byte[] value; 用于存储String的字节编码 1234private final byte coder;static final boolean COMPACT_STRINGS = true;static final byte LATIN1 = 0;static final byte UTF16 = 1; 这些是JDK 9用于解决字符串占用内存空间大的方案的变量 每个String对象都拥有一个coder变量，它有两个值:0或者1,分别对应LATIN1和UTF16；当coder=0时表示这个String对象是用LATIN1字符集进行编码，当coder=1时表示String对象是用UTF16进行编码。 我们可以根据构造函数作为切入点进行探究 12345678910111213141516171819202122public String(char[] value) &#123; this((char[])value, 0, value.length, (Void)null);&#125;String(char[] value, int off, int len, Void sig) &#123; if (len == 0) &#123; this.value = &quot;&quot;.value; this.coder = &quot;&quot;.coder; &#125; else &#123; if (COMPACT_STRINGS) &#123; byte[] val = StringUTF16.compress(value, off, len); if (val != null) &#123; this.value = val; this.coder = 0; return; &#125; &#125; this.coder = 1; this.value = StringUTF16.toBytes(value, off, len); &#125;&#125; 从第二个构造函数我们可以很清楚的看到实现方式： 12345678910111213141516171819202122232425262728293031323334if (COMPACT_STRINGS) &#123; byte[] val = StringUTF16.compress(value, off, len); if (val != null) &#123; this.value = val; this.coder = 0; return; &#125; &#125; this.coder = 1; this.value = StringUTF16.toBytes(value, off, len); //StringUTF16的方法 public static byte[] compress(char[] val, int off, int len) &#123; byte[] ret = new byte[len]; return compress((char[])val, off, ret, 0, len) == len ? ret : null;&#125; //StringUTF16的方法public static int compress(char[] src, int srcOff, byte[] dst, int dstOff, int len）&#123; for(int i = 0; i &lt; len; ++i) &#123; char c = src[srcOff]; if (c &gt; 255) &#123; len = 0; break; &#125; dst[dstOff] = (byte)c; ++srcOff; ++dstOff; &#125; return len;&#125; 首先根据String的类变量COMPACT_STRINGS 默认为true判断是否对String对象进行压缩；根据compress()方法我们能够看出来 压缩是根据字符串是不是全部能够根据ASCII码表找对应的编码，如果有一个字符不符合，那么就会返回0，从而不进行压缩，而是直接采用UTF16进行编码。 内置的比较器1public static final Comparator&lt;String&gt; CASE_INSENSITIVE_ORDER = new String.CaseInsensitiveComparator(); 这个是String内部默认的排序方式 1234567891011121314151617181920private static class CaseInsensitiveComparator implements Comparator&lt;String&gt;, Serializable &#123; private static final long serialVersionUID = 8575799808933029326L; private CaseInsensitiveComparator() &#123; &#125; public int compare(String s1, String s2) &#123; byte[] v1 = s1.value; byte[] v2 = s2.value; if (s1.coder() == s2.coder()) &#123; return s1.isLatin1() ? StringLatin1.compareToCI(v1, v2) : StringUTF16.compareToCI(v1, v2); &#125; else &#123; return s1.isLatin1() ? StringLatin1.compareToCI_UTF16(v1, v2) : StringUTF16.compareToCI_Latin1(v1, v2); &#125; &#125; private Object readResolve() &#123; return String.CASE_INSENSITIVE_ORDER; &#125;&#125; 从代码也可以很容易看出来就是从第一个字符开始挨着挨着的比较，如果有一个字符不一样，那么就会直接比较这两个字符的大小，从而得出两个字符串的大小。 从源码可以学到的东西 检查方法参数是否正确 12345678910111213141516171819202122public String(char[] value, int offset, int count) &#123; this(value, offset, count, rangeCheck(value, offset, count));&#125; String(char[] value, int off, int len, Void sig) &#123; if (len == 0) &#123; this.value = "".value; this.coder = "".coder; &#125; else &#123; if (COMPACT_STRINGS) &#123; byte[] val = StringUTF16.compress(value, off, len); if (val != null) &#123; this.value = val; this.coder = 0; return; &#125; &#125; this.coder = 1; this.value = StringUTF16.toBytes(value, off, len); &#125;&#125; 我们可以用Void类型作为参数，接受如果运行正确的方法返回值为void的方法。 String类中存在的同步 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public boolean contentEquals(CharSequence cs) &#123; if (cs instanceof AbstractStringBuilder) &#123; if (cs instanceof StringBuffer) &#123; synchronized(cs) &#123; return this.nonSyncContentEquals((AbstractStringBuilder)cs); &#125; &#125; else &#123; return this.nonSyncContentEquals((AbstractStringBuilder)cs); &#125; &#125; else if (cs instanceof String) &#123; return this.equals(cs); &#125; else &#123; int n = cs.length(); if (n != this.length()) &#123; return false; &#125; else &#123; byte[] val = this.value; if (this.isLatin1()) &#123; for(int i = 0; i &lt; n; ++i) &#123; if ((val[i] &amp; 255) != cs.charAt(i)) &#123; return false; &#125; &#125; &#125; else if (!StringUTF16.contentEquals(val, cs, n)) &#123; return false; &#125; return true; &#125; &#125;&#125;private boolean nonSyncContentEquals(AbstractStringBuilder sb) &#123; int len = this.length(); if (len != sb.length()) &#123; return false; &#125; else &#123; byte[] v1 = this.value; byte[] v2 = sb.getValue(); if (this.coder() == sb.getCoder()) &#123; int n = v1.length; for(int i = 0; i &lt; n; ++i) &#123; if (v1[i] != v2[i]) &#123; return false; &#125; &#125; return true; &#125; else &#123; return !this.isLatin1() ? false : StringUTF16.contentEquals(v1, v2, len); &#125; &#125;&#125; 在多线程中可能存在在比较的过程中，被比较的字符串被其它县城关改变，造成运行出错。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>String对象</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[面向实习的java后台学习知识点（待完善）]]></title>
    <url>%2F2018%2F03%2F12%2Fjava%2F%E9%9D%A2%E5%90%91%E5%AE%9E%E4%B9%A0%E7%9A%84java%E5%90%8E%E5%8F%B0%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E7%82%B9%EF%BC%88%E5%BE%85%E5%AE%8C%E5%96%84%EF%BC%89%2F</url>
    <content type="text"><![CDATA[java基础 集合框架 hashmap、linkedlist、arraylist 线程安全 vector、concurrenthash、hashtable 线程安全 关键字： syncronized、 violate 、reenterlock jvm锁优化 自旋锁….. String 常量池：运行时常量池、静态常量池 final —-&gt; 并发 StringBUffer、StringBuilder 线程 很杂（多线程面经） 线程池 有哪些 阻塞队列 拒绝策略 io BIO NIO nio在RPC框架中的作用 object toString hushcode equals 深克隆和浅克隆 wait 和sleep() notify 和notifyall JVM 内存区域 内存分配 内存回收 (GC 和 GC算法) class文件结构 内存模型(线程) 线程实现 线程优化 类加载器 Spring IOC(很重要的点，需要了解底层) AOP（很重要的点，需要了解底层） 事务 mybaties 怎么实现事务 spring mvc SpringBeanFactory spirngMVC处理流程 springmvc容器初始化 mysql 事务（四个特性、隔离级别、读问题） 并发处理(悲观锁、乐观锁) 索引(betry，hash、全文、空间) 优化(sql优化、分库分表(mycat) ) 计算机网络 http：分层、https 数字含义 tcp：三次握手、四次挥手 udp cookie、session 操作系统 调度算法 cpu 大文件的排序 数据结构 数组(内存形式)—&gt; 链表(栈(递归调用)、队列)—&gt;树(二叉树、完全二叉树、排序二叉树、平衡二叉树(B树)、遍历过程（中序、）)—&gt;图(因为现在还没有学习数据结构，学习过后再来总结这里的大的知识点) 算法 查找 排序 动态规划(贪婪算法) 项目 RPC(三宗罪、nio) 负载均衡(无状态服务) 注册中心(nio、路由算法、缓存(雪崩、扩展、内存/jvm 缓存)) 数据库缓存集群（读写分离、分库分表、高可用高扩展） Redis了解其基本实现]]></content>
      <tags>
        <tag>学习路线</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux上安装和部署redis]]></title>
    <url>%2F2018%2F03%2F09%2Flinux%2Flinux%E4%B8%8A%E5%AE%89%E8%A3%85%E5%92%8C%E9%83%A8%E7%BD%B2%2F</url>
    <content type="text"><![CDATA[关于linux下软件通过源码的安装 主要是以下四个步骤： ./configure 这个步骤主要是为了建立MakeFile文档 make clean 主要是为了清除可能已经产生了修改却编译了的目标文件 make 使用make就是要将原始码编译成为可以被执行的可执行档，而这个可执行档会放置在目前所在的目录之下，尚未被安装到预定安装的目录中 make install 通常这就是最后的安装步骤了，make会依据Makefile这个档案里面关于install的项目，将上一个步骤所编译完成的资料给他安装到预定的目录中 redis的安装和部署1.基础知识 redis是用C语言开发的一个开源的高性能键值对（key-value）数据库。它通过提供多种键值数据类型来适应不同场景下的存储需求，目前为止redis支持的键值数据类型如下字符串、列表（lists）、集合（sets）、有序集合（sorts sets）、哈希表（hashs）2.redis的应用场景 缓存（数据查询、短连接、新闻内容、商品内容等等）。（最多使用） 分布式集群架构中的session分离。 聊天室的在线好友列表。 任务队列。（秒杀、抢购、12306等等） 应用排行榜。 网站访问统计。 数据过期处理（可以精确到毫秒）3.安装redis 下面介绍在Linux环境下，Redis的安装与部署，使用redis-3.0稳定版,因为redis从3.0开始增加了集群功能。在后面我也会分享redis集群。 1.可以通过官网下载 地址：http://download.redis.io/releases/redis-3.0.0.tar.gz 2.使用linux wget命令 1wget http://download.redis.io/releases/redis-3.0.0.tar.gz 将redis-3.0.0.tar.gz拷贝到/usr/local下 1cp redis-3.0.0.rar.gz /usr/local 解压源码 1tar -zxvf redis-3.0.0.tar.gz 进入解压后的目录进行编译 1cd /usr/local/redis-3.0.0 安装到指定目录 如 /usr/local/redis 1make PREFIX=/usr/local/redis install redis.conf是redis的配置文件，redis.conf在redis源码目录。拷贝配置文件到安装目录下进入源码目录，里面有一份配置文件 redis.conf，然后将其拷贝到安装路径下 123cd /usr/local/redismkdir confcp /usr/local/redis-3.0.0/redis.conf /usr/local/redis/bin 进入安装目录bin下 1cd /usr/local/redis/bin 此时我们看到的目录结构是这样的 redis-benchmark redis性能测试工具redis-check-aof AOF文件修复工具redis-check-rdb RDB文件修复工具redis-cli redis命令行客户端redis.conf redis配置文件redis-sentinal redis集群管理工具redis-server redis服务进程 4.启动redis 1.前端模式启动直接运行bin/redis-server将以前端模式启动，前端模式启动的缺点是ssh命令窗口关闭则redis-server程序结束，不推荐使用此方法 1./redis-server 如图 2.后端模式启动修改redis.conf配置文件， daemonize yes 以后端模式启动 1vim /usr/local/redis/bin/redis.conf 执行如下命令启动redis： 12cd /usr/local/redis./bin/redis-server ./redis.conf 连接redis 1/usr/local/redis/bin/redis-cli 5.关闭redis强行终止redis进程可能会导致redis持久化数据丢失。正确停止Redis的方式应该是向Redis发送SHUTDOWN命令，命令为： 12cd /usr/local/redis./bin/redis-cli shutdown 强行终止redis 1pkill redis-server 让redis开机自启 123vim /etc/rc.local//添加/usr/local/redis/bin/redis-server /usr/local/redis/etc/redis-conf 至此redis已经全部安装完，后面我会分享redis.conf 详细配置以及说明。 安装redis的一些问题 若出现如下提示，则说明未安装gcc，使用命令安装gcc：apt-get install gcc 12345678[root@localhost redis-2.8.17]# makecd src &amp;&amp; makeallmake[1]: Entering directory `/root/redis-2.8.17/src‘CC adlist.o/bin/sh:cc: command not foundmake[1]: *** [adlist.o] Error127make[1]: Leaving directory `/root/redis-2.8.17/src‘make: *** [all] Error2 若出现如下提示，则将make改为make MALLOC=libc，推测是因为编译库的问题。 12345678910[root@localhost redis-2.8.17]#makecd src &amp;&amp; make allmake[1]: Entering directory `/root/redis-2.8.17/src‘CC adlist.oIn file included from adlist.c:34:0:zmalloc.h:50:31: error: jemalloc/jemalloc.h: No suchfileor directoryzmalloc.h:55:2: error:#error&quot;Newer version of jemalloc required&quot;make[1]: *** [adlist.o] Error1make[1]: Leaving directory `/root/redis-2.8.17/src‘make: *** [all] Error2 ​ jekins的安装下载程序包1wget http://mirrors.jenkins.io/war/latest/jenkins.war 启动程序包1java -jarjenkins.war --httpPort=8081 这里就相当于运行java程序，并且设置端口号为8081 当运行成功后就可以 使用浏览器进行访问 至于具体使用和配置可以参数 这个链接。 ssr的搭建下载安装ssr程序安装程序 1wget -N --no-check-certificate https://raw.githubusercontent.com/ToyoDAdoubi/doubi/master/ssr.sh &amp;&amp; chmod +x ssr.sh &amp;&amp; bash ssr.sh 然后按照安装程序走就行 如果希望查看ssr信息使用下面的命令 1bash ssr.sh 使用BBR加速 12345wget --no-check-certificate https://github.com/teddysun/across/raw/master/bbr.shchmod +x bbr.sh./bbr.sh lsmod | grep bbr 如果出现tcp_bbr字样表示bbr已安装并启动成功]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于spring-data]]></title>
    <url>%2F2018%2F03%2F09%2Fjavaweb%2F%E5%85%B3%E4%BA%8Espring-data%E7%9A%84%E5%9D%91%2F</url>
    <content type="text"><![CDATA[只导入spring-date-redis是会在运行的时候报错的，需要自己导入下面两个包 1234567891011&lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-pool2&lt;/artifactId&gt; &lt;version&gt;2.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;version&gt;2.9.0&lt;/version&gt;&lt;/dependency&gt; spring-data-redis 2.x 只适合spring5.x hespring boot2.x]]></content>
      <categories>
        <category>javaweb</category>
      </categories>
      <tags>
        <tag>spring-date redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux装windwos后修复MBR]]></title>
    <url>%2F2018%2F03%2F03%2Flinux%2Flinux%E8%A3%85windwos%E5%90%8E%E4%BF%AE%E5%A4%8DMBR%2F</url>
    <content type="text"><![CDATA[原因在linux系统下安装windows系统，windows系统比较霸道，会覆盖掉所有的MBR文件，所有下次启动的时候不会使你选择启动的系统而是直接进入windows系统。这个时候就需要修复引导文件。 修复引导文件 用U盘做一个linux的启动盘 用启动盘进入试用 打开命令行终端 sudo add-apt-repository ppa:yannubuntu/boot-repair &amp;&amp; sudo apt-get update sudo apt-get install -y boot-repair &amp;&amp; boot-repair 出现的界面里面选择Recommended repair 使用完成就完成了 注意 如果有些人不小心点击了Create a BootInfo summary的话，那你的开机启动界面将会出来一大堆你以前没见过的东西。 那样的话，你可以输入名令：cd /boot/grub 接着输入sudo gedit grub.cfg,打开grub.cfg文件后，通过搜索找到windows，然后把下面这些删去就和原来一样了。]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>MBR</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql相关问题]]></title>
    <url>%2F2018%2F02%2F27%2Fmysql%2Fmysql%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[增加远程登录权限 本地登录mysql后执行一下命令 12grant all privileges on *.* to root@&apos;%&apos; identified by &apos;root&apos;;flush privileges; ​]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git命令]]></title>
    <url>%2F2018%2F02%2F27%2Fgit%2Fgit%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[删除远程仓库中的文件或者文件夹1git rm -r -n --cached */src/\* 这个命令是删除远程仓库的src目录下的所有文件， -n 加上这个这个参数是执行命令时预览要删除的文件，但是这个命令不会执行删除操作。 所以最终执行的是： 1git rm -r --cached */src/\* 然后再 git commit， git push 就完成了远程仓库文件的删除。]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux软件推荐]]></title>
    <url>%2F2018%2F02%2F26%2Flinux%2Flinux%E8%BD%AF%E4%BB%B6%E6%8E%A8%E8%8D%90%2F</url>
    <content type="text"><![CDATA[linux端的ssrgithub地址 跨平台百度网盘github地址 操作方法github上很详细 直接在命令行操作方便 #####自制webapp 首先安装appifier github地址 安装deb包 sudo dpkg -i Appifier_x.x.x_amd64.deb 安装npm包 sudo apt-get install npm 安装electron npm install electron –save-dev –save-exact 安装electron-installer-debian包 npm install -g electron-installer-debian 然后是在appifier上生成文件 然后通过以下命令生成deb包，安装(以下命令安装或者通过软件管理器安装) electron-installer-debian –src /home/jingle/Desktop/Wechat-linux-x64/ –dest /home/jingle/Desktop/wechat/ –arch amd64 dpkg -i dir 在这里可能会遇到类似错误： 123Error: No Description or ProductDescription provided at getOptions (/usr/lib/node_modules/electron-installer-debian/src/installer.js:149:11) at getDefaults.then.defaults (/usr/lib/node_modules/electron-installer-debian/src/installer.js:418:23) &apos;Error: No Description or ProductDescription provided\n at getOptions (/usr/lib/node_modules/electron-installer-debian/src/installer.js:149:11)\n at getDefaults.then.defaults (/usr/lib/node_modules/electron-installer-debian/src/installer.js:418:23)&apos; 只需要在/home/…/Desktop/Gmail-linux-x64/resources/app.asar.unpacked/package.json文件里面按照格式添加description和productDescription属性。 参考链接 http://ijingle.cc/2018/02/11/appifier-build-webapp/]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux软件</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多线程]]></title>
    <url>%2F2018%2F02%2F26%2Fjava%2F%E5%A4%9A%E7%BA%BF%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[关于创建线程池 如果熟悉了线程池的创建过程或者说一些参数的意义那么可以直接使用下列方式进行线程池的创建 123ExecutorService executorService = Executors.newCachedThreadPool();ExecutorService executorService2 = Executors.newFixedThreadPool(int);ExecutorService executorService3 = Executors.newSingleThreadExecutor(); 讲一讲各种线程池的好坏 CachedThreadPool: 好处:在程序执行过程中通常会创建与所需数量相同的线程，然后在它回收旧线程时停止创建新线程，因此它是合理的Executor的首选； 坏处：线程最大数是Integer.MAX_VALUE，可能会创建数量非常多的线程，甚至oom； FixedThreadPool: 好处：一次性预先执行代驾高昂的线程分配，因而也就可以限制线程数量。这可以节省时间，因为你不用为每个任务都固定的付出创建线程的开销。 坏处：堆积的请求处理的队列耗费非常大的内存，甚至oom SingleThreadPool： 好处：确保任意时刻在任何线程中都只有唯一的任务在运行，在这种方式下你不需在共享资源上处理同步。 坏处：堆积的请求处理的队列耗费非常大的内存，甚至oom 在不熟悉的情况下使用ThreadPoolExecutor创建线程池，因为在这样的情况下我们可以更加明确线程池的运行规则，规避资源耗尽的风险。 用ThreadPoolExecutor创建线程池的方式： 1ExecutorService executorSeervice = new ThreadPoolExecutor(&apos;corePoolSize&apos;,&apos;maximumPoolSize&apos;,&apos;keepAliveTime&apos;,&apos;timeUnit&apos;,&apos;blockingQueue&apos;,&apos;abortPolicy&apos;) 对每个参数解释一下： corePoolSize：核心线程数量 maximumPoolSize：最大线程数量 keepAliveTime：保持活动时间，如果池中当前有多于corePoolSize，则这些多出的线程在空闲的使劲超过keepAliveTime时将会终止 BlockingQueue都可用于传输和保持提交的任务，使用此队列与池大小进行交互；如果请求任务时运行的线程数小于corePoolSize那么直接创建新的线程 运行任务；多于的话就将添加到队列里面；超出MaxPoolSize那么任务就会被拒绝，然后用abortPolicy进行任务拒绝。 排队有三种通用策略： 1231. 直接提交：工作队列的默认选项是使用SynchronousQueue，通常要求无界的maxPoolSize；2. 无界队列：如使用LinkedBlockingQueue；3. 有界队列：如 ArrayBlockingQueue 拒绝规则 有四种拒绝规则，当任务被拒绝过后就使用这些拒绝规则 ThreadPoolExecutor.AbortPolicy：用于被拒绝任务的处理程序，它将抛出 RejectedExecutionException ThreadPoolExecutor.CallerRunsPolicy:用于被拒绝任务的处理程序，它直接在 execute 方法的调用线程中运行被拒绝的任务；如果执行程序已关闭，则会丢弃该任务。 ThreadPoolExecutor.DiscardLOldestPolicy：用于被拒绝任务的处理程序，它放弃最旧的未处理请求，然后重试 execute；如果执行程序已关闭，则会丢弃该任务。 ThreadPoolExecutor.DiscardPolicy:用于被拒绝任务的处理程序，默认情况下它将丢弃被拒绝的任务。 threadPoolExecutor的其它方法： 钩子方法：用于在每个任务执行之前执行一些方法 队列维护：通过getQueue()方法方位工作队列然后通过remove（）或者purge（）取消大量已排队任务时帮助进行存储回收。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[内部类]]></title>
    <url>%2F2018%2F02%2F26%2Fjava%2F%E5%86%85%E9%83%A8%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[内部类使用内部类的原因： 内部类的方法可以访问该类定义所在的作用域中的数据，包括私有的数据； 内部类可以对同一个包中的其他类隐藏依赖； 当想要定义一个回调函数且不想编写大量代码的时候，使用匿名内部类比较便捷 使用内部类访问对象的状态 就是内部类隐式的含有一个外部类的指针，所以可以访问创建她的外围类对象的数据域 内部类的特殊语法规则 引用外围对象的变量 虽然我们在内部类可以直接使用变量名来直接使用，但是正规语法要复杂一些： 1OuterClass.this.变量名 比如：TalkingClock.this.beep 构造内部类 12TalkingClock jabberer = new TalkingClock(...);TalkingClock.TimePrinter listener = jabber.new TimePrinter(); 内部类中声明的所有静态域都必须是final的，原因就是我们希望一个静态域只有一个实例，不过对于每个外部对象，会分别有一个单独的内部类实例；也就是说我们希望每个外围对象都有一个特定的内部类实例。 关于内部类的一些讨论 内部类是一个编译器现象，与虚拟机无关，编译器会把所有内部类翻译成用$分隔开外部类名与内部类型的常规文件，而虚拟机对此一无所知；下面是一个Demo 1234567public class TalkingClock$TimePrinter&#123; public TalkingClock$TImePrinter(TalkingClock); public void actionPerformed(ActionEvent); final TalkingClock this$0;&#125; 上面的Demo就说明 内部类只是通过构造器初始化了一个外围类；然后通过this$0指向外围类； 可以在方法中使用局部内部类 匿名内部类: 在现在我的理解就是实例化一个只有一个方法的接口；现在完全可以用lambda表达式替代； 静态内部类： 使用原因：有时候内部类只是为了把一个类隐藏在另外一个类的内部，并不需要内部类引用外围类的对象。 也就是你只是临时想给外围类提供一个对象用于存储一些变量的时候可以使用静态内部类；]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>内部类</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[voilatile引发的血案]]></title>
    <url>%2F2018%2F02%2F25%2Fjava%2Fvoilatile%E5%BC%95%E5%8F%91%E7%9A%84%E8%A1%80%E6%A1%88%2F</url>
    <content type="text"><![CDATA[java内存模型每条线程都拥有自己的内存空间，自己内存空间的变量其它线程无法访问；共享的变量是存放在主内存 中的，如果线程要访问，那么就会从主内存中拷贝过来，然后在自己的内存空间中使用。 这有可能引发脏读问题，也就是说当一个线程获取到一个资源后对它进行了修改，但是并没有立即提交到主存，这就造成了其它线程去读取这个资源的时候获取到的资源不是最新的； 问题：初始时，两个线程访问同一个变量i=10，两个线程也都对他们进行了+1操作，这是因为两个线程都取得的i为10所以加1后都为11，所以最终主存中i的值为11；而我们期望的是12；解决方法：使用java.util.concurrent.atomic包下提供了一些原子操作类对变量进行操作，这样这个变量对的取值和赋值为一个原子性的操作不会被打断，那么不管另外一个线程什么时候读取i变量都能够保证为一个最新的值，即能保证i最终为12 并发编程的三大概念 原子性 定义：一个操作或者多个操作要么全部执行并且执行过程中不能够被打断，要么都不执行。 java中的原子性：对基本类型的读取和赋值是原子性的x=10;y=x;x++;x=x+1;其中只有第一句话是原子性的操作；第一句话是直接将数值10写入到线程的内存当中；第二句话是先去读取x的值，然后再讲值写入y代表的内存当中；第三句话差不多也是先读取x的值然后进行+1操作；第四句话和第三句话一样。 voilatile不能保证变量+-的原子性，可以使用java.util.concurrent.atomic包下提供了一些原子操作类 可见性 定义：可见性是当多个线程访问同一个变量的时候，一个线程修改了这个歌变量的值，其他线程能够立即看得到修改的值。 java中的可见性对于可见性java提供了volatile关键字来保证可见性。当一个共享变量被volatile修饰时，它会保证修改的值立即被更新到主存，当有其它线程需要读取值时也都会到主存中读取；而普通的共享变量被修改过后什么时候写入到主存是不确定的； 有序性 定义：即程序执行的顺序按照代码的先后顺序执行； ​ 给一个例子 12345678910111213context = loadContext; //语句1inited = true; //语句2//线程2:while(!inited )&#123;sleep&#125;doSomethingwithconfig(context); 上面的代码中由于语句1和语句2没有数据依赖，因此可能会重排序。假如发生了重排序，在线程1执行过程中先执行语句2，而此是线程2会以为初始化工作已经完成，那么就会跳出while循环，去执行doSomethingwithconfig(context)方法，而此时context并没有被初始化，就会导致程序出错。 ​ java的有序性 在Java内存模型中，允许编译器和处理器对指令进行重排序，但是重排序过程不会影响到单线程程序的执行，却会影响到多线程并发执行的正确性。 1234567891011121314在Java里面，可以通过volatile关键字来保证一定的“有序性”。即volatile变量的语句不会与它前面或者后面的语句进行重排序，但是不能保证它前面或者后面的语句之间不会重排序。 happens-before原则：- 程序次序规则：：一个线程内，按照代码顺序，书写在前面的操作先行发生于书写在后面的操作 注意，虽然这条规则中提到“书写在前面的操作先行发生于书写在后面的操作”，这个应该是程序看起来执行的顺序是按照代码顺序执行的，但是虚拟机可能会对程序代码进行指令重排序。虽然进行重排序，但是最终执行的结果是与程序顺序执行的结果一致的，它只会对不存在数据依赖性的指令进行重排序。因此，在单个线程中，程序执行看起来是有序执行的，这一点要注意理解。事实上，这个规则是用来保证程序在单线程中执行结果的正确性，但无法保证程序在多线程中执行的正确性。- 锁定规则：一个unLock操作先行发生于后面对同一个锁的lock操作 也就是说无论在单线程中还是多线程中，同一个锁如果处于被锁定的状态，那么必须先对锁进行了释放操作，后面才能继续进行lock操作。- volatile变量规则 直观地解释就是，如果一个线程先去写一个变量，然后一个线程去进行读取，那么写入操作肯定会先行发生于读操作。- 传递规则：如果操作A先行发生于操作B，而操作B又先行发生于操作C，则可以得出操作A先行发生于操作C- 线程启动规则- 线程中断规则- 线程终结规则- 对象终结规则]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>volatile</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[javaweb中的编码]]></title>
    <url>%2F2018%2F02%2F25%2Fjavaweb%2Fjavaweb%E4%B8%AD%E7%9A%84%E7%BC%96%E7%A0%81%2F</url>
    <content type="text"><![CDATA[JavaWeb中的编码问题 编码的原因： 计算机中存储信息的最小单位是一个字节，所能表示的字符范围是0—255个 人类要表示的符号太多，无法用1个字节表示。 一些对于编码问题的总结 只要有IO流就必定有编码和解码 关于IDEA平台下的System.out.println()，它是直接将我们的经过解码的字符串的字节数组进行打印，然后操作系统用这些字符数组与字符形状表进行对比，打印出来 什么时编码解码 编码：编码的原因是把我们人类所认识的字符编码为计算机认识的0,1代码，便于存储在计算机的磁盘中或者在网络中传输；又出现了一个问题，为什么不对解码的内容直接进行存储，而非要编码为计算机认识的0，1代码？又因为地区的不一样或者甚至说不同软件之间都可能采用不同的编码，比如说记事本一般采用GBK编码而IDEA我们可以设置为UTF-8进行存储，如果我们直接对字节集解码的内容进行存储，就会不具有通用性。 解码：将计算机磁盘存储的数据或者网络IO流中的数据，按照字符集解码为对应的字节数组；有了这样的字节数组那么计算机就可以对应字符形状表显示在显示器上 常见的编码 ASCII ISO-8859-1:256个字符，涵盖大多数西欧字符； GB2312：双字节，中文编码； GBK： GB2312的扩展； GB18030：中文，单双四字节都有； UTF-16：两个字节表示一个字符； UTF-8：运用变长技术，ASCII用单字节表示，中文用三个字节表示。 Java中如何解编码 首先会根据指定的charsetName也就是你指定的编码类型，通过Charset.forName(charsetName)找到Charset类，然后根据Charset创建CharsetEncoder对象，再调用CharsetEncoder.encode对字符串编码，不同的编码类型都会对应到一个类中 ，实际的编码过程就是在这些类中完成的。 几种编码方式的比较对于中文字符由于GBK比GB2312范围更大，编码方式相同，所以GBK更好。UTf-16编码效率更高，只是把一个字节拆成两个字节就完成它的工作，所以在磁盘与内存上的操作它更适合，但是在字节容易损坏的网络上utf-8更适合，它不像utf-16顺序编码，一个字节的损坏会影响后面的字符。且编码效率上utf-8介于GBK和utf-16之间。 JavaWeb中涉及的编码 url的编解码 http://localhost:8080//examples/servlets/serlet/君山?authod=君山 sheme domin port contextPath servletPath pathInfo queryString 一般情况下pathInfo采用的是utf-8编码，然后浏览器会将非ASCII字符按照某种编码格式编码成16进制数字后将每个16进制数字表示的字节前加上%，Tomcat的设置上默认也是按照utf-8解码pathInfo；queryString是按照传输中在header中设置的contentType编码方式进行编码，然后在Tomcat中可以设置useBodyEncodingForURI=“true”将queryString的解码方式采用的也是contentType设置的编码方式。 HTTP Header 的编解码 header中只能传输ASCII字符，不能采用其他编解码方式；如果一定要传递可以先将这些字符用URIEncoder编码再添加到Header中。 Post表单上的编解码 在POST提交的时候会按照ContentType编码，tomcat也会按照ContentType解码；Tomcat在getParameter方法之前会获取contentType中的charset；但是这里有一种特殊情况，在 POST提交表单的时候默认情况下 ContentType是不会有值的就会采用默认的ISO-8859-1；而在jsp中设置的contentType中的Charset是告诉浏览器该页面该用什么解码。 HTTP body的编解码 在服务器通过response返给浏览器的时候与request给服务器的编解码过程差不多；通过设置response的contentType然后服务器和浏览器就用这个charset对body进行编解码。]]></content>
      <categories>
        <category>javaweb</category>
      </categories>
      <tags>
        <tag>javaweb编码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[生成ssh秘钥]]></title>
    <url>%2F2018%2F02%2F25%2Fgit%2F%E7%94%9F%E6%88%90ssh%E7%A7%98%E9%92%A5%2F</url>
    <content type="text"><![CDATA[首先检查有没有ssh秘钥 ls -al ~/.ssh 生成秘钥 ssh-keygen -t rsa -C “your_email@example.com“]]></content>
      <tags>
        <tag>ssh秘钥</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[有关linux的命令]]></title>
    <url>%2F2018%2F02%2F25%2Flinux%2F%E6%9C%89%E5%85%B3linux%E7%9A%84%E5%91%BD%E4%BB%A4%E5%92%8C%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[比较好的linux基础命令总结 命令错误的情况sudo: add-apt-repository：找不到命令 solution：sudo apt-get install python-software-properties ​ sudo apt-get install software-properties-common 设置命令的快捷方式 vim ~/.bashrc设置别名 alias ll=’ls -al’ 如果要执行多条命令中间用分好分隔就行 source ~/.bashrc #####配置java环境变量 首先下载jdk 在linux下通过wget下载 命令示例： 1wget --no-check-certificate --no-cookies --header &quot;Cookie: oraclelicense=accept-securebackup-cookie&quot; http://download.oracle.com/otn-pub/java/jdk/8u111-b14/jdk-8u111-linux-x64.tar.gz sudo tar zxvf ./{jdk文件} -C /usr/lib cd /usr/lib sudo mv {jdk文件} jdk8 sudo vi /etc/profile 在最后加入 1234export JAVA_HOME=/usr/lib/jdk7export JRE_HOME=$&#123;JAVA_HOME&#125;/jreexport CLASSPATH=.:$&#123;JAVA_HOME&#125;/lib/tools.jar:$&#123;JRE_HOME&#125;/lib/dt.jarexport PATH=$&#123;JAVA_HOME&#125;/bin:$&#123;JAVA_HOME&#125;/jre/bin:$PATH sudo source /ect/profile 最后 通过 java -version 进行检查 #####设置系统自启动程序 rc.local自启动 在使用了systemd作为启动器的系统（如较新版的deepin）中，如果没有rc.local就自己创建，然后在文件里面写下如下内容： 123456#!/bin/bash# rc.local config file created by use把你需要执行的命令写在这里exit 0 再赋予权限 sudo chmod +x /etc/rc.local，下次重启时systemd就会自动执行rc.local里面的命令了 autostart自启动 在~/.configure/autostart 目录下添加自启动命令，以代理工具 XX-Net 为例，假定其启动脚本位于~/Documents/XX-Net-3.3.1/start。 12345678910111213141516171819[Desktop Entry]Type=ApplicationExec=&quot;~/Documents/XX-Net-3.3.1/start&quot;Hidden=falseNoDisplay=falseX-GNOME-Autostart-enabled=trueName[en_IN]=XX-NetName=XX-NetComment[en_IN]=XX-NetComment=XX-Net 系统启动时会执行 Exec所指定的命令 进程相关命令查询进程 ps命令查找与进程相关的PID号： ps a 显示现行终端机下的所有程序，包括其他用户的程序。 ps -A 显示所有程序。 ps c 列出程序时，显示每个程序真正的指令名称，而不包含路径，参数或常驻服务的标示。 ps -e 此参数的效果和指定”A”参数相同。 ps e 列出程序时，显示每个程序所使用的环境变量。 ps f 用ASCII字符显示树状结构，表达程序间的相互关系。 ps -H 显示树状结构，表示程序间的相互关系。 ps -N 显示所有的程序，除了执行ps指令终端机下的程序之外。 ps s 采用程序信号的格式显示程序状况。 ps S 列出程序时，包括已中断的子程序资料。 ps -t&lt;终端机编号&gt; 指定终端机编号，并列出属于该终端机的程序的状况。 ps u 以用户为主的格式来显示程序状况。 ps x 显示所有程序，不以终端机来区分。 最常用的方法是ps aux,然后再通过管道使用grep命令过滤查找特定的进程,然后再对特定的进程进行操作。ps aux | grep program_filter_word,ps -ef |grep tomc 杀死进程 通过PID杀死进程 1kill PID 通过进程名称杀死进程 1killall NAME ​ 网络相关指令netstat Netstat 命令用于显示各种网络相关信息，如网络连接，路由表，接口状态 (Interface Statistics)，masquerade 连接，多播成员 (Multicast Memberships) 等等。 相关参数 a (all)显示所有选项，默认不显示LISTEN相关 t (tcp)仅显示tcp相关选项 u (udp)仅显示udp相关选项 n 拒绝显示别名，能显示数字的全部转化成数字。 l 仅列出有在 Listen (监听) 的服務状态 p 显示建立相关链接的程序名 r 显示路由信息，路由表 e 显示扩展信息，例如uid等 s 按各个协议进行统计 c 每隔一个固定时间，执行该netstat命令。 提示：LISTEN和LISTENING的状态只有用-a或者-l才能看到 查看指定端口号的进程1# netstat -an | grep &apos;:80&apos; 杀死指定端口号的所有进程1kill -9 $(sudo lsof -i tcp:进程号 -t) 安装deb包 下面是一个例子： 1sudo dpkg -i Appifier_9.6.2_amd64.deb 实时跟踪tomcat的输出 进入tomcat的logs目录 例如： 1cd /usr/local/tomcat8/logs 1tail -f catalina.out linux下解压所有类型压缩类型文件的命令.tar解包：tar xvf FileName.tar打包：tar cvf FileName.tar DirName（注：tar是打包，不是压缩！）———————————————.gz解压1：gunzip FileName.gz解压2：gzip -d FileName.gz压缩：gzip FileName .tar.gz 和 .tgz解压：tar zxvf FileName.tar.gz压缩：tar zcvf FileName.tar.gz DirName———————————————.bz2解压1：bzip2 -d FileName.bz2解压2：bunzip2 FileName.bz2压缩： bzip2 -z FileName .tar.bz2解压：tar jxvf FileName.tar.bz2压缩：tar jcvf FileName.tar.bz2 DirName———————————————.bz解压1：bzip2 -d FileName.bz解压2：bunzip2 FileName.bz压缩：未知 .tar.bz解压：tar jxvf FileName.tar.bz压缩：未知———————————————.Z解压：uncompress FileName.Z压缩：compress FileName.tar.Z 解压：tar Zxvf FileName.tar.Z压缩：tar Zcvf FileName.tar.Z DirName———————————————.zip解压：unzip FileName.zip压缩：zip FileName.zip DirName———————————————.rar解压：rar x FileName.rar压缩：rar a FileName.rar DirName———————————————.lha解压：lha -e FileName.lha压缩：lha -a FileName.lha FileName———————————————.rpm解包：rpm2cpio FileName.rpm | cpio -div———————————————.deb解包：ar p FileName.deb data.tar.gz | tar zxf -——————————————— .tar .tgz .tar.gz .tar.Z .tar.bz .tar.bz2 .zip .cpio .rpm .deb .slp .arj .rar .ace .lha .lzh .lzx .lzs .arc .sda .sfx .lnx .zoo .cab .kar .cpt .pit .sit .sea解压：sEx x FileName.压缩：sEx a FileName. FileName sEx只是调用相关程序，本身并无压缩、解压功能，请注意！ gzip 命令减少文件大小有两个明显的好处，一是可以减少存储空间，二是通过网络传输文件时，可以减少传输的时间。gzip 是在 Linux 系统中经常使用的一个对文件进行压缩和解压缩的命令，既方便又好用。 语法：gzip [选项] 压缩（解压缩）的文件名该命令的各选项含义如下： -c 将输出写到标准输出上，并保留原有文件。-d 将压缩文件解压。-l 对每个压缩文件，显示下列字段： 压缩文件的大小；未压缩文件的大小；压缩比；未压缩文件的名字-r 递归式地查找指定目录并压缩其中的所有文件或者是解压缩。-t 测试，检查压缩文件是否完整。-v 对每一个压缩和解压的文件，显示文件名和压缩比。-num 用指定的数字 num 调整压缩的速度，-1 或 –fast 表示最快压缩方法（低压缩比），-9 或–best表示最慢压缩方法（高压缩比）。系统缺省值为 6。指令实例： gzip % 把当前目录下的每个文件压缩成 .gz 文件。gzip -dv % 把当前目录下每个压缩的文件解压，并列出详细的信息。gzip -l *% 详细显示例1中每个压缩的文件的信息，并不解压。gzip usr.tar% 压缩 tar 备份文件 usr.tar，此时压缩文件的扩展名为.tar.gz。 vim使用技巧使用关键字查询使用‘/’加你要查询的内容 替换需要注意的是如果是url可以将下面的’/‘换成’#’ :s（substitute）命令用来查找和替换字符串。语法如下： 1:&#123;作用范围&#125;s/&#123;目标&#125;/&#123;替换&#125;/&#123;替换标志&#125; 例如:%s/foo/bar/g会在全局范围(%)查找foo并替换为bar，所有出现都会被替换（g）。 作用范围 作用范围分为当前行、全文、选区等等。 当前行： 1:s/foo/bar/g 全文： 1:%s/foo/bar/g 选区，在Visual模式下选择区域后输入:，Vim即可自动补全为 :&#39;&lt;,&#39;&gt;。 1:&apos;&lt;,&apos;&gt;s/foo/bar/g 2-11行： 1:5,12s/foo/bar/g 当前行.与接下来两行+2： 1:.,+2s/foo/bar/g 替换标志 上文中命令结尾的g即是替换标志之一，表示全局global替换（即替换目标的所有出现）。 还有很多其他有用的替换标志： 空替换标志表示只替换从光标位置开始，目标的第一次出现： 1:%s/foo/bar i表示大小写不敏感查找，I表示大小写敏感： 123:%s/foo/bar/i# 等效于模式中的\c（不敏感）或\C（敏感）:%s/foo\c/bar c表示需要确认，例如全局查找&quot;foo&quot;替换为&quot;bar&quot;并且需要确认： 1:%s/foo/bar/gc 回车后Vim会将光标移动到每一次&quot;foo&quot;出现的位置，并提示 1replace with bar (y/n/a/q/l/^E/^Y)? 按下y表示替换，n表示不替换，a表示替换所有，q表示退出查找模式， l表示替换当前位置并退出。^E与^Y是光标移动快捷键，参考： Vim中如何快速进行光标移动。 一些插件使用技巧 NERDTree Control + W 跳转窗格 然后使用上下作用控制游标 sp可以将当前窗格进行划分 Center OS7 center os7安装后默认是安装了并启用了firewalld防火墙 所以以下是一些命令操作该防火墙基本命令，有其它需求自行在网上搜索 123456789101112启动防火墙systemctl start firewalld 禁用防火墙systemctl stop firewalld设置开机启动systemctl enable firewalld停止并禁用开机启动sytemctl disable firewalld重启防火墙firewall-cmd --reload 查看状态systemctl status firewalld或者 firewall-cmd --state ubuntu下快速构建java 环境 安装jre 1sudo apt-get install default-jre 安装jdk 1sudo apt-get install default-jdk 下面是全面的安装 1234567sudo add-apt-repository ppa:webupd8team/java sudo apt-get update sudo apt-get install oracle-java8-installer sudo apt-get install oracle-java8-set-default 关闭ubutnu下面的哔哔声 1234sudo echo "blacklist pcspkr" &gt;&gt; /etc/modprobe.d/blacklist//或者直接通过sudo su进入root//然后执行 echo "blacklist pcspkr" &gt;&gt; /etc/modprobe.d/blacklist//然后 重启电脑 关闭vim的哔哔声 1set vb t_vb=]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux命令，环境</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux下tomcat的安装]]></title>
    <url>%2F2018%2F02%2F25%2Flinux%2Flinux%E4%B8%8Btomcat%E7%9A%84%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[下载tomcat压缩文件 tar -zxvf {tomcat文件} 移动到/usr/local 文件下 并把文件名称改为类似tomcat9 配置环境变量 vi /etc/profile 在文件最后加入 1export CATALINA_HOME=/usr/local/tomcat9 source /etc/profile 配置tomcat的catAlina.sh文件 cd $CATALINA_HOME/bin vi catalina.sh 找到OS specific support 然后在下面添加 12CATALINA_HOME=/usr/local/tomcat9JAVA_HOME=jdk文件所在位置 安装tomcat服务 cp catalina.sh /etc/init.d/tomcat chkconfig –add tomcat chkconfig tomcat on chkconfig –liist 查看tomcat是否添加服务成功 权限问题 cd $CATALINA_HOME/bin sudo chmod 777 *.sh cd /etc/init.d sudo chmod 777 tomcat]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>tomcat的安装</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于hexo]]></title>
    <url>%2F2018%2F02%2F25%2Fhexo%2F%E5%85%B3%E4%BA%8Ehexo%2F</url>
    <content type="text"><![CDATA[###linux ####环境的准备 sudo apt-get install git sudo apt-get install nodejs sudo apt-get install npm ####自己遇到的一些问题 #####npm安装过慢 npm安装hexo过慢：用官网的npm install hexo-cli -g速度非常感人 用淘宝的npm分流，安装命令： 1npm install -g cnpm --registry=https://registry.npm.taobao.org 安装完过后用法和之前一样，只不过把npm改为cnpm 设置social链接时候可能出现的问题 在设置social链接的时候，记得一定要把social前面的#去掉，还有记得在设置什么参数的时候记得留一个空格 hexo d 时可能出现的问题 如果其他没有问题出现 ERROR Deployer not found: git问题，那么可以尝试 npm install hexo-deployer-git –save ####其它有用的链接 http://chitanda.me/2015/06/11/tips-for-setup-hexo/]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
</search>
