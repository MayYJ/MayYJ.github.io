<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Python中的作用域]]></title>
    <url>%2F2019%2F03%2F14%2FPython%2F%E5%9F%BA%E7%A1%80%2FPython%E4%B8%AD%E7%9A%84%E4%BD%9C%E7%94%A8%E5%9F%9F%2F</url>
    <content type="text"><![CDATA[首先说明python中不像JAVA 或者 C一样存在块级作用域，比如说下面的例子是可以运行的： 123name = 'may'if 1==1: print(name) 所以像if、for、while 语句都没有自己的作用域变量，而是使用自己身处作用域的变量 下面介绍python中的几种作用域： 内置作用域就是 python 中每个模块都拥有内置的一些变量，比如说 doc,name,cached 全局作用域每个模块都是一个全局作用域(也就是说，一个创建于模块文件顶层的变量的命名空间)。对于外部的全局变量就成为一个模块对象的属性，但是在模块中能够像简单的变量一样使用 嵌套作用域就是一个函数包含另外一个函数，比如说递归就是一种特殊情况 本地作用域由函数包裹的作用域 变量名的解析遵循LEGB原则LEGB 即 Local –&gt; Enclosed Local –&gt; Global –&gt; Build In 先从本地作用域里面寻找有没有该变量，如果没有且存在外层函数那么就从外层函数的作用域里面寻找，如果还是没有就从全局作用域里面寻找，如果还是没有就从内置作用域里面寻找]]></content>
      <tags>
        <tag>python 作用域</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redo.log和undo.log]]></title>
    <url>%2F2019%2F03%2F13%2FMysql%2Fredo-log%E5%92%8Cundo%2F</url>
    <content type="text"><![CDATA[undo.log概述undo.log 实现了有两个功能： 数据回滚 MVCC 的实现 需要注意的是undo.log是逻辑日志，所以对于数据的回滚它不是通过物理的恢复到执行语句或事务之前的样子，而是逻辑的把前面的修改都取消了，即使用了相反的SQL语句 下面我将重点讲Innodb MVCC的实现，在讲解其实现之前先要有下面的知识点： 数据存储 在《高性能Mysql》中提到了其实现是通过添加了两个隐藏列，一个创建版本号一个删除版本号，而这两个版本号其实是通过undo.log 的指针得到的 所以这里又得提到InnodB 聚簇索引存储数据的格式，它会在每行数据后面添加两个字段：一个时6字节的事务ID(DB_TRX_ID)字段，用于标记最近修改该数据的事务ID，每处理一个事务，该值加1；7字节的回滚指针(DB_ROLL_PTR)字段，指向当前记录项的rollback segment的undo.log，找之前版本的数据就是通过这个指针 undo.log 的存储管理 undo.log的存储管理：Innodb 对 undo.log的管理采用段的方式，Innodb存储引擎有rollback segment，每个回滚段中记录了1024个undo log segment，而在每个undo log segment段中进行undo页的申请；每个事务Commit了不会立即将undo.log删除了，而是将其放入一个链表中，等待purge线程来判断什么时候删除； undo.log 里面会记录每个事务修改的记录原始的值；所以对于增加、删除、以及修改就会有不同的行为，undo.log 分为Insert undo.log 和 update undo log； 对于添加操作添加到insert undo log，在提交完成后会直接删除，因为事务的隔离性其它事务在该事务提交前是不能看到添加的数据所以也就对于MVCC没有意义，它的作用就是用于回滚；修改和删除操作都是记录到update undo log，记录的新数据的备份，以便其它的记录能够看到；删除操作只是作一个标记，最终删除操作是要等purge线程判断可以删除该undo页的时候再真实的删除 事务链表MySQL中的事务在开始到提交这段过程中，都会被保存到一个叫trx_sys的事务链表中，这是一个基本的链表结构： 事务链表中保存的都是还未提交的事务，事务一旦被提交，则会被从事务链表中摘除。 ReadView有了前面隐藏列和事务链表的基础，接下去就可以构造MySQL实现MVCC的关键——ReadView。 ReadView说白了就是一个数据结构，在SQL开始的时候被创建。这个数据结构中包含了3个主要的成员：ReadView{low_trx_id, up_trx_id, trx_ids}，在并发情况下，一个事务在启动时，trx_sys链表中存在部分还未提交的事务，那么哪些改变对当前事务是可见的，哪些又是不可见的，这个需要通过ReadView来进行判定，首先来看下ReadView中的3个成员各自代表的意思： low_trx_id表示该SQL启动时，当前事务链表中最大的事务id编号，也就是最近创建的除自身以外最大事务编号； up_trx_id表示该SQL启动时，当前事务链表中最小的事务id编号，也就是当前系统中创建最早但还未提交的事务； trx_ids表示所有事务链表中事务的id集合。 上述3个成员组成了ReadView中的主要部分，简单图示如下： 根据上图所示，所有数据行上DATA_TRX_ID小于up_trx_id的记录，说明修改该行的事务在当前事务开启之前都已经提交完成，所以对当前事务来说，都是可见的。而对于DATA_TRX_ID大于low_trx_id的记录，说明修改该行记录的事务在当前事务之后，所以对于当前事务来说是不可见的。 注意，ReadView是与SQL绑定的，而并不是事务，所以即使在同一个事务中，每次SQL启动时构造的ReadView的up_trx_id和low_trx_id也都是不一样的，至于DATA_TRX_ID大于low_trx_id本身出现也只有当多个SQL并发的时候，在一个SQL构造完ReadView之后，另外一个SQL修改了数据后又进行了提交，对于这种情况，数据其实是不可见的。 最后，至于位于（up_trx_id, low_trx_id）中间的事务是否可见，这个需要根据不同的事务隔离级别来确定。对于RC的事务隔离级别来说，对于事务执行过程中，已经提交的事务的数据，对当前事务是可见的，也就是说上述图中，当前事务运行过程中，trx1~4中任意一个事务提交，对当前事务来说都是可见的；而对于RR隔离级别来说，事务启动时，已经开始的事务链表中的事务的所有修改都是不可见的，所以在RR级别下，low_trx_id基本保持与up_trx_id相同的值即可。 MVCC实现图示过程 redo.logredo.log 称为重做日志，用来保证事务的原子性和持久性 与binlog的区别redo.log 是Innodb 存储引擎层产生的，是物理格式日志记录的是对相应页的修改；而binlog是在Mysql数据库的上层产生的，其是一种逻辑日志，记录的是其对应的sql语句 binlog 只在事务commit的时候记录，redo.log由于会记录undo.log的日志所以它会在事务进行过程中记录事务的多个条目 redo.log 在加上checkPoint机制，能够实现崩溃恢复；binlog 用来进行POINT-IN-TIME的恢复及主从复制环境的建立 下面我用一张图来表示redo.log 记录传输过程 其实Innodb里面对所有数据的操作都满足这样的三个步骤；只不过这里不一样的是用LSN对这些步骤进行了连接，三个步骤的LSN 分别对应了Innodb的三个参数 Log sequence number 表示当前的LSN，Log flushed up to 表示刷新到重做日志文件的LSN，Last checkPoint at 表示刷新到磁盘的LSN；通过这个LSN也给崩溃恢复提供了沃土 参考MVCC 的实现 https://zhuanlan.zhihu.com/p/40208895 https://juejin.im/entry/5a4b52eef265da431120954b 《Mysql技术内部》]]></content>
      <tags>
        <tag>redo.log,undo.log</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于引用]]></title>
    <url>%2F2019%2F03%2F11%2FJava%20%E5%9F%BA%E7%A1%80%2F%E5%85%B3%E4%BA%8E%E5%BC%95%E7%94%A8%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[关于IO]]></title>
    <url>%2F2019%2F03%2F10%2FIO%2F%E5%85%B3%E4%BA%8EIO%2F</url>
    <content type="text"><![CDATA[FileChannel 的write和read方法都是线程安全的 BufferInputStream 为什么比较高效以前一直有个误解，在BufferInputStream源码中存在一个byte数组，所以认为它高效的原因是不用每次都系统调用从外存获取数据；但是这里没有注意到磁盘缓存，磁盘缓存是为了缓和内存的速度和磁盘的速度根据局部性原理将读取数据的相邻数据都会一并读到磁盘缓存中；磁盘缓存存在于内核空间，所以每次去取数据都会存在用户空间和内核空间的切换；也就是说BufferInputStream 比较高效的原因是减少了用户空间和内核空间的切换从而节省了CPU资源 JAVA 中IO的方式普通IO， FileChannel、MMAP(内存映射) 为什么FileChannel 比普通IO要快因为FileChannel采用了ByteBuffer这样的内存缓冲区，让我们可以精准的控制写盘的大小，其实就跟前面的BufferInputStream 一样，可以减少系统调用的次数，但是FileChannel可以根据系统自身情况调整ByteBuffer大小 虚拟地址空间、逻辑地址、线性地址、物理地址逻辑地址 如果以分页存储管理方式就是页号加页内偏移量 线性地址就是虚拟地址，这个地址存在的原因是内存交换技术，比如说32位的操作系统，每个进程可以拥有总的内存量为2^32 也就是4个G的内存，只不过是通过磁盘在逻辑上扩展物理内存进而达到好像该进程好像就拥有这么内存一样 逻辑地址通过地址转换机构得到的就是虚拟地址 物理地址就是真正物理意义上的物理内存上的内存单元地址 在没有使用虚拟存储器的机器上，虚拟地址被直接送到内存总线上，使具有相同地址的物理存储器被读写；而在使用了虚拟存储器的情况下，虚拟地址不是被直接送到内存地址总线上，而是送到存储器管理单元MMU，把虚拟地址映射为物理地址。 直接IO直接IO 存在原因PageCache也就是操作系统会将 I/O 的数据缓存在文件系统的页缓存（ page cache ）中，也就是说，数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。DMA 方式可以将数据直接从磁盘读到页缓存中，或者将数据从页缓存直接写回到磁盘上，而不能直接在应用程序地址空间和磁盘之间进行数据传输，这样的话，数据在传输过程中需要在应用程序地址空间和页缓存之间进行多次数据拷贝操作，这些数据拷贝操作所带来的 CPU 以及内存开销是非常大的。 详细的可以见 这篇IBM文章 但是需要注意的是JDK8是没有支持直接IO的类的 直接内存1ByteBuffer directBuffer = ByteBuffer.allocateDirect(1024); 通过上面这条语句分配的就是直接内存，一系列问题就出来了，什么是直接内存，它和JVM运行时数据区域有什么不同，它的好处是什么，下面就一一解答 直接内存就是一段 JVM运行时数据区域以外的内存，它不受JVM的管控，需要注意的是它依然属于用户内存 为什么要使用直接内存呢？ 这就牵扯到JAVA IO 读取数据的机制 DMA 读取数据时先将数据读取到内核缓冲区当中，PageCache也就是在这个时候发生的；然后再将数据复制到堆外的一段内存当中，最后才将数据从堆外的直接内存复制到JVM 的堆内存当中，这里又会产生一个问题为什么不直接从内核缓冲区复制到JVM堆内存中，非要有一个中间堆外内存的复制过程？ 这是因为虽然内核态下可以操作所有的内存，但是 它是通过物理地址的方式直接操作内存；所以这里就会产生一个问题，就是 JVM 对于大内存的分配都是直接在老年代内分配，JVM运行过程中很有可能会发生GC，而老年代大多数垃圾收集器又是用的标记整理算法，也就是会产生数据的移动，就会导致数据内存地址的变化，但是这个变化对于内核的复制是不可知的；所以从内核复制数据到的内存是不能够变化的，也就是这里的直接内存 下面是FileChannel.read方法调用的IOUtil.read方法，其中就可以看到这样的一个过程： 1234567891011121314151617181920212223242526272829303132333435static int read(FileDescriptor fd, ByteBuffer dst, long position, boolean directIO, int alignment, NativeDispatcher nd) throws IOException &#123; if (dst.isReadOnly()) throw new IllegalArgumentException("Read-only buffer"); // 如果是直接内存那么直接将数据读进直接内存中 if (dst instanceof DirectBuffer) return readIntoNativeBuffer(fd, dst, position, directIO, alignment, nd); // Substitute a native buffer ByteBuffer bb; int rem = dst.remaining(); if (directIO) &#123; Util.checkRemainingBufferSizeAligned(rem, alignment); bb = Util.getTemporaryAlignedDirectBuffer(rem, alignment); &#125; else &#123; // 获取临时的直接内存 bb = Util.getTemporaryDirectBuffer(rem); &#125; try &#123; // 将数据读进了临时直接内存中 int n = readIntoNativeBuffer(fd, bb, position, directIO, alignment,nd); bb.flip(); // 再将直接内存的数据复制到堆内存中 if (n &gt; 0) dst.put(bb); return n; &#125; finally &#123; Util.offerFirstTemporaryDirectBuffer(bb); &#125; &#125; 至于为什么从直接内存到堆内存可以实现，可以参考来自知乎上的回答： 12345678910111213DirectByteBuffer 自身是一个Java对象，在Java堆中；而这个对象中有个long类型字段address，记录着一块调用 malloc() 申请到的native memory。HotSpot VM里的GC除了CMS之外都是要移动对象的，是所谓“compacting GC”。如果要把一个Java里的 byte[] 对象的引用传给native代码，让native代码直接访问数组的内容的话，就必须要保证native代码在访问的时候这个 byte[] 对象不能被移动，也就是要被“pin”（钉）住。可惜HotSpot VM出于一些取舍而决定不实现单个对象层面的object pinning，要pin的话就得暂时禁用GC——也就等于把整个Java堆都给pin住。HotSpot VM对JNI的Critical系API就是这样实现的。这用起来就不那么顺手。所以 Oracle/Sun JDK / OpenJDK 的这个地方就用了点绕弯的做法。它假设把 HeapByteBuffer 背后的 byte[] 里的内容拷贝一次是一个时间开销可以接受的操作，同时假设真正的I/O可能是一个很慢的操作。于是它就先把 HeapByteBuffer 背后的 byte[] 的内容拷贝到一个 DirectByteBuffer 背后的native memory去，这个拷贝会涉及 sun.misc.Unsafe.copyMemory() 的调用，背后是类似 memcpy() 的实现。这个操作本质上是会在整个拷贝过程中暂时不允许发生GC的，虽然实现方式跟JNI的Critical系API不太一样。（具体来说是 Unsafe.copyMemory() 是HotSpot VM的一个intrinsic方法，中间没有safepoint所以GC无法发生）。然后数据被拷贝到native memory之后就好办了，就去做真正的I/O，把 DirectByteBuffer 背后的native memory地址传给真正做I/O的函数。这边就不需要再去访问Java对象去读写要做I/O的数据了。 没有安全点，不会停下来GC 直接内存的创建和回收机制 创建 关于直接内存的创建主要就涉及到它的构造器和reserveMemory方法 大致流程： 调用reserveMemory 检查是否足够的直接内存分配 reserveMemory 大致流程是这样的： 有足够内存直接返回， 尝试释放可能已经被回收的DirectBuffer 对象所关联的直接内存 如果 2 没有成功则 调用System.gc() 进行FullGC 循环等待9秒 等待FullGc完成 如果4没有成功那么抛出 直接内存溢出的Error 通过unsafe.allocateMemory申请直接内存，返回内存的首地址 构建Cleaner对象用于跟踪DirectByteBuffer对象的垃圾回收，以实现当DirectByteBuffer被垃圾回收时，堆外内存也会被释放 12345678910111213141516171819202122232425DirectByteBuffer(int cap) &#123; // package-private super(-1, 0, cap, cap); boolean pa = VM.isDirectMemoryPageAligned(); int ps = Bits.pageSize(); long size = Math.max(1L, (long)cap + (pa ? ps : 0)); Bits.reserveMemory(size, cap); long base = 0; try &#123; base = unsafe.allocateMemory(size); &#125; catch (OutOfMemoryError x) &#123; Bits.unreserveMemory(size, cap); throw x; &#125; unsafe.setMemory(base, size, (byte) 0); if (pa &amp;&amp; (base % ps != 0)) &#123; // Round up to page boundary address = base + ps - (base &amp; (ps - 1)); &#125; else &#123; address = base; &#125; cleaner = Cleaner.create(this, new Deallocator(base, size, cap)); att = null;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475static void reserveMemory(long size, int cap) &#123; if (!memoryLimitSet &amp;&amp; VM.initLevel() &gt;= 1) &#123; maxMemory = VM.maxDirectMemory(); memoryLimitSet = true; &#125; // optimist! if (tryReserveMemory(size, cap)) &#123; return; &#125; final JavaLangRefAccess jlra = SharedSecrets.getJavaLangRefAccess(); boolean interrupted = false; try &#123; // Retry allocation until success or there are no more // references (including Cleaners that might free direct // buffer memory) to process and allocation still fails. boolean refprocActive; do &#123; try &#123; refprocActive = jlra.waitForReferenceProcessing(); &#125; catch (InterruptedException e) &#123; // Defer interrupts and keep trying. interrupted = true; refprocActive = true; &#125; if (tryReserveMemory(size, cap)) &#123; return; &#125; &#125; while (refprocActive); // trigger VM's Reference processing System.gc(); // A retry loop with exponential back-off delays. // Sometimes it would suffice to give up once reference // processing is complete. But if there are many threads // competing for memory, this gives more opportunities for // any given thread to make progress. In particular, this // seems to be enough for a stress test like // DirectBufferAllocTest to (usually) succeed, while // without it that test likely fails. Since failure here // ends in OOME, there's no need to hurry. long sleepTime = 1; int sleeps = 0; while (true) &#123; if (tryReserveMemory(size, cap)) &#123; return; &#125; if (sleeps &gt;= MAX_SLEEPS) &#123; break; &#125; try &#123; if (!jlra.waitForReferenceProcessing()) &#123; Thread.sleep(sleepTime); sleepTime &lt;&lt;= 1; sleeps++; &#125; &#125; catch (InterruptedException e) &#123; interrupted = true; &#125; &#125; // no luck throw new OutOfMemoryError("Direct buffer memory"); &#125; finally &#123; if (interrupted) &#123; // don't swallow interrupts Thread.currentThread().interrupt(); &#125; &#125;&#125; 回收 自动回收 自动回收其实就是在分配内存的时候，如果发现直接内存不够的时候就会调用System.gc进行全局回收对象；但是问题就来了，对象的回收是怎么跟直接内存的回收挂钩的 DirectByteBuffer对象在创建的时候关联了一个PhantomReference也就是下面这行代码： 1cleaner = Cleaner.create(this, new Deallocator(base, size, cap)); PhantomReference的作用是用来跟踪对象何时被回收的，它不能影响gc决策，但是gc过程中如果发现某个对象除了只有PhantomReference引用它之外，并没有其他的地方引用它了，那将会把这个引用放到java.lang.ref.Reference.pending队列里，在gc完毕的时候通知ReferenceHandler这个守护线程去执行一些后置处理，下面我会根据Reference的源码进一步说明 Cleaner 继承于PhantomReference 并将其虚引用(其实就是 其子类Reference中的 referent的指向)指向了this即创建的DirectByteBuffer，就可以达到追踪DirectByteBuffer对象被回收的时机的效果 如下面的代码所示，其实Cleaner 只是一个维护了Cleaner 双向链表的类，起到了保存回收其关联对象的回调方法即thunk属性的作用 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105public class Cleaner extends PhantomReference&lt;Object&gt;&#123; private static final ReferenceQueue&lt;Object&gt; dummyQueue = new ReferenceQueue&lt;&gt;(); private static Cleaner first = null; private Cleaner next = null, prev = null; private static synchronized Cleaner add(Cleaner cl) &#123; if (first != null) &#123; cl.next = first; first.prev = cl; &#125; first = cl; return cl; &#125; private static synchronized boolean remove(Cleaner cl) &#123; // If already removed, do nothing if (cl.next == cl) return false; // Update list if (first == cl) &#123; if (cl.next != null) first = cl.next; else first = cl.prev; &#125; if (cl.next != null) cl.next.prev = cl.prev; if (cl.prev != null) cl.prev.next = cl.next; cl.next = cl; cl.prev = cl; return true; &#125; private final Runnable thunk; private Cleaner(Object referent, Runnable thunk) &#123; super(referent, dummyQueue); this.thunk = thunk; &#125; public static Cleaner create(Object ob, Runnable thunk) &#123; if (thunk == null) return null; return add(new Cleaner(ob, thunk)); &#125; /** * Runs this cleaner, if it has not been run before. */ public void clean() &#123; if (!remove(this)) return; try &#123; thunk.run(); &#125; catch (final Throwable x) &#123; AccessController.doPrivileged(new PrivilegedAction&lt;&gt;() &#123; public Void run() &#123; if (System.err != null) new Error("Cleaner terminated abnormally", x) .printStackTrace(); System.exit(1); return null; &#125;&#125;); &#125; &#125;&#125; private static class ReferenceHandler extends Thread &#123; private static void ensureClassInitialized(Class&lt;?&gt; clazz) &#123; try &#123; Class.forName(clazz.getName(), true, clazz.getClassLoader()); &#125; catch (ClassNotFoundException e) &#123; throw (Error) new NoClassDefFoundError(e.getMessage()).initCause(e); &#125; &#125; static &#123; // pre-load and initialize Cleaner class so that we don't // get into trouble later in the run loop if there's // memory shortage while loading/initializing it lazily. ensureClassInitialized(Cleaner.class); &#125; ReferenceHandler(ThreadGroup g, String name) &#123; super(g, null, name, 0, false); &#125; public void run() &#123; while (true) &#123; processPendingReferences(); &#125; &#125; &#125; 下面就是比较重要的类了 Reference 其中有个静态代码块，这个类在rt.jar包下，所有是由BootStrapClassLoader加载的，也就是一开始就会执行这个静态代码块的内容，其中启动了一个ReferenceHandler的线程 其中详细的代码就不仔细讲了，如果有兴趣可以自己下去深究；它主要干的事情就是上面所说的gc过程中如果发现某个对象除了只有PhantomReference引用它之外，并没有其他的地方引用它了，那将会把这个引用放到java.lang.ref.Reference.pending队列里，在gc完毕的时候通知ReferenceHandler这个守护线程去执行一些后置处理，这里的后置处理就是Cleaner 的clean方法，clean方法又会调用当前对象保存的Runnable的run方法，即DirectByteBuffer 创建Cleaner 时传过去的Runnable，也就达到了追踪DirectByteBuffer销毁并做一定处理的效果，在DirectByteBuffer中所做的处理及传给Cleaner的Runnable 就是销毁自己创建的直接内存的操作 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091public abstract class Reference&lt;T&gt; &#123; private T referent; /* Treated specially by GC */ ReferenceQueue&lt;? super T&gt; queue; Reference next; transient private Reference&lt;T&gt; discovered; /* used by VM */ static private class Lock &#123; &#125;; private static Lock lock = new Lock(); private static Reference pending = null; ... static &#123; ThreadGroup tg = Thread.currentThread().getThreadGroup(); for (ThreadGroup tgn = tg; tgn != null; tg = tgn, tgn = tg.getParent()); Thread handler = new ReferenceHandler(tg, "Reference Handler"); /* If there were a special system-only priority greater than * MAX_PRIORITY, it would be used here */ handler.setPriority(Thread.MAX_PRIORITY); handler.setDaemon(true); handler.start(); &#125; public T get() &#123; return this.referent; &#125; public void clear() &#123; this.referent = null; &#125; public boolean isEnqueued() &#123; synchronized (this) &#123; return (this.queue != ReferenceQueue.NULL) &amp;&amp; (this.next != null); &#125; &#125; public boolean enqueue() &#123; return this.queue.enqueue(this); &#125; /* -- Constructors -- */ Reference(T referent) &#123; this(referent, null); &#125; Reference(T referent, ReferenceQueue&lt;? super T&gt; queue) &#123; this.referent = referent; this.queue = (queue == null) ? ReferenceQueue.NULL : queue; &#125;&#125;private static void processPendingReferences() &#123; waitForReferencePendingList(); Reference&lt;Object&gt; pendingList; synchronized (processPendingLock) &#123; pendingList = getAndClearReferencePendingList(); processPendingActive = true; &#125; while (pendingList != null) &#123; Reference&lt;Object&gt; ref = pendingList; pendingList = ref.discovered; ref.discovered = null; //后置处理 if (ref instanceof Cleaner) &#123; ((Cleaner)ref).clean(); synchronized (processPendingLock) &#123; processPendingLock.notifyAll(); &#125; &#125; else &#123; ReferenceQueue&lt;? super Object&gt; q = ref.queue; if (q != ReferenceQueue.NULL) q.enqueue(ref); &#125; &#125; synchronized (processPendingLock) &#123; processPendingActive = false; processPendingLock.notifyAll(); &#125; &#125; 直接内存的应用场景DirectBuffer 直接分配在JVM之外的物理内存，而不是 JVM 中的逻辑内存，需要往 Socket 或其他接口写的时候，不需要将数据从 JVM 复制到物理内存，直接输出即可。 缺点是当你需要对这些数据进行额外处理的时候，如编码，过滤等，数据还是会复制到 JVM，所以请确保你不需要对数据进行这些额外操作，只是从一个文件复制数据到另一个文件，一个Socket到另一个的时候才使用。 内存映射文件内存映射文件和之前说的 标准IO操作最大的不同之处就在于它虽然最终也是要从磁盘读取数据，但是它并不需要将数据读取到OS内核缓冲区，而是直接将进程的用户私有地址空间中的一 部分区域与文件对象建立起映射关系，就好像直接从内存中读、写文件一样，速度当然快了。为了说清楚这个，我们以 Linux操作系统为例子，看下图： 此图为 Linux 2.X 中的进程虚拟存储器，即进程的虚拟地址空间，如果你的机子是 32 位，那么就有 2^32 = 4G的虚拟地址空间，我们可以看到图中有一块区域： “Memory mapped region for shared libraries” ，这段区域就是在内存映射文件的时候将某一段的虚拟地址和文件对象的某一部分建立起映射关系，此时并没有拷贝数据到内存中去，而是当进程代码第一次引用这 段代码内的虚拟地址时，触发了缺页异常，这时候OS根据映射关系直接将文件的相关部分数据拷贝到进程的用户私有空间中去，当有操作第N页数据的时候重复这样的OS页面调度程序操作。注意啦，原来内存映射文件的效率比标准IO高的重要原因就是因为少了把数据拷贝到OS内核缓冲区这一步。 为什么顺序读比随机读好还是因为PageCache的原因，当顺序读的时候PageCache的命中率提高，更少的去磁盘读数据 FileChannel.transferToJava NIO中提供的FileChannel拥有transferTo和transferFrom两个方法，可直接把FileChannel中的数据拷贝到另外一个Channel，或者直接把另外一个Channel中的数据拷贝到FileChannel。该接口常被用于高效的网络/文件的数据传输和大文件拷贝。在操作系统支持的情况下，通过该方法传输数据并不需要将源数据从内核态拷贝到用户态，再从用户态拷贝到目标通道的内核态，同时也避免了两次用户态和内核态间的上下文切换，也即使用了“零拷贝”，所以其性能一般高于Java IO中提供的方法。 下面是简单的例子： 1234567RandomAccessFile fromFile = new RandomAccessFile(&quot;fromFile.txt&quot;, &quot;rw&quot;);FileChannel fromChannel = fromFile.getChannel();RandomAccessFile toFile = new RandomAccessFile(&quot;toFile.txt&quot;, &quot;rw&quot;);FileChannel toChannel = toFile.getChannel();long position = 0;long count = fromChannel.size();toChannel.transferFrom(position, count, fromChannel); 参考https://blog.csdn.net/coslay/article/details/44210993 https://www.cnkirito.moe/file-io-best-practise/]]></content>
      <tags>
        <tag>IO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[StampLock解析]]></title>
    <url>%2F2019%2F03%2F09%2FJava%20%E5%B9%B6%E5%8F%91%2FStampLock%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[基本使用https://www.jianshu.com/p/481071ddafd3 源码分析https://www.jianshu.com/p/bfd5d2321cc0 大概总结下它与ReentrantReadWriteLock的不同 StampedLock 更加高效，而他高价高效的原因是因为它在读模式、写模式的前提下引入了第三种模式乐观读模式；乐观读读模式下认为不会有其它写线程来修改当前线程要读取的数据，不用CAS操作去维护状态，使用了锁的版本号来识别是否有其它线程并发的修改了共享数据，所以使用它就要遵循一定的流程，具体流程见基本使用 StampedLock支持在三种模式中提供有条件的转换；这些方法的表现形式旨在帮助减少由于基于重试(retry-based)设计造成的代码膨胀。 StampedLock 不基于AQS，是不可重入的，所以在锁的内部不能调用其他尝试重复获取锁的方法,StampedLocks是可序列化的，但是反序列化后变为初始的非锁定状态，所以在远程锁定中是不安全的。 StampedLock 内部队列实现： 应用场景读多写少]]></content>
      <tags>
        <tag>StampLock</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ReentranReadWriteLock源码解析]]></title>
    <url>%2F2019%2F03%2F08%2FJava%20%E5%B9%B6%E5%8F%91%2FReetranReadWriteLock%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[因为ReentrantReadWriteLock是基于AQS实现的同步，所以在介绍这个类之前，首先要对AQS比较熟悉，所以涉及到它的知识点我不会加以解释 大体框架 Sync ReentrantReadWriteLock 专门实现的AQS的同步器 NonfairSync 、 FairSync 公平锁和非公平锁的实现 ReadLock 读锁的实现，与Sync 是组合的关系 WriteLock 写锁的实现， 与Sync 是组合的关系 重要方法解析 tryAcquire 运行流程： 如果readCount 或者 writeCount非零且owner 非本线程，获取锁失败 如果加锁数量太大(这个是受限于 16位的status 记录写线程数量)，获取锁失败 否则，当前线程可以因为是重入锁或者遵循锁策略 而获得锁，修改state、owner 12345678910111213141516171819202122232425262728293031protected final boolean tryAcquire(int acquires) &#123; /* * Walkthrough: * 1. If read count nonzero or write count nonzero * and owner is a different thread, fail. * 2. If count would saturate, fail. (This can only * happen if count is already nonzero.) * 3. Otherwise, this thread is eligible for lock if * it is either a reentrant acquire or * queue policy allows it. If so, update state * and set owner. */ Thread current = Thread.currentThread(); int c = getState(); int w = exclusiveCount(c); if (c != 0) &#123; // (Note: if c != 0 and w == 0 then shared count != 0) if (w == 0 || current != getExclusiveOwnerThread()) return false; if (w + exclusiveCount(acquires) &gt; MAX_COUNT) throw new Error("Maximum lock count exceeded"); // Reentrant acquire setState(c + acquires); return true; &#125; if (writerShouldBlock() || !compareAndSetState(c, c + acquires)) return false; setExclusiveOwnerThread(current); return true; &#125; tryAcquireShared 运行流程: 如果其它线程拥有了写锁那么获取失败 否则，根据加锁策略加写锁，再CAS修改state，修改count 如果步骤2失败了，调用fullTryAcquireShared 死循环尝试修改 123456789101112131415161718192021222324252627282930313233343536373839404142protected final int tryAcquireShared(int unused) &#123; /* * Walkthrough: * 1. If write lock held by another thread, fail. * 2. Otherwise, this thread is eligible for * lock wrt state, so ask if it should block * because of queue policy. If not, try * to grant by CASing state and updating count. * Note that step does not check for reentrant * acquires, which is postponed to full version * to avoid having to check hold count in * the more typical non-reentrant case. * 3. If step 2 fails either because thread * apparently not eligible or CAS fails or count * saturated, chain to version with full retry loop. */ Thread current = Thread.currentThread(); int c = getState(); if (exclusiveCount(c) != 0 &amp;&amp; getExclusiveOwnerThread() != current) return -1; int r = sharedCount(c); if (!readerShouldBlock() &amp;&amp; r &lt; MAX_COUNT &amp;&amp; compareAndSetState(c, c + SHARED_UNIT)) &#123; if (r == 0) &#123; firstReader = current; firstReaderHoldCount = 1; &#125; else if (firstReader == current) &#123; firstReaderHoldCount++; &#125; else &#123; HoldCounter rh = cachedHoldCounter; if (rh == null || rh.tid != getThreadId(current)) cachedHoldCounter = rh = readHolds.get(); else if (rh.count == 0) readHolds.set(rh); rh.count++; &#125; return 1; &#125; return fullTryAcquireShared(current);&#125; 如何保存读线程和写线程数量12345678910static final int SHARED_SHIFT = 16;static final int SHARED_UNIT = (1 &lt;&lt; SHARED_SHIFT);static final int MAX_COUNT = (1 &lt;&lt; SHARED_SHIFT) - 1;static final int EXCLUSIVE_MASK = (1 &lt;&lt; SHARED_SHIFT) - 1;/** Returns the number of shared holds represented in count */static int sharedCount(int c) &#123; return c &gt;&gt;&gt; SHARED_SHIFT; &#125;/** Returns the number of exclusive holds represented in count */static int exclusiveCount(int c) &#123; return c &amp; EXCLUSIVE_MASK; &#125; 在ReentrantReadWriteLock 中用AQS的state变量包含了写锁的数量和读锁的数量 state 是一个int型变量，前16位用来表示读锁的数量，后16位用来表示写锁数量 如何实现可重入在写锁 里面依然跟ReentrantLock 一样使用的state变量，重入一次写锁数量就加1 读锁使用了ThreadLocal 12345678910111213141516private transient ThreadLocalHoldCounter readHolds;private transient HoldCounter cachedHoldCounter;static final class ThreadLocalHoldCounter extends ThreadLocal&lt;HoldCounter&gt; &#123; public HoldCounter initialValue() &#123; return new HoldCounter(); &#125; &#125;static final class HoldCounter &#123; int count = 0; // Use id, not reference, to avoid garbage retention final long tid = getThreadId(Thread.currentThread()); &#125; 读锁重入一次 count+1 缓存的体现1234private transient Thread firstReader = null;private transient int firstReaderHoldCount;private transient HoldCounter cachedHoldCounter; 这里根据应用场景，使用了两个缓存 因为大多数ReentrantReadWriteLock 都只会被一个线程获取读锁，没有必要把它放到线程的ThreadLocalMap中，所以如果是第一次那么直接赋值firstReader、firstReaderHoldCount 避免了释放锁的时候，从ThreadLocalMap 中取查询 holdCounter 为什么允许锁降级不能锁升级锁降级：在拥有写锁的情况下去获取读锁 锁升级：在拥有读锁的情况下去获取写锁 锁升级会造成死锁，因为在线程拥有了读锁还没有释放的情况下，再去获取写锁那么就会造成当前线程阻塞等待读锁释放，也就造成了死锁的情况发生 关于写饥饿问题非公平模式下，在读多写少的情况下，会造成可能写线程等待读线程释放读锁后，但是因为又发生了获取了读并且修改了state变量，造成写线程获取写锁失败，进而导致修改不能及时反映 在ReentrantReadWriteLock 中启发函数中即 readerShouldBlock 中采用了如果当前等待队列中第一个等待的线程要获取写锁那么该获取读锁线程就不能去同写锁进行竞争插队而只能放到等待队列里面进行等待 所以这个可能造成一个问题，就是如果第一个读线程需要运行比较久的时间，而接下来是一个写线程等待，那么接下来的所有的读线程都只能等待，不能并发读数据 具体可见https://zhuanlan.zhihu.com/p/34672421 应用场景12345* ReentrantReadWriteLocks can be used to improve concurrency in some* uses of some kinds of Collections. This is typically worthwhile* only when the collections are expected to be large, accessed by* more reader threads than writer threads, and entail operations with* overhead that outweighs synchronization overhead. 在collections 足够大且读线程比写线程多的情况下 参考https://www.jianshu.com/p/6923c126e762]]></content>
      <tags>
        <tag>ReentranReadWriteLock</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一步一步理解dubbo]]></title>
    <url>%2F2019%2F03%2F03%2FJavaweb%2F%E4%B8%80%E6%AD%A5%E4%B8%80%E6%AD%A5%E7%90%86%E8%A7%A3dubbo%2F</url>
    <content type="text"><![CDATA[JAVA SPISPI 全称为 (Service Provider Interface)，是JDK内置的一种服务发现机制；SPI是一种动态替换发现的机制， 比如有个接口，想运行时动态的给它添加实现，你只需要添加一个实现。JAVA 中主要用java.util.ServiceLoader 类实现服务发现 JDBC服务发现机制 在JDBC4.0 之前 我们需要 Class.forName(“com.mysql.jdbc.Driver”) 这样一条代码来主动加载Mysql的驱动类；但是在JDBC4.0之后，我们可以不用写这样的代码，JDBC内部提供了服务发现机制 下面是DriverManager 的静态代码块 1234static &#123; loadInitialDrivers(); println("JDBC DriverManager initialized"); &#125; 下面是 loadInitialDrivers()的实现 12345678910111213141516171819202122private static void loadInitialDrivers() &#123; String drivers; ... AccessController.doPrivileged(new PrivilegedAction&lt;Void&gt;() &#123; public Void run() &#123; ServiceLoader&lt;Driver&gt; loadedDrivers = ServiceLoader.load(Driver.class); Iterator&lt;Driver&gt; driversIterator = loadedDrivers.iterator(); try&#123; while(driversIterator.hasNext()) &#123; driversIterator.next(); &#125; &#125; catch(Throwable t) &#123; // Do nothing &#125; return null; &#125; &#125;); .... &#125; &#125; 实例化生成对应要加载接口对应实现的 ServiceLoader iterator 会搜索classpath下以及jar包中所有的META-INF/services 目录下java.sql.Driver文件，并找到文件中的实现类的名字]]></content>
      <tags>
        <tag>dubbo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发编程实战总结]]></title>
    <url>%2F2019%2F03%2F03%2FJava%20%E5%B9%B6%E5%8F%91%2FJava%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E6%88%98%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[Guava介绍和使用]]></title>
    <url>%2F2019%2F03%2F02%2FJava%20%E5%9F%BA%E7%A1%80%2FGuava%E4%BB%8B%E7%BB%8D%E5%92%8C%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[dubbo-study]]></title>
    <url>%2F2019%2F03%2F02%2FJavaweb%2Fdubbo-study%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[zookeeper-study]]></title>
    <url>%2F2019%2F03%2F02%2FJavaweb%2Fzookeeper-study%2F</url>
    <content type="text"><![CDATA[安装和使用zookeeper 下载 官方下载非常慢，所以这里给个清华镜像源的下载地址 ​ zookeeper 下载地址 配置 解压文件后 到 conf 目录下 将zoo_simple.cfg 修改为 zoo.cfg并修改里面的参数， 例如： 12dataDir=E:\\software\\zookeeper\\zookeeper-3.4.13\\datadataLogDir=E:\\software\\zookeeper\\zookeeper-3.4.13\\log 启动 进入bin目录下 如果是 Linux 就选择zkServer.sh启动；如果是 Windows 就选择 zkServer.cmd启动 使用 客户端基本命令 123456建立节点 create /zk hello获得节点 get /zk 设置节点 set /zk hello2建立子节点 set /zk/subzk hello3输出节点目录 ls /zk删除节点 delete /zk]]></content>
      <tags>
        <tag>zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大型网站技术架构]]></title>
    <url>%2F2019%2F02%2F27%2FReading%2F%E5%A4%A7%E5%9E%8B%E7%BD%91%E7%AB%99%E6%8A%80%E6%9C%AF%E6%9E%B6%E6%9E%84%2F</url>
    <content type="text"><![CDATA[大型网站架构演化大型网站架构演化的驱动因素：高并发，大流量；高可用；海量数据；用户分布广发，网络情况复杂；安全环境恶劣；需求快速变更，发布频繁；渐进式发展 初始阶段 在这个阶段应用程序、文件系统和数据库都是在一台服务器上，能够解决应用的初始阶段的使用问题 数据和服务分离阶段随着业务的发展，越来越多的人使用应用，数据量越来越大，导致数据空间的不足，这个时候就需要将数据库和文件系统单独分离出来，形成下面的结构 使用缓存由于存在热点数据，业务的访问主要集中在热点数据上；如果使用缓存能够大大降低数据库服务的压力 集群随着业务的发展，用户数量的急剧增长，导致并发量上去了，那么应用服务器就成为了瓶颈；所以通过使用集群的方式来解决并发的请求;并用负载均衡调度服务器来分发请求 数据库读写分离使用主从的方式进行读写分离，读写分离的好处有以下三点： 通过增加物理服务器，可以提高并发的性能 写在主服务器上，读在从服务器上；减少了X锁和S锁的竞争，提高了并行度 提高了系统的数据库的可用性，因为主服务器挂了还有从服务器 反向代理和CDN反向代理通过在访问的时候先访问反向代理服务器，反向代理服务器具有缓存；如果缓存命中直接返回，降低了应用服务器的压力 CDN是用户在请求网站服务的时候，直接到离自己最近的网络提供商机房取得数据；这样加速访问网页的速度 使用分布式文件系统和分布式数据库随着业务的发展，数据量越来越大，一台服务器不能支撑这样的数据量；所以使用分布式数据库，将数据分布在不同的物理服务器上，分布式文件系统和分布式数据库是不区分是不是同一张表同一个业务 网站更常用的手段是根据业务分库，将不同业务的数据库放在不同的物理服务器上 使用NOSQL 和 搜索引擎业务拆分由于业务场景越来越复杂，将整个网站业务分成不同的产品线，形成不同的应用 分布式服务随着业务的拆分越来越小，存储系统越来越庞大，应用系统的整体复杂度呈指数级增加，部署越来越困难且数据库连接资源不足]]></content>
      <tags>
        <tag>架构演进</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CopyOnWriteArrayList源码分析]]></title>
    <url>%2F2019%2F02%2F21%2FJava%20%E5%B9%B6%E5%8F%91%2FCopyOnWriteArrayList%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[数据结构知识点总结]]></title>
    <url>%2F2019%2F02%2F21%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[二叉树平衡二叉树BF(平衡因子) = 左子树高度 - 右子树高度 插入节点时分四种情况，四种情况对应的旋转方法是不同的： 插入方式 描述 旋转方式 LL 在a的左子树根节点的左子树上插入节点而破坏平衡 右旋转 RR 在a的右子树根节点的右子树上插入节点而破坏平衡 左旋转 LR 在a的左子树根节点的右子树上插入节点而破坏平衡 先左旋后右旋 RL 在a的右子树根节点的左子树上插入节点而破坏平衡 先右旋后左旋 表述旋转的实现： 右旋转：以从底向上第一个不平衡因子作为根节点向右旋转，由根节点的左子树的根节点为新的根节点，如果新的根结点有右子树那么将其作为原根节点的左子树 左旋转：以从底向上第一个不平衡因子作为根节点向左旋转，由根节点的右子树的根节点为新的根节点，如果新的根结点有左子树那么将其作为原根节点的右子树 红黑树 红黑树的特点 节点是红色或者黑色 根节点是黑色 每个叶子节点都是黑色的空节点 每个红色结点的两个子节点都是黑色（从每个到根的所有路径上不能有两个连续的红色结点） 从任一结点到其每个叶子的所有路径都包含相同数目的黑色节点 基本平衡操作 变色 左旋转 右旋转]]></content>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[final关键字总结]]></title>
    <url>%2F2019%2F02%2F20%2FJava%20%E5%9F%BA%E7%A1%80%2Ffinal%E5%85%B3%E9%94%AE%E5%AD%97%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[基本用法 修饰变量 final可以修饰成员变量和本地本地变量，在声明变量的时候就必须赋值，且为只读，如果尝试再次初始化编译器将会报错 修饰方法 final 修饰方法的意义在于子类不能复写此方法；final方法编译的时候就可以绑定具体的方法地址，不需要运行时动态绑定；final和static关键字不能同时修饰一个方法，因为static方法子类也不能够复写，在不需要运行时绑定包含了final的语义 修饰类 final 修饰类意义在于表明该类不能被继承，JDK中许多类都是final的，比如说String，Integer以及其它包装类 final 的重排序的规则 在构造函数内对一个final域的写入，与随后把这个被构造对象的引用赋值给一个引用变量，这两个操作不能重排序 初次读一个包含final域的对象的引用与读这个final域不能重排序 稍微解释一下： 对于第一条在线程下，可能在属性还没有被赋值完成，该对象的引用就已经被传递出去了；所以对final域的写能够保证对象在构造完之后才能够传递出去 对于第二条，其实这两个操作本来就包含了间接依赖，必须有了对象的引用才能够去读对象中的属性，只是有些处理器没有支持，这个没有什么讲的]]></content>
      <tags>
        <tag>final</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM知识点总结]]></title>
    <url>%2F2019%2F02%2F19%2FJVM%2FJVM%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[TLAB（本地线程分配缓冲）]]></content>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ReentranLock源码分析]]></title>
    <url>%2F2019%2F02%2F19%2FJava%20%E5%B9%B6%E5%8F%91%2FReentranLock%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[可重入实现原理]]></content>
      <tags>
        <tag>ReentranLock</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sychronize和wait/notify实现原理]]></title>
    <url>%2F2019%2F02%2F19%2FJava%20%E5%B9%B6%E5%8F%91%2Fsychronize%E5%92%8Cwait%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[基本使用方法 使用synchronized 修饰普通方法 使用synchronized 修饰静态方法 使用synchronized 修饰同步代码块 Java 对象头在HotSpot虚拟机中，Java对象由三部分组成：对象头，实例数据、对齐填充 对象头又由两部分组成：运行时数据（Mark Word），对象类型指针； MarkWord在HotSpot中的实现在 markOop.hpp 文件中，一个对象在HotSpot中的实现在 oop.hpp 文件中 MarkWord 中的内容就如下图： 从上图也可以看出，偏向锁、轻量级锁、重量级锁的标志都在对象头中，所以他是锁实现的基本 字节码层面理解sychronized 使用ACC_SYNCHRONIZED标记同步方法 123456789101112public synchronized boolean test1(); descriptor: ()Z flags: ACC_PUBLIC, ACC_SYNCHRONIZED Code: stack=1, locals=2, args_size=1 0: iconst_1 1: istore_1 2: iconst_1 3: ireturn LineNumberTable: line 4: 0 line 5: 2 使用monitorenter 和 monitorexit 同步 1234567891011121314151617181920public boolean test1(); descriptor: ()Z flags: ACC_PUBLIC Code: stack=2, locals=4, args_size=1 0: aload_0 1: dup 2: astore_1 3: monitorenter 4: iconst_1 5: istore_2 6: iconst_1 7: aload_1 8: monitorexit 9: ireturn 10: astore_3 11: aload_1 12: monitorexit 13: aload_3 14: athrow 不管是从哪种方式用哪种方式实现的同步，在虚拟中实现同步都是基于进入和退出管程(Monitor)对象来实现的 从虚拟机层面理解sychronizedMonitor 监控器在MarkWord 中，如果是重量级锁的话，指向重量级锁的指针就是指向的一个Monitor对象； 其在HotSpot虚拟机源码实现在 ObjectMonitor.hpp文件 其数据结构如下： 123456789101112131415161718ObjectMonitor() &#123; _header = NULL; _count = 0; //记录个数 _waiters = 0, _recursions = 0; // 用于实现可重入锁，下面会有介绍 _object = NULL; _owner = NULL; // 用于标志拥有这个锁的线程，其实多线程下线程争抢不过就是这个字段；使用CAS将本线程赋值给这个字段，赋值成功就拥有了执行权限 _WaitSet = NULL; //处于wait状态的线程，会被加入到_WaitSet；等待池 _WaitSetLock = 0 ; _Responsible = NULL ; _succ = NULL ; _cxq = NULL ; //处于等待锁block状态的线程，会被加入到该列表 没有明白与EntryList区别 FreeNext = NULL ; _EntryList = NULL ; //处于等待锁block状态的线程，会被加入到该列表 _SpinFreq = 0 ; _SpinClock = 0 ; OwnerIsThread = 0 ; &#125; 偏向锁实现轻量级锁实现重量级锁实现上面三个标题见参考 占小狼 JVM源码分析之synchronized实现 从虚拟机层面理解wait/notify上面说过，ObjectMonitor对象中有两个队列：_WaitSet 和 _EntryList，用来保存ObjectWaiter对象列表；_owner指向获得ObjectMonitor对象的线程。 _WaitSet ：处于wait状态的线程，会被加入到wait set； _EntryList：处于等待锁block状态的线程，会被加入到entry set； wait 方法实现，下面我用语言描述过程，虚拟机实现参考 占小狼 JVM源码分析之synchronized实现 将当前线程封装成ObjectWaiter对象node 将上面创建的node 加入等待池中 释放当前对象的ObjectMonitor对象 notify方法实现 取等待池中的第一个ObjectWaiter唤醒 参考占小狼 深入浅出synchronized 占小狼 JVM源码分析之synchronized实现 占小狼 JVM源码分析之Object.wait/notify实现 深入理解Java并发之synchronized实现原理]]></content>
      <categories>
        <category>Java并发</category>
      </categories>
      <tags>
        <tag>sychronized</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[volatile关键字总结]]></title>
    <url>%2F2019%2F02%2F19%2FJava%20%E5%B9%B6%E5%8F%91%2Fvolatile%E5%85%B3%E9%94%AE%E5%AD%97%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[ConcurrentHashMap源码分析]]></title>
    <url>%2F2019%2F02%2F19%2FJava%20%E5%B9%B6%E5%8F%91%2FConcurrentHashMap%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[数据结构数组、链表、红黑树 属性及其含义1234567891011121314151617181920212223242526private static final int DEFAULT_CONCURRENCY_LEVEL = 16;// 负载因子，即当前元素个数超过 length*LOAD_FACTOR 就会扩容private static final float LOAD_FACTOR = 0.75f;// 链表转为红黑树的阈值static final int TREEIFY_THRESHOLD = 8;// 红黑树转换为链表的阈值static final int UNTREEIFY_THRESHOLD = 6;// 链表能够转换为红黑树的最小的总的节点数static final int MIN_TREEIFY_CAPACITY = 64;// 并发转移结点时，每个线程每次转移最少的结点数private static final int MIN_TRANSFER_STRIDE = 16;// 哈希表transient volatile Node&lt;K,V&gt;[] table;// 临时哈希表，用于扩容时临时存放private transient volatile Node&lt;K,V&gt;[] nextTable;// 结点数量，与counterCells一起计算结点数量private transient volatile long baseCount;// -1 代表有线程在进行扩容// -N 代表有N-1个线程在进行扩容// 正数 表示table大小private transient volatile int sizeCtl;// 用于多个线程之间的扩容协作，当一个线程扩容后 transferIndex = transferIndex - stride// 下一个线程就要从这个 被减后的transferIndex开始转移结点private transient volatile int transferIndex;private transient volatile CounterCell[] counterCells; ConcurrentHashMap实现并发的方式 CAS sychronized volatile 原子操作 核心方法以及实现putVal 延迟初始化 首先检查table初始化没有，如果没有那么就进行初始，如果在初始化时有其它线程访问，那么就让出时间片 12if (tab == null || (n = tab.length) == 0) tab = initTable() 如果hash值的位置上为NULL,就直接通过CAS操作添加结点 12345else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) &#123; if (casTabAt(tab, i, null, new Node&lt;K,V&gt;(hash, key, value, null))) break; // no lock when adding to empty bin &#125; 如果不能添加，并且发现在扩容，那么该线程就去帮助扩容；所以这里就涉及到了多线程扩容机制以及怎么使用FwordingNodeing 实现扩容的同时检索 12else if ((fh = f.hash) == MOVED) tab = helpTransfer(tab, f); 不是上面的情况就是要么hash值的位置上有结点要么是存在竞争CAS失败，那么就通过对哈希桶加锁添加 addCount 和 sumCount有一些比较重要的字段需要讲解 sizeCtl： 用来控制table初始化和扩容操作 0或者正数也就是0.75n：表示没有进行初始化或者下次扩容大小 -1：代表table正在初始化 -N：代表有N-1个线程正在进行 扩容 baseCount：在没有并发的时候，ConcurrentHashMap size加1直接加在这个字段上 counterCells：这是一个CounterCell的数组，在出现并发的不能利用CAS修改baseCount的时候，就会首先尝试随机取一个counterCell然后加1；如果上一个操作依然失败了那么就会调用addFullCount方法去实例化一个counterCell加1； 使用这个的目的是为了减轻对baseCount的负担；如果所有的添加都是在baseCount上操作，如果并发量大的话，必定在访问baseCount这里就会堆积大量的线程这样性能反而会差，但是如果把这些访问随机分配到CounterCells数组里，就会大大减少并发的堆积 cellBusy:这是修改counterCell的标志，在向counterCells添加元素的时候和counterCells扩容的时候其会被置为1 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960// 从 putVal 传入的参数是 1， binCount，binCount 默认是0，只有 hash 冲突了才会大于 1.且他的大小是链表的长度（如果不是红黑数结构的话）。private final void addCount(long x, int check) &#123; CounterCell[] as; long b, s; // 如果计数盒子不是空 或者 // 如果修改 baseCount 失败 if ((as = counterCells) != null || **!U.compareAndSwapLong(this, BASECOUNT, b = baseCount, s = b + x)) &#123; CounterCell a; long v; int m; boolean uncontended = true; // 如果计数盒子是空（尚未出现并发） // 如果随机取余一个数组位置为空 或者 // 修改这个槽位的变量失败（出现并发了） // 执行 fullAddCount 方法。并结束 if (as == null || (m = as.length - 1) &lt; 0 || // ThreadLocalRandom这个其实就是线程安全的随机数类 (a = as[ThreadLocalRandom.getProbe() &amp; m]) == null || !(uncontended = U.compareAndSwapLong(a, CELLVALUE, v = a.value, v + x))) &#123; fullAddCount(x, uncontended); return; &#125; if (check &lt;= 1) return; s = sumCount(); &#125; // 如果需要检查,检查是否需要扩容，在 putVal 方法调用时，默认就是要检查的。 if (check &gt;= 0) &#123; Node&lt;K,V&gt;[] tab, nt; int n, sc; // 如果map.size() 大于 sizeCtl（达到扩容阈值需要扩容） 且 // table 不是空；且 table 的长度小于 1 &lt;&lt; 30。（可以扩容） while (s &gt;= (long)(sc = sizeCtl) &amp;&amp; (tab = table) != null &amp;&amp; (n = tab.length) &lt; MAXIMUM_CAPACITY) &#123; // 根据 length 得到一个标识 int rs = resizeStamp(n); // 如果正在扩容 if (sc &lt; 0) &#123; // 如果 sc 的低 16 位不等于 标识符（校验异常 sizeCtl 变化了） // 如果 sc == 标识符 + 1 （扩容结束了，不再有线程进行扩容）（默认第一个线程设置 sc ==rs 左移 16 位 + 2，当第一个线程结束扩容了，就会将 sc 减一。这个时候，sc 就等于 rs + 1） // 如果 sc == 标识符 + 65535（帮助线程数已经达到最大） // 如果 nextTable == null（结束扩容了） // 如果 transferIndex &lt;= 0 (转移状态变化了) // 结束循环 if ((sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 || sc == rs + MAX_RESIZERS || (nt = nextTable) == null || transferIndex &lt;= 0) break; // 如果可以帮助扩容，那么将 sc 加 1. 表示多了一个线程在帮助扩容 if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) // 扩容 transfer(tab, nt); &#125; // 如果不在扩容，将 sc 更新：标识符左移 16 位 然后 + 2. 也就是变成一个负数。高 16 位是标识符，低 16 位初始是 2. else if (U.compareAndSwapInt(this, SIZECTL, sc, (rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2)) // 更新 sizeCtl 为负数后，开始扩容。 transfer(tab, null); s = sumCount(); &#125; &#125;&#125; 这个方法其实就是完成了两个动作： ConcurrentHashMap size加1（下面是一个不断复杂的过程，有点类似于锁的膨胀过程） 尝试直接修改baseCount，如果直接修改失败则执行下一步 如果计数盒子为空即尚未出现过并发或者随机取一个计数盒子里面的位置为空或者尝试修改随机取得countCell失败，则执行下一步 fullAddCount 主要完成以下三件事情：如果CounterCells没有初始化则初始化；初始化了的就实例化CountterCell死循环添加进CounterCells；对CounterCells进行扩容 检查是否需要扩容 如果容量大于了阈值且不再扩容，那么赋值sizeCtl 开始扩容 如果容量大于了阈值且正在扩容，那么帮助扩容 这里是一个循环，进入的线程都会一直帮助扩容 1234567891011final long sumCount() &#123; CounterCell[] as = counterCells; CounterCell a; long sum = baseCount; if (as != null) &#123; for (int i = 0; i &lt; as.length; ++i) &#123; if ((a = as[i]) != null) sum += a.value; &#125; &#125; return sum; &#125; 在讲addCount方法第一步的时候其实已经囊括了讲解这里了 size 其实就是将baseCount加上因为并发冲突添加到CounterCell里面的数 多线程扩容机制什么时候会扩容在ConcurrentHashMap里面有两个地方存在扩容 在树化的时候，如果发现数组长度小于了MIN_TREEIFY_CAPACITY，默认是64 就会调用tryPresize方法把数组长度扩大到原来的两倍，并触发transfer方法，重新调整节点的位置。 在添加结点的时候会调用addCount方法记录元素个数，并检查是否需要进行扩容，当数组元素个数达到阈值时，会触发transfer方法，重新调整节点的位置 怎么扩容的 (Transfer方法)下面讲述大致过程： 通过计算CPU核心数和Map数组的长度得到每个线程要帮助处理桶数；默认每个线程处理16个桶 初始化nextTable为原table的两倍 死循环开始转移；根据finishing变量来判断退出循环 while循环有三个作用 从大到小取每一个桶 赋值 i 退出循环转移完成 每个线程进行扩容的时候取得的transferIndex，得到转移的范围 转移完成的出口 如果oldTable 数组位置为NULL则赋为FowordNode表示该位置转移完成 如果oldTable 数组位置正在扩容就继续循环 具体的转移过程；这里会给每一个转移的哈希桶位置加锁，保证转移该位置上所有结点不会产生线程安全问题；转移数组位置上单个链表的时候会将其按照一定的算法分隔成两段然后插入到新的哈希表中；在转移完成后会将原哈希表该数组位置上赋值为ForwardingNode以便其它扩容线程看到表示该节点已经转移完成，也能够保证在扩容过程中依然能够支持哈希表的查找 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143private final void transfer(Node&lt;K,V&gt;[] tab, Node&lt;K,V&gt;[] nextTab) &#123; int n = tab.length, stride; // 计算每个线程分配的转移hash桶数 if ((stride = (NCPU &gt; 1) ? (n &gt;&gt;&gt; 3) / NCPU : n) &lt; MIN_TRANSFER_STRIDE) stride = MIN_TRANSFER_STRIDE; // subdivide range // 初始化nextTab if (nextTab == null) &#123; // initiating try &#123; @SuppressWarnings("unchecked") // 扩容两倍 Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n &lt;&lt; 1]; nextTab = nt; &#125; catch (Throwable ex) &#123; // try to cope with OOME sizeCtl = Integer.MAX_VALUE; return; &#125; nextTable = nextTab; transferIndex = n; &#125; int nextn = nextTab.length; // 实例化ForwardingNode hash桶转移完成的标志 ForwardingNode&lt;K,V&gt; fwd = new ForwardingNode&lt;K,V&gt;(nextTab); boolean advance = true; boolean finishing = false; // to ensure sweep before committing nextTab for (int i = 0, bound = 0;;) &#123; Node&lt;K,V&gt; f; int fh; while (advance) &#123; int nextIndex, nextBound; // 向前推进 得到一个hash桶 if (--i &gt;= bound || finishing) advance = false; // 退出出口 else if ((nextIndex = transferIndex) &lt;= 0) &#123; i = -1; advance = false; &#125; // 每个线程从这里分配自己转移的hash桶的范围 else if (U.compareAndSwapInt (this, TRANSFERINDEX, nextIndex, nextBound = (nextIndex &gt; stride ? nextIndex - stride : 0))) &#123; bound = nextBound; i = nextIndex - 1; advance = false; &#125; &#125; // 真正的出口，标志转移完成 if (i &lt; 0 || i &gt;= n || i + n &gt;= nextn) &#123; int sc; if (finishing) &#123; nextTable = null; table = nextTab; sizeCtl = (n &lt;&lt; 1) - (n &gt;&gt;&gt; 1); return; &#125; if (U.compareAndSwapInt(this, SIZECTL, sc = sizeCtl, sc - 1)) &#123; if ((sc - 2) != resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT) return; finishing = advance = true; i = n; // recheck before commit &#125; &#125; // 赋值原hash表NULL值hash桶为fwd，标志转移完成 else if ((f = tabAt(tab, i)) == null) advance = casTabAt(tab, i, null, fwd); // 标志该hash桶转移完成 else if ((fh = f.hash) == MOVED) advance = true; // already processed else &#123; // 真正的转移过程 synchronized (f) &#123; if (tabAt(tab, i) == f) &#123; Node&lt;K,V&gt; ln, hn; if (fh &gt;= 0) &#123; int runBit = fh &amp; n; Node&lt;K,V&gt; lastRun = f; for (Node&lt;K,V&gt; p = f.next; p != null; p = p.next) &#123; int b = p.hash &amp; n; if (b != runBit) &#123; runBit = b; lastRun = p; &#125; &#125; if (runBit == 0) &#123; ln = lastRun; hn = null; &#125; else &#123; hn = lastRun; ln = null; &#125; for (Node&lt;K,V&gt; p = f; p != lastRun; p = p.next) &#123; int ph = p.hash; K pk = p.key; V pv = p.val; if ((ph &amp; n) == 0) ln = new Node&lt;K,V&gt;(ph, pk, pv, ln); else hn = new Node&lt;K,V&gt;(ph, pk, pv, hn); &#125; setTabAt(nextTab, i, ln); setTabAt(nextTab, i + n, hn); setTabAt(tab, i, fwd); advance = true; &#125; else if (f instanceof TreeBin) &#123; TreeBin&lt;K,V&gt; t = (TreeBin&lt;K,V&gt;)f; TreeNode&lt;K,V&gt; lo = null, loTail = null; TreeNode&lt;K,V&gt; hi = null, hiTail = null; int lc = 0, hc = 0; for (Node&lt;K,V&gt; e = t.first; e != null; e = e.next) &#123; int h = e.hash; TreeNode&lt;K,V&gt; p = new TreeNode&lt;K,V&gt; (h, e.key, e.val, null, null); if ((h &amp; n) == 0) &#123; if ((p.prev = loTail) == null) lo = p; else loTail.next = p; loTail = p; ++lc; &#125; else &#123; if ((p.prev = hiTail) == null) hi = p; else hiTail.next = p; hiTail = p; ++hc; &#125; &#125; ln = (lc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(lo) : (hc != 0) ? new TreeBin&lt;K,V&gt;(lo) : t; hn = (hc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(hi) : (lc != 0) ? new TreeBin&lt;K,V&gt;(hi) : t; setTabAt(nextTab, i, ln); setTabAt(nextTab, i + n, hn); setTabAt(tab, i, fwd); advance = true; &#125; &#125; &#125; &#125; &#125;&#125; 大致总结上面的终点就是： 数组扩大两倍 通过CPU数量计算每个线程转移数量 每个线程通过transferIndex计算自己转移的范围 具体转移过程中，会将原链表或者红黑树分隔，并且转移过程中转移完成的位置会用FowrdingNoding表示转移完成 ConcurrentHashMap保证数组可见性在JAVA 中volatile字段修饰数组，只能保证对数组引用修改的可见性，不能保证对数组元素存取的可见性；在ConcurrentHashMap中，tabAt 方法中使用getVolatileValue保证了对取的可见性，使用CAS操作保证了对存的可见性 123static final &lt;K,V&gt; Node&lt;K,V&gt; tabAt(Node&lt;K,V&gt;[] tab, int i) &#123; return (Node&lt;K,V&gt;)U.getObjectVolatile(tab, ((long)i &lt;&lt; ASHIFT) + ABASE);&#125; 怎么保证GET方法 不用加锁 ConcurrentHashMap 使用volatile、CAS、sychronized、getVolatileValue 保证了所有操作的可见性 使用FwordingNode 保证了在扩容的同时依然能够查询]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>ConcurrentHashMap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HashMap源码分析]]></title>
    <url>%2F2019%2F02%2F19%2FJava%20%E5%9F%BA%E7%A1%80%2FHashMap%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[常见属性及其含义123456789101112// 默认的初始化容量static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // aka 16// 最大容量 static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30; // 默认的负载因子 static final float DEFAULT_LOAD_FACTOR = 0.75f; // 哈希桶里面的结点数大于该值就会 从链表转换为红黑树 static final int TREEIFY_THRESHOLD = 8; // 哈希桶里面的结点数从较大值变为该值，就会从红黑树转换为链表 static final int UNTREEIFY_THRESHOLD = 6; // 如果总容量小于该值但是哈希桶里面的结点数又大于threshold，就会扩容使结点分散 static final int MIN_TREEIFY_CAPACITY = 64; 重要方法及其实现putValputVal 延迟初始化 123// 在resize 方法里面完成初始化if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; 定位：使用除留余数法完成hash桶的定位 12if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); 对相同对象的判断方式 123if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; 首先会判断hash值相同否，再判断equals方法是否相同；这样判断的原因是hashcode一样，不一定equals方法返回true 这里就涉及到一个原理 复写了equals方法是否需要复写hashcode hashCode方法上面的注释有这样一句话，如果两个对象equals，那么它们的hashCode所返回的Integer应该是相等的，所以equals方法被重写意味着判断它们相等的方式产生了变化，也就需要根据新的条件来保证两个对象equals，hashCode方法返回的Integer相等 红黑树化 12if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); 当hash桶size &gt; TREEIFY_THRESHOLD - 1 就会扩容 扩容 将数组增大为原来的两倍，在转移过程中就会有二种情况： 原hash表的hash桶只有一个元素，那么就直接添加到新hash表中 当不只一个元素的时候，又有下面两种情况： 为红黑树，就按照红黑树将一棵树划分成两颗 为链表就按照新的hash表的容量做除留余数法，切割成两个链表添加进新的 resize123456789if (oldCap &gt; 0) &#123; if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold &#125; 这里将capacity和threshold都扩大了两倍 1234else &#123; // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; 这里是给putVal的延迟初始化用的，当table为NULL，那么就回使用resize进行初始化 下面就是具体的转移过程 一些常见问题为什么hashMap的capacity要选取2的幂因为这样(数组长度-1)正好相当于一个低位掩码，这样也正好对应了数组的长度，可以得到数组的一个下标 1234 10100101 11000100 00100101 &amp; 00000000 00000000 00001111-------------------------------- 00000000 00000000 00000101 //高位全部归零，只保留末四位 hash 方法原理(h&gt;&gt;&gt;16)因为Object.hashCode是返回int型的散列值也就是32位，这里右移了16位得到了hash值得高16位，前16位用0填充这样高位的信息被变相的保留了下来，再进行(h^(h&gt;&gt;&gt;16))也就增加了低位的随机性下面使用的地方会使用 (n-1) &amp; hash(key)就会随机得到一个Node数组的一个下标，随机性增强了那么碰撞的可能也就减少了 为什么HashMap 非线程安全 这里只说明一个例子：现在有两个线程同时操作一个HashMap，他们现在同时取得了插入哈希表的同一个地址，现在第一个线程插入进去把next指针指向了它，但是第二个线程对此一无所知，依然进行了同样的操作，最后也就覆盖了第一个线程的操作。 还有个什么死循环看不怎么懂 ….. 在多线程中HashMap的死循环问题在java1.8之后 JDK解决了多线程的死循环问题，所以下面贴的代码也是JDK8之前的 这是移动的逻辑 123456789101112131415void transfer(Entry[] newTable, boolean rehash) &#123; int newCapacity = newTable.length; for (Entry&lt;K,V&gt; e : table) &#123; while(null != e) &#123; Entry&lt;K,V&gt; next = e.next; if (rehash) &#123; e.hash = null == e.key ? 0 : hash(e.key); &#125; int i = indexFor(e.hash, newCapacity); e.next = newTable[i]; newTable[i] = e; e = next; &#125; &#125;&#125; 我们假设负载因子是1,所以当添加下一个元素时就会进行扩容操作 现在我们假设有A、B两个线程 A,B两个线程会分别创建自己的newTable 假设线程2运行到Entry&lt;K,V&gt; next = e.next 时间片用完了；这个时候e 指向 a 结点，next指向 b 结点；且在再hash的时候三个结点又同时在同一个hash桶 在线程1 运行的时候就会按照从头结点加入的方式加入哈希桶中 这个时候线程1的时间片用完，线程2继续执行；就会将a结点加入自己新表中的哈希桶中，得到下图中的结果 因为在上一个时间片已经赋值next为b；又会将哈希桶首位置变为b，b结点的next依然指向a 这个时候又取 b 结点的next 得到 a 结点，又将哈希桶首位置赋值 a 结点，且 a 结点的next 为 b结点;这样便形成了一个环 这样不管最终那个线程 赋值了table，那么get 这个哈希桶的值的时候就会陷入死循环 为什么线程安全的集合键值不可以为NULL而非线程安全的却可以在例如HashMap非线程安全的集合 中可以设置键值为NULL 而不会产生到底是值本身是NULL还是哈希表中不存在这个键的歧义的原因是 在HashMap中我们可以使用ContainsKey来判断是否存在这个值 就避免了上述的歧义 而在线程安全的集合中 在 get 方法和 containsKey 方法之间可能存在其它线程删除键值对]]></content>
  </entry>
  <entry>
    <title><![CDATA[计算机网络]]></title>
    <url>%2F2019%2F02%2F18%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[操作系统]]></title>
    <url>%2F2019%2F02%2F18%2F%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%2F%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[计算机Cache原理]]></title>
    <url>%2F2019%2F02%2F14%2F%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%2F%E8%AE%A1%E7%AE%97%E6%9C%BACache%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[主存因为在讲Cache的时候会涉及到主存的相关知识点，所以先讲主存的一些知识点 主存中的地址分配在计算机中，主存各存储单元的空间位置是由单元地址号来表示的，而地址总线是用来指出存储单元的地址号的；一般来说，CPU在读取主存中的数据的时候，既可以以字寻址，也可以按字节寻址；至于字和字节的关系，就用下面的图来表示 字地址有用高位字节表示和低位字节表示，这里演示使用的是高位字节表示；这里的一个字地址就是 后面会提到的字块；所以在地址线用地址号来寻址的时候，字地址会用高地址表示，然后使用一定的低地址位来表示字节地址； 还需要说明一下缓存行与字地址的关系；一个缓存行就是一个字块(字地址表示的内存位置) 在Cache映射算法中，组相联映射中，一个组包含多个缓存行也就表示一个组包含多个字块 Cache一次刷新的也是一个缓存行 高速缓存概述 使用原因 局部性原理 基本结构及其基本工作原理实现缓存由以下几块：Cache存储体，地址映射变换机构，Cache替换机构 在缓存和主存中，都有相同的块大小，所以缓存中可以缓存主存中的字块；其基本工作过程如下面的图片 Cache的读写操作 在Cache读的过程中，不仅需要获取需要的数据，如果不是从缓存中得到的数据还要讲数据存入缓存中去； 在Cache写的过程有两种方法： 写回法：即写操作时只把数据写入Cache而不写入主存，但当Cache数据被替换才写入主存 写直达法：每次写操作不仅要写入缓存还要写回主存 Cache的改进 二级缓存 统一缓存和分立缓存 定义：统一缓存就是将指令和数据都放在一个Cache内；而分立缓存指的是指令和数据的分别放在两个缓存中，一个为数据Cache，一个为指令Cache； 实现分立Cache的原因是实现超前控制或者叫指令预取；如果指令和数据不分开可能出现取值和执行过程对同一缓存的征用，也就不能达到指令预取的目的指令的预取和执行并行执]]></content>
      <categories>
        <category>计算机</category>
      </categories>
      <tags>
        <tag>Cache</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Future模式]]></title>
    <url>%2F2019%2F02%2F12%2FJava%20%E5%B9%B6%E5%8F%91%2FFuture%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[并发模式: Future模式Future模式有其基本结构，如下： 对象 作用 Client 取数据，立即返回FutureData，并新建线程构建RealData Data 接口，FutureData，RealData都实现于它 FutureData Future数据，是RealData的封装，用于立即返回，是一个虚拟数据 RealData 真实的数据，构造比较慢 以下就是上述对象的基本模型： 123456789101112131415161718192021222324252627282930313233343536public class Client&#123; // 用于请求，立即返回FutureData，并在其中新建线程构造RealData然后赋值给FutureData public Data request(T t)&#123; ... &#125;&#125;public class Data&#123; public T getResult();&#125;public class FutureData implements Data&#123; private RealData realData; private boolean ready; // public synchronized T getResult()&#123; if(!ready) &#123; try &#123; wait(); &#125;catch(InterruptException e) &#123; .... &#125; &#125; return realData.result; &#125; public synchronized void setResult(RealData realData) &#123; if(ready) &#123; return; &#125; this.realData = realData; ready = true; notifyAll(); &#125;&#125; JDK 中的Future 模式在JDK 中是将上述Future模式的基本对象全部封装在了FutureTask中了； 其中run方法就实现了构造真实对象，并且改变状态赋值结果 1234567891011121314151617181920212223242526272829303132public void run() &#123; if (state != NEW || !UNSAFE.compareAndSwapObject(this, runnerOffset, null, Thread.currentThread())) return; try &#123; Callable&lt;V&gt; c = callable; if (c != null &amp;&amp; state == NEW) &#123; V result; boolean ran; try &#123; result = c.call(); ran = true; &#125; catch (Throwable ex) &#123; result = null; ran = false; setException(ex); &#125; if (ran) set(result); &#125; &#125; finally &#123; // runner must be non-null until state is settled to // prevent concurrent calls to run() runner = null; // state must be re-read after nulling runner to prevent // leaked interrupts int s = state; if (s &gt;= INTERRUPTING) handlePossibleCancellationInterrupt(s); &#125;&#125; get方法就类似于FutureData的getResult 123456public V get() throws InterruptedException, ExecutionException &#123; int s = state; if (s &lt;= COMPLETING) s = awaitDone(false, 0L); return report(s);&#125; 一般我们就将线程池作为Client，将FutureTask交给它]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>Future模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AQS源码分析]]></title>
    <url>%2F2019%2F01%2F28%2FJava%20%E5%B9%B6%E5%8F%91%2FAQS%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[概述AQS 抽象队列同步器，是JAVA concurrent包锁机制实现基类，在JAVA1.6 虚拟机层面没有对Synchronized进行优化的时候 它的使用性能比synchronized 要好很多；JAVA 虚拟机层面一些锁优化 在AQS里面也有实现 AQS 实现了两种锁机制：共享锁和排他锁；ReentrantLock 相关类就是排他锁的实现类，CountDownLatch，CyclicBarrier就是共享锁的实现类 数据结构FiFO队列、双向链表 重要属性12345678910111213141516171819/** 等待队列的头结点 * Head of the wait queue, lazily initialized. Except for * initialization, it is modified only via method setHead. Note: * If head exists, its waitStatus is guaranteed not to be * CANCELLED. */private transient volatile Node head;/**等待队列的尾结点 * Tail of the wait queue, lazily initialized. Modified only via * method enq to add new wait node. */private transient volatile Node tail;/**同步状态 * The synchronization state. */private volatile int state; FIFO队列的实现1234567891011121314static final class Node &#123; static final Node SHARED = new Node(); static final Node EXCLUSIVE = null; static final int CANCELLED = 1; // 取消状态 static final int SIGNAL = -1; // 等待触发状态 static final int CONDITION = -2; // 等待条件状态 static final int PROPAGATE = -3; // 状态需要向后传播 volatile int waitStatus; volatile Node prev; volatile Node next; volatile Thread thread; Node nextWaiter; ... &#125; 实现原理排它锁获取锁的过程子类重写tryAcquire 和 tryRelease方法通过CAS指令修改状态变量state 1234public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125; 所以加锁操作就是两个操作： 尝试直接修改state得到锁 加入等待队列 加入队列过程源码如下，大致总结一下过程 生成新的Node结点，并用CAS操作尝试插入到尾结点中；如果CAS操作没有成功，那么使用死循环强行使用CAS操作添加到队列中；在这里如果尾结点为空则赋值头结点为空，并让尾结点执行头结点 node插入队尾后，并不会立马挂起，会进行自旋操作，判断在node插入过程中，刚刚运行的线程是否执行完成，如果pred = head说明当前结点是队列中第一个有效的结点，因此尝试tryAcquire获取锁 如果成功获取到锁，表明线程B已经执行完成，线程A不需要挂起。 如果获取失败，表示线程B还未完成，至少还未修改state值；继续下面的步骤 只有前一个结点pred的线程状态为SIGNAL时，当前结点的线程才能被挂起 如果pred的waitStatus == 0，则通过CAS指令修改waitStatus为Node.SIGNAL。 如果pred的waitStatus &gt; 0，表明pred的线程状态CANCELLED，需从队列中删除。 如果pred的waitStatus为Node.SIGNAL，则通过LockSupport.park()方法把线程A挂起，并等待被唤醒，被唤醒后进入下一步 每次被唤醒都要进行中断检查，如果发现当前线程被中断，那么抛出InterruptedException并退出循环。从无限循环的代码可以看出，并不是被唤醒的线程一定能获得锁，必须调用tryAccquire重新竞争，因为锁是非公平的，有可能被新加入的线程获得，从而导致刚被唤醒的线程再次被阻塞，这个细节充分体现了“非公平”的精髓。 1234567891011121314private Node addWaiter(Node mode) &#123; Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure Node pred = tail; if (pred != null) &#123; node.prev = pred; if (compareAndSetTail(pred, node)) &#123; pred.next = node; return node; &#125; &#125; enq(node); return node;&#125; 123456789101112131415private Node enq(final Node node) &#123; for (;;) &#123; Node t = tail; if (t == null) &#123; // Must initialize if (compareAndSetHead(new Node())) tail = head; &#125; else &#123; node.prev = t; if (compareAndSetTail(t, node)) &#123; t.next = node; return t; &#125; &#125; &#125;&#125; 123456789101112131415161718192021final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; return interrupted; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; 123456789101112131415161718192021222324252627private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123; int ws = pred.waitStatus; if (ws == Node.SIGNAL) /* * This node has already set status asking a release * to signal it, so it can safely park. */ return true; if (ws &gt; 0) &#123; /* * Predecessor was cancelled. Skip over predecessors and * indicate retry. */ do &#123; node.prev = pred = pred.prev; &#125; while (pred.waitStatus &gt; 0); pred.next = node; &#125; else &#123; /* * waitStatus must be 0 or PROPAGATE. Indicate that we * need a signal, but don't park yet. Caller will need to * retry to make sure it cannot acquire before parking. */ compareAndSetWaitStatus(pred, ws, Node.SIGNAL); &#125; return false;&#125; 排它锁释放过程 修改state和锁的偏向状态 默认从队列下一个结点的线程unPark，但是就像上面说的它不一定能够获得运行的权力，因为还是要跟新加入的线程竞争 1234567891011public final boolean release(int arg) &#123; // 修改state和锁的偏向状态 if (tryRelease(arg)) &#123; Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) // 默认去取下一个结点的线程来执行 unparkSuccessor(h); return true; &#125; return false;&#125; 1234567891011121314151617181920212223242526private void unparkSuccessor(Node node) &#123; /* * If status is negative (i.e., possibly needing signal) try * to clear in anticipation of signalling. It is OK if this * fails or if status is changed by waiting thread. */ int ws = node.waitStatus; if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0); /* * Thread to unpark is held in successor, which is normally * just the next node. But if cancelled or apparently null, * traverse backwards from tail to find the actual * non-cancelled successor. */ Node s = node.next; if (s == null || s.waitStatus &gt; 0) &#123; s = null; for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; &#125; if (s != null) LockSupport.unpark(s.thread);&#125; 弱一致性在AQS 中存在弱一致性，维护一致性通常需要牺牲部分性能，为了进一步的提升性能，脑洞大开的神牛们想出了各种高性能的弱一致性模型。尽管模型允许了更多弱一致状态，但所有弱一致状态都在控制之下，不会出现一致性问题。 在AQS 中比如说unparkSuccessor中 都是从tail开始往前遍历结点，这是因为AQS 中enq代码 没有对 前一个node的next属性维护一致性 12345678910111213141516private Node enq(final Node node) &#123; for (;;) &#123; Node t = tail; if (t == null) &#123; // Must initialize if (compareAndSetHead(new Node())) tail = head; &#125; else &#123; node.prev = t; if (compareAndSetTail(t, node)) &#123; // 这里对竞态变量修改没有维护一致性，有可能在这个时候分配的时间片用完，下一个运行的线程并不会看到这个变化 t.next = node; return t; &#125; &#125; &#125; &#125; AQS 删除Canceled 节点过程中，也是弱一致性的 12345678910111213141516171819202122232425262728private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123; int ws = pred.waitStatus; if (ws == Node.SIGNAL) /* * This node has already set status asking a release * to signal it, so it can safely park. */ return true; if (ws &gt; 0) &#123; /* * Predecessor was cancelled. Skip over predecessors and * indicate retry. */ do &#123; // 这里不同线程可能看不到这里的修改 node.prev = pred = pred.prev; &#125; while (pred.waitStatus &gt; 0); pred.next = node; &#125; else &#123; /* * waitStatus must be 0 or PROPAGATE. Indicate that we * need a signal, but don't park yet. Caller will need to * retry to make sure it cannot acquire before parking. */ compareAndSetWaitStatus(pred, ws, Node.SIGNAL); &#125; return false; &#125;]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>AQS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库知识点]]></title>
    <url>%2F2019%2F01%2F28%2FMysql%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9F%A5%E8%AF%86%E7%82%B9%2F</url>
    <content type="text"><![CDATA[事务定义： 事务是访问并可能修改数据库中各种数据项的一个程序执行单元 隔离级别未提交读在此并发隔离级别下，存在脏读的可能性；在第一个事务执行SQL后，第二个事务读数据库数据有第一个事务提交的数据，但是第一个事务后面又回滚了事务，导致第二个事务脏读 提交读在此并发隔离级别下，避免了脏读，但是不可重复读；不可重复读就是第一个事务读取了数据库的数据，第二个事务然后修改了事务一读取的数据，事务一再读数据就发生了不可重复读 可重复读在此并发隔离级别下，避免以上的数据可能的错误，但是会有幻读；脏读就是事务一读取了数据库的数据，但是后面事务二又添加了事务一读取的数据，事务一再次读取数据的时候发现多了一条数据 串行化避免了上述的所有可能的数据错误，但是性能不好，所以一般不使用这个]]></content>
      <categories>
        <category>database</category>
      </categories>
      <tags>
        <tag>数据库知识点</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从Spring源码中看设计模式]]></title>
    <url>%2F2019%2F01%2F14%2FJavaweb%2F%E4%BB%8ESpring%E6%BA%90%E7%A0%81%E4%B8%AD%E7%9C%8B%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[适配器模式 HandlerAdapter 在Spring MVC中存在多个Controller，而每个Controller处理的方式不同，如果不按照适配器模式去做我们正常的处理方式会像下面这样： 1234567if(a instanceof B) &#123; B b = (B)a； b.doSomethingB();&#125;else if(a instanceof C) &#123; C c = (C)a; c.doSomethingC();&#125;.... 如果这样的话，要添加一个新的Controller，就只能在这个分支选择里面再添加一条，那么就会违背开放闭合原则 Spring 使用适配器模式 将判断类型和在该类型下面的动作全部分离了出来 12345678public interface HandlerAdapter &#123; boolean supports(Object var1); @Nullable ModelAndView handle(HttpServletRequest var1, HttpServletResponse var2, Object var3) throws Exception; long getLastModified(HttpServletRequest var1, Object var2);&#125; 那么在添加一个新类型的时候，只需要创建一个该类型的Adapter，然后再将该Adapter添加到Adapter列表里面 执行的时候取得Controller 处理后返回的类型，然后遍历Adapter列表找到属于它的Adapter，再直接通过Adapter调用处理方法 AdvisorAdapter 在Spring AOP中需要将所有Advisor 转换成MethodInterceptor形成一个线性表，然后执行方法的时候就遍历执行这个表就行 这里的Advisor 有不同类型且对应不同的MethodInterceptor 如果使用分支选择就会下面这样： 1234567if(a instanceof B) &#123; B b = new B(); return b;&#125;else if(a instanceof C) &#123; C c = new C(); return c;&#125;.... 但是这样就不具有扩展性了，所以也跟上面一样 判断类型 和具体的处理进行了分离 1234567public interface AdvisorAdapter &#123; boolean supportsAdvice(Advice advice); MethodInterceptor getInterceptor(Advisor advisor); &#125; 责任链模式 Filter链 HandlerExecutionChain Aop中的MethodInterceptor 观察者模式 Tomcat生命周期Listener Spring事件监听器 工厂方法模式 不同WebServer的构建]]></content>
      <categories>
        <category>javaweb</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[解释器、编译器、解释程序、编译程序]]></title>
    <url>%2F2019%2F01%2F13%2F%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%2F%E8%A7%A3%E9%87%8A%E5%99%A8%E3%80%81%E7%BC%96%E8%AF%91%E5%99%A8%E3%80%81%E8%A7%A3%E9%87%8A%E7%A8%8B%E5%BA%8F%E3%80%81%E7%BC%96%E8%AF%91%E7%A8%8B%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[解释器、编译器、解释程序、编译程序这几个词语让我觉得非常的模糊，感觉它们的界限不是很清晰，下面是我读了R大的博客，百度百科词条过后的理解 解释器：就是个黑箱，输入的是源码，输出的就是程序的执行结果，很多解释器内部都是以编译器+虚拟机的执行方式，比如说python；这里输入不一定一定是高级语言，在python中就是高级语言，python代码，在JVM中，就是java 字节码 编译器：就是把一种语言翻译成另一种较低级别的语言的一端程序；前者可能是高级语言，那么输出一般是中间代码，比如说java 中的字节码，也可能是中间代码，输出的就是本地代码，本地代码就是跟计算机硬件相关的指令集的机器码 解释程序和编译程序在《计算机组成原理》书籍中是这样定义的， 解释程序：将源程序的一条语句翻译成对应的机器码并且立即执行，接着翻译源程序的下一条语句并执行这条语句，如此重复直至完成源程序的全部翻译任务；所以解释器和解释程序不是平等的关系，一般来说是解释器包含了解释程序 编译程序：将用户编写的高级语言程序的全部语句一次全部翻译成及其语言程序，而后执行机器语言程序；编译程序跟编译器没有什么关系 在JAVA执行引擎中有一种执行模式是混合模式，即解释执行和编译执行混合的执行模式 那么什么叫混合模式呢？ 其实这个跟JAVA执行引擎采用的JIT编译器有关，JIT编译器会在代码运行过程中不停的优化代码，还会将字节码直接转换为本地代码；所以它既有了上面解释程序一条一条翻译字节码执行的特点又有了编译程序中会将字节码直接替换为本地代码的特点]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Java并发编程艺术总结]]></title>
    <url>%2F2019%2F01%2F02%2FReading%2FJava%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E8%89%BA%E6%9C%AF%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[并发编程的挑战上下文切换定义 上下文切换就是CPU调度切换线程的时候，将上一个线程的数据保存下来，然后将下一个线程的数据引入CPU以便接下来的运行，如果线程的数量较多这是一个不小得开销 切换原因 时间片使用完 中断处理 用户状态切换 IO阻塞 用户代码挂起当前任务 减少切换次数方法 无锁并发：在有锁的情况下，大量的线程会由runnable-&gt;waiting，waiting-&gt;runnable 两种状态切换，也就会导致大量的线程的切换 CAS算法：操作系统级别提供的原子操作，减少锁从而减少上面的情况出现 减少线程数：线程数量越多，如果任务少越多的线程处于waiting状态，那么增加由waiting-&gt;runnable状态的切换也就增加了上下文切换的次数 使用协程 线程数量的平衡 高并发，低耗时：建议少线程，满足并发即可；这种情况下我们就应该考虑怎样减少上下文切换，因为大量的连接但是每个连接又只做很少的事情如果单独创建一个线程，就会在上下文切换中花费大量的时间；这也是IO多路复用使用的原因，很多连接只需要在一个线程里面处理即可 低并发，高耗时：建议多线程，保证有空闲的线程接受新的任务；如果这种情况下使用IO多路复用，会出现任务反应很慢的情况，因为多路复用必须要等到上一个任务完成才能执行下一个任务]]></content>
      <categories>
        <category>reading</category>
      </categories>
      <tags>
        <tag>Java并发编程艺术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于git开发规范]]></title>
    <url>%2F2018%2F12%2F14%2FGit%2F%E5%85%B3%E4%BA%8Egit%E5%BC%80%E5%8F%91%E6%B5%81%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[开发的整个流程应该规范化，不然每一个人都用自己的一套就会让项目显得杂乱无章，让项目的进行不顺利，也让项目后期举步维艰，因为我们无法去定位代码问题；也让项目的迭代很困难，因为其它接手的同学看着乱糟糟的代码就头痛 在这里我也想说说什么叫项目的迭代，就是在现有项目的基础上添加一些新的功能 Git分支规范第一种 有四类分支 master、dev_xxx、test_xxx、hotfix_xxx master: 主分支，主要用来发布版本，每一次提交到master 分支都需要打tag dev_xxx：开发分支，由迭代确定发布内容后创建开发分支，xxx指的是某个模块或者功能加上截止日期 test_xxx：迭代测试分支，由开发同学在自测通过后创建通过后创建该分支，然后由测试同学去测试上面的代码，有错误的话开发的同学在开发分支上进行修改bug，测试同学自行安排时间合并开发分支上的代码 hotfix_xxx：紧急修复分支，该分支主要是解决合并代码后，在sit环境、预付发布环境、线上发现bug时创建 第二种 master：主分支，主要用来发布版本，每一次提交到master 分支都需要打tag dev：日常开发分支，要保证上线都是最新的和正确的代码 feature：功能分支，具体的某个功能的分支，至于dev分支交互且该分支只是本地的分支，当该分支功能测试通过后再合并到dev分支 release：该分支是用来做测试用的，当某个功能开发完成后并且合并到dev分支，就将该功能的commit cherry pick 到release 分支上做测试，如果有bug则直接在该分支上修改，待测试全部通过后再合并到dev分支和master分支 hotfix：进行线上修复bug的分支 Commit 规范大致的格式如下： 1type(scope): description.. type类型如下： feat：提交新功能 fix：修补bug docs：提交文档 refactor：重构代码 test：添加测试 chore：构建过程或辅助工具的变动 需要注意的是 只有feat 和 fix 出现在change log之中，其它不要出现其中；即提交用feat和fix type的代码 用git merge，而其它用git rebase]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于垃圾收集器]]></title>
    <url>%2F2018%2F12%2F12%2FJVM%2F%E5%85%B3%E4%BA%8E%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%2F</url>
    <content type="text"><![CDATA[在讲JVM的垃圾收集器之前先讲解一下可达性分析算法GC Roots的实现 在安全点枚举根节点https://www.jianshu.com/p/0f1f5adffdc1) 根节点就是在虚拟机栈中的引用、方法区的中的静态对象引用、方法区中的常量引用、本地栈中的引用 所谓“GC roots”，或者说tracing GC的“根集合”，就是一组必须活跃的引用。 在安全点上在OopMap的数据结构上记录栈和寄存器上哪些位置是引用，这样就不用每次都去全局的检查哪些位置上有引用，这些位置上的引用也就会成为GCRoots 垃圾收集器总体上来说新生代的收集器 Serial收集器、ParNew收集器、Parallel Scavenge收集器 老年代收集器 Serial Old收集器、Parallel Old收集器、CMS收集器 通用 G1收集器 分别介绍 Serial收集器 特点：单线程执行、STW 使用场景：单cpu，新生代内存小，对暂停时间要求不高的应用 ParNew 收集器 特点：Serial收集器的多线程版本 使用场景：多cpu,对暂停时间较短的应用 Parallel Scavenge 收集器 特点：吞吐量可以控制，并行，不能搭配CMS使用 使用场景: 多cpu；可以控制短的STW时间(以吞吐量和新生代的空间为代价)提升用户交互体验；可以控制较高的吞吐量来提高CPU利用率，运行多后台运行少用户交互的任务 Serial Old收集器 特点：单线程、STW Parallel Old收集器 特点：Parallel Scanvage收集器的老年代版本，结合使用,实现吞吐量和CPU利用率的控制 CMS收集器 垃圾回收算法：标记清除算法 默认并发线程数：(CPU数量 + 3)/4 回收过程： 初始标记：标记GC Roots能关联到的对象，需停顿 并发标记：GC Roots Tracing 重新标记：修改并发标记期间因用户程序运行而导致标记产生的变动，需停顿 并发清除：清除不可达的对象 优点:STW时间短，给用户的良好的体验 缺点： 对CPU资源敏感，并发执行阶段占用不少于25%的资源，牺牲了吞吐量 并发清除阶段可能标记会变动，可能会产生浮动垃圾，所以需要预留老年代的空间给新生代的对象做担保，这会减小应用的吞吐量；如果空间不够了会使用Serail Old收集器进行老年代的收集 标记清除算法引起空间碎片 G1收集器 特点： 并发与并发 分代收集 空间整合 可预测的停顿 堆内存结构：在G1算法中，采用了另外一种完全不同的方式组织堆内存，堆内存被划分为多个大小相等的内存块（Region），每个Region是逻辑连续的一段内存，结构如下 从这张图我们可以了解到G1收集器依然保留了新生代和老年代，采用的算法和晋升机制也和其它收集器一样；这里新添加了一个Humongous 空间，这表示这些Region存储的是巨型对象（humongous object，H-obj），当新建对象大小超过Region大小一半时，直接在新的一个或多个连续Region中分配，并标记为H。 Region： 堆内存中一个Region的大小可以通过-XX:G1HeapRegionSize参数指定，大小区间只能是1M、2M、4M、8M、16M和32M，总之是2的幂次方，如果G1HeapRegionSize为默认值，则在堆初始化时计算Region的实践大小，默认Region数量为2048个，具体实现如下： GC模式： young GC： 和前面的收集器的minor GC差不多，这里就不多说了 mixed GC： 收集对象：新生代和部分老年代(根据执行计划确定 ) 初始标记：标记一下GC Roots能直接关联的对象，需停顿 并发标记：可达性分析，标记存活对象 最终标记：修改并发标记期间变化的对象，变化从Remembered Set Log中获取，停顿但可并行 筛选回收：首先对各个Region的回收价值和成本进行排序，根据用户期望的GC停顿时间来指定回收计划，需停顿但可并行，建议停顿 full GC：如果对象内存分配速度过快，mixed gc来不及回收，导致老年代被填满，就会触发一次full gc，G1的full gc算法就是单线程执行的serial old gc，会导致异常长时间的暂停时间，需要进行不断的调优，尽可能的避免full gc Remember Set:其实这个就是GC Roots的扩充，虚拟机的实现中，为了能够单独回收每一个Region，每一个Region都拥有一个Remember Set；在GC 一个Region的时候只需要将该Region的Remember Set添加到GC Roots的范围中，就能够清除不可达对象 G1 收集器的优点： 其实我这里的优点都是相对于CMS来说的，它本来就是为了替代CMS而生的 不会占用用户程序太多的资源，因为是根据指定的停顿时间来定制部分收集计划 因为筛选回收阶段是STW，所以不会产生浮动垃圾，也就不需要为此预留空间，增加了应用的吞吐量 使用标记整理算法，所以不会产生碎片空间 ZGC 特点： 并行，并不是完全没有STW，标记GC Roots仍然需要 STW 在ZGC 官网上有介绍，前面基准测试中的32核服务器，128G堆的场景下，它的配置是： 20条ParallelGCThreads，在那三个极短的STW阶段并行的干活 － mark roots， weak root processing（StringTable, JNI Weak Handles,etc）和 relocate roots ； 4条ConcGCThreads，在其他阶段与应用并发地干活 － Mark，Process Reference，Relocate。 仅仅四条，高风亮节地尽量不与应用争抢CPU 。 ConcCGCThreads开始时各自忙着自己平均分配下来的Region，如果有线程先忙完了，会尝试“偷”其他线程还没做的Region来干活，非常勤奋。 想G1一样分Region，但是没有每个Region都有Remember set，且256k以下的对象分配在Small Page， 4M以下对象在Medium Page，以上在Large Page。 所以ZGC能更好的处理大对象的分配；所以每次都是对整个堆进行回收 垃圾回收过程 初始停顿标记:停顿JVM地标记Root对象，1，2，4三个被标为live。 并发标记:并发地递归标记其他对象，5和8也被标记为live。 移动对象:活的对象都移走之后，这个region可以立即释放掉，并且用来当作下一个要扫描的region的to region。所以理论上要收集整个堆，只需要有一个空region就OK了。 修正指针：最后将指针都妥帖地更新指向新地址。这里R大还提到一个亮点： “上一个阶段的Remap，和下一个阶段的Mark是混搭在一起完成的，这样非常高效，省却了重复遍历对象图的开销。 为什么GC 分代GC分代本来是基于这样一个事实，大量的对象都是朝生夕死；基于这样的事实，则大部分垃圾对象都能在young GC中被收集掉，由于young gen的大小配置通常只占整个GC堆的较小部分，而且较高的对象死亡率（或者说较低的对象存活率）让它非常适合使用copying算法来收集，这样就不但能降低单次GC的时间长度，还可以提高GC的工作效率。 在并发的收集器中，使用分代的原因是GC能够应付的应用内存分配速率（allocation rate）可以得到巨大的提升。并发GC根本上要跟应用玩追赶游戏：应用一边在分配，GC一边在收集，如果GC收集的速度能跟得上应用分配的速度，那就一切都很完美；一旦GC开始跟不上了，垃圾就会渐渐堆积起来，最终到可用空间彻底耗尽的时候，应用的分配请求就只能暂时等一等了，等GC追赶上来。 参考学长的JVM介绍博客 R大介绍的增量式GC G1收集器的介绍 R大对ZGC的讲解 R大讲为什么GC需要分代 R大讲GC模式 ​]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>JVM垃圾收集器</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>%2F2018%2F11%2F29%2FReading%2Fnetty%E5%AE%9E%E6%88%98%2F</url>
    <content type="text"><![CDATA[BootStrap是怎么把EventloopGroup 、Eventloop、Channel、ChannelHandlerContext、ChannelPipeline结合起来的 我们从Bootstrap的connect方法进去 123456789public ChannelFuture connect(SocketAddress remoteAddress) &#123; if (remoteAddress == null) &#123; throw new NullPointerException("remoteAddress"); &#125; else &#123; //这里判断了在connect之前是否添加了Channelhandler this.validate(); return this.doResolveAndConnect(remoteAddress, this.config.localAddress()); &#125;&#125; 1234567891011121314151617181920212223private ChannelFuture doResolveAndConnect(final SocketAddress remoteAddress, final SocketAddress localAddress) &#123;// 这里的initAndRegister()方法很重要，所以下面是详细解释 ChannelFuture regFuture = this.initAndRegister(); final Channel channel = regFuture.channel(); if (regFuture.isDone()) &#123; return !regFuture.isSuccess() ? regFuture : this.doResolveAndConnect0(channel, remoteAddress, localAddress, channel.newPromise()); &#125; else &#123; final PendingRegistrationPromise promise = new PendingRegistrationPromise(channel); regFuture.addListener(new ChannelFutureListener() &#123; public void operationComplete(ChannelFuture future) throws Exception &#123; Throwable cause = future.cause(); if (cause != null) &#123; promise.setFailure(cause); &#125; else &#123; promise.registered(); Bootstrap.this.doResolveAndConnect0(channel, remoteAddress, localAddress, promise); &#125; &#125; &#125;); return promise; &#125;&#125; 1234567891011121314151617181920212223242526272829final ChannelFuture initAndRegister() &#123; Channel channel = null; try &#123; //这里是通过我们前面传给Bootstrp 的SocketChannel类型反射创建channel channel = this.channelFactory.newChannel(); // 这里对channel进行了初始化，这里也比较重要，下面也进行了详细解释 this.init(channel); &#125; catch (Throwable var3) &#123; if (channel != null) &#123; channel.unsafe().closeForcibly(); return (new DefaultChannelPromise(channel, GlobalEventExecutor.INSTANCE)).setFailure(var3); &#125; return (new DefaultChannelPromise(new FailedChannel(), GlobalEventExecutor.INSTANCE)).setFailure(var3); &#125; ChannelFuture regFuture = this.config().group().register(channel); if (regFuture.cause() != null) &#123; if (channel.isRegistered()) &#123; channel.close(); &#125; else &#123; channel.unsafe().closeForcibly(); &#125; &#125; return regFuture;&#125; 1234567891011121314151617181920// 这里使用的代码是Bootstrp的init方法void init(Channel channel) throws Exception &#123; ChannelPipeline p = channel.pipeline(); p.addLast(new ChannelHandler[]&#123;this.config.handler()&#125;); Map&lt;ChannelOption&lt;?&gt;, Object&gt; options = this.options0(); synchronized(options) &#123; setChannelOptions(channel, options, logger); &#125; Map&lt;AttributeKey&lt;?&gt;, Object&gt; attrs = this.attrs0(); synchronized(attrs) &#123; Iterator var6 = attrs.entrySet().iterator(); while(var6.hasNext()) &#123; Entry&lt;AttributeKey&lt;?&gt;, Object&gt; e = (Entry)var6.next(); channel.attr((AttributeKey)e.getKey()).set(e.getValue()); &#125; &#125; &#125;]]></content>
  </entry>
  <entry>
    <title><![CDATA[2018-11-24]]></title>
    <url>%2F2018%2F11%2F26%2Fgive_me_offer%2F2018-11-28%2F</url>
    <content type="text"><![CDATA[m阶B树的定义： 每个节点至多有m个子节点 如果根节点不是叶子节点，则其最少有两颗子树 所有叶子节点都位于同一层次 树中的结点和图中的顶点就是指数据结构中的数据元素 如果两个单链表相交，那他们的尾结点一定相同 快慢指针是判断一个单向链表有没有一个环的方法 有环的单向链表和无环的单向链表不可能相交 序列化中的readObject只是从文件中还原对象，clone方法只是一种赋值拷贝对象，都不会调用构造函数 分页存储管理中存储保护通过页表来完成，因为页表中有一个访问的标志位 对换技术的主要作用是提高内存利用率 为了允许不同用户的文件使用相同的文件名，通常用多级目录的方法 多道程序的特点：多道，宏观上并行，微观上串行 优点：cpu利用率高，设备利用率高，系统吞吐率高 多道程序设计中并没有增加系统的运行速度，只是让CPU利用率得到了提升 从系统观点看，操作系统是计算机资源管理者 从用户观点看，操作系统是控制和管理计算机资源的软件 从软件观点看，操作系统是程序和数据结构的集合 对于DFS和BFS来说，时间复杂度和存储结构有关： 若采用邻接矩阵存储，时间复杂度为O(n*e) 若采用邻接表存储，时间复杂度为O(n+e) 有N个顶点的完全图，有N(N-1)/2条边 只有一个结点的二叉树的度为0，二叉树最大的度为2 UNIX是多道批处理系统 在请求分页存储管理中，页面长度固定并且是硬件设计特性 应用层协议：HTTP、FTP、TFTP、TELNET、DNS、EMAIL、SNMP DNS、TFTP、SNMP建立在UDP之上 VPN属于数据链路层协议 计数排序算法 基数分类]]></content>
  </entry>
  <entry>
    <title><![CDATA[2018-11-24]]></title>
    <url>%2F2018%2F11%2F24%2Fgive_me_offer%2F2018-11-24%2F</url>
    <content type="text"><![CDATA[求最小生成树的普里姆算法中边上的权可正可负 循环队列一般有两种形式，一种是对首前一位或者队尾后一位不存储元素，仅用来方便判断队列是空还是满另一种是队首队尾指向的位置存储元素，充分利用空间 对于第一种情况：元素个数为：(rear -front+maxsize)%maxsize 对于第二种情况：元素个数为：(rear-front+1+maxsize)%maxsize StringBuffer是线程安全的，StringBuilder不是线程安全的 可以用卡特兰数来得到入栈序列的最大出栈序列数 次优查找树可以表示静态查找表 高度为h的满二叉树对应的森林由h棵树构成 带头结点的链栈指的是头结点不存储数据 最坏情况下，合并两个大小为n的已排序数组所需要的比较次数是2n-1 事务属性种类:传播行为，隔离级别，只读，事务超时 传播行为： PROPAGATION_REQUIRED–支持当前事务，如果当前没有事务，就新建一个事务。这是最常见的选择。PROPAGATION_SUPPORTS–支持当前事务，如果当前没有事务，就以非事务方式执行。PROPAGATION_MANDATORY–支持当前事务，如果当前没有事务，就抛出异常。PROPAGATION_REQUIRES_NEW–新建事务，如果当前存在事务，把当前事务挂起。PROPAGATION_NOT_SUPPORTED–以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。 PROPAGATION_NEVER–以非事务方式执行，如果当前存在事务，则抛出异常 隔离级别 未提交读、比较读、可重复读、可序列化 String s = new String(“xyz”); 创建了两个object 一个在堆，一个在常量池 页式虚拟存储系统形成内部碎片，段氏虚拟存储系统产生外部碎片，段页式虚拟存储系统不会产生内部碎片也不会产生外部碎片 分页式存储管理中，地址转换工作是由MMU完成的，MMU内存管理单元 UNIX系统中文件存储空间的管理常用空闲块成组链接法 在2n个结点的完全二叉树中，叶子结点数为n 细同轴电缆的传输距离理论上最大为185米 IPX地址网络地址有10个字节]]></content>
  </entry>
  <entry>
    <title><![CDATA[2018-11-21]]></title>
    <url>%2F2018%2F11%2F21%2Fgive_me_offer%2F2018-11-21%2F</url>
    <content type="text"><![CDATA[在有N个结点的二叉链表中，必其余定有2N个链域，除根结点外其余N-1个结点都有一个父节点，所以一共有N-1个非空链域，(2N - (N-1))即 N+1个空链域 线性表中，顺序表物理相邻逻辑相邻，链表逻辑相邻物理不相邻 常见的批处理作业调度算法 先来先服务 短作业优先 最高响应比优先调度 基于优先数调度算法 均衡调度算法即多级队列调度算法 进程调度算法 先来先服务 时间片轮转 最高优先级算法 多级队列反馈法 空闲分区分配算法 首先适应算法 最佳适应算法 最坏适应算法 虚拟页式存储管理中页面置换算法 想页面置换算法 先进先出页面置换算法 最近最久未使用算法 最少使用 磁盘调度 先来先服务 最短寻道时间优先 扫面算法即电梯算法 循环扫描算法 广播地址为 网络号 + 全1 常用的以太网卡工作模式: 广播模式:将会接收所有目的地址为广播地址(0XFFFFFF)的数据包,一般所有的网卡都会设置这个模式，这个也是ARP工作的原理 多播传送：多播传送地址作为目的物理地址的帧可以被组内的其它主机混杂模式:网卡接收所有的流过网卡的帧，信保捕获程序就是在这种模式下运行的 粗缆是指粗铜缆电缆，其最大传输距离是500米，如果结点之间的距离超过500米，那么要用一个中继器设备来扩大局域网覆盖范围 在一个有8个int数据的数组中，随机给出数组的数据，找出最大和次大元素一共需要进行9此比较 筛选法建堆从二叉树的最后一个非叶子节点开始用从上到下过滤方法调整以该非叶结点为根节点的二叉树为最大堆。 堆从任一结点出发到跟的路径上所经过的结点序列按其关键字有序 建立符号链接时，引用计数直接复制；建立硬链接时，引用计数值加1 管道是用于连接一个读进程和一个写进程以实现进程之间通信的一种共享文件，数据格式是字符流]]></content>
      <categories>
        <category>offer</category>
      </categories>
      <tags>
        <tag>offer 啊 offer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于二叉树的所有操作的总结]]></title>
    <url>%2F2018%2F11%2F20%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%2F%E5%85%B3%E4%BA%8E%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E6%89%80%E6%9C%89%E6%93%8D%E4%BD%9C%E7%9A%84%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[二叉树的建立递归非递归左右子树的交换递归1234567public void static exchangeLeftRight(TreeNode root)&#123; if(root == null) return; if(root.left == null &amp;&amp; root.right == null) return; swap(root.left, root.right); exchangeLeftRight(root.left); exchangeLeftTight(root.right);&#125; 非递归123public void static exchangeLeftRight(TreeNode root)&#123; &#125; 二叉树的深度递归非递归二叉树的层次遍历递归非递归12345678910111213141516public List&lt;List&lt;Integer&gt;&gt; levelOrder(TreeNode root) &#123; List&lt;List&lt;Integer&gt;&gt; lists = new LinkedList&lt;&gt;(); Queue&lt;TreeNode&gt; treeNodes = new LinkedList&lt;&gt;(); treeNodes.add(root); while (!treeNodes.isEmpty()) &#123; List&lt;Integer&gt; integers = new LinkedList&lt;&gt;(); while (!treeNodes.isEmpty())&#123; TreeNode node = treeNodes.poll(); integers.add(node.val); if (node.left != null) treeNodes.add(node.left); if (node.right != null) treeNodes.add(node.right); &#125; lists.add(integers); &#125; return lists;&#125; 线索二叉树的遍历对称二叉树递归123456public boolean symmetric(TreeNode node1, TreeNode node2) &#123; if (node1 == null &amp;&amp; node2 == null) return true; if (node1 == null || node2 == null) return false; return (node1.val == node2.val) &amp;&amp; symmetric(node1.left, node2.right) &amp;&amp; symmetric(node1.right, node2.left); &#125; 非递归1234567891011121314151617181920public boolean isSymmetric2(TreeNode root)&#123; if (root == null) return true; Stack&lt;TreeNode&gt; stack = new Stack&lt;&gt;(); stack.push(root.left); stack.push(root.right); while (!stack.isEmpty())&#123; TreeNode node1 = stack.pop(); TreeNode node2 = stack.pop(); if (node1 == null &amp;&amp; node2 == null) continue; if (node1 == null || node2 == null) return false; if (node1.val != node2.val) return false; stack.push(node1.left); stack.push(node2.right); stack.push(node1.right); stack.push(node2.left); &#125; return true;&#125;]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>二叉树</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2018-11-20]]></title>
    <url>%2F2018%2F11%2F20%2Fgive_me_offer%2F2018-11-19%2F</url>
    <content type="text"><![CDATA[Cpi:表示每条计算机指令执行所需要的时间 并行传输：是在传输中有多个数据位同时在设备之间进行的传输。 串行传输：是指使用一条数据线，将数据一位一位地依次传输，每一位数据占据一个固定的时间长度。 同步传输：是指传输过程有统一的时钟控制 突发传输：在一个总线周期中，可以传输多个存储地址连续的数据 线索二叉树：https://www.jianshu.com/p/deb1d2f2549a 方法是对象的成员而非的类的成员]]></content>
      <categories>
        <category>offer</category>
      </categories>
      <tags>
        <tag>offer 啊 offer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2018-11-20]]></title>
    <url>%2F2018%2F11%2F20%2Fgive_me_offer%2F2018-11-20%2F</url>
    <content type="text"><![CDATA[稀疏矩阵存储方式：三元组，十字链表 特殊矩阵：下三角矩阵，上三角矩阵，对称矩阵 SMTP是发送邮件的协议，POP用于支持使用客户端远程管理在服务器上的电子邮件，IMAP用来从本地邮件客户端访问远程服务器上的邮件。]]></content>
  </entry>
  <entry>
    <title><![CDATA[2018/11/18]]></title>
    <url>%2F2018%2F11%2F18%2Fgive_me_offer%2F2018-11-18%2F</url>
    <content type="text"><![CDATA[servlet 本身是线程不安全的，因为servlet一般来说是无状态的，所以保证了它的线程安全 DBMS 中事务有四个特性：A(Atomic)原子性、C(consistency)一致性、I(isolation)隔离性、D(Durability)持久性；持久性实现回复管理子系统，一致性实现并发控制子系统，完整性实现完整性管理子系统，隔离性实现安全控制管理子系统 1234567891011121314151617181920public class Test &#123; private static int j = 0; private static Boolean methodB(int k) &#123; j += k; return true; &#125; public static void methodA(int i) &#123; boolean b; b = i &lt; 10 | methodB(4); b = i &lt; 10 || methodB(8); &#125; public static void main(String args[]) &#123; methodA(0); System.out.println(j); &#125;&#125; 答案是 4； || 运算符，如果第一项满足为真，那么不进行第二项运算 关于排序的稳定性：通俗地讲就是能保证排序前2个相等的数其在序列的前后位置顺序和排序后它们两个的前后位置顺序相同。 空栈时 top=-1 广义表表头是元素，表尾一定是广义表 常用的线性结构是：线性表，堆栈，队列，双队列，数组，串 非线性结构是：二位数组，多维数组，广义表，树，图 管态称为特权态，特权态或核心态 拒绝服务，英文名称是Denial of Service ，又称dos攻击，即是攻击者想办法让目标机器停止提供服务，是黑客常用的攻击手段之一 。 传输二进制数字信号需要的带宽比模拟信号的小 当发送数据时，主机A会在自己的ARP缓存表中寻找是否有目标IP地址： ​ ①如果找到了，也就知道了目标MAC地址，直接把目标MAC地址写入帧里面发送就可以了； ​ ②如果在ARP缓存表中没有找到相对应的IP地址，主机A就会在网络上发送一个广播，目标MAC地址是“FF.FF.FF.FF.FF.FF”，这表示向同一网段内的所有主机发出这样的询问：“192.168.30.2的MAC地址是什么？”网络上其他主机并不响应ARP询问，只有主机B接收到这个帧时，才向主机A做出这样的回应：“192.168.30.2的MAC地址是34-12-65-ae-c9-0a”。 Unix的文件系统是索引文件结构，MS-DOS的则是显式链接文件结构 一个首次装入内存的页面不可能来自磁盘对换区，因为磁盘对换区的只会存在被对换出来的页面]]></content>
      <categories>
        <category>offer 啊 offer</category>
      </categories>
      <tags>
        <tag>练习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于类加载器]]></title>
    <url>%2F2018%2F11%2F04%2FJava%20%E5%9F%BA%E7%A1%80%2F%E5%85%B3%E4%BA%8E%E7%B1%BB%E5%8A%A0%E8%BD%BD%E5%99%A8%2F</url>
    <content type="text"><![CDATA[因为最近了解了一些关于热加载的东西，而这个技术就是基于类加载器，所以就想来总结一下类加载器的知识点 概述类加载器，在《深入理解java虚拟机》中，关于为什么使用它有过解释，目的是想把字节码文件的来源解耦；我们一般的字节码文件的来源都是classpath，但是我们如果想直接从网络中获取呢，所以这个时候就需要自定义类加载器定义类的获取机制 类加载层次结构1. 启动类加载器 加载JVM自身需要的类，由C++实现，是虚拟机自身的一部分 这个类加载器负责将存放在&lt;JAVA_HOME&gt;\lib目录下的或者被-Xbootclasspath 参数所指定的路径中的，并且是虚拟机识别的，加载到虚拟机内存中 2. 扩展类加载器 负责加载&lt;JAVA_HOME&gt;/lib/ext目录下或者由系统变量-Djava.ext.dir指定位路径中的类库 3. 应用程序类加载器 它负责加载系统类路径java -classpath或-D java.class.path 指定路径下的类库，也就是我们经常用到的classpath路径，开发者可以直接使用系统类加载器，一般情况下该类加载是程序中默认的类加载器，通过ClassLoader#getSystemClassLoader()方法可以获取到该类加载器。 双亲委派模型工作过程 如果一个类加载器收到了类加载对的请求，它首先不会自己去尝试加载这个类，而是把这个请求委派给父类加载器去完成，每一个层次的类加载器都是如此，因为所有的类加载请求最终都会传送到顶层类加载器，只有当父类加载器反馈不能加载时，子加载器才会尝试自己去加载 优势 JAVA类与类加载器都有了优先级关系，避免了类的重复加载，父类加载器加载了该类，那么子类加载器就不必要去加载此类了 安全，java api 本身的提供的类不会被随意替换 线程上下文类加载器这是一个破坏双亲委派模型的实现 它产生的原因是在JAVA应用中存在着很多服务提供接口，这些接口允许第三方为他们提供实现；这些接口一般在rt.java中即由启动类加载器加载，而第三方实现代码则是作为Java应用所依赖的 jar 包被存放在classpath路径下， 由于SPI接口中的代码经常需要加载具体的第三方实现类并调用其相关方法 但SPI的核心接口类 是由引导类加载器来加载的；但是如果遵守双亲委派模型是不能得到实现类的，在这种情况下，我们就需要一种特殊的类加载器来加载第三方的类库，而线程上下文类加载器就是很好的选择。 线程上下文类加载器（contextClassLoader）是从 JDK 1.2 开始引入的，我们可以通过java.lang.Thread类中的getContextClassLoader()和 setContextClassLoader(ClassLoader cl)方法来获取和设置线程的上下文类加载器。如果没有手动设置上下文类加载器，线程将继承其父线程的上下文类加载器，初始线程的上下文类加载器是系统类加载器（AppClassLoader）,在线程中运行的代码可以通过此类加载器来加载类和资源，如下图所示，以jdbc.jar加载为例 热部署类加载器热部署就是利用同一个class文件不同的类加载在内存中创造两个不同的class对象 由于类加载器在加载之前会检测请求的类是否被加载过了，如果加载过了那么则直接从内存获取；如果我们使用不同的类加载器，那么就可以实现同一个文件加载一个class文件两次 Tomcat类加载机制 上面就是Tomcat类加载模型 下面分别分析 前面三个类就是正常的JVM类加载器 Common：以应用类加载器为父类，是tomcat顶层的公用类加载器，其路径由conf/catalina.properties中的common.loader指定，默认指向${catalina.home}/lib下的包。 Catalina：以Common类加载器为父类，是用于加载Tomcat应用服务器的类加载器，其路径由server.loader指定，默认为空，此时tomcat使用Common类加载器加载应用服务器。 Shared：以Common类加载器为父类，是所有Web应用的父类加载器，其路径由shared.loader指定，默认为空，此时tomcat使用Common类加载器作为Web应用的父加载器 在Bootstrap的init方法 我们知道上面三个类加载器默认是使用的同一个类加载器 1234567this.commonLoader = this.createClassLoader("common", (ClassLoader)null); if (this.commonLoader == null) &#123; this.commonLoader = this.getClass().getClassLoader(); &#125; this.catalinaLoader = this.createClassLoader("server", this.commonLoader); this.sharedLoader = this.createClassLoader("shared", this.commonLoader); Web应用类加载器默认的加载顺序是： 先从缓存中加载 如果没有，则从JVM的Bootstrap类加载器加载； 如果没有，则从当前类加载器加载（按照WEB-INF/classes、WEB-INF/lib的顺序）； 如果没有，则从父类加载器加载，由于父类加载器采用默认的委派模式，所以加载顺序是AppClassLoader、Common、Shared。 从上面的加载顺序也可以知道没有完全遵守双亲委派模型 WebApp类加载器加载类 12345678910111213141516171819202122public void start() throws LifecycleException &#123; this.state = LifecycleState.STARTING_PREP; // 加载所有web应用的class文件 WebResource classes = this.resources.getResource("/WEB-INF/classes"); if (classes.isDirectory() &amp;&amp; classes.canRead()) &#123; this.localRepositories.add(classes.getURL()); &#125; // 加载web应用lib目录下jar文件 WebResource[] jars = this.resources.listResources("/WEB-INF/lib"); WebResource[] arr$ = jars; int len$ = jars.length; for(int i$ = 0; i$ &lt; len$; ++i$) &#123; WebResource jar = arr$[i$]; if (jar.getName().endsWith(".jar") &amp;&amp; jar.isFile() &amp;&amp; jar.canRead()) &#123; this.localRepositories.add(jar.getURL()); this.jarModificationTimes.put(jar.getName(), jar.getLastModified()); &#125; &#125; this.state = LifecycleState.STARTED; &#125; 上面是来自WebappClassLoaderBase(WebAppClassLoader父类)类的方法，实现了web应用的class文件的加载 从上面也可以了解到 Tomcat应用的类加载与 JVM的类加载是不同的，JVM中类加载是代码执行过程中有没有加载的类才出发类加载；Tomcat应用的类加载是首先把所有的类都先加载到内存，根据以上方法可以知道 所有类都加载到了resources中了；然后findclass时候也在这里面去找最后通过找到的构造实例 自定义类加载器总的来说 就是继承ClassLoader类，重写findClass方法 下面是我自己的一个例子 123456789101112131415161718192021public class MayClassLoader extends ClassLoader &#123; @Override protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException &#123; String fileName = name + ".class"; InputStream is = getClass().getResourceAsStream(fileName); if (is == null)&#123; return super.findClass(name); &#125; try &#123; byte[] b; b = new byte[is.available()]; is.read(b); return defineClass(name, b, 0, b.length); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; return super.findClass(name); &#125;&#125;]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>类加载器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[阻塞队列详解]]></title>
    <url>%2F2018%2F10%2F30%2FJava%20%E5%B9%B6%E5%8F%91%2F%E9%98%BB%E5%A1%9E%E9%98%9F%E5%88%97%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[阻塞队列详解BlockingQueue add() 这个方法是向阻塞队列中添加一个元素，添加元素时如果队列满了不会等待，会直接抛出异常，添加成功就会返回true offer() 这个方法时向阻塞队列中添加一个元素，添加元素时如果队列满了不会等待，但是不会抛异常，而是返回false，添加成功返回true put() 这个方法是向阻塞队列中添加一个元素，添加元素时如果队列满了会进行阻塞等待，所以不会返回什么 offer(e, timeout, unit) 添加元素时，会进行timeout的时间等待，其它就跟offer()方法一样了 take() 这个跟put方法对应，进行阻塞的取元素 poll(timeout, unit) 等待timeout的时间取元素，如果超时就返回null SynchronizeQueue该队列大概的结构如下 TransferStack这是非公平的，想对于公平来说，这个实现的区别是每次添加元素时，公平的实现是如果不能够匹配直接将结点加入到最后，但是非公平的方式是帮助前一个正在传递数据的两个节点完成交易，然后放在栈首；它主要想要达到的是线程局部性，以此来提高性能 SNode 一些属性 12345678910//连接下一个结点volatile SNode next; // next node in stack//如果有与当前节点匹配的节点，就把该节点赋值给这个属性volatile SNode match; // the node matched to this//该节点控制的线程volatile Thread waiter; // to control park/unpark//该节点拥有的数据Object item; // data; or null for REQUESTs//该节点的模式，有三种模式 REQUEST、DATA、FULFILLINGint mode; 一些栈元素的操作 需要注意的是timed，nanos参数，这两个参数是用来是永久等待还是等待一段时间,其实其中的offer、put方法已经很典型了；offer方法不等待，直接检查容器里面有没有匹配的结点，如果没有直接返回false；而put方法如果没有匹配的结点会把自己加入结点中，然后一直等待匹配结点的出现 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980E transfer(E e, boolean timed, long nanos) &#123; /* * Basic algorithm is to loop trying one of three actions: * * 1. If apparently empty or already containing nodes of same * mode, try to push node on stack and wait for a match, * returning it, or null if cancelled. * * 2. If apparently containing node of complementary mode, * try to push a fulfilling node on to stack, match * with corresponding waiting node, pop both from * stack, and return matched item. The matching or * unlinking might not actually be necessary because of * other threads performing action 3: * * 3. If top of stack already holds another fulfilling node, * help it out by doing its match and/or pop * operations, and then continue. The code for helping * is essentially the same as for fulfilling, except * that it doesn't return the item. */ SNode s = null; // constructed/reused as needed int mode = (e == null) ? REQUEST : DATA; for (;;) &#123; SNode h = head; // 如果头结点为空或者模式相等，消费者直接返回null，生产者那么保存到栈中等待匹配 if (h == null || h.mode == mode) &#123; // empty or same-mode if (timed &amp;&amp; nanos &lt;= 0) &#123; // can't wait if (h != null &amp;&amp; h.isCancelled()) casHead(h, h.next); // pop cancelled node else return null; &#125; else if (casHead(h, s = snode(s, e, h, mode))) &#123; SNode m = awaitFulfill(s, timed, nanos); if (m == s) &#123; // wait was cancelled clean(s); return null; &#125; if ((h = head) != null &amp;&amp; h.next == s) casHead(h, s.next); // help s's fulfiller return (E) ((mode == REQUEST) ? m.item : s.item); &#125; // 匹配成功了 且 头结点没有正在执行则将当前请求作为结点加入栈 // 匹配两个结点 释放两个结点的线程锁 &#125; else if (!isFulfilling(h.mode)) &#123; // try to fulfill if (h.isCancelled()) // already cancelled casHead(h, h.next); // pop and retry else if (casHead(h, s=snode(s, e, h, FULFILLING|mode))) &#123; for (;;) &#123; // loop until matched or waiters disappear SNode m = s.next; // m is s's match if (m == null) &#123; // all waiters are gone casHead(s, null); // pop fulfill node s = null; // use new node next time break; // restart main loop &#125; SNode mn = m.next; if (m.tryMatch(s)) &#123; casHead(s, mn); // pop both s and m return (E) ((mode == REQUEST) ? m.item : s.item); &#125; else // lost match s.casNext(m, mn); // help unlink &#125; &#125; // 头结点是正在执行的状态，帮助完成栈中前两个结点的匹配和弹出 &#125; else &#123; // help a fulfiller SNode m = h.next; // m is h's match if (m == null) // waiter is gone casHead(h, null); // pop fulfilling node else &#123; SNode mn = m.next; if (m.tryMatch(h)) // help match casHead(h, mn); // pop both h and m else // lost match h.casNext(m, mn); // help unlink &#125; &#125; &#125; &#125; 这个就是实现的算法： 当栈为空或者栈中的首元素的模式与匹配的结点的模式相同，那么就会把结点推入栈等待匹配，这里的等待需要注意的是会调用awaitFulfill，这个方法不会直接将线程阻塞进行等待，而是先进行自旋，自旋后没能够够成功匹配才进行阻塞等待； 如果当前栈顶的结点与请求交易的结点互补，那么将这个请求交易的节点的模式变为FULFILLING，然后将其压入栈中，和互补的节点进行匹配，完成交易之后将两个节点一起弹出，并且返回交易的数据。 如果栈顶已经存在一个模式为FULFILLING的节点，说明栈顶的节点正在进行匹配，那么就帮助这个栈顶节点快速完成交易，然后继续交易。我想要说一下这里的帮助，其实就是把正在进行数据传递的两个节点从栈中移除。 123456789101112boolean tryMatch(SNode s) &#123; if (match == null &amp;&amp; UNSAFE.compareAndSwapObject(this, matchOffset, null, s)) &#123; Thread w = waiter; if (w != null) &#123; // waiters need at most one unpark waiter = null; LockSupport.unpark(w); &#125; return true; &#125; return match == s;&#125; 这个方法是在进入栈中的时候尝试去匹配互补模式的节点，匹配成功就会使栈中节点拥有的线程唤醒 TransferQueue123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384E transfer(E e, boolean timed, long nanos) &#123; /* Basic algorithm is to loop trying to take either of * two actions: * * 1. If queue apparently empty or holding same-mode nodes, * try to add node to queue of waiters, wait to be * fulfilled (or cancelled) and return matching item. * * 2. If queue apparently contains waiting items, and this * call is of complementary mode, try to fulfill by CAS'ing * item field of waiting node and dequeuing it, and then * returning matching item. * * In each case, along the way, check for and try to help * advance head and tail on behalf of other stalled/slow * threads. * * The loop starts off with a null check guarding against * seeing uninitialized head or tail values. This never * happens in current SynchronousQueue, but could if * callers held non-volatile/final ref to the * transferer. The check is here anyway because it places * null checks at top of loop, which is usually faster * than having them implicitly interspersed. */ QNode s = null; // constructed/reused as needed boolean isData = (e != null); for (;;) &#123; QNode t = tail; QNode h = head; if (t == null || h == null) // saw uninitialized value continue; // spin if (h == t || t.isData == isData) &#123; // empty or same-mode QNode tn = t.next; if (t != tail) // inconsistent read continue; if (tn != null) &#123; // lagging tail advanceTail(t, tn); continue; &#125; if (timed &amp;&amp; nanos &lt;= 0) // can't wait return null; if (s == null) s = new QNode(e, isData); if (!t.casNext(null, s)) // failed to link in continue; advanceTail(t, s); // swing tail and wait Object x = awaitFulfill(s, e, timed, nanos); if (x == s) &#123; // wait was cancelled clean(t, s); return null; &#125; if (!s.isOffList()) &#123; // not already unlinked advanceHead(t, s); // unlink if head if (x != null) // and forget fields s.item = s; s.waiter = null; &#125; return (x != null) ? (E)x : e; &#125; else &#123; // complementary-mode QNode m = h.next; // node to fulfill if (t != tail || m == null || h != head) continue; // inconsistent read Object x = m.item; if (isData == (x != null) || // m already fulfilled x == m || // m cancelled !m.casItem(x, e)) &#123; // lost CAS advanceHead(h, m); // dequeue and retry continue; &#125; advanceHead(h, m); // successfully fulfilled LockSupport.unpark(m.waiter); return (x != null) ? (E)x : e; &#125; &#125; &#125; 算法设计思路： 如果队列为空，或者请求交易的节点和队列中的节点具有相同的交易类型，那么就将该请求交易的节点添加到队列尾部等待交易，直到被匹配或者被取消 如果队列中包含了等待的节点，并且请求的节点和等待的节点是互补的，那么进行匹配并且进行交易 关于awaitfulfill方法12345678910111213141516171819202122232425262728293031SNode awaitFulfill(SNode s, boolean timed, long nanos) &#123;final long deadline = timed ? System.nanoTime() + nanos : 0L; Thread w = Thread.currentThread(); int spins = (shouldSpin(s) ? (timed ? maxTimedSpins : maxUntimedSpins) : 0); for (;;) &#123; if (w.isInterrupted()) s.tryCancel(); SNode m = s.match; if (m != null) return m; //实现过期机制 if (timed) &#123; nanos = deadline - System.nanoTime(); if (nanos &lt;= 0L) &#123; s.tryCancel(); continue; &#125; &#125; //实现自旋等待 if (spins &gt; 0) spins = shouldSpin(s) ? (spins-1) : 0; else if (s.waiter == null) s.waiter = w; // establish waiter so can park next iter //这里就是线程会不会过期，不会过期直接阻塞；会过期就调用parkNanos然后重新执行循环，就会重新检查nanos，这个时候nanos会&lt;=0就会cancel这个结点 else if (!timed) LockSupport.park(this); else if (nanos &gt; spinForTimeoutThreshold) LockSupport.parkNanos(this, nanos); &#125; &#125; spins = shouldSpin(s) ? (spins-1) : 0; 这里实现了自旋等待；timed和nanos是给结点设置过期时间，time out了就会s.tryCancel();如果在自旋的时间内没有找到匹配的结点，那么进行阻塞等待，然后等到有匹配的线程到来，通过SNode的waiter属性占到当前线程进行唤醒；这里需要知道有了过期时间就不会有线程阻塞。 关于公平和非公平的区别12345* The (Lifo) stack is used for non-fair mode, and the (Fifo) * queue for fair mode. The performance of the two is generally * similar. Fifo usually supports higher throughput under * contention but Lifo maintains higher thread locality in common * applications. （Lifo）堆栈用于非公平模式，而（Fifo）队列用于公平模式。 两者的表现大致相似。 Fifo通常支持更高的吞吐量，但Lifo在常见应用程序中维护更高的线程局部性。 流程图展示整个大概的流程 ArrayBlockingQueue这个容器没有什么好讲的，我们看一下它的变量就差不多知道它的实现方式 12345678final Object[] items;int takeIndex;int putIndex;int count;final ReentrantLock lock;private final Condition notEmpty;private final Condition notFull;transient Itrs itrs = null; 1234567891011121314151617181920//这里需要讲的是，这里也设置了一个过期时间，这里的实现方式是当一个元素添加到容器里面时，如果容器满了，就等待一段时间，如果等待一段时间后，还是不可以添加，就添加失败 public boolean offer(E e, long timeout, TimeUnit unit) throws InterruptedException &#123; checkNotNull(e); long nanos = unit.toNanos(timeout); final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try &#123; while (count == items.length) &#123; if (nanos &lt;= 0) return false; nanos = notFull.awaitNanos(nanos); &#125; enqueue(e); return true; &#125; finally &#123; lock.unlock(); &#125; &#125; LinkedBlockingQueue数据结构单向链表 变量 12345678private final int capacity;private final AtomicInteger count = new AtomicInteger();transient Node&lt;E&gt; head;private transient Node&lt;E&gt; last; private final ReentrantLock takeLock = new ReentrantLock(); private final Condition notEmpty = takeLock.newCondition();private final ReentrantLock putLock = new ReentrantLock();private final Condition notFull = putLock.newCondition(); 1234567891011private E dequeue() &#123; // assert takeLock.isHeldByCurrentThread(); // assert head.item == null; Node&lt;E&gt; h = head; Node&lt;E&gt; first = h.next; h.next = h; // help GC head = first; E x = first.item; first.item = null; return x;&#125; 关于Help GC这里的原因在《深入理解 JAVA 虚拟机》局部变量表那里讲过，在一个 这个方法需要注意的是，h.next = h;这里是通过自己的属性指向自己形成一个环， GC就会认为它是无用的 BlockingQueue 唤醒机制12345678910111213141516171819private void signalNotEmpty() &#123; final ReentrantLock takeLock = this.takeLock; takeLock.lock(); try &#123; notEmpty.signal(); &#125; finally &#123; takeLock.unlock(); &#125; &#125; private void signalNotFull() &#123; final ReentrantLock putLock = this.putLock; putLock.lock(); try &#123; notFull.signal(); &#125; finally &#123; putLock.unlock(); &#125; &#125; 从上面我们可以看出 在使用ReentrantLock的conditionObject 的时候也要遵循 先获取锁再进行 notify notifyAll await操作 BlockingQueue怎么保证并发的插入和删除123456789101112131415161718192021222324252627/** * Links node at end of queue. * * @param node the node */ private void enqueue(Node&lt;E&gt; node) &#123; // assert putLock.isHeldByCurrentThread(); // assert last.next == null; last = last.next = node; &#125; /** * Removes a node from head of queue. * * @return the node */ private E dequeue() &#123; // assert takeLock.isHeldByCurrentThread(); // assert head.item == null; Node&lt;E&gt; h = head; Node&lt;E&gt; first = h.next; h.next = h; // help GC head = first; E x = first.item; first.item = null; return x; &#125; 因为LinkedBlockingQueue 插入是从尾结点插入，删除是从头结点删除； 且 头结点是一个空结点，可以避免对于第一个结点的并发添加和删除的问题，最后总会在链表中剩下这个空节点，在并发添加的删除结点的时候也只会修改分别修改它的item 和 next LinkedTransferQueuexfer方法讲解12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849private E xfer(E e, boolean haveData, int how, long nanos) &#123; if (haveData &amp;&amp; (e == null)) throw new NullPointerException(); Node s = null; // the node to append, if needed retry: for (;;) &#123; // restart on append race for (Node h = head, p = h; p != null;) &#123; // 尝试与第一个结点匹配 boolean isData = p.isData; Object item = p.item; if (item != p &amp;&amp; (item != null) == isData) &#123; // 防止多线程下被匹配过了 if (isData == haveData) // 两个结点类型相同，匹配失败 break; if (p.casItem(item, e)) &#123; // 匹配成功，cas修改 //删除头结点 for (Node q = p; q != h;) &#123; Node n = q.next; // update by 2 unless singleton if (head == h &amp;&amp; casHead(h, n == null ? q : n)) &#123; h.forgetNext();// 形成自引用便于垃圾垃圾回收 break; &#125; // advance and retry if ((h = head) == null || (q = h.next) == null || !q.isMatched()) break; // unless slack &lt; 2 &#125; // 唤醒 头结点中的线程 LockSupport.unpark(p.waiter); return LinkedTransferQueue.&lt;E&gt;cast(item); &#125; &#125; Node n = p.next; p = (p != n) ? n : (h = head); // 是p指向头结点 &#125; if (how != NOW) &#123; // No matches available if (s == null) s = new Node(e, haveData); Node pred = tryAppend(s, haveData); //将新添加的元素添加到表尾，如果添加过程中 //产生了新的类型相反的元素，那么返回null if (pred == null) continue retry; // 产生了上面的情况，那么就返回匹配过程 if (how != ASYNC) return awaitMatch(s, pred, e, (how == TIMED), nanos); &#125; return e; // not waiting &#125; &#125; SynchronizeQueue和LinkedTransferQueue的差异SynchronizeQueue 和 LinkedTransferQueue 都是无锁实现的高性能阻塞队列； SynchronizeQueue 不能保存生产者的生产的产品，如果使用put方法 那么使当前线程阻塞等待直到有消费者线程，如果使用offer方法 那么直接返回null 表示没有消费者线程消费 LinkedTransferQueue 则既可以实现SynchronizeQueue的直接递交生产者生产的物品，如果没有消费者线程又可以保存下来等待消费者消费，生产者线程不会被阻塞 SynchronizeQueue 与其它队列差异我们知道 LinkedBlockingQueue 和 ArrayBlockingQueue 差异就是一个有界一个无界 SynchronizeQueue 相对于它们两者差异就是 能否保存生产者生产的产品 总结LinkedBlockingQueue 较高的易读性，可用性，但是添加删除都直接锁住整个队列，性能不高 SynchronizeQueue 无锁，性能高，但是不能在容器去存储元素，必须添加元素和删除元素配对出现 LinkedTransferQueue 无锁，在保留生产者消费者配对功能的情况下能够将元素存储在容器里面，是LinkedBlockingQueue、SynchronizeQueue的结合]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>阻塞队列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ThreadPoolExecutor源码解析]]></title>
    <url>%2F2018%2F10%2F30%2FJava%20%E5%B9%B6%E5%8F%91%2FThreadPoolExecutor%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[ThreadPoolExecutor源码详解一些属性 clt 1private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0)); 这个属性前三位存储的是线程池的状态，后面的29位存储的是线程池的工作线程数 线程池的状态： RUNNING(运行状态)：能接受新提交的任务，并且能处理阻塞队列中的任务 SHUTDOWN(关闭状态):不能接受新提交的任务，但却可以继续处理阻塞队列中已保存的任务 。 在线程池处于 RUNNING 状态时, 调用 shutdown()方法会使线程池进入到该状态. STOP:不能接受新提交的任务, 也不能处理阻塞队列中已保存的任务, 并且会中断正在处理中的任务. 在线程池处于 RUNNING 或 SHUTDOWN 状态时, 调用 shutdownNow() 方法会使线程池进入到该状态. TIDYING (清理状态): 所有的任务都已终止了, workerCount (有效线程数) 为0, 线程池进入该状态后会调用 当线程池处于 SHUTDOWN 状态时, 如果此后线程池内没有线程了并且阻塞队列内也没有待执行的任务了 (即: 二者都为空), 线程池就会进入到该状态. 当线程池处于 STOP 状态时, 如果此后线程池内没有线程了, 线程池就会进入到该状态. TERMINATED : terminated() 方法执行完后就进入该状态. corePoolSize 核心线程数，这个属性的意义是，当线程池里面的workerCount&lt;corePoolSize那么提交一个新的任务，都会新建一个线程去处理，然后这些核心线程处理完任务后及时处于空闲状态，也不会对它们消除。 maximumPoolSize 最大线程数，这个属性的意义是线程池最大拥有的线程数，当一个新的任务到达时先是考虑把它添加到阻塞队列里面，如果添加失败，也就是说阻塞队列满了，那么就会创建一个线程去执行任务。但是创建的线程数量加上核心线程的数量不能超过这个值，超过了就应该进行拒绝策略进行拒绝 keepAliveTime 非核心线程的空闲保活时间，当创建了一个非核心线程执行任务后，因为没有任务执行一直处理空闲状态，当这个状态的时间超过该属性的值，就会对该线程销毁 workQueue 是一个用于保存等待执行任务的阻塞队列，提交任务，对于任务的处理有三种方式，这三种方式其实上面的处理都提到了，这里我总结一下,就是excute()方法的逻辑： 如果线程池中的线程数小于核心线程数，那么就会创建新的线程执行任务 如果线程池中的数量大于核心线程数，那么就将任务添加到阻塞队列 如果队列满了或者其他情况，导致添加失败，就会创建新的线程用于执行任务 三种处理策略： 直接切换(使用SynchronizeQueue):当提交一个任务到包含这种 SynchronousQueue 队列的线程池以后, 线程池会去检测是否有可用的空闲线程来执行该任务, 如果没有就直接新建一个线程来执行该任务而不是将该任务先暂存在队列中. “直接切换”的意思就是, 处理方式由”将任务暂时存入队列”直接切换为”新建一个线程来处理该任务”. 这种策略适合用来处理多个有相互依赖关系的任务, 因为该策略可以避免这些任务因一个没有及时处理而导致依赖于该任务的其他任务也不能及时处理而造成的锁定效果. 因为这种策略的目的是要让几乎每一个新提交的任务都能得到立即处理, 所以这种策略通常要求最大线程数 maximumPoolSizes 是无界的(即: Integer.MAX_VALUE). 静态工厂方法 Executors.newCachedThreadPool() 使用了这个队列。 使用无界队列：使用无界队列将使得线程池中能够创建的最大线程数就等于核心线程数 corePoolSize, 这样线程池的 maximumPoolSize 的数值起不到任何作用. 当要处理的多个任务之间没有任何相互依赖关系时, 就适合使用这种队列策略来处理这些任务. 静态工厂方法 Executors.newFixedThreadPool() 使用了这个队列。 使用有界队列：需要合理的分配最大线程数和队列容量 threadFactory 线程构造工厂 handler 拒绝策略，拒绝的条件： 当线程池处于 SHUTDOWN (关闭) 状态时 (不论线程池和阻塞队列是否都已满) 当线程池中的所有线程都处于运行状态并且线程池中的阻塞队列已满时 具体的拒绝策略 AbortPolicy: 这是一种直接抛异常的处理方式, 抛出 RejectedExecutionException 异常. CallerRunsPolicy: 将新提交的任务放在 ThreadPoolExecutor.execute()方法所在的那个线程中执行. DiscardPolicy: 直接不执行新提交的任务. DiscardOldestPolicy: 当线程池未关闭时, 会将阻塞队列中处于队首 (head) 的那个任务从队列中移除, 然后再将这个新提交的任务加入到该阻塞队列的队尾 (tail) 等待执行. 线程调度 首先我们按照逻辑，把其中调度的重要的源码贴出来 execute 12345678910111213141516171819public void execute(Runnable command) &#123; if (command == null) throw new NullPointerException(); int c = ctl.get(); if (workerCountOf(c) &lt; corePoolSize) &#123; if (addWorker(command, true)) return; c = ctl.get(); &#125; if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; int recheck = ctl.get(); if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); else if (workerCountOf(recheck) == 0) addWorker(null, false); &#125; else if (!addWorker(command, false)) reject(command); &#125; 这个我在上面已经讲了，就是提交任务后对任务处理的三种情况 addWorker 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566private boolean addWorker(Runnable firstTask, boolean core) &#123; retry: for (;;) &#123; int c = ctl.get(); int rs = runStateOf(c); // Check if queue empty only if necessary. if (rs &gt;= SHUTDOWN &amp;&amp; ! (rs == SHUTDOWN &amp;&amp; firstTask == null &amp;&amp; ! workQueue.isEmpty())) return false; for (;;) &#123; int wc = workerCountOf(c); if (wc &gt;= CAPACITY || wc &gt;= (core ? corePoolSize : maximumPoolSize)) return false; if (compareAndIncrementWorkerCount(c)) break retry; c = ctl.get(); // Re-read ctl if (runStateOf(c) != rs) continue retry; // else CAS failed due to workerCount change; retry inner loop &#125; &#125; boolean workerStarted = false; boolean workerAdded = false; Worker w = null; try &#123; w = new Worker(firstTask); final Thread t = w.thread; if (t != null) &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; // Recheck while holding lock. // Back out on ThreadFactory failure or if // shut down before lock acquired. int rs = runStateOf(ctl.get()); if (rs &lt; SHUTDOWN || (rs == SHUTDOWN &amp;&amp; firstTask == null)) &#123; if (t.isAlive()) // precheck that t is startable throw new IllegalThreadStateException(); workers.add(w); int s = workers.size(); if (s &gt; largestPoolSize) largestPoolSize = s; workerAdded = true; &#125; &#125; finally &#123; mainLock.unlock(); &#125; if (workerAdded) &#123; t.start(); workerStarted = true; &#125; &#125; &#125; finally &#123; if (! workerStarted) addWorkerFailed(w); &#125; return workerStarted; &#125; 这个方法是根据线程池的状态和限制判断是否可以添加新线程，如果可以，改变workerCount并且以参数fisrtTask为任务，进行运行； Worker的run方法内容 12345678910111213141516171819202122232425262728293031323334353637383940414243final void runWorker(Worker w) &#123; Thread wt = Thread.currentThread(); Runnable task = w.firstTask; w.firstTask = null; w.unlock(); // allow interrupts boolean completedAbruptly = true; try &#123; while (task != null || (task = getTask()) != null) &#123; w.lock(); // If pool is stopping, ensure thread is interrupted; // if not, ensure thread is not interrupted. This // requires a recheck in second case to deal with // shutdownNow race while clearing interrupt if ((runStateAtLeast(ctl.get(), STOP) || (Thread.interrupted() &amp;&amp; runStateAtLeast(ctl.get(), STOP))) &amp;&amp; !wt.isInterrupted()) wt.interrupt(); try &#123; beforeExecute(wt, task); Throwable thrown = null; try &#123; task.run(); &#125; catch (RuntimeException x) &#123; thrown = x; throw x; &#125; catch (Error x) &#123; thrown = x; throw x; &#125; catch (Throwable x) &#123; thrown = x; throw new Error(x); &#125; finally &#123; afterExecute(task, thrown); &#125; &#125; finally &#123; task = null; w.completedTasks++; w.unlock(); &#125; &#125; completedAbruptly = false; &#125; finally &#123; processWorkerExit(w, completedAbruptly); &#125;&#125; 主worker循环执行这个内容，不断的从队列中获取并执行它们 讲解一下Executors工厂方法构建出来的线程池 newFixedThreadPool 123return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()); 根据名称我们知道目的是想构建一个拥有固定线程数的线程池，源码得出以下特点： 核心线程数和最大线程线程数相同 阻塞队列为无界队列 根据以上特点我们知道核心线程数和最大线程数相同那么这个线程池只会创建nThreads的线程，然后根据第第二个特点我们知道这个线程池也不会拒绝任务，所有的任务都会加入无界队列 newCachedThreadPool 123return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;()); 根据方法名目的是想创建一个根据需求创建线程的线程池，源码得出以下特点： 没有核心线程 最大线程数无穷大 阻塞队列为SynchronousQueue 根据这几个特点我们知道这个线程池会为所有新来的任务创建新的线程，而且线程数不受限制 newSingleThreadPool 1234return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;())); 根据方法名目的是想创建一个只有一个线程的线程池，源码得出以下特点： 最大线程数和核心线程数都为1 阻塞队列为LinkedBlockingQueue 这个线程池只有用一个线程来完成所有任务，所有任务都添加到阻塞队列里面]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>ThreadPoolExecutor</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于ThreadLocal]]></title>
    <url>%2F2018%2F10%2F30%2FJava%20%E5%B9%B6%E5%8F%91%2F%E5%85%B3%E4%BA%8EThreadLocal%2F</url>
    <content type="text"><![CDATA[基本使用ThreadLocal 是什么ThreadLocalMap 是一个类似于HashMap的类，存储以ThreadLocal为键以想要存储的值为值的键值对，每个线程拥有自己的ThreadLocalMap ThreadLocal 就是操作这个每个线程独有的ThreadLocalMap 的类 从源码分析大致实现方式set方法12345678public void set(T value) &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value);&#125; 取得本线程自己的 ThreadLocalMap 以ThreadLocal为键和以想要存储的值为值存进ThreadLocalMap get 方法12345678910111213public T get() &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings("unchecked") T result = (T)e.value; return result; &#125; &#125; return setInitialValue();&#125; 取得本线程的ThreadLocalMap 以ThreadLocal 在ThreadLocalMap中取得存储的值 ThreadLocalMap 解决哈希冲突ThreadLocalMap 没有采用链地址的方式来解决哈希冲突 123456789101112131415161718192021222324252627282930313233// ThreadLocalMapprivate void set(ThreadLocal&lt;?&gt; key, Object value) &#123; // We don't use a fast path as with get() because it is at // least as common to use set() to create new entries as // it is to replace existing ones, in which case, a fast // path would fail more often than not. Entry[] tab = table; int len = tab.length; int i = key.threadLocalHashCode &amp; (len-1); for (Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == key) &#123; e.value = value; return; &#125; if (k == null) &#123; replaceStaleEntry(key, value, i); return; &#125; &#125; tab[i] = new Entry(key, value); int sz = ++size; if (!cleanSomeSlots(i, sz) &amp;&amp; sz &gt;= threshold) rehash(); &#125; 根据threadLocalHashCode 每次加上固定的0x61c88647 大小得到下一个Index位置 如果Index位置不为空且与key值相等，则替换值 如果index位置不为空且与key值不相等，则寻找下一个空位置插入 如果index位置为空那直接插入 ThreadLocal的内存泄漏导致内存泄漏时因为下面的代码 123456789static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123; /** The value associated with this ThreadLocal. */ Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; super(k); value = v; &#125; &#125; 这个是ThreadLocalMap保存的键值对数组元素，我们可以看到ThreadLocal是弱引用，那么现在就存在一个问题，弱引用所引用的对象会在下一次垃圾回收回收掉；那么在我没有删除这个Entry，但是GC自动回收了ThreadLocal对象，造成了无法删除value 那么怎么解决呢？ 在调用ThreadLocal的get()、set()可能会清除ThreadLocalMap中key为null的Entry对象，这样对应的value就没有GC Roots可达了，下次GC的时候就可以被回收，当然如果调用remove方法，肯定会删除对应的Entry对象。 如果使用ThreadLocal的set方法之后，没有显示的调用remove方法，就有可能发生内存泄露，所以养成良好的编程习惯十分重要，使用完ThreadLocal之后，记得调用remove方法。 1234567ThreadLocal&lt;String&gt; localName = new ThreadLocal();try &#123; localName.set("占小狼"); // 其它业务逻辑&#125; finally &#123; localName.remove();&#125;]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>ThreadLocal</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java虚拟机参数]]></title>
    <url>%2F2018%2F10%2F30%2FJVM%2Fjava%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%8F%82%E6%95%B0%2F</url>
    <content type="text"><![CDATA[Java 虚拟机参数-Xms 设置初始堆大小 -Xmx 设置最大堆大小 -XX:ReservedCodeCacheSize=240m 这个参数主要用来设置codecache大小，比如我们jit编译的代码都是放在codecache里的，所以codecache如果满了的话，那带来的问题就是无法再jit编译了，而且还会去优化。 因此大家可能碰到这样的问题：cpu一直高，然后发现是编译线程一直高（系统运行到一定时期），这个很大可能是codecache满了，一直去做优化。 -XX:+PrintGCDetails 打印GC日志 -Verbose:gc 用于垃圾收集时的信息打印 -XX:+PrintGCDateStamps 打印GC时间戳 -Xloggc:C:\Users\ligj\Downloads\gc.log GC 把GC日志输出的地方 虚拟机默认参数在命令行输入一下内容直接查看： 1java -XX:+PrintFlagsInitail 查看虚拟机使用的虚拟机1234public static void main(String[] args)&#123; List&lt;GarbageCollectorMXBean&gt; l = ManagementFactory.getGarbageCollectorMXBeans(); l.forEach(b -&gt; System.out.println(b.getName())); &#125;]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java 虚拟机</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解java虚拟机]]></title>
    <url>%2F2018%2F10%2F29%2FReading%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3java%E8%99%9A%E6%8B%9F%E6%9C%BA%2F</url>
    <content type="text"><![CDATA[Java 内存区域运行时数据区域java程序的运行时通过java虚拟机来实现的。通过类加载器将class字节码文件加载进JVM，然后根据预定的规则执行。Java虚拟机在执行java程序的过程中会把它所管理的内存划分为若干个不同的数据区域，这些内存区域被统一叫做运行时数据区域。 程序计数器是一块较小的内存空间，它可以看做是当前线程所执行的字节码的行号指令器。每条线程都有一个程序计数器，在每个线程内，分支，循环，跳转，异常处理都是通过改变这个计算器来指定下一个需要执行的指令。在线程间，通过它来恢复到正确的执行位置。 java虚拟机栈线程私有，描述的是java方法执行的内存模型：每个方法在执行的同时都会创建一个栈帧用于存储局部变量表、操作数栈，动态链接、方法出口等信息。 本地方法栈与java虚拟机栈类似，只不过虚拟机栈是执行java方法，而本地方法栈是执行本地方法。 java堆数据共享的一个区域，几乎所有的对象实例都是在这里非配内存。 元空间在java1.8之前使用的是方法区也叫永久代，是各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息，常量，静态变量，即时编译器编译后的代码等数据。 为什么将方法区变为了元空间 实质上方法区变为元空间就是将方法区这个内存空间从运行时数据区域移到了电脑的本地内存空间。 原来字符串常量池在方法区内，容易出现性能问题和内存泄漏 类和方法等信息难确定其大小，因此对于永久代指定大小比较困难，太小出现永久代溢出，太大则出现老年代溢出。 永久代会为GC带来不必要的复杂度，并且回收效率偏低。所以在元空间的垃圾回收，对于僵死的类及类加载器的垃圾回收将在元数据使用到“MaxMetaspaceSize”参数的设定值时进行。 持续的元空间垃圾回收说明，可能存在类、类加载器导致的内存泄漏或是大小设置不合适。 运行时常量池是元空间的一部分，用于存放编译期生成的各种字面量和符号引用。具备动态性，运行期间也可以将常量放入常量池。 直接内存不是虚拟机运行时数据区域的一部分，可以使用Native函数库直接分配堆外内存，然后通过一个存储在java堆中的DirectByteBuffer对象作为这块内存的引用进行操作。这样能在一些场景中显著提高性能，因为避免了在java堆和Native堆中来回复制数据。 Java对象对象的创建 一般情况下通过new关键字，在常量池中看能否定位到类的符号引用，然后查看该类是否被加载解析初始化过，没有则执行 因为类加载过后类的内存大小是可以确定的，所以就划分空间，在划分空间由于空间的不连续性，所有这里有两个解决方案，如果空间是连续的就进行指针碰撞，分配内存时仅仅是把那个指针向空闲区域挪动一段与对象相等大小的距离；还有一种方式就是‘空闲列表’，根据空闲空间来维护一个空闲列表，然后在空闲列表上去分配对象空间 在类分配过程中也有并发情况下的线程安全问题，虚拟机是采用CAS配上失败重试来保证操作的原子性；还有一种方式是给每一个线程一个空间，在自己的线程上分配对象空间。 对象的内存布局 对象在内存中存储的布局可以分为3个区域：对象头，实例数据，和对齐填充 对象头又分为两个部分，一部分是对象自身的运行时数据，如哈希码，GC分代年龄，锁状态标志，线程持有的锁等； 另一部分就是类型指针，即对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例，但并不是所有的虚拟机实现都必须在对象数据上保留类型指针，也就是说查找对象的元数据并一定要经过对象本身。 对齐填充没有意义，虚拟机要求对象大小必须是8字节的整数倍，这个就是用来填充剩余空间的。 对象的定位访问 句柄访问方式：在java堆中划分出一块内存来 作为句柄池，局部变量表中存储的引用存储的就是对象的句柄地址，句柄中包含了对象实例数据与类型数据各自的具体地址信息。 直接访问方式：局部变量表中存储的对象在堆中的实际地址，对象的实例中有存放了对象类型数据的指针。 两种方式的优劣：第一种是在对象被移动（垃圾回收时对象移动频繁）时只会改变句柄中实例数据的地址，而引用本身不改变。第二种方式时速度更快，节省了一次指针定位的开销。虚拟机使用的第二种。 垃圾收集器和内存分配策略可达性分析算法 定义：通过一系列称为GC roots的对象作为起始点，在这些结点开始向下搜索，搜索所走过的路径称为引用链，当一个对象到GC roots没有任何引用链相连，则证明这个对象是不可用的。 GC Roots 的产生 虚拟机栈中（栈帧中本地变量表）中引用的对象 方法区中类静态属性引用的对象 方法区中常量引用的对象 本地方法栈中引用的对象 四大引用 强引用：指程序代码中普遍存在的引用，有引用存在垃圾收集器永远不会回收掉被引用的对象； 软引用：还有用但并非必须的对象；在系统在将要发生系统溢出时，将会把这些对象列进回收范围中进行二次回收； 弱引用：被软引用引用的实例对象只能生存到下一次垃圾回收之前； 虚引用：一个对象是否有虚引用的存在，完全不会对其生存时间构成影响，也无法通过虚引用来获取一个对象实例。它的为一作用就是在系统对对象进行回收时收到一个系统通知。 元空间的回收 元空间主要回收两部分内容：废弃的常量和无用的类。 回收常量是判断当前系统中没有一个String和要回收的常量一样 回收类要满足下面三个条件： 该类的所有实例都被回收 加载该类的ClassLoader已经被回收 该类对应的Class对象没有在任何地方被引用 垃圾收集算法 标记清除算法 定义：首先标记需要清除的对象，在标记完成后统一回收所有被标记的对象 缺点： 效率问题，标记和清除的效率不高 空间问题，标记清除后会产生大量不连续的内存碎片 复制算法 定义：将内存分为两块，每次只使用其中的一块，然后当着一块内存用完了，就将还活着的对象复制到另一块上面 优点：相对于标记清除算法解决了效率问题，也不会存在内存碎片的问题 缺点：内存缩小到原来的一半 标记整理算法 定义：首先是标记待清除对象，然后是让所有存活的对象都向一端移动，然后直接清理掉端边界以外的内存。 分代收集算法 一般是将java堆分成新生代和老年代，在新生代因为每次垃圾收集时都发现大批对象死去，只有少量存活，所以使用复制算法；老年代因为对象存活率高没有额外的担保空间，就使用标记整理算法。 Hotspot的算法实现 枚举根结点：java虚拟机使用的是准确式GC(即需要虚拟机停顿下来检测引用)，在hotpot实现中，是使用一组称为OopMap的数据结构来达到这个目的的，在类加载完成后，hotspot就把对象内什么偏移量上是什么类型的数据计算出来，在JIT编译过程中，也会在特定位置记录下栈和寄存器中哪些位置是引用，这样GC在扫描时就可以直接得知信息了 在OopMap的协助下我们可以快速的完成GC Roots，但是我们不能每一条引用指令都生成对应的OopMap，这样会需要大量的空间；所以这个时候我们就需要安全点，即程序不是在所有地方都能停下来开始GC，只有到达安全点时才能暂停。但是这里有一个问题如何在GC发生时让所有线程都跑到最近的安全点上再停顿下来；这里有两种方式：一种是抢先式中断即先让所有线程都中断，然后让没有到安全点上的线程恢复运行跑到安全点上。而现在的虚拟机大多数使用第二种主动式中断，即在每个线程执行时轮询中断标志，发现这个标志为真时就自己中断挂起。轮询标志的地方和安全点是重合的，另外在加上创建对象需要分配内存的地方 安全区域：在线程处于Sleep和Blocked状态时，无法响应中断请求，也就无法走到安全点上执行GC，这个时候就需要安全区域，在线程执行到安全区域代码时，先标识自己进入了安全区域，那么当JVM发起GC，就可以不管该线程； 当线程离开了安全区域时要检测是否正在发生GC，完成时就继续执行，否则等待直到收到可以离开安全区域信号时为止。 垃圾收集器 Serial收集器 定义：单线程收集器，在进行垃圾收集时，必须停下所有工作线程，直到它收集结束。 由于它只专心做垃圾收集的工作，所有它的效率很高。 ParNew 收集器 定义： Serial收集器的多线程版本，收集算法，Stop the word，对象分配规则都和Serial收集器一样，在实现上他们也共用了很多代码。 Parallel Scavenge 收集器 定义：其它收集器关注的是缩短垃圾收集时用户进程停顿的时间，但是这个收集器关注的是吞吐量，即CPU用于运行用户代码的时间与CPU总消耗时间的比值。（在我看来这两者的差别就是一段时间内可能会产生许多次垃圾回收，导致吞吐量下降） 前面三者都是新生代的垃圾收集器 后面三者是老年代收集器 Serial Old 收集器 定义：同样是单线程收集器，使用“标记-整理算法” Parallel Old收集器 定义：Parallel Scavenge收集器的老年代版本 CMS收集器 定义：是一种以获取最短停顿时间为目标的收集器。 运行过程：大致为 初始标记 –&gt;并发标记 –&gt; 重新标记 –&gt;并发清除 其中初始标记和重新标记仍然需要停顿虚拟机；初始标记仅仅是标记一下GC roots能直接关联的对象，速度很快，并发标记就是进行GC Roots Tracing的过程，而重新标记阶段则是为了修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录；其中比较消耗时间的并发标记和并发清除都是与用户线程一起的。 缺点： 对CPU资源比较敏感，在并发阶段，虽然不会停顿用户进程，但是会占用一部分CPU资源导致用户程序变慢，总吞吐量下降 CMS收集器无法处理浮动垃圾。 CMS收集器基于“标记清除算法”，所以存在内存碎片。 G1收集器 特点： 并行与并发：减少用户线程停顿时间 分代收集 空间整合：整体基于“标记清除算法” 可预测的停顿：可预测的停顿时间模型，G1跟踪每个Region里面的垃圾堆积的价值大小，在后台维护一个优先列表，根据要求时间来收集 使用Remember set避免全盘扫描 大致过程： 初始标记 –&gt; 并发标记 –&gt;最终标记 –&gt;筛选回收 内存分配与回收策略 对象优先在Eden空间，当其没有足够空间时就会进行Minor GC 大对象进入老年代 长期存活的对象进入老年代 动态对象年龄判断：相同年龄超过Survivor空间的一半 空间分配担保：Minor GC 需要 老年代空间进行担保，老年代根据经验值进行FULL GC GC 日志分析15.617（时间戳）: [GC（Young GC） 5.617（时间戳）: [ParNew（GC的区域）: 43296K（垃圾回收前的大小）-&gt;7006K（垃圾回收以后的大小）(47808K)（该区域总大小）, 0.0136826 secs（回收时间）] 44992K（堆区垃圾回收前的大小）-&gt;8702K（堆区垃圾回收后的大小）(252608K)（堆区总大小）, 0.0137904 secs（回收时间）] [Times: user=0.03（GC用户耗时） sys=0.00（GC系统耗时）, real=0.02 secs（GC实际耗时）] JVM调优实战总结 使用虚拟机逻辑集群来利用硬件资源；使用逻辑集群又有以下的缺点： 尽量避免节点竞争全局资源，最典型的就是磁盘竞争 很难最高效率的利用某些资源池。可以使用JNDI， 但是其本身又有性能消耗 使用本地缓存的应用会造成资源浪费，因为每个节点都会有一份缓存，考虑使用集中式缓存 集群之间的数据同步可能会带来一定的网络同步开销。 堆外内存溢出： 直接内存 线程堆栈 Socket缓存区：Receive和Send缓存区 JNI代码 虚拟机和GC：虚拟机、GC代码执行也需要消耗一定的内存 外部命令导致系统缓慢 远端调用速度不匹配导致JVM进程崩溃 不恰当数据结构导致内存占用过大 由windows虚拟内存导致的长时间停顿 类文件结构 Class文件数据结构组成： | 类型 | 名称 | 数量 || ————– | ——————- | ——————— || u4 | magic | 1 || u2 | minor_version | 1 || u2 | major_version | 1 || u2 | constant_pool_count | 1 || cp_info | constant_pool | constant_pool_count-1 || u2 | access_flags | 1 || u2 | this_class | 1 || u2 | super_class | 1 || u2 | interfaces_count | 1 || u2 | interfaces | interfaces_count || u2 | filelds_count | 1 || field_info | fields | fields_count || u2 | methods_count | 1 || method_info | methods | methods_count || u2 | attributes_count | 1 || atrtibute_info | attributes | attributes_count | magic魔数： 类似于我们一般的文件扩展名，有这个是为了安全，不能修改 minor_version、major_version 此版本号，主版本号，标志该Class文件的JDK版本，高版本JDK能向下兼容低版本JDK constant_pool 常量池：主要存放两大常量：字面量如文本字符串，声明为final的常量值等；符号引用即类和接口的全限定名、字段的名称和描述符、方法的名称和描述符。 access_flags 类访问标志：用于识别一些类或者接口层次的访问信息 this_class 类索引：用于确定这个类的全限定名 super_class 父类索引: 用于确定父类全限定名（出来Object外至少有一个） interfaces 接口索引： 接口索引集合 field_info 字段表集合：包含类级变量以及实例级变量，但不包括局部变量 | 类型 | 名称 | 数量 | 描述 || ————— | —————– | —————- | ————————————————- || u2 | access_flags | 1 | 字段修饰符，例如public，private，static，volatile || u2 | name_index | 1 | 字段名称 || u2 | description_index | 1 | 数据类型 || u2 | attributes_count | 1 | || attributes_info | attrbutes | attributes_count | | method_info 方法表集合：如果不重载父类的方法，父类的方法是不会出现在这里 | 类型 | 名称 | 数量 | 描述 || ————— | —————– | —————- | ————————————————- || u2 | access_flags | 1 | 方法修饰符，例如public，private，static，volatile || u2 | name_index | 1 | 方法名称 || u2 | description_index | 1 | 参数列表、返回值 || u2 | attributes_count | 1 | || attributes_info | attrbutes | attributes_count | | attributes_info 属性表集合：在Class文件、字段表、方法表都可以携带，用于描述一些专有场景 字节码指令： 同步指令：java虚拟机可以支持方法级的同步和方法内部一段指令序列的同步，这两种同步结构都是用管程来实现的，当调用方法时，调用指令将会检查方法的ACC_SYNCRONIZED标志是否有，如果有线程要求先成功持有管程，然后才能执行方法，最后当方法完成时释放管程。在java虚拟机指令集中有monitorenter和monitorexit两条指令来支持synchronized关键字语义。 类加载机制概述虚拟机把描述类的数据从class文件加载到内存，并对数据进行校验、转换解析和初始化，最终形成可以被虚拟机使用的java类型 类初始化时机 使用new关键字 读取或设置一个类的静态字段 调用一个类的静态方法 对类进行反射调用 父类没有初始化时 主类 需要主要的特殊情况 对于静态字段，只有直接定义这个字段的类才会被初始化 new一个空数组，不会产生初始化 引用一个类的常量不会引起该类的初始化 类加载过程 加载 过程： 通过一个类的全限定名来获取定义此类的二进制字节流 将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构 在内存中生成一个代表这个类的Class对象，作为方法区这个类的各种数据的访问入口 数组类的加载过程 是引用元素，就加载引用类型，并且数组将在加载该组件类型的类加载的类名称空间上被标识 不是引用元素，数组就会与引导类加载器关联 数组类型的可见性与组件类型的可见性相同，基本类型组件默认为public 验证 文件格式验证 元数据验证 字节码验证 符号引用验证 准备：正式为类变量分配内存并设置类变量初始值的阶段 解析 类或接口的解析 字段解析 类方法解析 接口方法解析 初始化 这里就主要涉及() 方法，其实有编译器自动收集类中的所有类实例变量的赋值动作和静态语句块中的语句合并产生的，编译器收集顺序是有语句在源文件中出现的顺序所决定的； 父类的方法总是比子类的先执行 虚拟机会保证方法执行的原子性 类加载器 类和类加载器共同决定一个类的唯一性 双亲委派模型 启动类加载器：负责将存放在&lt;JAVA_HOME&gt;\lib目录中的类 扩展类加载器：负责加载&lt;JAVA_HOME&gt;\lib\ext 目录中的类 应用程序类加载器：负责加载用户类路径上所指定的类库，是ClassLoader.getSystemClassLoader()的返回值 这个模型主要是说在加载一个类时，总是先让父类去加载，只有所有父类不去加载的时候自己才去尝试加载 虚拟机字节码执行引擎运行时栈帧结构 局部变量表：用于存放方法参数和方法内的局部变量，是通过可以复用的变量槽（Slot）来实现的，且变量槽的第一个位置是用来存放this的 操作数栈：就是方法在执行过程中需要的最大栈深 动态链接：每个栈帧都包含一个指向运行时常量池中该栈帧所属方法的引用，持有这个引用是为了支持方法调用过程中的动态链接 方法返回地址：在每个方法执行结束后都需要返回到方法被调用的位置，在栈帧中就需要保存这个信息 方法调用 解析：静态解析即在解析阶段能够唯一确定调用方法版本的非虚方法：静态方法、私有方法、实例构造器、父类方法还有final方法 分派 静态分派： 所有依赖静态类型来定位方法执行版本的分派动作称为静态分派。（如重载） 动态分派：所有依赖动态类型来定位方法执行版本的分派动作称为动态分派。（如重写） 在这里我简单描述一下动态分派的过程：先是把实例对象压到栈顶，然后再在类型C中找到与常量中的描述符合简单名称都相同的方法，这里寻找过程中使用到了虚方法表，这样也就脱离了与静态类型的关系 栈指令集和寄存器指令集 栈指令集：缺点是在内存上操作且指令多造成速度慢，优点就是可移植姓，因为不受本地硬件的限制，是通过虚拟机最终变成机器码 寄存器指令集：速度快，但是由于不同的硬件有不同的寄存器指令集 早期编译优化解析与填充符号表即编译过程的前几步，词法分析形成Token流，语法分析形成抽象语法树，然后额外做一个填充符号表 插入式注解处理器的注解处理过程分析和字节码生成 抽象语法树能保证一个结构正确的源程序，但是无法保证源程序是符合逻辑的，所以接下来就是语义分析 晚期优化解释器和编译器共存java虚拟机是解释器和编译器共存的，解释器用来迅速启动和执行程序，省去编译的时间，编译器是在运行过程中不断的优化代码，把越来愈多的代码编译成本地代码，可以提高运行效率； 虚拟机中有C1（Client Compiler）和C2（Server Compiler）编译器，两者的差别就是C1编译器编译得更快，但是优化得没有C2编译器更好 编译对象和触发条件 被多次调用的对象 被多次执行的循环体 实现方式：方法调用计数器和回边计数器 优化技术]]></content>
      <categories>
        <category>reading</category>
      </categories>
      <tags>
        <tag>java虚拟机</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于Tomcat]]></title>
    <url>%2F2018%2F10%2F29%2FJavaweb%2F%E5%85%B3%E4%BA%8ETomcat%2F</url>
    <content type="text"><![CDATA[概述​虽然以前通过SpringBoot的源码看了一些其内置的Tomcat源码，但是因为看得比较马虎 :disappointed: 所以只知道大概，今天要根据自己看得几篇博客和Tomcat源码来总结下在我看来的Tomcat，然后后面准备自己模仿Tomcat实现一个自己的HTTP服务器，想想还是很激动 :laughing: TomcatTomcat 服务器是一个免费的开放源代码的Web 应用服务器，属于轻量级应用服务器，在中小型系统和并发访问用户不是很多的场合下被普遍使用，是开发和调试JSP 程序的首选。 Tomcat顶层架构 大致关系一个Server可以有多个Service 一个Service只能有一个Container 一个Service拥有多个Connector 一个Container可以有多个Context 组件功能Server 拥有自己的生命周期，在这里讲解一下声明是声明周期，首先它可以控制组件整个流程，然后就是能够监听生命周期中的事件，方便用户自定义；主要控制Tomcat的生死大权 Service 顾名思义服务，我们根据Service接口，差不多也知道了它的主要功能 123456789101112131415161718192021222324252627282930313233343536public interface Service extends Lifecycle &#123; Engine getContainer(); void setContainer(Engine var1); String getName(); void setName(String var1); Server getServer(); void setServer(Server var1); ClassLoader getParentClassLoader(); void setParentClassLoader(ClassLoader var1); String getDomain(); void addConnector(Connector var1); Connector[] findConnectors(); void removeConnector(Connector var1);// 这里会添加到Executor链表中，并且会在线程池中取运行 void addExecutor(Executor var1); Executor[] findExecutors(); Executor getExecutor(String var1); void removeExecutor(Executor var1); Mapper getMapper();&#125; 取得子组件 取得父组件 管理Connectors 将任务丢进线程池里面去运 Engine 我们依然使用接口来了解它的功能 12345678910111213public interface Engine extends Container &#123; String getDefaultHost(); void setDefaultHost(String var1); String getJvmRoute(); void setJvmRoute(String var1); Service getService(); void setService(Service var1);&#125; 与Service建立上下级关系 管理Host,即管理站点，下面我们详细介绍这里的Host即站点是什么 Host 站点，虚拟主机，使用的情况是在同一台服务器下部署两个应用，但是想用不同域名访问这两个应用就可以使用不用的Host, 主要功能就是管理Context，即封装和管理Servlet 上面这张图是对Engine和Host的总结，这里不知道有没有一个为什么要把Servlet封装成Wrapper的疑问，因为Container接口里面findChild 返回类型为Container，我们必须将Servlet封装成Wrapper，刚好也把所有ServletContext中设置的参数放进这个wapper中 Connector 主要功能就是用于接受请求并将请求封装成Request和Response来具体处理； 其中具体处理过程如上图 Endpoint：处理底层Socket的网络连接 Processor : Endpoint接收到的Socket封装成Request Adapter: 将Request交给Container进行具体的处理 参考https://blog.csdn.net/qq_38245537/article/details/79009448]]></content>
      <categories>
        <category>javaweb</category>
      </categories>
      <tags>
        <tag>tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[单点登录]]></title>
    <url>%2F2018%2F10%2F27%2FJavaweb%2F%E5%8D%95%E7%82%B9%E7%99%BB%E5%BD%95%2F</url>
    <content type="text"><![CDATA[单系统登录http无状态web采用的C/S架构，采用了HTTP协议，但是http是无状态的一种协议，即每一次请求都是独立的不会与上一次或者下一次的请求产生联系，但是我们又想在请求中记录用户的状态，那么就产生了cookie和session的会话机制 会话机制 浏览器第一次访问服务器的时候，服务器产生此会话的session，并且在response中的cookies中添加sessionId，浏览器接收到response就会把cookie保存在本地cookie中；当下一次再访问服务器的时候，浏览器就会在cookies中带着这个sessionId，服务器就可以通过sessionId在session池里面取出本次会话的session 有了这个会话机制，我们就可以在session里面存储我们的登录状态，在单系统中我们就是通过在session里面设置isLogin的字段 实现自动登录 多系统登录cookie传送要求在单系统中，只涉及到一个服务器，一个域名那么就不存在跨域问题；所谓cookie的跨域问题是正常的cookie的传输是在本地cookie文件中，每一个cookie都对应着一个域名，在向服务器发送请求如果有该域名下的cookie那么就会在请求中添加cookie；但是不同的域名是不能共享一个cookie的 cookie的跨域共享在早期的系统中，就是采用这种方式进行单点登录，但是存在的缺点是各服务器使用的技术相同，因为cookie的key值 要相同；其次应用群域名得统一 ；然后cookie本身不安全 单点登录登录 注销]]></content>
      <categories>
        <category>javaweb</category>
      </categories>
      <tags>
        <tag>单点登录vav</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于跨域请求]]></title>
    <url>%2F2018%2F10%2F27%2FJavaweb%2F%E5%85%B3%E4%BA%8E%E8%B7%A8%E5%9F%9F%E8%AF%B7%E6%B1%82%2F</url>
    <content type="text"><![CDATA[什么是跨域请求跨域请求就是比如我们在浏览器中正在访问一个aaa.com的网站，它其中有一个链接是bbb.com，如果我们点击这个链接那么它就是一个跨域请求，但是我们如果访问以aaa.com开头的所有链接都不是跨域请求 CROSCORS即Cross-Origin Resource Sharing是一个新的W3C标准，它新增了一组HTTP首部字段，允许服务端其声明哪些源站有权限访问哪些资源 具体实现方式对于简单请求浏览器直接发送原请求，如果响应中没有相应的字段那么不会收到任何数据；如果是非简单请求，那么浏览器会使用Option方法发起一个预检请求，从而在响应中得知是否允许跨域，如果允许在发送原请求 至于具体的字段配置看下面的参考 参考https://www.jianshu.com/p/f880878c1398]]></content>
      <categories>
        <category>javaweb</category>
      </categories>
      <tags>
        <tag>跨域请求</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Swagger详解]]></title>
    <url>%2F2018%2F10%2F27%2FJavaweb%2FSwagger%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[Swagger注解使用说明 @Api 这个注解用来生命此类为Swagger resource API ，只有被这个@Api注解的类才能被Swagger扫描到；但是我发现这个不是必要的，不要这个注解有其它条件也可以扫描到类下面的Api @ApiOperation 这个注解用来声明单个方法为一个Api接口，其中value是用来给这个Api作简短的介绍；notes 允许你给出重要的和更详细的该接口的信息；response和responseContainer主要是用来展示返回示例的，如果在此使用了这两个就会体现在Example Value上 @ApiResponses、@ApiResponse 这两个注解组合使用在类上，是为了展示方法返回状态码的含义 @ApiParam 此注解就是用来显示请求该接口需要哪些参数,这个用来GET方法上 @ApiImplicitParam、@ApiImplicitParam 此注解也是用来显示接口参数，但是是用在参数放在Body里面的参数 @ApiModel、@ApiModelProperty 这两个注解是用来在请求参数中如果有对象，可以用这两个注解来具体描述里面的参数]]></content>
      <categories>
        <category>javaweb</category>
      </categories>
      <tags>
        <tag>Swagger</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>%2F2018%2F09%2F03%2FReading%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%2F</url>
    <content type="text"><![CDATA[概述交换技术电路交换 大致过程：端到端先建立好连接，整个端到端的链路就不能被其它访问，然后进行数据交换，最后释放连接，其它端才能访问，所以这种方式的传输效率会非常低 分组交换 大致过程：采用存储转发技术。我们把要发送的整个数据叫做报文；在发送之前，我们将报文划分成为一个个更小的等长的数据段并在每个数据段之前加上一些必要的控制信息组成的首部。每个分组独立的选择转发路由，对通信电路是逐段占用 报文交换 就是不进行划分的分组交换 计算机网络的性能指标 速率：在计算机网上的主机在数字信道上传送数据的速率 带宽：是指数字信道所能传送的最大数据率 吞吐量：表示在单位时间内通过某个网络的数据量 时延：是指数据从网络的一端传送到另一端所需要的时间 物理层基本概念 物理层考虑的是怎样才能在连接各种计算机的传输媒体上传输数据的比特流，而不是指具体的传输媒体 物理层的主要任务描述为确定与传输媒体的接口有关的特性： 机械特性、电气特性、功能特性、过程特性 网络层网络层概述网络层向上只提供简单灵活的、无连接的、近最大努力交付的数据报服务 ICMP概述 网际控制报文协议，目的是更有效的转发IP数据报和提高交付成功的机会；ICMP不是高层协议而是IP协议，作为IP层数据报的数据，加上数据报的首部，组成IP数据报发送出去 ICMP报文种类 差错报告报文 终点不可达 原点抑制 时间超过 参数问题 改变路由 询问报文 回送请求和回答(ping) 时间戳请求和回答(时钟同步和测量时间) VPN和NAT**VPN（virtual private network） 定义：虚拟专用网，目的是解决两个专用网的通信，在因特网上的传输过程中数据加密 NAT（network address translation） 定义：网络地址转换，由于全球ip地址紧缺，通过路由器形成一个专用网，路由器拥有全球专有ip地址且安装了NAT软件，动态的分配IP地址给上网的用户，然后通过路由器进行专用网内的计算机与因特网上的计算机进行通信；所以也不难理解专用网内的计算机不能作服务器 运输层运输层概述运输层为应用程序提供端到端的逻辑通信 UDP用户数据报协议 概述 UDP是无连接的 尽最大努力交付 面向报文 没有拥塞控制 支持一对一，一对多，多对一，多对多的交付通信 首部开销小 首部格式 源端口、目的端口、长度、检验和 TCP传输控制协议 概述 面向连接的传输层协议 提供可靠交付的服务 全双工通信 面向字节流 可靠传输的工作原理 停止等待协议 无差错：每次发送一个分组，等到收到收到分组的确认就再发送下一个分组 出现差错：发送一个分组后，超过一定时间没有收到确认，那么就会重传此分组 确认丢失和确认迟到 连续ARQ协议 由于停止等待协议的信道利用率低，就有了这种协议 TCP报文的首部格式 源端口和目的端口 序号:本报文段所发送的数据的第一个字节的序号 确认号：期望收到对方下一个报文段的第一个数据字节的序号 数据偏移：指出TCP报文段的数据起始处距离TCP报文段起始处有多远 保留 紧急URG 确认ACK：仅当ACK=1时确认号字段才有效；建立连接后所有报文首部ACK=1 推送PSH 复位RST 同步SYN：在连接建立时用来同步序号 终止FIN：用来释放连接 窗口：指的是发送本报文段的一方的接受窗口 检验和 TCP可靠传输的实现 滑动窗口实现 TCP的流量控制 通过响应报文中的rwnd实现 TCP拥塞控制 慢开始和拥塞避免 快重传和快恢复]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2018%2F08%2F27%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%2FCookie%E5%92%8CSession%2F</url>
    <content type="text"><![CDATA[Cookie机制 定义 Cookie使服务器在本地机器上存储的小段文本并随每一个请求发送至同一服务器 产生流程 正统的cookie分发使通过扩展HTTP协议实现的，服务器通过在HTTP响应头中加一行特殊的指示以提示浏览器按照指示生成相应的cookie，一般这个时候就会把服务器产生的sessionId发送给浏览器保存在cookie中以便维持有状态。当浏览器发送请求时，会检查所有存储的cookie，如果某个cookie所声明的作用范围大于等于将要请求的资源所在位置，则把该cookie附在请求资源的HTTP请求头上发送给浏览器。 Session机制 定义 session机制是一种服务器端的机制，服务器使用一种类似于散列表的结构来保存信息 产生流程 当程序需要为某个客户端的请求创建一个session时，服务器首先会检查这个客户端的请求里是否已经包含了一个sessionId，如果有就将该session检索出来放在Request中来使用，如果没有就创建一个新的seesion放在Request来使用，产生的sessionId将被在本次响应中返回给客户端保存，一般保存方式就是cookie 两者的不同点 存取方式的不同 Cookie只能保存ASCII字符串，存储UNICODE字符需要先进行编码 Session能保存任何类型的数据甚至java类 隐私策略不同 Cookie对于客户端是可见的，Session是不可见的 有效期上的不同 Cookie可以设置一个较长时间的过期时间，但是Session关闭了阅读器该Session就会失效，因而不能长期有效，如果Session长时间有效会导致服务器内存溢出 服务器压力不同 Cookie存储在本地，Session存储在服务器 跨域的支持上的不同 Cookie支持跨域，但是Session不支持跨域，不同域名使用不同Session 关于Cookie和Session的跨域共享 正常情况下Cookie发送 现在我们有两个站点 12www.example.com/site1www.example.com/site2 这两个站点因为在同一个域名下，所以在访问这两个站点时，会发送相同的cookie，因为浏览器存储cookie域是www.example.com 我们想实现的是同一个域但是不同的子域如何进行单点登录 12sub1.onmpw.comsub2.onmpw.com 上面就是两个同一个域但是不同的子域的例子，我们可以采用以下的实现方式实现： 登录sub1.onmpw.com系统 登录成功以后，设置cookie信息。这里需要注意，我们可以将用户名和密码存到cookie中，但是在设置的时候必须将这cookie的所属域设置为顶级域 .onmpw.com。这里可以使用setcookie函数，该函数的第四个参数是用来设置cookie所述域的。 1cookie.setDomain(&quot;.onmpw.com&quot;); 访问sub2.onmpw.com系统，浏览器会将cookie中的信息username和password附带在请求中一块儿发送到sub2.onmpw.com系统。这时该系统会先检查session是否登录，如果没有登录则验证cookie中的username和password从而实现自动登录。 sub2.onmpw.com 登录成功以后再写session信息。以后的验证就用自己的session信息验证就可以了。 但是现在出现了一个问题 问题：当我们进入一个子域，要退出时我们可以删除自身的session信息和所属域为.onmpw.com的cookie，但是由于session时不跨域的不能删除另一个子域的session信息，也就是不能同时退出 解决方案：把第一登录生成的JSESSIONID，通过setDomain放到一个共享的自定义的cookie中。之后访问二级域名的时候，将自定义cookie中的值取出来，然后再放到JESSIONID的cookie值中 123Cookie c = new Cookie(&quot;JSESSIONID&quot;, session.getId()); c.setDomain(&quot;abc.com&quot;); resp.addCookie(c);]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2018%2F08%2F14%2FJavaweb%2FDocker%2F</url>
    <content type="text"><![CDATA[更换Docker镜像源编辑 /etc/docker/daemon.json 的文件，如果没有就添加，docker版本要大于1.12 1&#123;"registry-mirrors":[]&#125; [] 里面可以填一下的镜像源： Docker官方中国区：https://registry.docker-cn.com 网易： http://hub-mirror.c.163.com ustc：https://docker.mirrors.ustc.edu.cn 区DaoCloud获取地址]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2018%2F08%2F05%2FReading%2F%E9%AB%98%E6%80%A7%E8%83%BDMysql%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[MYSQL 基本架构 Mysql的三层逻辑结构 第一层连接器用于连接处理，授权认证，安全管理 第二层查询缓存、解析器、优化器是mysql中的服务器层，大多数Mysql的核心服务都在这一层，包括查询解析、分析、优化、缓存以及所有的内置函数，还有存储过程、触发器、视图等 第三层是存储引擎层，存储引擎负责Mysql中的数据的存储和提取 并发控制Mysql在两个层面存在并发控制：服务器层和存储引擎层 锁类型：排它锁、共享锁 锁粒度： 表级锁：是Mysql最基本的锁策略，并且是开销最小的策略，是Mysql服务器层的锁集机制 行级锁：可以最大层度的支持并发处理（同时也带来了最大的锁开销） 事务定义：一组原子性的SQL查询，或者说一个独立的工作单元 事务特性 隔离级别 死锁：为了解决死锁，数据库系统实现了各种死锁检测和死锁超时机制；InnnoDB存储引擎目前处理死锁的方法是，将持有最少行级排他锁的事务进行回滚 事务日志：事务日志可以帮助提高事务的效率；使用事务日志，存储引擎在修改表的数据时只需要修改其内存拷贝，再把该行为记录到持久在硬盘上的事务日志中(事务日志采用追加方式是顺序IO，所以会比较快)；事务日志持久之后，内存中被修改的数据在后台可以慢慢刷回到磁盘；这种方式通常叫做预写式日志 Innodb主要通过事务日志实现ACID特性，事务日志包括：重做日志redo和回滚日志undo Redo记录的是已经全部完成的事务，就是执行了Commit的事务 undo记录的是已部分完成并且已经写入硬盘的未完成的事务 能够实现系统崩溃后，重启后能够自动恢复数据 Mysql中的事务：mysql默认采用自动提交模式即每个查询都会被当做一个事务进行提交 两阶段锁定协议：在事务执行过程中，随时都可以锁定，在Commit或者Rollback时才会被释放，并且所有锁在同一时刻被释放 隐式锁：Innodb根据隔离级别自动加锁 显示锁：通过特定语句显示的加锁 多版本并发控制MVCC是行级锁的变种，很多情况下会避免加锁操作 InnoDB的MVCC是通过在每行记录后面保存两个隐藏的列来实现的，这两个列，一个保存了创建时间，一个保存的删除时间；当然这里的时间并不是真正的时间而是系统事务的版本号，当新建一个事务，事务版本号就会递增加1 MyISAM和InnoDB的差异 Innodb支持事务 MyISAM不支持 Innodb 支持外键 MyISAM不支持 Innodb 使用聚簇索引 MyISAM 使用非聚簇索引 Innodb 具有崩溃恢复机制 MyISAM没有 Innodb支持行级锁 MyISAM不支持 Mysql 中索引类型 哈希索引 哈希索引基于哈希表，对于每一行存储引擎都使用所有索引列计算一个哈希码 全文索引 全文索引是目前搜索引擎使用的一种关键技术，它能够利用分词技术等多种算法智能分析出文本中关键字词出现的频率及重要性，然后按照一定的算法规则智能筛选出我们想要的搜索结果 剖析Mysql查询的方法剖析单条查询的方法 show profiles： set profiling = 1； show profiles； show profile for query ?; 第一条代码开启分析查询语句时间功能 第二条代码查看所有查询语句总耗时 第三条代码查看每条查询语句执行的每个阶段耗时 Schema与数据类型优化 选择优化得数据类型原则： 更小的通常更好 简单就好 尽量避免NULL，因为可为NULL的列使得索引，索引统计和值比较都更为复杂 尽量不要使用Decimal，因为其会比DOUBLE或者FLOAT占用更大的空间且计算开销，除非你真的需要精确的小数计算比如存储财务数据 关于VARCHAR和CHAR VARCHAR 它比定长更节省空间，因为它仅使用必要的空间；所以在以下情况下最好使用该类型： 字符串列的长度比平均长度大很多 列的更新很少，所以碎片不是问题(因为VARCHAR的更新可能会导致原来的页剩余的空间不够而需要采取其它的技术手段) 使用了UTF-8这样复杂的字符集，每个字符使用不同的字节数进行存储 CHAR Mysql总是会根据定义的字符串长度分配足够的空间，它会删除末尾的空格 使用情况： 很短的字符串且定长 经常变更的数据 关于DATETIME和TIMESTAMP TIMESTAMP会比DATETIME是更好的选择，因为前者会使用比后者一半对的存储空间但是它前者能够存储的时间范围比后者小 关于Blob和Text Blob和Test的差别仅有分别采用二进制和字符串方式存储；它们不能对整个数据进行索引，而是截取前面的一些字段进行索引 Mysql 调优创建高性能的索引B-Tree索引 可以使用B-tree索引的查询类型 全值匹配：指的是和索引中的所有列进行匹配 匹配最左前缀 匹配列前缀 匹配范围值 精确匹配某一列并范围匹配另外一列 只访问索引的查询 B-TREE索引的限制 如果不是按照索引的最左列开始查找，则无法使用索引 不能跳过索引中的列 如果查询中有某个列的范围查询，则右边所有列都无法使用索引优化查找 索引的优点 索引大大减少了服务器需要扫描的数据量 快速定位，所以不需要导入全部数据进行顺序查找 索引可以帮助服务器避免排序和临时表 顺序存储，便于ORDER BY、GROUP BY ；当需要排序时，不是顺序存储的如果数据表小的话就把数据导入内存不然就用磁盘然后建立一个临时表进行排序这是一个非常耗时间的过程 索引可以将随机IO变为顺序IO 因为数据在索引中顺序存放的 三星索引三星索引其实就是对应的实现上面索引的三个优点； 通过一个例子来说明： 1select A,B,C,D from user where A="xx" and B = "xx" order by C; A 的选择性为0.01% B 的选择性为0.1% 最佳的索引是（A,B,C,D），这是一个三星索引 第一颗星：过滤尽可能多的行，这意味着把选择性高的索引放在前面A,B；减少索引片的大小，以减少需要扫描的数据行 第二颗星：经过了A，B的筛选之后，筛选出来的行本身就是有序的；避免排序，减少磁盘IO和内存使用 第三颗星：通过宽索引实现覆盖索引；避免每一个索引对应的数据行都需要进行一次随机IO从聚集索引中读取数据 高性能的索引策略独立的列如果查询中的列不是独立的，则Mysql就不会使用索引；”独立的列”是指索引列不能是表达式的一部分，也不能是函数的一部分 ex：select actor_id from actor where actor_id + 1 = 5 前缀索引和索引选择性前缀索引：索引开始的部分字符，这样可以大大节约索引空间，从而提高索引效率。但是这样也会降低索引的选择性 索引的选择性：不重复的索引值和数据表的记录总数(#T)的比值 怎样确定索引前多少个字符? 12345select count(distinct left(city,3))/count(*) as sel3,count(distinct left(city,4))/count(*) as sel4,count(distinct left(city,5))/count(*) as sel5,count(distinct left(city,6))/count(*) as sel6,count(distinct left(city,7))/count(*) as sel7 选择选择性增加幅度很小的情况，但是也要注意数据分布不均匀的情况，即最常出现的前缀次数比最常出现的城市次数大很多的情况 前缀索引的缺点：无法使用前缀索引做ORDER BY 和 GROUP BY 多列索引举个例子：select film_id,actor_id from actor where actor_id=’1’ and film_id=’1’；但是只有两个独立的分别是film_id的和actor_id的索引，那么mysql在查询时会使用”索引联合”策略，但是这个会有性能的问题，需要耗费大量CPU和内存资源在算法的缓存、排序和合并操作上；索引在EXPLAIN中有索引合并应该好好检查一下查询和表结构 选择合适的索引列顺序 将选择性最高的列索引放到最前列 根据那些运行频率最高的插叙来调整索引列的顺序 聚簇索引聚簇：表示数据行和相邻的键值紧凑地存储在一起 聚簇索引包含了一张表的全部数据，一张表只能一个聚簇索引 优点： 可以把相关数据保存在一起(通过索引我们只需读取少量有我们想要数据的数据页，而如果是MYISAM，就是通过索引得到想要数据的物理地址，读取一行就是一次磁盘IO) 数据访问很快 使用覆盖索引扫描的查询可以直接使用页结点中的主键值 缺点： 最大限度提高了IO密集型应用的性能，但如果数据在内存中就没有用了 插入速度严重依赖于插入顺序 更新聚簇索引代价很高 插入行可能有页分裂的问题 聚簇索引可能导致全表扫描变慢 二级索引可能比想象的要更大，因为二级索引的叶子结点包含了引用行的主键 二级索引访问需要二次索引查找，而不是一次(如果你select 的字段比二级索引多，然后过滤条件能使用此二级索引，第一次先用二级索引进行查找找到对应的主键，然后通过主键在聚簇索引中找到想要的数据) Innodb和MyISAM数据分布差异 MyISAM数据分布 主键索引和普通索引没有区别； 按照数据插入的顺序插入的顺序存储在磁盘上，在索引数据行的旁边显示行号，从0开始递增，索引形式如图： 即叶子结 Innodb数据分布 就用下面的图来标识吧，很清晰了 覆盖索引 定义：如果一个索引包含所有需要查询的字段值，我们就称之为”覆盖索引” 全表扫描和全索引扫描全表扫描：是指通过物理表获取数据，顺序读磁盘上的数据 全索引扫描：查询时，遍历索引树来获取数据行 使用索引扫描来做排序Mysql有两种方式生成有序结果：通过排序操作或者按索引顺序扫描；所以如果直接通过排序操作，就可能用到中间表用来存储获取的数据然后通过算法排序，这样效率比较低 使用索引排序的要求： 索引的列顺序和ORDER BY字句的顺序完全一致，并且所有列的排序方向都一样时。如果查询需要关联多张表，则只有当ORDER BY字句引用的字段全部为第一个表时，才能使用索引做排序 索引的第一列被只能为一个常数，也能使用索引排序 冗余和重复索引Mysql 需要单独维护重复的索引，并且优化器在优化查询的时候也需要逐个的进行考虑，这会影响性能 未使用的索引索引和锁Innodb只有在访问行的时候才会对其加锁，而索引能够减少Innodb访问的行数，从而减少锁的数量 查询性能优化为什么查询速度慢在每一个消耗大量时间的查询案例中，我们都能看到一些不必要的额外操作，某些操作被额外的重复了很多次、某些操作执行得太慢等。优化查询的目的就是减少和消除这些操作所花费的时间 慢查询基础：优化数据访问查询性能低下的最基本原因是访问的数据太多 确认应用程序是否在检索大量超过需要的数据即列数是否是你需要的 确认Mysql服务器层是否在分析大量超过需要的行 是否向数据库请求了不需要的数据 查询不需要的记录 多表关联时返回全部列 总是取出全部列 重复查询相同的数据 Mysql是否在扫描额外的记录 衡量查询开销的三个指标如下： 响应时间：等待时间和响应时间的总和 扫描的行数 返回的行数 扫描的行数和返回的行数：理想情况下扫描的行数和返回的行数相同；如果我们使用了索引，那么就会先从索引中得到我们需要的数据的主键，然后使用这个主键去聚簇索引中得到需要的数据，这样也就减少了扫描的行数；如果是全表扫描，那么就会把全部数据加载进内存，然后一个一个跟条件比较得到结果 扫描的行数和访问类型(type) 访问类型：扫描表、扫描索引、范围访问和单值访问 索引让Mysql以最高效、扫描行数最少的方式找到需要的记录 如果存在扫描的行数远大于返回的行数，一般的解决方式如下； 使用索引覆盖扫描，把所有需要用到的列都放到索引中 改变库表结构：例如使用单独的汇总表 重写这个复杂的查询，让Mysql优化器以更优化的方式去执行 重构查询方式 一个复杂查询还是多个简单查询 切分查询 分解关联查询 查询执行的基础Mysql发送一个请求的时候，Mysql到底做了些什么： 客户端发送 一条查询给服务器 服务器先检查查询缓存，如果命中了缓存，则立刻返回存储在缓存中的结果。否则进入下一阶段 服务器进行SQL解析、预处理，再由优化器生成对应的执行计划 Mysql根据优化器生产的执行计划、调用存储引擎的API来执行查询 将结果返回给客户端 Mysql客户端/服务器通信协议 查询状态 Sleep 线程正在等待客户端 Query 线程正在执行查询或者正在将结果发送给客户端 Locked 在Mysql服务器层，该线程正在等待表锁 Analyzing and statistics 线程正在收集存储引擎的统计信息，并生成查询的执行计划 Copying to tem table 线程正在执行查询，并且将其结果集收集都复制到一个临时表中 Storing result 线程正在对结果集进行排序 Sending data 线程可能在多个状态之间传递数据，或者在生成结果集，或者在向客户端返回数据 优化特定类型的查询 优化COUNT()查询 COUNT()的作用：是它可以统计某个列值的数量，也可以统计行数，在统计值时要求列值是非空的 关于MyISAM的神话： MyISAM的COUNT()函数总是非常快，这是个误解，只有在没有任何WHERE条件的COUNT(*)才非常快 简单的优化 优化LIMIT分页 为什么单纯的LIMIT性能不好，因为mysql会扫描全部数据，丢弃前面无用数据，然后只返回LIMIT的数据量 把LIMIT更改为使用 BETWEEN … AND 记录上一次查询返回的id，下一次从该id开始查询 ex：select * from rental where rental_id &lt; 16030 order by rental_id limit 201 Innodb存储引擎Innodb 锁机制Mysql 查看锁的操作 通过命令show engine innodb status命令查看当前锁请求信息 在infomation_schema 架构下添加了表Innodb_trx、innodb_locks、innodb_lock_waits；通过这三张表，用户可以更加简单地监控当前事务并分析可能存在的锁问题 共享锁和排他锁 一个共享锁允许事务持有这个锁来读取数据 一个排它锁允许事务持有这个锁来修改数据 意向锁 这个锁允许事务行级锁和表级锁同时存在 意向共享锁：事务想要获得一张表中某几行的共享锁 意向排它锁：事务想要获得一张表中某几行的排它锁 举例来说：在对记录r加X锁之前，已经有事务对表1进行了S表锁，那么表1上已经存在S锁，之后事务需要对记录r在表上加上IX，由于不兼容，所以该事务需要等待表锁操作的完成 记录锁（Record Lock）单个行记录上的锁，总是会锁住索引记录，有以下几点问题： 在不通过索引条件查询的时候，Innodb使用的是表锁，而不是行锁 当表有多个索引的时候，不同的事务可以使用不同的索引锁定不同的行，另外，不论是使用主键索引、唯一索引或普通索引，InnoDB都会使用行锁来对数据加锁。 即便在条件中使用了索引字段，但是否使用索引来检索数据是由MySQL通过判断不同执行计划的代价来决定的，如果MySQL认为全表扫描效率更高，比如对一些很小的表，它就不会使用索引，这种情况下InnoDB将使用表锁，而不是行锁。因此，在分析锁冲突时，别忘了检查SQL的执行计划，以确认是否真正使用了索引。 间隙锁（GAP Lock）间隙锁的作用是为了阻止多个事务将记录插入同一范围内，防止了幻读的出现 例如一个索引有10，11，13，20这四个值，那么该索引可能被Next-Key Locking的区间为： (-无穷， 10]； (10, 11]; (11, 13]; (13, 20]; (20, +无穷]; Next-Key Lock是记录锁 + 间隙锁的；在查询的列是唯一索引的时候，Next-Key Lock 会降级为记录锁；因为在Repeatable Read 中Innodb就会使用间隙锁，所以Repeatable Read 就能够解决幻读 缓冲池因为在事务中提到了内存拷贝，所以看了一些关于Mysql缓存 缓冲池的知识 缓冲池是主存储器中的一个区域，用于在访问时缓存表和索引数据。缓冲池允许直接从内存处理常用数据，从而加快处理速度。在专用服务器上，通常会将最多80％的物理内存分配给缓冲池。 为了提高大容量读取操作的效率，缓冲池被分成可以容纳多行的页面。为了提高缓存管理的效率，缓冲池被实现为链接的页面列表; 使用LRU算法的变体，很少使用的数据在缓存中老化 。 缓冲池LRU算法 Mysql缓冲池 分为两个部分 新字列表部分，旧字列表部分 其算法操作大致如下： 3/8的缓冲池专用于旧子列表 列表的中点是新子列表的尾部与旧子列表的头部相交的边界。 当InnoDB将页面读入缓冲池时，它最初将其插入中点（旧子列表的头部）。可以读取页面，因为它是用户指定的操作（如SQL查询）所必需的，或者是由自动执行的预读操作的一部分 InnoDB。 访问旧子列表中的页面使其 “ 年轻 ”，将其移动到缓冲池的头部（新子列表的头部）。如果因为需要而读取页面，则会立即进行第一次访问，并使页面变得年轻。如果由于预读而读取了页面，则第一次访问不会立即发生（并且在页面被逐出之前可能根本不会发生）。 随着数据库的运行，在缓冲池的页面没有被访问的“ 年龄 ”通过向列表的尾部移动。新旧子列表中的页面随着其他页面的变化而变旧。旧子列表中的页面也会随着页面插入中点而老化。最终，仍然未使用的页面到达旧子列表的尾部并被逐出。 Innodb 页结构InnoDB数据页由以下七个部分组成，如图所示： File Header（文件头）。 Page Header（页头）。 Infimun+Supremum Records。 User Records（用户记录，即行记录）。 Free Space（空闲空间）。 Page Directory（页目录）。 File Trailer（文件结尾信息）。 我这里主要想说三四点： 非聚餐索引就是这种形式存储所有记录的；也就是说每个B+-Tree叶子结点都是一个页，存储了具体的记录；B+树索引本身并不能找到具体的一条记录，B+树索引能找到只是该记录所在的页。数据库把页载入内存，然后通过Page Directory再进行二叉查找。只不过二叉查找的时间复杂度很低，同时内存中的查找很快，因此通常我们忽略了这部分查找所用的时间。 其它什么情况下会使用临时内存表EXPLAIN 字段说明 type system：表中只有一行数据或者是空表，且只能用于myisam和memory表。如果是Innodb引擎表，type列在这个情况通常都是all或者index const：使用唯一索引或者主键，返回记录一定是1行记录的等值where条件时，通常type是const。 ex：select * from student where student_id = 1; eq_ref：出现在要连接过个表的查询计划中，驱动表只返回一行数据，且这行数据是第二个表的主键或者唯一索引，且必须为not null，唯一索引和主键是多列时，只有所有的列都用作比较时才会出现eq_ref ex：explain select * from book,student where student.id = book.id; ![](https://ws1.sinaimg.cn/large/a67bf22fgy1fu0b5mr61nj20wj026mx8.jpg) ref：不像eq_ref那样要求连接顺序，也没有主键和唯一索引的要求，只要使用相等条件检索时就可能出现，常见与辅助索引的等值查找。或者多列主键、唯一索引中，使用第一个列之外的列作为等值查找也会出现，总之，返回数据不唯一的等值查找就可能出现。 使用了辅助索引的返回列数不唯一的查询 ex：select * from student where name=”梅勇杰” and sex=”男” 二种情况：过滤条件都有索引；多列主键、唯一索引，使用第一个列之外的列作为等值查找； fulltext：全文索引检索，要注意，全文索引的优先级很高，若全文索引和普通索引同时存在时，mysql不管代价，优先选择使用全文索引 index_merge：表示查询使用了两个以上的索引，最后取交集或者并集，常见and ，or的条件使用了不同的索引，官方排序这个在ref_or_null之后，但是实际上由于要读取所有索引，性能可能大部分时间都不如range ex：select * from student where name=”梅勇杰” and sex=”男” unique_subquery：用于where中的in形式子查询，子查询返回不重复值唯一值 index_subquery：用于in形式子查询使用到了辅助索引或者in常数列表，子查询可能返回重复值，可以使用索引将子查询去重 range：索引范围扫描，常见于使用 =, &lt;&gt;, &gt;, &gt;=, &lt;, &lt;=, IS NULL, &lt;=&gt;, BETWEEN, IN()或者like等运算符的查询中 index：索引全表扫描，把索引从头到尾扫一遍，常见于使用索引列就可以处理不需要读取数据文件的查询、可以使用索引排序或者分组的查询 all：这个就是全表扫描数据文件，然后再在server层进行过滤返回符合要求的记录 partitions 该列显示的为分区表命中的分区情况。 possible_keys 查询可能使用到的索引都会在这里列出来 key 查询真正使用到的索引，select_type为index_merge时，这里可能出现两个以上的索引，其他的select_type这里只会出现一个 key_len 用于处理查询的索引长度，如果是单列索引，那就整个索引长度算进去，如果是多列索引，那么查询不一定都能使用到所有的列，具体使用到了多少个列的索引，这里就会计算进去，没有使用到的列，这里不会计算进去。留意下这个列的值，算一下你的多列索引总长度就知道有没有使用到所有的列了。要注意，mysql的ICP特性使用到的索引不会计入其中。另外，key_len只计算where条件用到的索引长度，而排序和分组就算用到了索引，也不会计算到key_len中。 ref 如果是使用的常数等值查询，这里会显示const，如果是连接查询，被驱动表的执行计划这里会显示驱动表的关联字段，如果是条件使用了表达式或者函数，或者条件列发生了内部隐式转换，这里可能显示为func rows 这里是执行计划中估算的扫描行数，不是精确值 ；即按照辅助索引查找到的应该去聚集索引查找的数据行 filtered filtered = 最终结果的行数 / rows * 100% ； 即在Mysql服务器层对数据行过滤效果 extra 对于extra列，官网上有这样一段话： If you want to make your queries as fast as possible, look out for Extra column values of Using filesort and Using temporary, or, in JSON-formatted EXPLAINoutput, for using_filesort and using_temporary_table properties equal to true. 大概的意思就是说，如果你想要优化你的查询，那就要注意extra辅助信息中的using filesort和using temporary，这两项非常消耗性能，需要注意。 这个列可以显示的信息非常多，有几十种，常用的有： A：distinct：在select部分使用了distinc关键字 B：no tables used：不带from字句的查询或者From dual查询 C：使用not in()形式子查询或not exists运算符的连接查询，这种叫做反连接。即，一般连接查询是先查询内表，再查询外表，反连接就是先查询外表，再查询内表。 D：using filesort：排序时无法使用到索引时，就会出现这个。常见于order by和group by语句中 E：using index：查询时不需要回表查询，直接通过索引就可以获取查询的数据。 F：using join buffer（block nested loop），using join buffer（batched key accss）：5.6.x之后的版本优化关联查询的BNL，BKA特性。主要是减少内表的循环数量以及比较顺序地扫描查询。 G：using sort_union，using_union，using intersect，using sort_intersection： using intersect：表示使用and的各个索引的条件时，该信息表示是从处理结果获取交集 using union：表示使用or连接各个使用索引的条件时，该信息表示从处理结果获取并集 using sort_union和using sort_intersection：与前面两个对应的类似，只是他们是出现在用and和or查询信息量大时，先查询主键，然后进行排序合并后，才能读取记录并返回。 H：using temporary：表示使用了临时表存储中间结果。临时表可以是内存临时表和磁盘临时表，执行计划中看不出来，需要查看status变量，used_tmp_table，used_tmp_disk_table才能看出来。 I：using where：表示存储引擎返回的记录并不是所有的都满足查询条件，需要在server层进行过滤。查询条件中分为限制条件和检查条件，5.6之前，存储引擎只能根据限制条件扫描数据并返回，然后server层根据检查条件进行过滤再返回真正符合查询的数据。5.6.x之后支持ICP特性，可以把检查条件也下推到存储引擎层，不符合检查条件和限制条件的数据，直接不读取，这样就大大减少了存储引擎扫描的记录数量。extra列显示using index condition J：firstmatch(tb_name)：5.6.x开始引入的优化子查询的新特性之一，常见于where字句含有in()类型的子查询。如果内表的数据量比较大，就可能出现这个 K：loosescan(m..n)：5.6.x之后引入的优化子查询的新特性之一，在in()类型的子查询中，子查询返回的可能有重复记录时，就可能出现这个 除了这些之外，还有很多查询数据字典库，执行计划过程中就发现不可能存在结果的一些提示信息 filtered 使用explain extended时会出现这个列，5.7之后的版本默认就有这个字段，不需要使用explain extended了。这个字段表示存储引擎返回的数据在server层过滤后，剩下多少满足查询的记录数量的比例，注意是百分比，不是具体记录数。 参考explain字段说明：https://www.jianshu.com/p/73f2c8448722 Mysql 一篇全面的博客]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2018%2F07%2F23%2FJavaweb%2FSpring%20%E6%BA%90%E7%A0%81%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[SpringBoot AutoConfigure 流程自动配置的入口 是@SpringBootApplication 里面的@EnableAutoConfiguration注解 在@EnableAutoConfiguration注解里面import了AutoConfigurationImportSelector这个类 在SpringBoot refresh IOC容器调用BeanFactory的后置处理器ConfigurationClassPostProcessor的时候会调用AutoConfigurationImportSelector 的selectImports方法得到所有需要自动配置的类 123456789101112131415161718@Overridepublic String[] selectImports(AnnotationMetadata annotationMetadata) &#123; if (!isEnabled(annotationMetadata)) &#123; return NO_IMPORTS; &#125; AutoConfigurationMetadata autoConfigurationMetadata = AutoConfigurationMetadataLoader .loadMetadata(this.beanClassLoader); AnnotationAttributes attributes = getAttributes(annotationMetadata); List&lt;String&gt; configurations = getCandidateConfigurations(annotationMetadata, attributes); configurations = removeDuplicates(configurations); Set&lt;String&gt; exclusions = getExclusions(annotationMetadata, attributes); checkExcludedClasses(configurations, exclusions); configurations.removeAll(exclusions); configurations = filter(configurations, autoConfigurationMetadata); fireAutoConfigurationImportEvents(configurations, exclusions); return StringUtils.toStringArray(configurations);&#125; 这个方法是自动配置的核心过程 再看其中的getCandidateConfigurations方法 123456789protected List&lt;String&gt; getCandidateConfigurations(AnnotationMetadata metadata, AnnotationAttributes attributes) &#123; List&lt;String&gt; configurations = SpringFactoriesLoader.loadFactoryNames( getSpringFactoriesLoaderFactoryClass(), getBeanClassLoader()); Assert.notEmpty(configurations, "No auto configuration classes found in META-INF/spring.factories. If you " + "are using a custom packaging, make sure that file is correct."); return configurations; &#125; 这里有一个SpringFactoriesLoader，这本质是Spring将自动配置的类导入IOC容器的核心工具类，下面我会详细讲 SpringFactoryLoader有以下四个方法 1234567891011121314151617181920/*** 如果是第一次调用，这个方法会将类路径下所有META-INF/spring.factories里的键值对与 classLoader绑* 保存下来保存在SpringFactoriesLoader 中的名为cache的Map里面*/private static Map&lt;String, List&lt;String&gt;&gt; loadSpringFactories(@Nullable ClassLoader classLoader)/*** 从cache里面查找factoryClass键对应的类全路径，有那么将其加载到内存中，注意没有实例化*/public static &lt;T&gt; List&lt;T&gt; loadFactories(Class&lt;T&gt; factoryClass, @Nullable ClassLoader classLoader);/*** 查找指定factoryClass的类对应的所有类全路径*/public static List&lt;String&gt; loadFactoryNames(Class&lt;?&gt; factoryClass, @Nullable ClassLoader classLoader);/*** 将指定类实例化*/private static &lt;T&gt; T instantiateFactory(String instanceClassName, Class&lt;T&gt; factoryClass, ClassLoader classLoader) 现在再来理解 getCandidateConfigurations中的这段代码 12List&lt;String&gt; configurations = SpringFactoriesLoader.loadFactoryNames( getSpringFactoriesLoaderFactoryClass(), getBeanClassLoader()); getSpringFactoriesLoaderFactoryClass() 返回的是EnableAutoConfiguration.class 那么会将SpringBootAutoConfigure这个jar包下META-INF/spring.factories 里面EnableAutoConfiguration类全路径键对应的全部类全路径值全部加载到SpringLoaderFactory cache里面 Spring Boot 内置Web容器创建启动流程这里以Tomcat容器为例 内置Web容器的创建的入口是 ServletWebServerApplicationContext 的onRefresh()方法 其中调用了 createWebServer(); 方法 12345678910111213141516171819private void createWebServer() &#123; WebServer webServer = this.webServer; ServletContext servletContext = getServletContext(); if (webServer == null &amp;&amp; servletContext == null) &#123; ServletWebServerFactory factory = getWebServerFactory(); // 在这里创建了WebServer this.webServer = factory.getWebServer(getSelfInitializer()); &#125; else if (servletContext != null) &#123; try &#123; getSelfInitializer().onStartup(servletContext); &#125; catch (ServletException ex) &#123; throw new ApplicationContextException("Cannot initialize servlet context", ex); &#125; &#125; initPropertySources();&#125; 1234567891011121314151617181920// 创建了Tomcat容器 @Override public WebServer getWebServer(ServletContextInitializer... initializers) &#123; Tomcat tomcat = new Tomcat(); File baseDir = (this.baseDirectory != null ? this.baseDirectory : createTempDir("tomcat")); tomcat.setBaseDir(baseDir.getAbsolutePath()); Connector connector = new Connector(this.protocol); tomcat.getService().addConnector(connector); customizeConnector(connector); tomcat.setConnector(connector); tomcat.getHost().setAutoDeploy(false); configureEngine(tomcat.getEngine()); for (Connector additionalConnector : this.additionalTomcatConnectors) &#123; tomcat.getService().addConnector(additionalConnector); &#125; // 在这里准备创建应用上下文 prepareContext(tomcat.getHost(), initializers); return getTomcatWebServer(tomcat); &#125; 123456789101112131415161718192021222324252627282930313233343536373839protected void prepareContext(Host host, ServletContextInitializer[] initializers) &#123; File documentRoot = getValidDocumentRoot(); // 这个就是创建了应用上下文 它是继承于StandartContext // 下面都是在给它设置属性值，比如就在这里设置了它的ClassLoader TomcatEmbeddedContext context = new TomcatEmbeddedContext(); if (documentRoot != null) &#123; context.setResources(new LoaderHidingResourceRoot(context)); &#125; context.setName(getContextPath()); context.setDisplayName(getDisplayName()); context.setPath(getContextPath()); File docBase = (documentRoot != null ? documentRoot : createTempDir("tomcat-docbase")); context.setDocBase(docBase.getAbsolutePath()); context.addLifecycleListener(new FixContextListener()); context.setParentClassLoader( this.resourceLoader != null ? this.resourceLoader.getClassLoader() : ClassUtils.getDefaultClassLoader()); resetDefaultLocaleMapping(context); addLocaleMappings(context); context.setUseRelativeRedirects(false); configureTldSkipPatterns(context); WebappLoader loader = new WebappLoader(context.getParentClassLoader()); loader.setLoaderClass(TomcatEmbeddedWebappClassLoader.class.getName()); loader.setDelegate(true); context.setLoader(loader); if (isRegisterDefaultServlet()) &#123; addDefaultServlet(context); &#125; if (shouldRegisterJspServlet()) &#123; addJspServlet(context); addJasperInitializer(context); &#125; context.addLifecycleListener(new StaticResourceConfigurer(context)); ServletContextInitializer[] initializersToUse = mergeInitializers(initializers); host.addChild(context); configureContext(context, initializersToUse); postProcessContext(context);&#125; 上面的步骤就将WebServer创建完成，并且已经将该应用对应的上下文已经准备好 内置Web容器启动入口在 ServletWebServerApplicationContext 的finishRefresh() 1234567private WebServer startWebServer() &#123; WebServer webServer = this.webServer; if (webServer != null) &#123; webServer.start(); &#125; return webServer;&#125; 12345678910111213141516171819202122232425262728293031323334@Overridepublic void start() throws WebServerException &#123; synchronized (this.monitor) &#123; if (this.started) &#123; return; &#125; try &#123; addPreviouslyRemovedConnectors(); Connector connector = this.tomcat.getConnector(); if (connector != null &amp;&amp; this.autoStart) &#123; // 重点关注这个方法 performDeferredLoadOnStartup(); &#125; checkThatConnectorsHaveStarted(); this.started = true; TomcatWebServer.logger .info("Tomcat started on port(s): " + getPortsDescription(true) + " with context path '" + getContextPath() + "'"); &#125; catch (ConnectorStartFailedException ex) &#123; stopSilently(); throw ex; &#125; catch (Exception ex) &#123; throw new WebServerException("Unable to start embedded Tomcat server", ex); &#125; finally &#123; Context context = findContext(); ContextBindings.unbindClassLoader(context, context.getNamingToken(), getClass().getClassLoader()); &#125; &#125;&#125; 12345678910111213141516private void performDeferredLoadOnStartup() &#123; try &#123; // 取得内置tomcat 虚拟主机的应用上下文， 也就是刚刚创建的TomcatEmbeddedContext for (Container child : this.tomcat.getHost().findChildren()) &#123; if (child instanceof TomcatEmbeddedContext) &#123; //这里就是加载Context下的Servlet ((TomcatEmbeddedContext) child).deferredLoadOnStartup(); &#125; &#125; &#125; catch (Exception ex) &#123; TomcatWebServer.logger.error("Cannot start connector: ", ex); throw new WebServerException("Unable to start embedded Tomcat connectors", ex); &#125;&#125; #### Spring IOCSpring IOC概述 依赖反转：把控制权从具体的业务对象手中转交到平台或者框架中，Spring IOC就是实现这个模式的载体 为什么要使用Spring IOC 因为在面向对象程序设计中，一个对象会包含其它的对象，如果合伙对象的引用或依赖关系的管理有具体对象来完成，会导致代码的高度耦合和可测试性降低；如果把对象的管理和对象的注入都 交给Spring IOC来处理，那么解耦代码的同时还提高了可测试性 GenericApplicationContext的类图 IOC容器的初始化过程 这里就会涉及到一个方法refresh，下面是它的源码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445 public void refresh() throws BeansException, IllegalStateException &#123; Object var1 = this.startupShutdownMonitor; synchronized(this.startupShutdownMonitor) &#123; //初始化IOC容器之前的准备工作 this.prepareRefresh(); //得到一个BeanFactory,并且调用refreshBeanFactory(),这个方法会进行Bean的定位 、载入和 //注册；但是在我看AnnotationConfigApplicationContext源码的时候，我没有发现它的载入和注 //册 ConfigurableListableBeanFactory beanFactory = this.obtainFreshBeanFactory(); //给BeanFactory设置一些属性 this.prepareBeanFactory(beanFactory); try &#123; //设置BeanFactory的后置处理 this.postProcessBeanFactory(beanFactory); //调用BeanFactory的后置处理器，这些处理器是在IOC容器中通过Bean注册的 this.invokeBeanFactoryPostProcessors(beanFactory); //注册Bean的后处理器，在Bena的创建过程中调用 this.registerBeanPostProcessors(beanFactory); //对上下文中的消息源进行初始化 this.initMessageSource(); //初始化上下文中的事件机制 this.initApplicationEventMulticaster(); //初始化其它特殊的Bean this.onRefresh(); //检查监听Bean并且将这些Bean向容器注册 this.registerListeners(); //实例化所有的单件 this.finishBeanFactoryInitialization(beanFactory); //发布容器事件，结束refresh过程 this.finishRefresh(); &#125; catch (BeansException var9) &#123; if (this.logger.isWarnEnabled()) &#123; this.logger.warn("Exception encountered during context initialization - cancelling refresh attempt: " + var9); &#125; //为防止Bean资源占用，在异常处理中销毁已经创建的单件Bean this.destroyBeans(); //重置'active'标志 this.cancelRefresh(var9); throw var9; &#125; finally &#123; this.resetCommonCaches(); &#125; &#125;&#125; 这个方法涉及到了BeanDefinition的定位、载入和注册三个基本过程 载入过程 Resource Resource 是一个对加载对象的描述，被加载对象里面封装了Bean的定义；这里使用了策略模式，不同Resource 可以使用不同的Resource的实现 ResourceLoader ResourceLoader 也有也有不同的实现，所以也是使用了策略模式，在不同情况下使用不同的ResourceLoader ;下面是AbstractApplicationContext 实现的ResourcePatternResolver的方法，实现了加载Resource 1234@Override public Resource[] getResources(String locationPattern) throws IOException &#123; return this.resourcePatternResolver.getResources(locationPattern); &#125; BeanDefinition BeanDefinition 在XMl中对应了里面的内容，&lt;bean&gt;元素标签拥有class、scope、lazy-init等配置属性，BeanDefinition则提供了相应的beanClass、scope、lazyInit属性，封装了对该对象实例化的时候的处理 实例化 12345678910111213141516171819202122try &#123; final RootBeanDefinition mbd = getMergedLocalBeanDefinition(beanName); checkMergedBeanDefinition(mbd, beanName, args); // Guarantee initialization of beans that the current bean depends on. String[] dependsOn = mbd.getDependsOn(); if (dependsOn != null) &#123; for (String dep : dependsOn) &#123; if (isDependent(beanName, dep)) &#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, "Circular depends-on relationship between '" + beanName + "' and '" + dep + "'"); &#125; registerDependentBean(dep, beanName); try &#123; getBean(dep); &#125; catch (NoSuchBeanDefinitionException ex) &#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, "'" + beanName + "' depends on missing bean '" + dep + "'", ex); &#125; &#125; &#125; 得到beanName 对应的RootBeanDefinition 取得RootBeanDefinition 对应的所有依赖 检查是否有自循环依赖 递归将RootBeanDefinition 依赖对象实例化到IOC 容器中 通过 populate 方法自动注入需要自动注入的对象 IOC容器的依赖注入 涉及到的源码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142// AbstractBeanFactory public &lt;T&gt; T getBean(String name, @Nullable Class&lt;T&gt; requiredType) throws BeansException &#123; return this.doGetBean(name, requiredType, (Object[])null, false); &#125; protected &lt;T&gt; T doGetBean(String name, @Nullable Class&lt;T&gt; requiredType, @Nullable Object[] args, boolean typeCheckOnly) throws BeansException &#123; String beanName = this.transformedBeanName(name); //从缓存中得到对象，避免重复创建 Object sharedInstance = this.getSingleton(beanName); Object bean; if (sharedInstance != null &amp;&amp; args == null) &#123; if (this.logger.isDebugEnabled()) &#123; if (this.isSingletonCurrentlyInCreation(beanName)) &#123; this.logger.debug("Returning eagerly cached instance of singleton bean '" + beanName + "' that is not fully initialized yet - a consequence of a circular reference"); &#125; else &#123; this.logger.debug("Returning cached instance of singleton bean '" + beanName + "'"); &#125; &#125; //因为IOC中有FactoryBean和普通Bean两种，所以这里就是如果这个Bean是FactoryBean， //就取得它的真实对象 bean = this.getObjectForBeanInstance(sharedInstance, name, beanName, (RootBeanDefinition)null); //下面就是从父级容器里面得到Bean &#125; else &#123; if (this.isPrototypeCurrentlyInCreation(beanName)) &#123; throw new BeanCurrentlyInCreationException(beanName); &#125; BeanFactory parentBeanFactory = this.getParentBeanFactory(); if (parentBeanFactory != null &amp;&amp; !this.containsBeanDefinition(beanName)) &#123; String nameToLookup = this.originalBeanName(name); if (parentBeanFactory instanceof AbstractBeanFactory) &#123; return ((AbstractBeanFactory)parentBeanFactory).doGetBean(nameToLookup, requiredType, args, typeCheckOnly); &#125; if (args != null) &#123; return parentBeanFactory.getBean(nameToLookup, args); &#125; return parentBeanFactory.getBean(nameToLookup, requiredType); &#125; if (!typeCheckOnly) &#123; this.markBeanAsCreated(beanName); &#125; //处理依赖，创建Bean try &#123; RootBeanDefinition mbd = this.getMergedLocalBeanDefinition(beanName); this.checkMergedBeanDefinition(mbd, beanName, args); String[] dependsOn = mbd.getDependsOn(); String[] var11; if (dependsOn != null) &#123; var11 = dependsOn; int var12 = dependsOn.length; for(int var13 = 0; var13 &lt; var12; ++var13) &#123; String dep = var11[var13]; if (this.isDependent(beanName, dep)) &#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, "Circular depends-on relationship between '" + beanName + "' and '" + dep + "'"); &#125; this.registerDependentBean(dep, beanName); try &#123; this.getBean(dep); &#125; catch (NoSuchBeanDefinitionException var24) &#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, "'" + beanName + "' depends on missing bean '" + dep + "'", var24); &#125; &#125; &#125; if (mbd.isSingleton()) &#123; sharedInstance = this.getSingleton(beanName, () -&gt; &#123; try &#123; return this.createBean(beanName, mbd, args); &#125; catch (BeansException var5) &#123; this.destroySingleton(beanName); throw var5; &#125; &#125;); bean = this.getObjectForBeanInstance(sharedInstance, name, beanName, mbd); &#125; else if (mbd.isPrototype()) &#123; var11 = null; Object prototypeInstance; try &#123; this.beforePrototypeCreation(beanName); prototypeInstance = this.createBean(beanName, mbd, args); &#125; finally &#123; this.afterPrototypeCreation(beanName); &#125; bean = this.getObjectForBeanInstance(prototypeInstance, name, beanName, mbd); &#125; else &#123; String scopeName = mbd.getScope(); Scope scope = (Scope)this.scopes.get(scopeName); if (scope == null) &#123; throw new IllegalStateException("No Scope registered for scope name '" + scopeName + "'"); &#125; try &#123; Object scopedInstance = scope.get(beanName, () -&gt; &#123; this.beforePrototypeCreation(beanName); Object var4; try &#123; var4 = this.createBean(beanName, mbd, args); &#125; finally &#123; this.afterPrototypeCreation(beanName); &#125; return var4; &#125;); bean = this.getObjectForBeanInstance(scopedInstance, name, beanName, mbd); &#125; catch (IllegalStateException var23) &#123; throw new BeanCreationException(beanName, "Scope '" + scopeName + "' is not active for the current thread; consider defining a scoped proxy for this bean if you intend to refer to it from a singleton", var23); &#125; &#125; &#125; catch (BeansException var26) &#123; this.cleanupAfterBeanCreationFailure(beanName); throw var26; &#125; &#125; if (requiredType != null &amp;&amp; !requiredType.isInstance(bean)) &#123; try &#123; T convertedBean = this.getTypeConverter().convertIfNecessary(bean, requiredType); if (convertedBean == null) &#123; throw new BeanNotOfRequiredTypeException(name, requiredType, bean.getClass()); &#125; else &#123; return convertedBean; &#125; &#125; catch (TypeMismatchException var25) &#123; if (this.logger.isDebugEnabled()) &#123; this.logger.debug("Failed to convert bean '" + name + "' to required type '" + ClassUtils.getQualifiedName(requiredType) + "'", var25); &#125; throw new BeanNotOfRequiredTypeException(name, requiredType, bean.getClass()); &#125; &#125; else &#123; return bean; &#125; &#125; doGetBean的流程图: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485protected Object doCreateBean(String beanName, RootBeanDefinition mbd, @Nullable Object[] args) throws BeanCreationException &#123; BeanWrapper instanceWrapper = null; if (mbd.isSingleton()) &#123; instanceWrapper = (BeanWrapper)this.factoryBeanInstanceCache.remove(beanName); &#125; if (instanceWrapper == null) &#123; instanceWrapper = this.createBeanInstance(beanName, mbd, args); &#125; Object bean = instanceWrapper.getWrappedInstance(); Class&lt;?&gt; beanType = instanceWrapper.getWrappedClass(); if (beanType != NullBean.class) &#123; mbd.resolvedTargetType = beanType; &#125; Object var7 = mbd.postProcessingLock; synchronized(mbd.postProcessingLock) &#123; if (!mbd.postProcessed) &#123; try &#123; this.applyMergedBeanDefinitionPostProcessors(mbd, beanType, beanName); &#125; catch (Throwable var17) &#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, "Post-processing of merged bean definition failed", var17); &#125; mbd.postProcessed = true; &#125; &#125; boolean earlySingletonExposure = mbd.isSingleton() &amp;&amp; this.allowCircularReferences &amp;&amp; this.isSingletonCurrentlyInCreation(beanName); if (earlySingletonExposure) &#123; if (this.logger.isDebugEnabled()) &#123; this.logger.debug("Eagerly caching bean '" + beanName + "' to allow for resolving potential circular references"); &#125; this.addSingletonFactory(beanName, () -&gt; &#123; return this.getEarlyBeanReference(beanName, mbd, bean); &#125;); &#125; Object exposedObject = bean; try &#123; this.populateBean(beanName, mbd, instanceWrapper); exposedObject = this.initializeBean(beanName, exposedObject, mbd); &#125; catch (Throwable var18) &#123; if (var18 instanceof BeanCreationException &amp;&amp; beanName.equals(((BeanCreationException)var18).getBeanName())) &#123; throw (BeanCreationException)var18; &#125; throw new BeanCreationException(mbd.getResourceDescription(), beanName, "Initialization of bean failed", var18); &#125; if (earlySingletonExposure) &#123; Object earlySingletonReference = this.getSingleton(beanName, false); if (earlySingletonReference != null) &#123; if (exposedObject == bean) &#123; exposedObject = earlySingletonReference; &#125; else if (!this.allowRawInjectionDespiteWrapping &amp;&amp; this.hasDependentBean(beanName)) &#123; String[] dependentBeans = this.getDependentBeans(beanName); Set&lt;String&gt; actualDependentBeans = new LinkedHashSet(dependentBeans.length); String[] var12 = dependentBeans; int var13 = dependentBeans.length; for(int var14 = 0; var14 &lt; var13; ++var14) &#123; String dependentBean = var12[var14]; if (!this.removeSingletonIfCreatedForTypeCheckOnly(dependentBean)) &#123; actualDependentBeans.add(dependentBean); &#125; &#125; if (!actualDependentBeans.isEmpty()) &#123; throw new BeanCurrentlyInCreationException(beanName, "Bean with name '" + beanName + "' has been injected into other beans [" + StringUtils.collectionToCommaDelimitedString(actualDependentBeans) + "] in its raw version as part of a circular reference, but has eventually been wrapped. This means that said other beans do not use the final version of the bean. This is often the result of over-eager type matching - consider using 'getBeanNamesOfType' with the 'allowEagerInit' flag turned off, for example."); &#125; &#125; &#125; &#125; try &#123; this.registerDisposableBeanIfNecessary(beanName, bean, mbd); return exposedObject; &#125; catch (BeanDefinitionValidationException var16) &#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, "Invalid destruction signature", var16); &#125; &#125; 这里有个BeanWapper，这个BeanWapper的作用是管理Bean的属性 容器相关特性的设计与实现ApplicationContext和Bean的初始化和销毁ApplicationContext初始化:prepareBeanFactory() ApplicationContext的销毁：doClose(); 容器的实现是通过IOC管理Bean生命周期来实现的： initailizeBean；doClose；destroy lazy-init属性和预实例化FactoryBean的实现其实在我看来FactoryBean其实就是Spring 帮我们封装一个简化的工厂方法，我们可以把这个FactoryBean放在IOC容器里面，然后通过这个工厂类生成我们想要的类 主要涉及到的源码： 1234567891011121314151617181920212223242526272829303132protected Object getObjectForBeanInstance(Object beanInstance, String name, String beanName, @Nullable RootBeanDefinition mbd) &#123; if (BeanFactoryUtils.isFactoryDereference(name)) &#123; if (beanInstance instanceof NullBean) &#123; return beanInstance; &#125; if (!(beanInstance instanceof FactoryBean)) &#123; throw new BeanIsNotAFactoryException(this.transformedBeanName(name), beanInstance.getClass()); &#125; &#125; if (beanInstance instanceof FactoryBean &amp;&amp; !BeanFactoryUtils.isFactoryDereference(name)) &#123; Object object = null; if (mbd == null) &#123; object = this.getCachedObjectForFactoryBean(beanName); &#125; if (object == null) &#123; FactoryBean&lt;?&gt; factory = (FactoryBean)beanInstance; if (mbd == null &amp;&amp; this.containsBeanDefinition(beanName)) &#123; mbd = this.getMergedLocalBeanDefinition(beanName); &#125; boolean synthetic = mbd != null &amp;&amp; mbd.isSynthetic(); object = this.getObjectFromFactoryBean(factory, beanName, !synthetic); &#125; return object; &#125; else &#123; return beanInstance; &#125; &#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647protected Object getObjectFromFactoryBean(FactoryBean&lt;?&gt; factory, String beanName, boolean shouldPostProcess) &#123; if (factory.isSingleton() &amp;&amp; this.containsSingleton(beanName)) &#123; synchronized(this.getSingletonMutex()) &#123; Object object = this.factoryBeanObjectCache.get(beanName); if (object == null) &#123; object = this.doGetObjectFromFactoryBean(factory, beanName); Object alreadyThere = this.factoryBeanObjectCache.get(beanName); if (alreadyThere != null) &#123; object = alreadyThere; &#125; else &#123; if (shouldPostProcess) &#123; if (this.isSingletonCurrentlyInCreation(beanName)) &#123; return object; &#125; this.beforeSingletonCreation(beanName); try &#123; object = this.postProcessObjectFromFactoryBean(object, beanName); &#125; catch (Throwable var14) &#123; throw new BeanCreationException(beanName, "Post-processing of FactoryBean's singleton object failed", var14); &#125; finally &#123; this.afterSingletonCreation(beanName); &#125; &#125; if (this.containsSingleton(beanName)) &#123; this.factoryBeanObjectCache.put(beanName, object); &#125; &#125; &#125; return object; &#125; &#125; else &#123; Object object = this.doGetObjectFromFactoryBean(factory, beanName); if (shouldPostProcess) &#123; try &#123; object = this.postProcessObjectFromFactoryBean(object, beanName); &#125; catch (Throwable var17) &#123; throw new BeanCreationException(beanName, "Post-processing of FactoryBean's object failed", var17); &#125; &#125; return object; &#125;&#125; 上面两个方法解释了从FactoryBean取得真实对象 BeanPostProcessor的实现这个我们看源码的initializeBean方法就行 1234567891011121314151617181920212223242526272829protected Object initializeBean(String beanName, Object bean, @Nullable RootBeanDefinition mbd) &#123; if (System.getSecurityManager() != null) &#123; AccessController.doPrivileged(() -&gt; &#123; this.invokeAwareMethods(beanName, bean); return null; &#125;, this.getAccessControlContext()); &#125; else &#123; this.invokeAwareMethods(beanName, bean); &#125; //得到的是一个BeanWapper Object wrappedBean = bean; if (mbd == null || !mbd.isSynthetic()) &#123; //这里就会一次调用所有Bean创建的前置处理器 wrappedBean = this.applyBeanPostProcessorsBeforeInitialization(bean, beanName); &#125; try &#123; //初始化Bean this.invokeInitMethods(beanName, wrappedBean, mbd); &#125; catch (Throwable var6) &#123; throw new BeanCreationException(mbd != null ? mbd.getResourceDescription() : null, beanName, "Invocation of init method failed", var6); &#125; if (mbd == null || !mbd.isSynthetic()) &#123; //调用所有Bean创建的后置处理器 wrappedBean = this.applyBeanPostProcessorsAfterInitialization(wrappedBean, beanName); &#125; return wrappedBean;&#125; 这个方法会在getBean -&gt;doGetBean() -&gt;createBean-&gt; doCreateBean中调用 autowiring 的实现123456789101112if (mbd.getResolvedAutowireMode() == 1 || mbd.getResolvedAutowireMode() == 2) &#123; MutablePropertyValues newPvs = new MutablePropertyValues((PropertyValues)pvs); if (mbd.getResolvedAutowireMode() == 1) &#123; this.autowireByName(beanName, mbd, bw, newPvs); &#125; if (mbd.getResolvedAutowireMode() == 2) &#123; this.autowireByType(beanName, mbd, bw, newPvs); &#125; pvs = newPvs;&#125; 这是自动装配的实现，在AbstractAutowireCapableBeanFactory的populateBean方法中，这个populateBean 会在调用doCreateBean中调用 Bean的生命周期流程 在这个方法里面，有许多用户自定义 这个方法的调用链是：getBean -&gt; doGetBean -&gt;doCreateBean -&gt;initializeBean 1234567891011121314151617181920212223242526272829303132333435//AbstractAutowireCapableBeanFactory protected Object initializeBean(final String beanName, final Object bean, @Nullable RootBeanDefinition mbd) &#123; if (System.getSecurityManager() != null) &#123; AccessController.doPrivileged((PrivilegedAction&lt;Object&gt;) () -&gt; &#123; invokeAwareMethods(beanName, bean); return null; &#125;, getAccessControlContext()); &#125; else &#123; // 实现有关Aware接口的方法 invokeAwareMethods(beanName, bean); &#125; Object wrappedBean = bean; // 调用Bean的前置处理器 if (mbd == null || !mbd.isSynthetic()) &#123; wrappedBean = applyBeanPostProcessorsBeforeInitialization(wrappedBean, beanName); &#125; try &#123; // 调用init方法，如果class 实现了InitializingBean接口，还会调用afterPropertiesSet方法；这两种方式都可以达到初始化实例的目的 invokeInitMethods(beanName, wrappedBean, mbd); &#125; catch (Throwable ex) &#123; throw new BeanCreationException( (mbd != null ? mbd.getResourceDescription() : null), beanName, "Invocation of init method failed", ex); &#125; if (mbd == null || !mbd.isSynthetic()) &#123; //调用Bean的后置处理器 wrappedBean = applyBeanPostProcessorsAfterInitialization(wrappedBean, beanName); &#125; return wrappedBean; &#125; 循环依赖问题构造器注入不能解决循环依赖，如果Bean的作用域为Prototype 也是不能解决循环依赖的，因为Spring中没有提前暴露对象的引用，从下面的代码中体现 1234567// AbstractBeanFactoryprotected &lt;T&gt; T doGetBean(final String name, @Nullable final Class&lt;T&gt; requiredType, @Nullable final Object[] args, boolean typeCheckOnly) throws BeansException &#123; if (isPrototypeCurrentlyInCreation(beanName)) &#123; throw new BeanCurrentlyInCreationException(beanName); &#125;&#125; 怎么检测Prototype产生循环依赖的 12345protected boolean isPrototypeCurrentlyInCreation(String beanName) &#123; Object curVal = this.prototypesCurrentlyInCreation.get(); return (curVal != null &amp;&amp; (curVal.equals(beanName) || (curVal instanceof Set &amp;&amp; ((Set&lt;?&gt;) curVal).contains(beanName))));&#125; prototypesCurrentlyInCreation 是一个ThreadLocal，避免添加的竞争 在SpringBoot中不存在构造器注入所以循环依赖可以解决 下面就讲一下是怎么解决的循环依赖 Spring中，使用了三级缓存解决循环依赖 12345678// 单例对象的cacheprivate final Map&lt;String, Object&gt; singletonObjects = new ConcurrentHashMap&lt;&gt;(256);//单例对象工厂的cache private final Map&lt;String, ObjectFactory&lt;?&gt;&gt; singletonFactories = new HashMap&lt;&gt;(16);//提前暴光的单例对象的Cache，检测是否存在循环依赖private final Map&lt;String, Object&gt; earlySingletonObjects = new HashMap&lt;&gt;(16); 下面就是具体的解决代码： 这段代码来自DefaultSingletonBeanRegistry 1234567891011121314151617181920212223@Nullableprotected Object getSingleton(String beanName, boolean allowEarlyReference) &#123; // 首先从一级缓存里面获取 Object singletonObject = this.singletonObjects.get(beanName); // 一级缓存取不到，并且正在创建，说明存在循环依赖 if (singletonObject == null &amp;&amp; isSingletonCurrentlyInCreation(beanName)) &#123; synchronized (this.singletonObjects) &#123; // 从二级缓存获取 singletonObject = this.earlySingletonObjects.get(beanName); // 二级缓存还没有并且允许提前获得其引用 if (singletonObject == null &amp;&amp; allowEarlyReference) &#123; ObjectFactory&lt;?&gt; singletonFactory = this.singletonFactories.get(beanName); if (singletonFactory != null) &#123; singletonObject = singletonFactory.getObject(); // 将存在循环依赖的对象放到earlySingletonObjects中 this.earlySingletonObjects.put(beanName, singletonObject); this.singletonFactories.remove(beanName); &#125; &#125; &#125; &#125; return singletonObject;&#125; 这段代码来自AbstractBeanFactory 12345678910111213// Eagerly cache singletons to be able to resolve circular references// even when triggered by lifecycle interfaces like BeanFactoryAware.// 判断是否存在循环依赖boolean earlySingletonExposure = (mbd.isSingleton() &amp;&amp; this.allowCircularReferences &amp;&amp; isSingletonCurrentlyInCreation(beanName));if (earlySingletonExposure) &#123; if (logger.isDebugEnabled()) &#123; logger.debug("Eagerly caching bean '" + beearlySingletonObjectsanName + "' to allow for resolving potential circular references"); &#125; // 提供存在循环依赖对象的对象工厂 addSingletonFactory(beanName, () -&gt; getEarlyBeanReference(beanName, mbd, bean));&#125; 其实这里存在一个问题：为什么singletonObjects 使用的是ConcurrentHashMap 而二级和三级缓存只使用了HashMap 因为对于earlySingletonObjects、singletonFactories的操作我们需要保证它们的一致性，也就是如果添加到earlySingletonObjects 元素就要相应的删除singletonFactories中的一个元素（你可以在源码下发现这两个操作总是配对的出现），所以必须用sychronized来保证这个操作的原子性；同时sychronized 也就保证了两个hashMap在 并发下的安全 FactoryBean实现这个我们了解很少，但是它的作用其实很大，它的主要思想就如它的名字一样 相当于向IOC容器里面放了一个工厂方法用于生成实例；比如说Spring自己实现的AOP就是用这个技术来生成代理对象 下面是AbstractBeanFactory 的doGetBean方法的部分 123456789101112131415161718String beanName = this.transform// 从IOC容器中取可能存在的实例；但是需要注意的是这里取出来得实例有可能是FactoryBean Object sharedInstance = this.getSingleton(beanName); Object bean; if (sharedInstance != null &amp;&amp; args == null) &#123; if (this.logger.isTraceEnabled()) &#123; if (this.isSingletonCurrentlyInCreation(beanName)) &#123; this.logger.trace("Returning eagerly cached instance of singleton bean '" + beanName + "' that is not fully initialized yet - a consequence of a circular reference"); &#125; else &#123; this.logger.trace("Returning cached instance of singleton bean '" + beanName + "'"); &#125; &#125; // 所以这个方法解决了不管是取出来的是什么对象，我们都可以得到我们想要的实例 bean = this.getObjectForBeanInstance(sharedInstance, name, beanName, (RootBeanDefinition)null); &#125; `````` `````` `````` getObjectForBeanInstance 方法 1234567891011121314151617181920212223242526272829303132333435protected Object getObjectForBeanInstance(Object beanInstance, String name, String beanName, @Nullable RootBeanDefinition mbd) &#123; if (BeanFactoryUtils.isFactoryDereference(name)) &#123; if (beanInstance instanceof NullBean) &#123; return beanInstance; &#125; if (!(beanInstance instanceof FactoryBean)) &#123; throw new BeanIsNotAFactoryException(this.transformedBeanName(name), beanInstance.getClass()); &#125; &#125; if (beanInstance instanceof FactoryBean &amp;&amp; !BeanFactoryUtils.isFactoryDereference(name)) &#123; Object object = null; if (mbd == null) &#123; // FactoryBean生成的Bean也有缓存 object = this.getCachedObjectForFactoryBean(beanName); &#125; if (object == null) &#123; FactoryBean&lt;?&gt; factory = (FactoryBean)beanInstance; if (mbd == null &amp;&amp; this.containsBeanDefinition(beanName)) &#123; mbd = this.getMergedLocalBeanDefinition(beanName); &#125; boolean synthetic = mbd != null &amp;&amp; mbd.isSynthetic(); // 从FactoryBean 构造Bean并放进其缓存 object = this.getObjectFromFactoryBean(factory, beanName, !synthetic); &#125; return object; &#125; else &#123; // 如果不是FactoryBean直接返回原对象 return beanInstance; &#125;&#125; Bean的作用域下面是体现Bean作用域的代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566//AbstractBeanFactoryprotected &lt;T&gt; T doGetBean(final String name, @Nullable final Class&lt;T&gt; requiredType, @Nullable final Object[] args, boolean typeCheckOnly) throws BeansException &#123; ...... if (mbd.isSingleton()) &#123; sharedInstance = getSingleton(beanName, () -&gt; &#123; try &#123; return createBean(beanName, mbd, args); &#125; catch (BeansException ex) &#123; // Explicitly remove instance from singleton cache: It might have been put there // eagerly by the creation process, to allow for circular reference resolution. // Also remove any beans that received a temporary reference to the bean. destroySingleton(beanName); throw ex; &#125; &#125;); bean = getObjectForBeanInstance(sharedInstance, name, beanName, mbd); &#125; else if (mbd.isPrototype()) &#123; // It's a prototype -&gt; create a new instance. Object prototypeInstance = null; try &#123; beforePrototypeCreation(beanName); prototypeInstance = createBean(beanName, mbd, args); &#125; finally &#123; afterPrototypeCreation(beanName); &#125; bean = getObjectForBeanInstance(prototypeInstance, name, beanName, mbd); &#125; else &#123; String scopeName = mbd.getScope(); final Scope scope = this.scopes.get(scopeName); if (scope == null) &#123; throw new IllegalStateException("No Scope registered for scope name '" + scopeName + "'"); &#125; try &#123; Object scopedInstance = scope.get(beanName, () -&gt; &#123; beforePrototypeCreation(beanName); try &#123; return createBean(beanName, mbd, args); &#125; finally &#123; afterPrototypeCreation(beanName); &#125; &#125;); bean = getObjectForBeanInstance(scopedInstance, name, beanName, mbd); &#125; catch (IllegalStateException ex) &#123; throw new BeanCreationException(beanName, "Scope '" + scopeName + "' is not active for the current thread; consider " + "defining a scoped proxy for this bean if you intend to refer to it from a singleton", ex); &#125; &#125; &#125; catch (BeansException ex) &#123; cleanupAfterBeanCreationFailure(beanName); throw ex; &#125; &#125; ...... &#125; 从源码我们可以看到 对于Scope的调用Spring使用了策略模式，解耦了对Scope的依赖 Spring AOP在Spring 中其实存在两种AOP方式，一种是Spring自己实现的AOP，还有一种就是使用的AspectJ的方式；在以前用xml配置的时候用Spring自己实现AOP比较多，但是现在更喜欢注解的方式去实现AOP，注解的方式其实就是用的AspectJ的方式 AspectJ 的方式我没有细探，但是大概知道其是通过运行时代码织入的形式修改原来方法的代码来实现的 下面我就细讲一下Spring AOP实现的原理 在弄懂Spring AOP之前要去看下上文的FactoryBean的实现，因为Spring AOP是在其上实现的 Spring AOP 的入口是ProxyFactoryBean 这个类， 看了上文的FactoryBean实现 你也就知道了如果想取得被扩展了的类其实就是从IOC里面取ProxyFactoryBean ， 只不过在IOC里面会把它转化成扩展的类而已 Spring AOP 概述业务逻辑的代码中不再含有针对特定领域问题代码的调用，业务逻辑同特定领域问题的关系通过切面来封装和维护，这样原本分散在整个应用程序中的变动就可以很好的管理起来 基础：视为待增强对象或者说目标对象； 切面：通常包含对于基础的增强应用； 配置：可以看成是一种编织，把基础和切面结合起来从而实现切面对目标对象的编织实现 在Spring AOP中有三个与上面对应： Advice通知：定义在切入点做什么，为切面增强提供织入接口，相当于上面的切面 Pointcut切点：定义通知应该作用于哪个连接点，相当于上面的基础 Advisor通知器：将切面和连接点结合起来的设计，相当于上面的配置 增强对象生成的过程首先给出AOP应用相关类的继承关系图： 我们先以ProxyFactoryBean来讲解Aop 配置ProxyFactoryBean 12345678910&lt;bean id="testAdvisor" class="comabc.TestAdvisor"/&gt;&lt;bean id="testAop" class="org.springframework.aop.ProxyFactoryBean"&gt;&lt;property name="proxyInterfaces"&gt;&lt;value&gt;com.test.AbcInterface&lt;/value&gt;&lt;/property&gt;&lt;property name="target"&gt; &lt;bean class="com.abc.TestTarget"/&gt;&lt;/property&gt;&lt;property name="intercerptorNames"&gt; &lt;list&gt;&lt;value&gt;testAdvisor&lt;/value&gt;&lt;/list&gt;&lt;/property&gt;&lt;/bean&gt; testAdvisor是定义切面 testAop定义ProxyFactoryBean，target属性是基础即待增强的类 ProxyFactoryBean生成AopProxy代理对象 生成AopProxy代理对象的流程图 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899public Object getObject() throws BeansException &#123; //初始化通知器链 this.initializeAdvisorChain(); //这里是对singleton和prototype的类型进行区分，生成对应的proxy if (this.isSingleton()) &#123; return this.getSingletonInstance(); &#125; else &#123; if (this.targetName == null) &#123; this.logger.warn("Using non-singleton proxies with singleton targets is often undesirable. Enable prototype proxies by setting the 'targetName' property."); &#125; return this.newPrototypeInstance(); &#125;&#125; private synchronized void initializeAdvisorChain() throws AopConfigException, BeansException &#123; if (!this.advisorChainInitialized) &#123; if (!ObjectUtils.isEmpty(this.interceptorNames)) &#123; if (this.beanFactory == null) &#123; throw new IllegalStateException("No BeanFactory available anymore (probably due to serialization) - cannot resolve interceptor names " + Arrays.asList(this.interceptorNames)); &#125; if (this.interceptorNames[this.interceptorNames.length - 1].endsWith("*") &amp;&amp; this.targetName == null &amp;&amp; this.targetSource == EMPTY_TARGET_SOURCE) &#123; throw new AopConfigException("Target required after globals"); &#125; String[] var1 = this.interceptorNames; int var2 = var1.length; //这里是添加Advisor链的调用，是通过interceprotNames属性进行设置的 for(int var3 = 0; var3 &lt; var2; ++var3) &#123; String name = var1[var3]; if (this.logger.isTraceEnabled()) &#123; this.logger.trace("Configuring advisor or advice '" + name + "'"); &#125; if (name.endsWith("*")) &#123; if (!(this.beanFactory instanceof ListableBeanFactory)) &#123; throw new AopConfigException("Can only use global advisors or interceptors with a ListableBeanFactory"); &#125; this.addGlobalAdvisor((ListableBeanFactory)this.beanFactory, name.substring(0, name.length() - "*".length())); &#125; else &#123; Object advice; if (!this.singleton &amp;&amp; !this.beanFactory.isSingleton(name)) &#123; advice = new ProxyFactoryBean.PrototypePlaceholderAdvisor(name); &#125; else &#123; advice = this.beanFactory.getBean(name); &#125; this.addAdvisorOnChainCreation(advice, name); &#125; &#125; &#125; this.advisorChainInitialized = true; &#125; &#125;private synchronized Object getSingletonInstance() &#123; if (this.singletonInstance == null) &#123; this.targetSource = this.freshTargetSource(); if (this.autodetectInterfaces &amp;&amp; this.getProxiedInterfaces().length == 0 &amp;&amp; !this.isProxyTargetClass()) &#123; Class&lt;?&gt; targetClass = this.getTargetClass(); if (targetClass == null) &#123; throw new FactoryBeanNotInitializedException("Cannot determine target class for proxy"); &#125; this.setInterfaces(ClassUtils.getAllInterfacesForClass(targetClass, this.proxyClassLoader)); &#125; super.setFrozen(this.freezeProxy); this.singletonInstance = this.getProxy(this.createAopProxy()); &#125; return this.singletonInstance; &#125; protected final synchronized AopProxy createAopProxy() &#123; if (!this.active) &#123; this.activate(); &#125; return this.getAopProxyFactory().createAopProxy(this); &#125; public AopProxy createAopProxy(AdvisedSupport config) throws AopConfigException &#123; if (!config.isOptimize() &amp;&amp; !config.isProxyTargetClass() &amp;&amp; !this.hasNoUserSuppliedProxyInterfaces(config)) &#123; return new JdkDynamicAopProxy(config); &#125; else &#123; Class&lt;?&gt; targetClass = config.getTargetClass(); if (targetClass == null) &#123; throw new AopConfigException("TargetSource cannot determine target class: Either an interface or a target is required for proxy creation."); &#125; else &#123; //如果有接口使用JDK动态代理，没有接口使用CGLIB return (AopProxy)(!targetClass.isInterface() &amp;&amp; !Proxy.isProxyClass(targetClass) ? new ObjenesisCglibAopProxy(config) : new JdkDynamicAopProxy(config)); &#125; &#125; &#125; Spring Aop拦截器调用实现 我们就以JDK invoke方法讲解 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071@Nullablepublic Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; Object oldProxy = null; boolean setProxyContext = false; TargetSource targetSource = this.advised.targetSource; Object target = null; Boolean var9; try &#123; if (this.equalsDefined || !AopUtils.isEqualsMethod(method)) &#123; //如果目标对象没有Object类的equals、hashCode方法 if (!this.hashCodeDefined &amp;&amp; AopUtils.isHashCodeMethod(method)) &#123; Integer var19 = this.hashCode(); return var19; &#125; if (method.getDeclaringClass() == DecoratingProxy.class) &#123; Class var18 = AopProxyUtils.ultimateTargetClass(this.advised); return var18; &#125; Object retVal; if (!this.advised.opaque &amp;&amp; method.getDeclaringClass().isInterface() &amp;&amp; method.getDeclaringClass().isAssignableFrom(Advised.class)) &#123; //根据代理对象的配置(ProxyConfig)来调用服务 retVal = AopUtils.invokeJoinpointUsingReflection(this.advised, method, args); return retVal; &#125; if (this.advised.exposeProxy) &#123; oldProxy = AopContext.setCurrentProxy(proxy); setProxyContext = true; &#125; target = targetSource.getTarget(); Class&lt;?&gt; targetClass = target != null ? target.getClass() : null; //获得经过过滤这个方法的所有拦截器 List&lt;Object&gt; chain = this.advised.getInterceptorsAndDynamicInterceptionAdvice(method, targetClass); if (chain.isEmpty()) &#123; Object[] argsToUse = AopProxyUtils.adaptArgumentsIfNecessary(method, args); retVal = AopUtils.invokeJoinpointUsingReflection(target, method, argsToUse); &#125; else &#123; //沿着拦截器链执行方法 MethodInvocation invocation = new ReflectiveMethodInvocation(proxy, target, method, args, targetClass, chain); retVal = invocation.proceed(); &#125; Class&lt;?&gt; returnType = method.getReturnType(); if (retVal != null &amp;&amp; retVal == target &amp;&amp; returnType != Object.class &amp;&amp; returnType.isInstance(proxy) &amp;&amp; !RawTargetAccess.class.isAssignableFrom(method.getDeclaringClass())) &#123; retVal = proxy; &#125; else if (retVal == null &amp;&amp; returnType != Void.TYPE &amp;&amp; returnType.isPrimitive()) &#123; throw new AopInvocationException("Null return value from advice does not match primitive return type for: " + method); &#125; Object var13 = retVal; return var13; &#125; var9 = this.equals(args[0]); &#125; finally &#123; if (target != null &amp;&amp; !targetSource.isStatic()) &#123; targetSource.releaseTarget(target); &#125; if (setProxyContext) &#123; AopContext.setCurrentProxy(oldProxy); &#125; &#125; return var9;&#125; AOP 拦截器链的调用 123456789101112131415public Object proceed() throws Throwable &#123; if (this.currentInterceptorIndex ==this.interceptorsAndDynamicMethodMatchers.size() - 1) &#123; return this.invokeJoinpoint(); &#125; else &#123; Object interceptorOrInterceptionAdvice = this.interceptorsAndDynamicMethodMatchers.get(++this.currentInterceptorIndex); if (interceptorOrInterceptionAdvice instanceof InterceptorAndDynamicMethodMatcher) &#123; InterceptorAndDynamicMethodMatcher dm = (InterceptorAndDynamicMethodMatcher)interceptorOrInterceptionAdvice; //如果通知器和调用的方法匹配，那么调用拦截器链的所有方法，否则继续匹配 return dm.methodMatcher.matches(this.method, this.targetClass, this.arguments) ? dm.interceptor.invoke(this) : this.proceed(); &#125; else &#123; return ((MethodInterceptor)interceptorOrInterceptionAdvice).invoke(this); &#125; &#125; &#125; 拦截器链的产生 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697 private synchronized void initializeAdvisorChain() throws AopConfigException, BeansException &#123; if (!this.advisorChainInitialized) &#123; if (!ObjectUtils.isEmpty(this.interceptorNames)) &#123; if (this.beanFactory == null) &#123; throw new IllegalStateException("No BeanFactory available anymore (probably due to serialization) - cannot resolve interceptor names " + Arrays.asList(this.interceptorNames)); &#125; if (this.interceptorNames[this.interceptorNames.length - 1].endsWith("*") &amp;&amp; this.targetName == null &amp;&amp; this.targetSource == EMPTY_TARGET_SOURCE) &#123; throw new AopConfigException("Target required after globals"); &#125; String[] var1 = this.interceptorNames; int var2 = var1.length; //这里是添加Advisor链的调用，是通过interceprotNames属性进行设置的 for(int var3 = 0; var3 &lt; var2; ++var3) &#123; String name = var1[var3]; if (this.logger.isTraceEnabled()) &#123; this.logger.trace("Configuring advisor or advice '" + name + "'"); &#125; if (name.endsWith("*")) &#123; if (!(this.beanFactory instanceof ListableBeanFactory)) &#123; throw new AopConfigException("Can only use global advisors or interceptors with a ListableBeanFactory"); &#125; this.addGlobalAdvisor((ListableBeanFactory)this.beanFactory, name.substring(0, name.length() - "*".length())); &#125; else &#123; Object advice; if (!this.singleton &amp;&amp; !this.beanFactory.isSingleton(name)) &#123; advice = new ProxyFactoryBean.PrototypePlaceholderAdvisor(name); &#125; else &#123; //从IOC容器中获得通知器或者切面，因为在实现中不管是通知器还是切面都会最终 //变成通知器Advisor advice = this.beanFactory.getBean(name); &#125; //添加到通知器中 this.addAdvisorOnChainCreation(advice, name); &#125; &#125; &#125; this.advisorChainInitialized = true; &#125; &#125;//这个完成了从所有的通知器中得到拦截器链public List&lt;Object&gt; getInterceptorsAndDynamicInterceptionAdvice(Advised config, Method method, @Nullable Class&lt;?&gt; targetClass) &#123; List&lt;Object&gt; interceptorList = new ArrayList(config.getAdvisors().length); Class&lt;?&gt; actualClass = targetClass != null ? targetClass : method.getDeclaringClass(); boolean hasIntroductions = hasMatchingIntroductions(config, actualClass); AdvisorAdapterRegistry registry = GlobalAdvisorAdapterRegistry.getInstance(); //从config中得到实现从xml中获得的所有通知器 Advisor[] var8 = config.getAdvisors(); int var9 = var8.length; for(int var10 = 0; var10 &lt; var9; ++var10) &#123; Advisor advisor = var8[var10]; //拦截器链 MethodInterceptor[] interceptors; if (advisor instanceof PointcutAdvisor) &#123; PointcutAdvisor pointcutAdvisor = (PointcutAdvisor)advisor; if (config.isPreFiltered() || pointcutAdvisor.getPointcut().getClassFilter().matches(actualClass)) &#123; //全局的注册工厂获得一个通知器的拦截器(这里是同注册工厂里面的适配器将所有的) //advisor变成特定类型的拦截器(MethodBeforeAdvice、AfterReturningAdvice等等) interceptors = registry.getInterceptors(advisor); //如果编码实现通知器，通知器中会实现切入点，只不过我们不怎么使用硬编码的形式实现 //切入点，所以下面再检查是否方法是否符合切入点 MethodMatcher mm = pointcutAdvisor.getPointcut().getMethodMatcher(); //下面是对所有的拦截器进行过滤，剩下这个方法的拦截器 if (MethodMatchers.matches(mm, method, actualClass, hasIntroductions)) &#123; if (mm.isRuntime()) &#123; MethodInterceptor[] var15 = interceptors; int var16 = interceptors.length; for(int var17 = 0; var17 &lt; var16; ++var17) &#123; MethodInterceptor interceptor = var15[var17]; //将所有方法加入拦截器链 interceptorList.add(new InterceptorAndDynamicMethodMatcher(interceptor, mm)); &#125; &#125; else &#123; interceptorList.addAll(Arrays.asList(interceptors)); &#125; &#125; &#125; &#125; else if (advisor instanceof IntroductionAdvisor) &#123; IntroductionAdvisor ia = (IntroductionAdvisor)advisor; if (config.isPreFiltered() || ia.getClassFilter().matches(actualClass)) &#123; interceptors = registry.getInterceptors(advisor); interceptorList.addAll(Arrays.asList(interceptors)); &#125; &#125; else &#123; Interceptor[] interceptors = registry.getInterceptors(advisor); interceptorList.addAll(Arrays.asList(interceptors)); &#125; &#125; return interceptorList; &#125; 方法增强的实现 12345678910111213141516171819202122232425//这个方法的意图是借助DefaultAdvisorAdapterRegistry的适配器将所有的Advisor变成特定的interceptor//方便在调用拦截器链时的调用public MethodInterceptor[] getInterceptors(Advisor advisor) throws UnknownAdviceTypeException &#123; List&lt;MethodInterceptor&gt; interceptors = new ArrayList(3); Advice advice = advisor.getAdvice(); if (advice instanceof MethodInterceptor) &#123; interceptors.add((MethodInterceptor)advice); &#125; Iterator var4 = this.adapters.iterator(); //根据所有的适配器来适配得到拦截器 while(var4.hasNext()) &#123; AdvisorAdapter adapter = (AdvisorAdapter)var4.next(); if (adapter.supportsAdvice(advice)) &#123; interceptors.add(adapter.getInterceptor(advisor)); &#125; &#125; if (interceptors.isEmpty()) &#123; throw new UnknownAdviceTypeException(advisor.getAdvice()); &#125; else &#123; return (MethodInterceptor[])interceptors.toArray(new MethodInterceptor[0]); &#125; &#125; 123456789101112131415//我们就分析这个adapter，supportsAdvice用来适配判断能够通过这个适配器来得到特定的拦截器；//getInterceptor就是用来得到特定的拦截器class MethodBeforeAdviceAdapter implements AdvisorAdapter, Serializable &#123; MethodBeforeAdviceAdapter() &#123; &#125; public boolean supportsAdvice(Advice advice) &#123; return advice instanceof MethodBeforeAdvice; &#125; public MethodInterceptor getInterceptor(Advisor advisor) &#123; MethodBeforeAdvice advice = (MethodBeforeAdvice)advisor.getAdvice(); return new MethodBeforeAdviceInterceptor(advice); &#125;&#125; 1234567891011121314//这个就是一种拦截器，通过invoke方法，我们也可以知道，其实就是在调用方法之前先执行了增强的内容public class MethodBeforeAdviceInterceptor implements MethodInterceptor, Serializable &#123; private MethodBeforeAdvice advice; public MethodBeforeAdviceInterceptor(MethodBeforeAdvice advice) &#123; Assert.notNull(advice, "Advice must not be null"); this.advice = advice; &#125; public Object invoke(MethodInvocation mi) throws Throwable &#123; this.advice.before(mi.getMethod(), mi.getArguments(), mi.getThis()); return mi.proceed(); &#125;&#125; 大概讲述一个Spring AOP实现的过程Spring AOP 是通过拦截器的形式实现的 初始化得到一个拦截器链：这里涉及到适配器的设计模式，将所有注册的Advisor 适配成对应的MethodInterceptor 加入拦截器链 通过动态代理生成AOPProxy 代理对象 其中invoke方法 大致实现为 将本方法加入到拦截器链中对应位置，然后通过一个类似于FilterChain 的责任链模式，根据index递归调用拦截器中的类的对应方法 ###Spring MVC 基于XML Spring MVC 源码详解关于web.xmlweb.xml其实是对ServletContext的参数设置也就是Tomcat的环境设置，我觉得通俗点讲就是所有Servlet的上下文环境的设置，其实它也是Tomcat和Spring项目的耦合点，也就是说Tomcat启动后会去加载这个文件里面的内容；然后也是基于此内容Spring 会去创建一个WebApplicationContext也就是IOC容器，在这里具体的是XmlWebApplicationContext，下面会具体讲怎么创建的，也基于此在web.xml中有下面的一段配置： 1234&lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;&lt;/param-value&gt;&lt;/context-param&gt; XmlWebApplicationContext 会将具体路径的配置加载到IOC容器中 关于ContextLoaderListener这个是具体Tomcat和Spring的耦合点，通过这个监听器Tomcat在启动完成后传递ServletContext给Spring然后完成一系列Spring项目的启动 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980public class ContextLoaderListener extends ContextLoader implements ServletContextListener &#123; public ContextLoaderListener() &#123; &#125; public ContextLoaderListener(WebApplicationContext context) &#123; super(context); &#125; //Tomat会在启动后通过监听器调用这个方法 public void contextInitialized(ServletContextEvent event) &#123; this.initWebApplicationContext(event.getServletContext()); &#125; public void contextDestroyed(ServletContextEvent event) &#123; this.closeWebApplicationContext(event.getServletContext()); ContextCleanupListener.cleanupAttributes(event.getServletContext()); &#125;&#125; public WebApplicationContext initWebApplicationContext(ServletContext servletContext) &#123; if (servletContext.getAttribute(WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE) != null) &#123; throw new IllegalStateException("Cannot initialize context because there is already a root application context present - check whether you have multiple ContextLoader* definitions in your web.xml!"); &#125; else &#123; Log logger = LogFactory.getLog(ContextLoader.class); servletContext.log("Initializing Spring root WebApplicationContext"); if (logger.isInfoEnabled()) &#123; logger.info("Root WebApplicationContext: initialization started"); &#125; long startTime = System.currentTimeMillis(); try &#123; if (this.context == null) &#123; //ContextLoader会去读ContextLoader.properties中的Context的类型来创建具体是什么 //Context this.context = this.createWebApplicationContext(servletContext); &#125; if (this.context instanceof ConfigurableWebApplicationContext) &#123; ConfigurableWebApplicationContext cwac = (ConfigurableWebApplicationContext)this.context; if (!cwac.isActive()) &#123; if (cwac.getParent() == null) &#123; //这里是NULL，也就是说着个容器已经是顶级容器 ApplicationContext parent = this.loadParentContext(servletContext); cwac.setParent(parent); &#125; //设置和初始化该ROOT IOC 容器 this.configureAndRefreshWebApplicationContext(cwac, servletContext); &#125; &#125; servletContext.setAttribute(WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE, this.context); ClassLoader ccl = Thread.currentThread().getContextClassLoader(); if (ccl == ContextLoader.class.getClassLoader()) &#123; currentContext = this.context; &#125; else if (ccl != null) &#123; currentContextPerThread.put(ccl, this.context); &#125; if (logger.isDebugEnabled()) &#123; logger.debug("Published root WebApplicationContext as ServletContext attribute with name [" + WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE + "]"); &#125; if (logger.isInfoEnabled()) &#123; long elapsedTime = System.currentTimeMillis() - startTime; logger.info("Root WebApplicationContext: initialization completed in " + elapsedTime + " ms"); &#125; return this.context; &#125; catch (RuntimeException var8) &#123; logger.error("Context initialization failed", var8); servletContext.setAttribute(WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE, var8); throw var8; &#125; catch (Error var9) &#123; logger.error("Context initialization failed", var9); servletContext.setAttribute(WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE, var9); throw var9; &#125; &#125; &#125; 12345678910111213141516171819202122232425262728protected void configureAndRefreshWebApplicationContext(ConfigurableWebApplicationContext wac, ServletContext sc) &#123; String configLocationParam; if (ObjectUtils.identityToString(wac).equals(wac.getId())) &#123; configLocationParam = sc.getInitParameter("contextId"); if (configLocationParam != null) &#123; wac.setId(configLocationParam); &#125; else &#123; wac.setId(ConfigurableWebApplicationContext.APPLICATION_CONTEXT_ID_PREFIX + ObjectUtils.getDisplayString(sc.getContextPath())); &#125; &#125; wac.setServletContext(sc); //通过ServletContext读取web.xml文件中设置的contextConfigLocation并把它赋值给wac //方便在后IOC容器的加载 configLocationParam = sc.getInitParameter("contextConfigLocation"); if (configLocationParam != null) &#123; wac.setConfigLocation(configLocationParam); &#125; ConfigurableEnvironment env = wac.getEnvironment(); if (env instanceof ConfigurableWebEnvironment) &#123; ((ConfigurableWebEnvironment)env).initPropertySources(sc, (ServletConfig)null); &#125; this.customizeContext(sc, wac); //IOC 容器启动啦 wac.refresh(); &#125; 关于DispatchServletDispatchServlet因为其自身本来就是一个Servlet所以它的初始化的完成时依赖于Servlet的init方法 下面关于它的继承关系图 1234567891011121314151617181920212223242526272829public final void init() throws ServletException &#123; if (this.logger.isDebugEnabled()) &#123; this.logger.debug("Initializing servlet '" + this.getServletName() + "'"); &#125; PropertyValues pvs = new HttpServletBean.ServletConfigPropertyValues(this.getServletConfig(), this.requiredProperties); if (!pvs.isEmpty()) &#123; try &#123; BeanWrapper bw = PropertyAccessorFactory.forBeanPropertyAccess(this); ResourceLoader resourceLoader = new ServletContextResourceLoader(this.getServletContext()); bw.registerCustomEditor(Resource.class, new ResourceEditor(resourceLoader, this.getEnvironment())); this.initBeanWrapper(bw); bw.setPropertyValues(pvs, true); &#125; catch (BeansException var4) &#123; if (this.logger.isErrorEnabled()) &#123; this.logger.error("Failed to set bean properties on servlet '" + this.getServletName() + "'", var4); &#125; throw var4; &#125; &#125; //初始化FrameworkServlet中的属性，其中就初始化了IOC容器 this.initServletBean(); if (this.logger.isDebugEnabled()) &#123; this.logger.debug("Servlet '" + this.getServletName() + "' configured successfully"); &#125; &#125; 12345678910111213141516//在DispatchServlet初始化IOC容器过程中有完成了对基础设施的初始化 protected void onRefresh(ApplicationContext context) &#123; this.initStrategies(context); &#125; protected void initStrategies(ApplicationContext context) &#123; this.initMultipartResolver(context); this.initLocaleResolver(context); this.initThemeResolver(context); this.initHandlerMappings(context); this.initHandlerAdapters(context); this.initHandlerExceptionResolvers(context); this.initRequestToViewNameTranslator(context); this.initViewResolvers(context); this.initFlashMapManager(context); &#125; SpringMVC 的特性监听器 基本使用方式 创建继承于ApplicationEvent的事件对象 创建实现ApplicationListener的监听器 并且形式参数为创建的Event 发布事件 1234567891011121314151617181920212223242526272829303132333435363738394041424344public class MyTestEvent extends ApplicationEvent&#123; /** * */ private static final long serialVersionUID = 1L; private String msg ; public MyTestEvent(Object source,String msg) &#123; super(source); this.msg = msg; &#125; public String getMsg() &#123; return msg; &#125; public void setMsg(String msg) &#123; this.msg = msg; &#125;&#125;@Componentpublic class MyNoAnnotationListener implements ApplicationListener&lt;MyTestEvent&gt;&#123; @Override public void onApplicationEvent(MyTestEvent event) &#123; System.out.println("监听器：" + event.getMsg()); &#125;&#125;@Componentpublic class MyTestEventPubLisher &#123; @Autowired private ApplicationContext applicationContext; // 事件发布方法 public void pushListener(String msg) &#123; applicationContext.publishEvent(new MyTestEvent(this, msg)); &#125;&#125; 监听器的源码实现 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253//AbstractApplicaionContext下的protected void publishEvent(Object event, @Nullable ResolvableType eventType) &#123; Assert.notNull(event, "Event must not be null"); if (this.logger.isTraceEnabled()) &#123; this.logger.trace("Publishing event in " + this.getDisplayName() + ": " + event); &#125; Object applicationEvent; if (event instanceof ApplicationEvent) &#123; applicationEvent = (ApplicationEvent)event; &#125; else &#123; applicationEvent = new PayloadApplicationEvent(this, event); if (eventType == null) &#123; eventType = ((PayloadApplicationEvent)applicationEvent).getResolvableType(); &#125; &#125; //如果有事件没有处理完，就加入earlyApplicationEvents里面等待被处理 if (this.earlyApplicationEvents != null) &#123; this.earlyApplicationEvents.add(applicationEvent); &#125; else &#123; //真正开始处理事件 this.getApplicationEventMulticaster().multicastEvent((ApplicationEvent)applicationEvent, eventType); &#125; if (this.parent != null) &#123; if (this.parent instanceof AbstractApplicationContext) &#123; ((AbstractApplicationContext)this.parent).publishEvent(event, eventType); &#125; else &#123; this.parent.publishEvent(event); &#125; &#125; &#125;//SimpleApplicationEventMulticaster public void multicastEvent(ApplicationEvent event, @Nullable ResolvableType eventType) &#123; ResolvableType type = eventType != null ? eventType : this.resolveDefaultEventType(event); //这里取得了所有注册的相关类型的事件，至于怎么得到的，我这里简单的说一下；AbstractApplicationEventMulticaster.ListenerRetriever 这个类就是专门用于存储所有的监听器的，而且在AbstractApplicationEventMulticaster这个类下会缓存最近取的相关key的所有监听器，所以就可以从这个类里面得到监听器了 Iterator var4 = this.getApplicationListeners(event, type).iterator(); while(var4.hasNext()) &#123; ApplicationListener&lt;?&gt; listener = (ApplicationListener)var4.next(); //如果有线程池，使用线程池完成所有的监听器里面的内容 Executor executor = this.getTaskExecutor(); if (executor != null) &#123; executor.execute(() -&gt; &#123; this.invokeListener(listener, event); &#125;); &#125; else &#123; this.invokeListener(listener, event); &#125; &#125; &#125; 与Tomcat 声明周期监听器实现的差别 123456789101112131415161718192021222324252627282930313233343536public interface Lifecycle &#123; String BEFORE_INIT_EVENT = "before_init"; String AFTER_INIT_EVENT = "after_init"; String START_EVENT = "start"; String BEFORE_START_EVENT = "before_start"; String AFTER_START_EVENT = "after_start"; String STOP_EVENT = "stop"; String BEFORE_STOP_EVENT = "before_stop"; String AFTER_STOP_EVENT = "after_stop"; String AFTER_DESTROY_EVENT = "after_destroy"; String BEFORE_DESTROY_EVENT = "before_destroy"; String PERIODIC_EVENT = "periodic"; String CONFIGURE_START_EVENT = "configure_start"; String CONFIGURE_STOP_EVENT = "configure_stop"; void addLifecycleListener(LifecycleListener var1); LifecycleListener[] findLifecycleListeners(); void removeLifecycleListener(LifecycleListener var1); void init() throws LifecycleException; void start() throws LifecycleException; void stop() throws LifecycleException; void destroy() throws LifecycleException; LifecycleState getState(); String getStateName(); public interface SingleUse &#123; &#125;&#125; 从上面可以看到 关于生命周期的四个方法 init、start、stop、destroy还有四个方法运行中的不同的状态 Spring 的监听器更像是一个完整的应用，你把Event以及和它绑定的listener 放进这个应用，那么你只需要调用就行 12345678public void fireLifecycleEvent(String type, Object data) &#123; LifecycleEvent event = new LifecycleEvent(lifecycle, type, data); LifecycleListener interested[] = listeners; for (int i = 0; i &lt; interested.length; i++) interested[i].lifecycleEvent(event); &#125; 上面是Tomcat 调用监听器的核心方法 这反应了另外一种 监听器获取模式 llistener自己过滤 SpringApplicationRunlistener实现 可以看下EventPublishingRunListener源码 可以发现它获取listener识别方式是通过 方法来识别 Spring MVC处理流程 概述其处理流程 图片大致了解其处理过程 结合源码描述其过程 首先用户发送请求，DispatcherServlet实现了Servlet接口，整个请求处理流：HttpServlet.service -&gt; FrameworkServlet.doGet -&gt; FrameworkServlet.processRequest -&gt; DispatcherServlet.doService -&gt; DispatcherServlet.doDispatch。 doDispatch 开始正式进入MVC 分发处理 从HandlerMapping中 获取HandlerExecutionChain（包含了 handler 和 拦截器） 12345678910111213141516protected HandlerExecutionChain getHandler(HttpServletRequest request) throws Exception &#123; if (this.handlerMappings != null) &#123; Iterator var2 = this.handlerMappings.iterator(); while(var2.hasNext()) &#123; HandlerMapping hm = (HandlerMapping)var2.next(); if (this.logger.isTraceEnabled()) &#123; this.logger.trace("Testing handler map [" + hm + "] in DispatcherServlet with name '" + this.getServletName() + "'"); &#125; HandlerExecutionChain handler = hm.getHandler(request); if (handler != null) &#123; return handler; &#125; &#125; &#125; HandlerMapping 实现可以参考这篇文章 由于前面的HandlerMapping 的不同，所以映射的结果有不同也就是处理方式不同；所以我们需要不同HandlerAdapter 来处理这些由不同HandlerMapping得到的handler，所以这里很明显使用了适配器模式，将处理方式和对处理方式的调用进行调用 123456789101112131415161718 protected HandlerAdapter getHandlerAdapter(Object handler) throws ServletException &#123; if (this.handlerAdapters != null) &#123; Iterator var2 = this.handlerAdapters.iterator(); while(var2.hasNext()) &#123; HandlerAdapter ha = (HandlerAdapter)var2.next(); if (this.logger.isTraceEnabled()) &#123; this.logger.trace("Testing handler adapter [" + ha + "]"); &#125; if (ha.supports(handler)) &#123; return ha; &#125; &#125; &#125; throw new ServletException("No adapter for handler [" + handler + "]: The DispatcherServlet configuration needs to include a HandlerAdapter that supports this handler");&#125; HandlerAdapter 实现的分析可以参考这篇文章 通过HandlerAdapter 调用具体的某种Handler来 处理请求并返回ModelAndView 视图解析，遍历DispatcherServlet的ViewResolver列表，获取对应的View对象，入口方法DispatcherServlet.processDispatchResult 渲染，调用5中获取的View的render方法，完成对Model数据的渲染。 DispatcherServlet 将6中渲染后的数据返回响应给用户，到此一个流程结束。 分析Spring Boot启动源码123456789101112131415161718192021222324252627282930313233343536373839404142434445public ConfigurableApplicationContext run(String... args) &#123; //用来监听只能运行一个Spring boot StopWatch stopWatch = new StopWatch(); stopWatch.start(); ConfigurableApplicationContext context = null; Collection&lt;SpringBootExceptionReporter&gt; exceptionReporters = new ArrayList(); this.configureHeadlessProperty(); //这个是Spring Boot专有的监听器 SpringApplicationRunListeners listeners = this.getRunListeners(args); listeners.starting(); Collection exceptionReporters; try &#123; ApplicationArguments applicationArguments = new DefaultApplicationArguments(args); ConfigurableEnvironment environment = this.prepareEnvironment(listeners, applicationArguments); this.configureIgnoreBeanInfo(environment); Banner printedBanner = this.printBanner(environment); //初始化IOC容器实例 context = this.createApplicationContext(); exceptionReporters = this.getSpringFactoriesInstances(SpringBootExceptionReporter.class, new Class[]&#123;ConfigurableApplicationContext.class&#125;, context); //这里面完成了BeanDefinition的定位、载入、注册 this.prepareContext(context, environment, listeners, applicationArguments, printedBanner); //进行IOC容器的初始化 this.refreshContext(context); this.afterRefresh(context, applicationArguments); stopWatch.stop(); if (this.logStartupInfo) &#123; (new StartupInfoLogger(this.mainApplicationClass)).logStarted(this.getApplicationLog(), stopWatch); &#125; listeners.started(context); this.callRunners(context, applicationArguments); &#125; catch (Throwable var10) &#123; this.handleRunFailure(context, var10, exceptionReporters, listeners); throw new IllegalStateException(var10); &#125; try &#123; listeners.running(context); return context; &#125; catch (Throwable var9) &#123; this.handleRunFailure(context, var9, exceptionReporters, (SpringApplicationRunListeners)null); throw new IllegalStateException(var9); &#125;&#125; 1234567891011//这个方法比较有趣，在初始化完IOC容器后，注册了一个这个应用的shutdownhookprivate void refreshContext(ConfigurableApplicationContext context) &#123; this.refresh(context); if (this.registerShutdownHook) &#123; try &#123; context.registerShutdownHook(); &#125; catch (AccessControlException var3) &#123; ; &#125; &#125; &#125; Spring 内置Tomcat启动源码解读123456789protected void onRefresh() &#123; super.onRefresh(); try &#123; this.createWebServer(); &#125; catch (Throwable var2) &#123; throw new ApplicationContextException("Unable to start web server", var2); &#125;&#125; 首先在初始化IOC容器的时候，通过onRefresh方法，调用creatWebServer创建指定的Web容器并启动 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081private void createWebServer() &#123; WebServer webServer = this.webServer; ServletContext servletContext = this.getServletContext(); if (webServer == null &amp;&amp; servletContext == null) &#123; ServletWebServerFactory factory = this.getWebServerFactory(); this.webServer = factory.getWebServer(new ServletContextInitializer[]&#123;this.getSelfInitializer()&#125;); &#125; else if (servletContext != null) &#123; try &#123; this.getSelfInitializer().onStartup(servletContext); &#125; catch (ServletException var4) &#123; throw new ApplicationContextException("Cannot initialize servlet context", var4); &#125; &#125; this.initPropertySources(); &#125; public WebServer getWebServer(ServletContextInitializer... initializers) &#123; Tomcat tomcat = new Tomcat(); File baseDir = this.baseDirectory != null ? this.baseDirectory : this.createTempDir("tomcat"); tomcat.setBaseDir(baseDir.getAbsolutePath()); Connector connector = new Connector(this.protocol); tomcat.getService().addConnector(connector); this.customizeConnector(connector); tomcat.setConnector(connector); tomcat.getHost().setAutoDeploy(false); this.configureEngine(tomcat.getEngine()); Iterator var5 = this.additionalTomcatConnectors.iterator(); while(var5.hasNext()) &#123; Connector additionalConnector = (Connector)var5.next(); tomcat.getService().addConnector(additionalConnector); &#125; this.prepareContext(tomcat.getHost(), initializers); return this.getTomcatWebServer(tomcat); &#125; protected TomcatWebServer getTomcatWebServer(Tomcat tomcat) &#123; return new TomcatWebServer(tomcat, this.getPort() &gt;= 0); &#125; public TomcatWebServer(Tomcat tomcat, boolean autoStart) &#123; this.monitor = new Object(); this.serviceConnectors = new HashMap(); Assert.notNull(tomcat, "Tomcat Server must not be null"); this.tomcat = tomcat; this.autoStart = autoStart; this.initialize(); &#125; private void initialize() throws WebServerException &#123; logger.info("Tomcat initialized with port(s): " + this.getPortsDescription(false)); Object var1 = this.monitor; synchronized(this.monitor) &#123; try &#123; this.addInstanceIdToEngineName(); Context context = this.findContext(); context.addLifecycleListener((event) -&gt; &#123; if (context.equals(event.getSource()) &amp;&amp; "start".equals(event.getType())) &#123; this.removeServiceConnectors(); &#125; &#125;); this.tomcat.start(); this.rethrowDeferredStartupExceptions(); try &#123; ContextBindings.bindClassLoader(context, context.getNamingToken(), this.getClass().getClassLoader()); &#125; catch (NamingException var5) &#123; ; &#125; this.startDaemonAwaitThread(); &#125; catch (Exception var6) &#123; this.stopSilently(); throw new WebServerException("Unable to start embedded Tomcat", var6); &#125; &#125; &#125; 通过上面一步一步我们很容易发现Tomcat是怎么启动的 关于Tomcat源码 omcat的架构图 Container的组成 一些名词 Server：服务器，一个Tomcat只能有一个Server，可以看做就是Tomcat，用于控制Tomcat的生命周期 Service：服务，有了Service就可以对外提供服务了，一个Server可以拥有多个Service Connector：连接器，表示接受请求的端点，并返回回复；Servlet容器处理请求，是需要Connector进行调度和控制的，Connector是Tomcat处理请求的主干，因此Connector的配置和使用对Tomcat的性能有着重要的影响 Engine：引擎，Engine下可以配置多个虚拟主机Virtual Host，每个虚拟主机都有一个域名，当Engine获得一个请求时，它把该请求匹配到某个Host上，然后把该请求交给该Host来处理，Engine有一个默认虚拟主机，当请求无法匹配到任何一个Host上的时候，将交给该默认Host来处理 Host：虚拟主机，每个虚拟主机和某个网络域名Domain Name相匹配 ，每个虚拟主机下都可以部署(deploy)一个或者多个Web App ,每个Web App对应于一个Context，有一个Context path，当Host获得一个请求时，将把该请求匹配到某个Context上，然后把该请求交给该Context来处理，匹配的方法是“最长匹配”，所以一个path==””的Context将成为该Host的默认Context，所有无法和其它Context的路径名匹配的请求都将最终和该默认Context匹配 Context ：一个Context对应于一个Web Application，一个Web Application由一个或者多个Servlet组成，Context在创建的时候将根据配置文件CATALINA_HOME/conf/web.xml和WEBAPP_HOME/WEB-INF/web.xml载入Servlet类，当Context获得请求时，将在自己的映射表(mapping table)中寻找相匹配的Servlet类，如果找到，则执行该类，获得请求的回应，并返回。 一个Host可以有多个Context，就相当于多个Web Application；其中TomcatEmbeddedContext就相当于这个 Wrapper：最底层的容器，是对 Servlet 的封装，负责 Servlet 实例的创 建、执行和销毁 需要注意的是 Engine、Host、Context、Wrapper都是实现Container接口的类，所以里面的结构就像第三张图一样一个容器嵌套一个容器 Spring Boot源码之内置Servlet容器创建WebServer并且启动 12345678910111213141516171819202122232425262728 protected void onRefresh() &#123; super.onRefresh(); try &#123; this.createWebServer(); &#125; catch (Throwable var2) &#123; throw new ApplicationContextException("Unable to start web server", var2); &#125; &#125;private void createWebServer() &#123; WebServer webServer = this.webServer; ServletContext servletContext = this.getServletContext(); if (webServer == null &amp;&amp; servletContext == null) &#123; ServletWebServerFactory factory = this.getWebServerFactory(); //参数是一些ServletContextInitializer，Servlet容器启动的时候会遍历这些ServletContextInitializer，并调用onStartup方法 this.webServer = factory.getWebServer(new ServletContextInitializer[]&#123;this.getSelfInitializer()&#125;); &#125; else if (servletContext != null) &#123; try &#123; this.getSelfInitializer().onStartup(servletContext); &#125; catch (ServletException var4) &#123; throw new ApplicationContextException("Cannot initialize servlet context", var4); &#125; &#125; this.initPropertySources(); &#125; ServletContextInitializer的其中一个具体内容，目的是添加Servlet、Filter、Listener，包括那些自定义的，它们最终都会通过适配器变为ServletRegistrationBean 1234567891011121314151617181920private void selfInitialize(ServletContext servletContext) throws ServletException &#123; this.prepareWebApplicationContext(servletContext); //得到 IOC容器 ConfigurableListableBeanFactory beanFactory = this.getBeanFactory(); ServletWebServerApplicationContext.ExistingWebApplicationScopes existingScopes = new ServletWebServerApplicationContext.ExistingWebApplicationScopes(beanFactory); WebApplicationContextUtils.registerWebApplicationScopes(beanFactory, this.getServletContext()); existingScopes.restore(); //将ServletContext注册到IOC容器 WebApplicationContextUtils.registerEnvironmentBeans(beanFactory, this.getServletContext()); //得到ServletContextInitializerBean遍历器 Iterator var4 = this.getServletContextInitializerBeans().iterator(); while(var4.hasNext()) &#123; //遍历执行所有ServletContextInitializer ServletContextInitializer beans = (ServletContextInitializer)var4.next(); beans.onStartup(servletContext); &#125; &#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133//IOC容器初始化过程protected void finishRefresh() &#123; super.finishRefresh(); WebServer webServer = this.startWebServer(); if (webServer != null) &#123; this.publishEvent(new ServletWebServerInitializedEvent(webServer, this)); &#125; &#125;//这里的启动WebServer其实就是注册所有的 private WebServer startWebServer() &#123; WebServer webServer = this.webServer; if (webServer != null) &#123; webServer.start(); &#125; return webServer; &#125;//这里以Tomcat启动为例 public void start() throws WebServerException &#123; Object var1 = this.monitor; synchronized(this.monitor) &#123; if (!this.started) &#123; boolean var10 = false; try &#123; var10 = true; this.addPreviouslyRemovedConnectors(); Connector var2 = this.tomcat.getConnector(); if (var2 != null &amp;&amp; this.autoStart) &#123; this.performDeferredLoadOnStartup(); &#125; this.checkThatConnectorsHaveStarted(); this.started = true; logger.info("Tomcat started on port(s): " + this.getPortsDescription(true) + " with context path '" + this.getContextPath() + "'"); var10 = false; &#125; catch (ConnectorStartFailedException var11) &#123; this.stopSilently(); throw var11; &#125; catch (Exception var12) &#123; throw new WebServerException("Unable to start embedded Tomcat server", var12); &#125; finally &#123; if (var10) &#123; Context context = this.findContext(); ContextBindings.unbindClassLoader(context, context.getNamingToken(), this.getClass().getClassLoader()); &#125; &#125; Context context = this.findContext(); ContextBindings.unbindClassLoader(context, context.getNamingToken(), this.getClass().getClassLoader()); &#125; &#125; &#125; private void performDeferredLoadOnStartup() &#123; try &#123; //得到该虚拟主机下的所有Context也就是WebApplication上下文 Container[] var1 = this.tomcat.getHost().findChildren(); int var2 = var1.length; for(int var3 = 0; var3 &lt; var2; ++var3) &#123; Container child = var1[var3]; if (child instanceof TomcatEmbeddedContext) &#123; ((TomcatEmbeddedContext)child).deferredLoadOnStartup(); &#125; &#125; &#125; catch (Exception var5) &#123; logger.error("Cannot start connector: ", var5); throw new WebServerException("Unable to start embedded Tomcat connectors", var5); &#125; &#125; public void deferredLoadOnStartup() &#123; ClassLoader classLoader = this.getLoader().getClassLoader(); ClassLoader existingLoader = null; if (classLoader != null) &#123; existingLoader = ClassUtils.overrideThreadContextClassLoader(classLoader); &#125; if (this.overrideLoadOnStart) &#123; //加载该上下文下的所有Servlet super.loadOnStartup(this.findChildren()); &#125; if (existingLoader != null) &#123; ClassUtils.overrideThreadContextClassLoader(existingLoader); &#125; &#125; public boolean loadOnStartup(Container[] children) &#123; TreeMap&lt;Integer, ArrayList&lt;Wrapper&gt;&gt; map = new TreeMap(); for(int i = 0; i &lt; children.length; ++i) &#123; Wrapper wrapper = (Wrapper)children[i]; int loadOnStartup = wrapper.getLoadOnStartup(); if (loadOnStartup &gt;= 0) &#123; Integer key = loadOnStartup; ArrayList&lt;Wrapper&gt; list = (ArrayList)map.get(key); if (list == null) &#123; list = new ArrayList(); map.put(key, list); &#125; list.add(wrapper); &#125; &#125; Iterator i$ = map.values().iterator(); while(i$.hasNext()) &#123; ArrayList&lt;Wrapper&gt; list = (ArrayList)i$.next(); Iterator i$ = list.iterator(); while(i$.hasNext()) &#123; Wrapper wrapper = (Wrapper)i$.next(); try &#123; wrapper.load(); &#125; catch (ServletException var8) &#123; this.getLogger().error(sm.getString("standardContext.loadOnStartup.loadException", new Object[]&#123;this.getName(), wrapper.getName()&#125;), StandardWrapper.getRootCause(var8)); if (this.getComputedFailCtxIfServletStartFails()) &#123; return false; &#125; &#125; &#125; &#125; return true; &#125;s Spring 事务管理Spring 事务传播行为 事务传播行为类型 说明 PROPAGATION_REQUIRED 如果当前没有事务，就新建一个事务，如果已经存在一个事务中，加入到这个事务中。这是最常见的选择。 PROPAGATION_SUPPORTS 支持当前事务，如果当前没有事务，就以非事务方式执行。 PROPAGATION_MANDATORY 使用当前的事务，如果当前没有事务，就抛出异常。 PROPAGATION_REQUIRES_NEW 新建事务，如果当前存在事务，把当前事务挂起。 PROPAGATION_NOT_SUPPORTED 以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。 PROPAGATION_NEVER 以非事务方式执行，如果当前存在事务，则抛出异常。 PROPAGATION_NESTED 如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则执行与PROPAGATION_REQUIRED类似的操作。 SpringBoot 如何自动配置事务相关类在上一节中讲了 原来Spring用ProxyFactoryBean实现的AOP动态代理，在SpringBoot中已经弃用这种方式 结合了自动配置的方式 首先使用SpringBoot 的自动配置类 TransactionAutoConfiguration 设置了transactionManager 在启用动态代理的同时用EnableTransactionManagement 注解启用了事务管理 启用事务管理就是加载自动生成代理的类(AutoProxyRegistrar, 这是Spring给用户开的后门用于编程式动态添加bean)和向IOC容器里面添加了关于事务的拦截器 通过代理生成器 结合IOC容器给Bean初始化时打开的口，动态生成了代理增强实例 Spring 事务管理的实现其实Spring的事务管理 就是依赖于 TransactionInterceptor 这个类 因为它是实现了 MethodIntercepor 的拦截器类，所以调用被代理对象的方法时会调用其invoke方法 12345public Object invoke(MethodInvocation invocation) throws Throwable &#123; Class&lt;?&gt; targetClass = (invocation.getThis() != null ? AopUtils.getTargetClass(invocation.getThis()) : null); return invokeWithinTransaction(invocation.getMethod(), targetClass, invocation::proceed);&#125; 在invokeWithinTransaction 方法中就实现了 事务的新建、提交和回滚的操作 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384protected Object invokeWithinTransaction(Method method, @Nullable Class&lt;?&gt; targetClass, final InvocationCallback invocation) throws Throwable &#123; // 如果当前没有事务就新建一个事务 TransactionAttributeSource tas = getTransactionAttributeSource(); final TransactionAttribute txAttr = (tas != null ? tas.getTransactionAttribute(method, targetClass) : null); final PlatformTransactionManager tm = determineTransactionManager(txAttr); final String joinpointIdentification = methodIdentification(method, targetClass, txAttr); if (txAttr == null || !(tm instanceof CallbackPreferringPlatformTransactionManager)) &#123; // Standard transaction demarcation with getTransaction and commit/rollback calls. TransactionInfo txInfo = createTransactionIfNecessary(tm, txAttr, joinpointIdentification); Object retVal = null; try &#123; // 这里就是MethodInterceptor的精华，会先去递归调用所有拦截器链中的所有方法 retVal = invocation.proceedWithInvocation(); &#125; catch (Throwable ex) &#123; // 发生异常 在这个方面里面进行回滚 completeTransactionAfterThrowing(txInfo, ex); throw ex; &#125; finally &#123; cleanupTransactionInfo(txInfo); &#125; commitTransactionAfterReturning(txInfo); return retVal; &#125; else &#123; final ThrowableHolder throwableHolder = new ThrowableHolder(); // It's a CallbackPreferringPlatformTransactionManager: pass a TransactionCallback in. try &#123; Object result = ((CallbackPreferringPlatformTransactionManager) tm).execute(txAttr, status -&gt; &#123; TransactionInfo txInfo = prepareTransactionInfo(tm, txAttr, joinpointIdentification, status); try &#123; return invocation.proceedWithInvocation(); &#125; catch (Throwable ex) &#123; if (txAttr.rollbackOn(ex)) &#123; // A RuntimeException: will lead to a rollback. if (ex instanceof RuntimeException) &#123; throw (RuntimeException) ex; &#125; else &#123; throw new ThrowableHolderException(ex); &#125; &#125; else &#123; // A normal return value: will lead to a commit. throwableHolder.throwable = ex; return null; &#125; &#125; finally &#123; cleanupTransactionInfo(txInfo); &#125; &#125;); // Check result state: It might indicate a Throwable to rethrow. if (throwableHolder.throwable != null) &#123; throw throwableHolder.throwable; &#125; return result; &#125; catch (ThrowableHolderException ex) &#123; throw ex.getCause(); &#125; catch (TransactionSystemException ex2) &#123; if (throwableHolder.throwable != null) &#123; logger.error("Application exception overridden by commit exception", throwableHolder.throwable); ex2.initApplicationException(throwableHolder.throwable); &#125; throw ex2; &#125; catch (Throwable ex2) &#123; if (throwableHolder.throwable != null) &#123; logger.error("Application exception overridden by commit exception", throwableHolder.throwable); &#125; throw ex2; &#125; &#125; &#125; 关于MethodInterceptor 和 其它的BeforeMethodInterceptor 等等区别在MethodIntercepot 注释上面有下面这样一句话 12* Intercepts calls on an interface on its way to the target. These* are nested "on top" of the target. 再 根据 ReflectiveMethodInvocation类里面的process 方法 下面这句代码 123if (dm.methodMatcher.matches(this.method, targetClass, this.arguments)) &#123; return dm.interceptor.invoke(this); &#125; 但是注意的是 在MethodInterceptor中invoke方法要回调 JoinPoint的proceed方法 相关面试题http://www.importnew.com/15851.html#ioc_di 其中值得学习的类 ResolveableType 这个类是为了解决获取泛型实际类型 这里具体使用方法 相关链接 Spring Boot源码分析 https://fangjian0423.github.io/2017/05/22/springboot-embedded-servlet-container/ Tomcat https://juejin.im/post/5af27c34f265da0b78687e14 http://www.importnew.com/27309.html https://juejin.im/post/58eb5fdda0bb9f00692a78fc]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2018%2F07%2F18%2FReading%2F%E5%85%B3%E4%BA%8Ejava8%20%E5%AE%9E%E6%88%98%2F</url>
    <content type="text"><![CDATA[关于java8 实战并行数据处理与性能 在使用前必须确保，需要并行化的数据没有数据相关性，也就是说，多个并行流之间不存在对共享数据进行操作 留意装箱和拆箱，这个比较消耗性能 与流中元素顺序相关的操作比顺序无关的操作性能差 设N是要处理的元素的总数，Q是一个元素通过 流水线的大致处理成本，则N*Q就是这个对成本的一个粗略的定性估计。Q值较高就意味 着使用并行流时性能好的可能性比较大。 少量的数据不用并行流 要考虑流背后的数据结构是否易于分解 ；根据ArrayList和LinkedList的拆分器我们就可以看得出来，ArrayList的拆分直接把自己拥有的元素数组赋值给拆分器的数组元素，然后对这个数组元素进行拆分；但是LInkedList是把自己的引用传给拆分器的collection属性，拆分的时候是通过遍历添加进新建的数组，然后又传给新建的数组拆分器 关于默认方法 怎么使用默认方法： 由于API 版本的迭代，我们发现实现一个接口缺少了某些必要的方法；但是如果直接向接口中添加方法就会发现没有实现这个方法而发生编译错误；但是使用默认方法，我们就可以避免这个问题，接口提供了一个默认实现，用户可以覆盖这个方法而有自己的实现。 实现一个接口，但是并不是所有实现的类都需要其中的所有方法，以前我们的解决方式是实现一个空方法，有了默认方法，我们就可以在接口中以以下方式实现这个方法 123default void method()&#123; throw new UnsupportedOperationException();&#125; 行为的多继承 解决多实现冲突的规则： 类或父类中声明的方法优先级高于任何声明为默认方法的优先级(也就是说默认方法如果被覆盖了就以被覆盖的方法为准) 如果无法根据第一条进行判断，那么子接口的优先级更高：函数签名相同时，优先选择拥有最具体实现的默认方法的接口，即如果B继承了A，那么B就比A具体 最后，如果还无法判断，继承了多个接口的类必须通过显示覆盖和调用期望方法]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2018%2F06%2F25%2FReading%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[存储器管理存储器的层次结构多级存储器结构 操作系统的存储管理，负责对可执行存储器的分配、回收以及提供在存储层次间数据移动的管理机制 主要分三层：CPU寄存器（寄存器），主存（高速缓存、主存、磁盘缓存）、辅存（磁盘、可移动介质） 程序的装入和链接程序的装入 绝对装入方式：程序员需要知道程序将驻留在什么位置 可重定位装入方式：程序指定程序驻留内存的相对位置 动态运行时装入方式：并不立即把装入模块中的相对无位置转换为绝对位置，而是把这种地址转换推迟到程序真正要执行时才运行 程序的链接 静态链接方式：在程序运行前，先将各目标模块及它们所需的库函数，链接成一个完整的装配模块，以后不再拆开 装入时动态链接：装入一个模块时，若发生一个外部模块调用事件，将引起装入程序去找对应的外部目标模块，并将它装入内存。 运行时动态链接：在程序运行时，将目标模块装入内存 连续分配方式单一连续分配固定分区分配 划分分区方法：将内存的用户空间划分为若干个固定大小的分区（有分区大小相等和不相等两种方式） 内存分配：使用一张分区使用表来进行分区的使用 动态分区分配 分配方式：根据进程的需要，动态的为之分配内存空间 分区分配中的数据结构： 空闲分区表 空闲分区链 分区分配算法 首次适应算法 定义：空闲分区链以地址递增的次序链接，在分配内存时从链首开始顺序查找 缺点：倾向于分配低地址部分，会留下许多难以利用的、很小的空闲分区，且查找是从头开始，会消耗多余的时间 循环首次适应算法 定义：对首次适应算法的改进，下次查找是从上一次分配的空间开始 缺点：缺乏大的空闲分区 最佳适应算法 定义：在所有的空闲分区按其容量有小到大的顺序形成一空闲分区链，在其中找到能满足要求的最小的空间 缺点：每次分配的是所切割下来的剩余部分总是最小的，在存储器中会留下许多难以利用的小空闲区 最坏适应算法 定义：从顺序空闲分区链中，找最大的空间分配 缺点：虽然可以减少碎片空间，但是缺少大的空闲分区 以上都是顺序搜索法 快速适应算法（分类搜索算法） 定义：将空闲分区根据其容量大小进行分类，对于没一类相同容量的所有空闲分区，单独设立一个空闲分区链表，寻找到能容纳它的最小空间区链表，取第一个 缺点：分区归还主存时算法复杂，系统开销大 分区分配操作 分配内存 回收内存 伙伴系统 定义：在系统运行过程中，由于不断的划分，可能会形成若干个不连续的空闲分区，将这些空闲分区根据分区的大小进行分类，在此基础上进行分配 可重定位分区分配 原因：在分区分配过程中会产生许多小空间，我们需要整合这些小空间，就需要移动原有程序 实现：动态运行时装入方式，利用硬件地址变换机构，即需在系统中增设一个重定位寄存器，用它来存放程序在内存中的起始地址 算法： 对换 定义：是指把内存中暂时不能运行的进程或者暂时不用的程序和数据调出到处到外存上，以便腾出足够的内存空间，再把已具备运行条件的进程或进程所需要的程序和数据调入到内存 对换空间的管理：通常是把外存分为文件区和对换区，文件去使用离散分配方式，对换区使用连续分配方式便于查找 基本分页存储管理方式 定义：前面都是连续分配方式，基于分页存储管理方式是离散分配方式 基本概念： 页面 将一个进程的逻辑地址空间分成若干个大小相等的片，称为页面 内存分为与页面相等大小的若干个存储块，称为物理块或者页框 页面大小 地址结构：20位页号12位位移量 即每页大小2^12 = 4K 页表：记录页面与物理块之间关系的表 地址变换机构 基本分段存储管理方式虚拟存储器 定义：仅需将那些当前要运行的少数页面或段先装入内存便可运行，在程序运行时再将没有调入的页面进行调入 特征： 多次性：一个程序被分成多次调用内存 对换性：作业在运行过程中换入换出 虚拟性：逻辑上对内存进行扩容 请求分页存储管理方式 硬件支持 页表机制 缺页中断机构 地址变换机构 页面置换算法 最佳置换算法：选择的被淘汰页面，将是以后永不使用的，这个是无法实现的 先进先出页面算法 LRU置换算法：硬件支持（寄存器或栈） Clock置换算法：根据访问位和修改位来判断置换的页面 请求分段存储管理方式进程管理进程的基本概念 进程顺序执行的基本特征：顺序性、封闭性、可再现性 进程并发执行的基本特征：间断性、失去封闭性、不可再现性 进程可能会有的所有状态：创建状态、就绪状态、执行状态、阻塞状态、挂起状态、终止状态 进程控制块（PCB）：一种数据结构，用于描述进程的当前情况以及控制进程运行的全部信息，PCB常驻内存。 其中有主要一下信息： 进程标识符 处理机状态 进程调度信息 进程控制信息 进程控制块组织方式： 链接方式 索引方式 进程控制 进程的创建 申请空白PCB 为新进程分配资源 初始化PCB 将PCB插入就绪队列 进程终止 进程的阻塞 改变PCB中的进程调度信息 插入阻塞队列 进程唤醒 改变PCB中的进程调度信息 插入就绪队列 进程的挂起 进程的激活 进程同步 基本概念 两种形式的制约关系 临界资源 临界区 信号量机制 整型信号量 记录型信息量 AND型信号量 信号量集 管程 定义：共享资源的数据结构，以及由对该数据结构实施操作的一组过程所组成的资源管理程序，共同构成了一个操作系统的资源管理模块 线程 线程与进程的比较 调度：同一进程的不同线程的切换不切换进程 并发性 拥有资源：访问隶属进程的资源，拥有很少量自己的自己的资源 系统开销：系统开销小 线程属性： 轻型实体 独立调度和分派的基本单位 可并发执行 共享进程资源 线程状态 线程的实现方式 内核支持线程 缺点：对于用户线程切换而言，开销很大 用户级线程 缺点：系统调用阻塞问题；多线程不能利用多处理机进行多重处理 组合方式 线程的实现 内核支持线程的实现：就类似于进程了 用户级线程的实现 运行时系统：用于管理和控制线程的函数集合 内核控制线程：每个进程拥有多个LWP，一个LWP连接多个用户进程，克服了内核线程的切换线程系统 开销大的问题，也克服了用户线程系统调用阻塞所有其它线程问题 处理机调度和死锁处理机调度层次 高级调度：根据某种算法，把外存上处理后备队列中的那些作业调入内存，调度的对象是作业 低级调度：调度的对象是进程 低级调度的功能： 保存处理机的现场信息，即进程运行时保存在各种寄存器里面的数据到PCB中 按某种算法选取下一个运行的进程 把处理器分配给下一个进程 低级调度的机制： 排队器：就绪进程队列 分派器：分派器就是由进程调度程序选定的进程，切换的进程首先把处理机切换到分派进程，然后分派进程再指定下一个进程并切换到下一个进程 上下文切换机制 进程调度方式 非抢占式调度：一个进程总是尝试运行完自己所有程序，除非遇到阻塞或异常而退出，再把处理机交给其它进程 抢占式调度：基于一定的优先原则，当优先级大的进程进入系统，会将当前运行的进程切换到优先级高的进程 中级调度：使那些暂时不能运行的进程调至外存上 调度队列模型和准则调度队列模型 仅有低级调度 低级调度和高级调度：从外存的后备队列上选择一个作业，然后封装为一个进程进行运行，进程运行有服从低级调度 三级调度都有：前面就像低级和高级调度的形式，然后在进程需要创建子进程内存空间不够的时候，就会换出暂时不会运行的线程到外存，变成外存就绪状态 调度算法的准则 面向用户准则 周期时间短 响应时间快 截止时间保证 优先权准则 面向系统准则 系统吞吐量：就是在一定的时间里能够完成的作业 处理机利用率 资源平衡利用 资源利用平衡 调度算法 高级调度和低级调度都适用的： 先来先服务调度算法：缺点是有利于长作业，不利于短作业；有利于CPU繁忙型作业，因为可以长时间占用处理机，导致其带权周转时间小 短作业调度优先：缺点是不利于长作业 高优先权优先调度算法：抢占式，非抢占式；静态优先权，动态优先权 高响应比优先调度算法：利用动态优先权，进程的优先权随着时间的改变而改变：响应时间/服务时间 低级调度适用的： 时间片轮转调度算法：在给定的时间片内，对按照先来先服务形成的就绪进程队列进程时间片周期轮转执行 多级反馈队列调度算法：设置多个就绪进程就绪队列，队列优先级依次降低，会首先执行优先级高的队列里面的进程且每一个低优先级都是其上一个优先级队列的分配时间片大一倍；创建一个进程时，先放到第一优先级队列，如果第一个时间片没有执行完在放到下一个优先级队列，依次类推；也仅有上一优先级队列为空时下一优先级队列才有机会执行，所以当有第一优先级队列有进程时，在执行第二优先级队列里面的进程时会被抢占 实时调度算法： 最早截止时间调度算法：有较早截止时间的进程有较高的优先级去执行 最低松弛度优先：在形成的松弛度有小到大的队列中选取第一个执行，松弛度=必须完成的时间-其本身时间-当前时间 产生死锁的原因和条件 产生死锁的原因： 竞争资源 竞争非剥夺性资源 竞争临时性资源 进程间推进顺序非法 产生死锁的必要条件 互斥条件 请求和保持条件 不剥夺条件 环路等待条件 设备管理IO控制方式 程序IO方式 中断驱动方式 口述一下就是IO程序发出读命令，然后检测IO设备是否空闲，空闲的话读取一个字到数据寄存器，然后发出中断信号，CPU检查输入过程是否有错，没有错再将字写到内存 直接存储器访问方式(DMA)控制方式 产生的原因：虽然产生了中断驱动IO控制方式，但是我们从上面的流程图可以得知，我们只能节省等待IO设备可用的时间，还有大量的IO传输速度与cpu不匹配所产生的cpu等待IO设备的时间会浪费，DMA方式成百倍的减少了CPU对IO的干预 DMA的特点： 每次传输一个数据块 DMA存在一个缓存区，即内存中的一块地方，所以DMA通过这个缓冲区与CPU进行数据传递，当CPU发送读命令时，从IO设备读取数据到这个缓存区，写命令时CPU右将数据发送到这个缓冲区 仅在一个数据块操作完成才需CPU干预，取下一个命令 关于设备控制器(DMA) 组成： DMA与CPU的接口：主要涉及数据线、地址线和控制线，这个三个线与命令/状态寄存器(CR)、内存地址寄存器(MDR)、数据寄存器(DR)、数据计数器(DR)进行数据传递； DMA与IO设备的接口 IO逻辑：实现对设备控制，通过一组控制线与处理机交互，处理机利用该逻辑向控制器发送IO命令；IO逻辑对收到的命令进行译码 DMA工作过程 IO通道控制方式 IO通道 定义：是一种特殊的处理机，但是它只能运行IO命令，且与处理机共享内存 产生的原因：DMA只能一次读取一个数据块的数据，IO通道则是DMA方式的发展，可以一次实现多个数据块的传送 执行过程：当CPU要完成一个读操作时，只需向IO通道发送一条IO指令，IO指令包括所要执行通道程序的首址和要访问的IO设备 中断处理程序 主要有以下几个步骤 唤醒被阻塞的驱动进程(这里唤醒的原因是需要中断处理程序处理IO完成后的工作) 保护被中断进程的CPU环境：我觉得这里需要注意的是与进程进行上下文切换机制不同，后者是将处理机现场信息保存到PCB中，但是这里是吧处理机状态字PSW和程序计数器保存在中断保留区，把被中断进程CPU现场信息压入中断栈中 转入相应设备处理程序 中断处理 恢复被中断进程现场 设备驱动程序 定义：他是IO进程与设备控制器之间的通信程序 产生原因：由于对不同硬件设备进行IO操作需要不同的指令代码，也即不同的硬件需要不同的驱动程序，所以在我们看来IO程序简单发出一个read或者write命令，但是如果设备控制器直接发给IO设备它是不认识的因为不同的硬件的内部结构是不一样的，所以这个时候就需要设备驱动程序对这个read或者write命令基于不同硬件解析为硬件认识的程序代码然后让设备控制器直接发给IO设备 操作系统接口系统调用 系统态和用户态：在现在的我看来是对处理机两种状态的标志，当处理机是系统态时可以使用所有指令和数据；而用户态只能使用非特权指令，不能使用系统态的空间和数据；这两个状态的切换时通过改变处理机状态字PSW 系统调用实现 主要是靠中断和陷入机制来完成的；当CPU执行到一条需要系统调用的指令时发生中断并将有关信号送给中断和陷入硬件机构，该机构收到信号后，启动相关的中断和陷入处理程序进行处理]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2018%2F06%2F15%2FJava%20%E5%B9%B6%E5%8F%91%2FHashTable%2F</url>
    <content type="text"><![CDATA[根据jdk类注释中可以得到的一些信息 HashTable是线程安全的，但是如果不要求线程安全推荐使用HashMap来代替HashTable， 要求线程安全那么就使用HashTable 要求键值不能为空 如果会用较多的元素使用，那么最好设置足够的容量来减少添加元素时扩容的浪费的时间 关于modCount：在HashTable被创建完成后，除了使用iterator自己的remove方法，其他任何对于它结构性改变的方法都会抛出ConcurrentModificationException；因此在面对同步更改的情况下iterator能够失败得快而干净。但是这并不能对于非同步的同时更改带来硬性保证不会出现问题。 我们在iterator中看到这个也就明白了，在得到自己的遍历器的时候就会自己期望的更改次数值为当前的已经的更改次数值。 1expectedModCount = modCount; 当一个对象得到它的遍历器的时候也就是准备遍历它的所有元素，那么在这个遍历过程中我也就不想其中有元素会有所改变，所以在这个时候如果我们通过直接调用容器的删除添加元素等方法就会造成。 HashTable处理哈希冲突的方法也是使用了链式存储法 其实其他的大多就跟HashMap一样，最大不一样也就是进行了共享资源的同步。]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2018%2F06%2F13%2FReading%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[线性表顺序存储方式 定义 用一段地址连续的存储空间存储线性表的元素 存储结构 1234typedef struct&#123; Elemtype data[MAX_SIZE]; int length;&#125;SqList 添加元素实现方式 实现原理 将要插入的位置以后的元素全部向后移一位，然后将插入的元素添加进去 算法 12345678Status insertElem(SqList *l, int i, Elemtype e)&#123; int k; for(k=l-&gt;length;k&gt;=i-1; k++)&#123; l-&gt;data[k]=l-&gt;data[k-1]; &#125; l-&gt;data[i-1] = e; return OK;&#125; 删除元素实现方式 实现原理 将要删除元素以后的所有元素向前移一位 算法 1234567Status deleteElem(SqList *l, int i)&#123; int k; for(k=i-1; k &lt; l-&gt;length; k++)&#123; l-&gt;data[k] = l-&gt;data[k+1]; &#125; return OK;&#125; 链式存储方式 存储结构 12345typedef struct Node&#123; ElemType data; struct Node *next;&#125;typedef struct Node *LinkList; 添加元素算法 1234567891011121314Status insertElem(LinkList *l, int i, ElemType e)&#123; int j = 1; LinkList p,q; p = *l; while(p &amp;&amp; j&lt;i)&#123; p=p-&gt;next; j++; &#125; q = (LinkList)malloc(sizeof(Node)); q-&gt;data = e; q-&gt;next = p-&gt;next; p-next = q; return OK;&#125; 删除元素算法 1234567891011121314Status deleteElem(LinkList *l, int i)&#123; int j = 1; LinkList p,q; p = *l; while(p &amp;&amp; j&lt;i)&#123; p=p-&gt;next; j++; &#125; q = p-&gt;next; p-next = q-&gt;next; free(q); l-&gt;length = l-&gt;length - 1; return OK;&#125; 循环链表 定义 如果从链表中间一个元素开始遍历链表，如果使用传统的方式会比较麻烦，这个时候如果使用循环链表就比较方便，即在尾节点上存储头节点的地址，而不是存储空； 双向链表 定义 在使用传统链表的时候如果需要查看当前节点的上一个节点会显得比较麻烦，这个时候如果有前驱后后继两个节点之分就会方便很多 存储结构 12345typedef struct Node&#123; Elemtype data; Node *previous; Node *next;&#125; 栈顺序存储方式 存储结构 1234typedef struct Stack&#123; Elemtype data[MAX_SIZE]; int top;&#125; 添加元素算法 1234567Status push(Stack *s, Elemtype e)&#123; if(top + 1 &gt; MAX_SEZE)&#123; return ERROE; &#125; s-&gt;data[++s-&gt;top] = e; return OK;&#125; 删除元素实现算法 1234567Status pop(Stack *s)&#123; if(top == 0)&#123; return ERROE; &#125; --s-&gt;top; return OK;&#125; 链式存储方式 存储结构 123456789typedef struct Node&#123; Elemtype data; Node *next;&#125;Node, *LinkStackPtr;typedef struct LinkStack&#123; LinkStackPtr top; int count;&#125; 添加元素算法 123456789101112Status push(LinkStatck *s, Elemtype e)&#123; Node *node = (LinkStatckPtr)malloc(sizeof(Node)); if(node)&#123; return ERROE; &#125; node-&gt;data = e; LinkStatckPtr top = s-&gt;top; node-&gt;next = top; s-&gt;top = node; ++s-&gt;count; return OK;&#125; 删除元素算法 1234567Status pop(LinkStatck *s)&#123; LinkStackPtr p = s-&gt;top; s-&gt;top = p-&gt;next; free(p); s-&gt;count--; return OK;&#125; 队列链队列 存储结构 12345678typedef struct QNode&#123; Elemtype data; QNode *next;&#125;QNode, *QueuePtr;typedef struct LinkQuene&#123; QueuePtr front, rear;&#125; 添加元素算法 12345678910Status enQueue(LinkQueue *q, Elemtype e)&#123; QueuePtr s = (QueuePtr)malloc(sizeof(QNode)); if(!q)&#123; exit(OVERFLOW); &#125; s-&gt;data = e; q-&gt;rear-&gt;next = s; q-&gt;rear = s; return OK;&#125; 删除元素算法 123456Status deQueue(LinkQueue *q)&#123; QueuePtr s = q-&gt;front; q-&gt;front = s-&gt;next; free(s); return OK;&#125; 循环队列 存储结构 12345typedef struct Queue&#123; Elemtype data[MAX_SIZE]; int front; int rear;&#125; 添加元素算法 1234567Status enQueue(Queue *q, Elemtype e)&#123; if((q-&gt;rear + 1)%MAX_SIZE == q-&gt;front)&#123; return OVERFLOW; &#125; data[++front] = e; return OK;&#125; 删除元素算法 1234567Status deQueue(Queue *q)&#123; if(q-&gt;front == q-&gt;rear)&#123; return ERROR; &#125; q-&gt;front--; return OK;&#125; 二叉树 定义 是n个节点的集合，该集合或者是空集，或者由一个根节点和两棵互不相交的、分别称为根节点的左子树和右子树的二叉树组成。 特殊二叉树 满二叉树：在一棵二叉树中，如果所有分支节点都存在左子树和右子树，并且所有叶子都在同一层上，这样的二叉树称为满二叉树。 完全二叉树：在一棵具有n个节点的二叉树按层序编号，如果编号为i的节点与同样深度的满二叉树中国编号为i的点在在二叉树中位置相同，则这棵二叉树就是完全二叉树。 性质 在二叉树的第i层上之多有2^i-1 个结点 深度为k的二叉树至多有(2^k)-1个结点 对于任何一棵二叉树T，如果其终端结点数为n0，度为2的结点数n2，则n0 = n2 +1 具有n个结点的完全二叉树的深度为（log2n）+ 1；(如果log2n不为整数，那么其为不大于log2n的整数) 如果对一棵有n个结点的完全二叉树的结点按层序编号，对任一结点i有 如果i=1，则结点i是二叉树的根，无双亲；如果i&gt;1则其双亲是结点(i/2) (不大于其的最大整数) 如果2i&gt;n则结点i无左孩子 如果2i+1&gt;n则结点无右孩子 存储结构 1234typedef struct BiTNode&#123; ElemType data; struct BiTNode *lChild, rChild;&#125;BiTNode, *BiTree; 遍历二叉树 前序遍历 方式: 先访问根节点，再访问左子树，最后右子树 算法： 12345678void preOrderTraverse(BiTree t, void (*visit)(BiTree))&#123; if(t == NULL)&#123; return ; &#125; visit(t); preOrderTraverse(t-&gt;lChild, visit); preOrderTraverse(t-&gt;rChild, visit);&#125; 中序遍历 方式:先方位右子树，再访问根结点，最有是右子树 算法 12345678void inOrderTraverse(BiTree t, void (*visit)(BiTree))&#123; if(t == null)&#123; return; &#125; preOrderTraverse(t-&gt;lChild, visit); visit(t); preOrderTraverse(t-&gt;rChild, visit);&#125; 后序遍历 方式:先访问右子树，再访问根结点，最后是左子树 算法 12345678void inOrderTraverse(BiTree t, void (*visit)(BiTree))&#123; if(t == null)&#123; return; &#125; preOrderTraverse(t-&gt;lChild, visit); preOrderTraverse(t-&gt;rChild, visit); visit(t);&#125; 一些方法用的遍历方式 在创建链二叉树的时候要使用前序遍历 在销毁链二叉树的时候要使用后序遍历 赫夫曼树 最优二叉树 实现原理： 根据给定的n个权值{w1,w2……wn}构成n颗二叉树集合F={T1,T2…..Tn},其中每颗二叉树Ti中只有一个带权为Wi根结点，其左右子树为空。 在F中选取两棵根结点的权值最小的树作为左右子树构造一棵新的二叉树，且置新的二叉树的根结点的权值为其左右子树上根结点的权值之和 在F中删除这两棵树，同时将新得到的二叉树加入F中 重复2 、3步骤，直到F中只含一棵树为止。 查找静态查找顺序查找 算法 12345678// 其中n为数组个数，key为要查找的值int sequential_Search(int *a, int n, int key)&#123; a[0] key; while(!a[n] == key)&#123; n--; &#125; return n;&#125; 有序表的查找 折半查找 算法 1234567891011121314151617// 其中n为数组个数，key为要查找的值int binary_Search(int *a, int n, int key)&#123; int low = 1; int high = n; int mid; while(low &lt;= hign)&#123; mid = (low + hign)/2; if(a[mid] &lt; key)&#123; low = mid+1; &#125;else if(a[mid] &gt; key)&#123; hign = mid + 1; &#125;else if(a[mid] = key)&#123; return mid; &#125; &#125; return 0;&#125; 插值查找 优点 对于分布比较均匀的数据来说，查找性能会更加的好，但是对于不均匀的数据查找性能还不如折半查找 算法 1234567891011121314151617// 其中n为数组个数，key为要查找的值int binary_Search(int *a, int n, int key)&#123; int low = 1; int high = n; int mid; while(low &lt;= hign)&#123; mid = low + (key-a[low])/(a[hign]- a[low])*(hign -low); if(a[mid] &lt; key)&#123; low = mid+1; &#125;else if(a[mid] &gt; key)&#123; hign = mid + 1; &#125;else if(a[mid] = key)&#123; return mid; &#125; &#125; return 0;&#125; 线性索引查找 稠密索引 实现原理：是指在线性索引中，将数据集的每个记录对应一个索引项。 缺点：如果数据集比较大，意味着索引也得同样的数据集长度规模，对于内存有限的计算机来说，可能就需要反复的访问磁盘，查找性能反而大大下降。 分块索引 实现原理：就是用分块有序(块内无序，块间有序)的方式，把数据集的记录分成了若干块，将每块对应一个索引，这种索引方法就是分块索引。 倒排索引 实现原理：就像在通过关键字搜索文章时，我们记录一张表，第一列是关键字，第二列是文章的编号；这里就是倒排索引通用的索引项结构，关键字是次关键码，文章编号为记录号表；其中记录号表存储具有相同次关键字的所有记录的记录号。这样的实现方式就是倒排索引。 动态查找二叉排序树 定义：它或者是一棵空树，或者具有以下性质： 若它的左子树不空，则左子树上所有结点的值均小于它的根结点的值。 若它的右子树不空，则右子树上所有结点的值均小于它的根结点的值。 它的左右子树也分别为二叉排序树。 查找操作 算法： 1234567891011121314151617//f 指向T的双亲结点，其初始值为NULL//若查找成功p指向该数据元素结点，否则指向查找路径上最后访问的结点Status searchBST(BiTree t, int key, BiTree f, BiTree *p)&#123; if(!t)&#123; *p=f; return false; &#125; else if(key == t-&gt;data)&#123; *p = t; return TRUE; &#125; else if(key &lt; t-&gt;data)&#123; return searchBST(t-&gt;lChild, key, t, p) &#125; else return searchBST(t-&gt;rChild, key, t, p);&#125; 插入操作 算法： 12345678910111213141516171819Status insertBST(BiTree *T, int key)&#123; BiTree p,s; if(!searchBST(T, key, NULL, &amp;p))&#123; s = (BiTree)malloc(sizeof(BiTNode)); s-&gt;data = key; s-&gt;lChild = s-&gt;rChild = NULL; if(!p)&#123; *T = s; &#125; else if(p-&gt;data &gt; key)&#123; p-&gt;lChild = s; &#125; else if(p-&gt;data &lt; key)&#123; p-&gt;rChild = s; &#125; return TRUEE; &#125; return FALSE;&#125; 删除操作 算法 123456789101112131415161718192021222324252627282930Status delete(BiTree p)&#123; BiTree q,s; if(p-&gt;rChild == NULL)&#123; q = p; p = p-&gt;lChild; free(q); &#125;else if(p-&gt;lChild == NULL)&#123; q = p; p = p-&gt;rChild; free(q); &#125;else&#123; s = p-&gt;lChild; while(s-&gt;rChild)&#123; q = s; s= s-&gt;rChild; &#125; p-&gt;data = s-&gt;data; //有可能被删除结点的左子树没有右子树 if(s == p-&gt;lChild)&#123; q = p; p = s; free(q); &#125; else&#123; //连接由于s被换走后空下来的位置 q-&gt;rChild = s-&gt;lChild; free(s); &#125; &#125;&#125; 平衡二叉树 定义:是一种特殊的二叉排序树，其中每一个节点的左子树和右子树的高度差之多为1 实现原理: 失去平衡后进行调整的规律有以下四种情况: 单向右旋平衡处理：由于在*a的左子树根结点的左子树上插入结点，致使其平衡因子由1变为2，则需要一次向右的顺时针旋转操作 单向左旋平衡处理：由于*a的右子树的根结点的右子树上插入结点，致使其不平衡，则需要一次左旋处理 双向旋转(先左后右)平衡处理:由于在*a的左子树根结点的右子树上插入结点，就需要先左旋处理再右旋处理 双向旋转(先有后左)平衡处理:由于在*a的右子树根结点的左子树上插入结点，就需要先右旋处理再左旋处理 多路查找树2-3 树 定义:2-3树是这样一棵多路查找树：其中的每一个结点都具有两个孩子(2结点)或三个孩子(3结点)；一个2结点包含一个元素和两个孩子，一个3结点包含一小一大两个元素和三个孩子 B树 定义:2-3树，2-3-4树是B树的特例。结点最大的孩子数目称为B树的阶。每一个结点和它的子树就可以覆盖一个范围，联合起来那么就是所有的结果。这样的方式可以让我们很快的定位出我们需要的结果。 B+树 实现原理：由于B树如果需要遍历的话比较麻烦，在遍历完一个子节点又需要回到双亲结点，然后找到下一个遍历的子节点，所以B+树就是在B树的基础上给每个子节点存储了一个指向后一叶子结点的指针。 哈希查找 定义：散列技术是在记录的存储位置和它的关键字之间建立一个确定的对应关系f，使得每个关键字key对应一个存储位置f(key). 散列函数构造方法 直接地址法:取关键字的某个线性函数值为散列地址 除留余数法：取模 处理哈希冲突 开放地址法：一旦发生了冲突，就去寻找下一个空的散列地址，只要散列表足够大，空的散列地址总能够找到。它的公式是：fi(key) = (f(key) + di) MOD m 链地址法:将所有关键字为同义词的记录存储在一个单链表中，在散列表中只存储所有同义词字表的头指针。当然这个也就带来了遍历链表的性能损耗。 再散列函数法：预备另一个散列函数，当发生冲突的时候使用这个散列函数来进行散列。 排序冒泡排序 算法实现 12345678910void bubbleSort(SqList *l)&#123; int i，j; for(i = 1; i&lt;l-&gt;length; i++)&#123; for(j=l-&gt;length-1; j&gt;=i; j--)&#123; if(l-&gt;r[j]&lt;l-&gt;r[j-1])&#123; swap(l,j,j-1); &#125; &#125; &#125;&#125; 简单选择排序法 算法实现 1234567891011121314void selectSort(SqList *l)&#123; int i, j, min, k; for(i = 1; i&lt;l-&gt;length; i++)&#123; k = i; for(j = i; j&lt;l-&gt;length; j++)&#123; if(l-&gt;r[j]&lt;l-&gt;r[i])&#123; k = j; &#125; &#125; if(i!=k)&#123; swap(l, i, k); &#125; &#125;&#125; 直接插入排序 算法 123456789101112void insertSort(SqList *l)&#123; int i,j; for(i = 2; i &lt; l-&gt;length; i++)&#123; if(l-&gt;r[i]&gt;l-&gt;[i-1])&#123; l-&gt;r[0] = l-&gt;r[i]; for(j=i-1;l-&gt;r[j]&gt;l-&gt;r[0]; j--)&#123; l-&gt;r[j+1] = l-&gt;r[j]; &#125; l-&gt;r[j] = l-&gt;r[0]; &#125; &#125;&#125; 希尔排序 实现原理:根据由大到小的增量将两个数从小到大的排序，在增量变小的过程中序列已经变为基本有序，最后元素交换的次数会越来越少。 堆排序 堆：堆是具有以下性质的完全二叉树：每个结点的值都大于或等于其左右孩子结点的值，称为大顶堆，相反则是小顶堆。 实现原理：将待排序的序列造成一个大顶堆。此时，整个序列的最大值就是堆顶的根结点。将它移走(其实就是将其与堆数组的末尾元素交换，此时末尾元素就是最大值)，然后将剩余的n-1个序列重新构造成一个大顶堆，这样就会得到n个元素中的次大元素。如此反复执行，便能够得到一个有序序列了。 归并排序快速排序]]></content>
  </entry>
  <entry>
    <title><![CDATA[设计模式]]></title>
    <url>%2F2018%2F05%2F12%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[代理模式静态代理所谓静态代理也就是在程序运行前就已经存在代理类的字节码文件，代理类和委托类的关系在运行前就确定了。 通过继承实现静态代理直接贴代码：1234567891011121314151617181920212223public interface MoveAble &#123; void move() throws InterruptedException;&#125;public class Car implements MoveAble &#123; @Override public void move() throws InterruptedException &#123; System.out.println(&quot;汽车正在行驶....&quot;); &#125;&#125;public class ExCar extends Car &#123; @Override public void move() throws InterruptedException &#123; long startTime = System.currentTimeMillis(); super.move(); Thread.sleep(1000); long endTime = System.currentTimeMillis(); System.out.println(&quot;行驶了&quot;+ (endTime - startTime) + &quot;时间....&quot; ); &#125;&#125; 通过继承被代理类，然后在代理类里面实现方法调用被代理类的被代理方法，在这个方法前后我们就可以我们自己想做的事情。 通过聚合实现静态代理1234567891011121314151617181920212223242526public interface MoveAble &#123; void move() throws InterruptedException;&#125;public class Car implements MoveAble &#123; @Override public void move() throws InterruptedException &#123; System.out.println(&quot;汽车正在行驶....&quot;); &#125;&#125;public class ImCar &#123; private MoveAble m; public ImCar(MoveAble m)&#123; this.m = m; &#125; public void move() throws InterruptedException &#123; long startTime = System.currentTimeMillis(); m.move(); long endTime = System.currentTimeMillis(); System.out.println(&quot;行驶了&quot;+ (endTime - startTime) + &quot;时间....&quot; ); &#125;&#125; 将被代理类作代理类的属性成员，然后在代理方法中调用被代理方法，也就可以在被代理方法调用前后进行自己的操作。 两种静态代理模式的比较聚合方式的静态代理比继承方式的静态代理更加的好因为聚合方式的静态代理的可扩展性更好；如果我们使用继承方式的静态代理当我们需要给对象添加一个代理功能时，有一个需求就添加一个代理类，这样就会非常麻烦；但是如果我们使用聚合方式的静态代理模式，那么我们就可以将不同的需要代理的功能分离出来，然后实现同一个接口，那么就可以实现代理功能，而且还可以像装饰者模式一样实现功能的叠加，即可插拔性更好。 动态代理如果都用静态代理的话会发现会产生很多动态代理的类，一个类加一个代理功能就需要一个动态代理类，那么动态代理就解决了这个问题。 jdk动态代理（被代理类必须实现了接口）public class Car implements MoveAble { @Override public void move() throws InterruptedException { System.out.println(“汽车正在行驶….”); }} public class TimeHandler implements InvocationHandler { Object target; public TimeHandler(Object target){ this.target = target; } @Override public Object invoke(Object o, Method method, Object[] objects) throws Throwable { long startTime = System.currentTimeMillis(); method.invoke(target); Thread.sleep(1000); long endTime = System.currentTimeMillis(); System.out.println(&quot;汽车行驶了&quot; + (endTime - startTime) + &quot;ms 时间...&quot; ); return null; } } public class TestJdkProxy { public static void main(String[] args) throws InterruptedException { Car car = new Car(); TimeHandler timeHandler = new TimeHandler(car); MoveAble m = (MoveAble) Proxy.newProxyInstance(ClassLoader.getSystemClassLoader(), car.getClass().getInterfaces(), timeHandler); m.move(); } }1下面是动态代理newProxyInstance的源码： @CallerSensitivepublic static Object newProxyInstance(ClassLoader loader, Class&lt;?&gt;[] interfaces, InvocationHandler h) { Objects.requireNonNull(h); Class&lt;?&gt; caller = System.getSecurityManager() == null ? null : Reflection.getCallerClass(); Constructor&lt;?&gt; cons = getProxyConstructor(caller, loader, interfaces); return newProxyInstance(caller, cons, h);}123结合聚合方式的静态代理我个人理解为，首先getProxyConstructor(caller, loader, interfaces);创建了代理类的含interfaces引用的构造器；newProxyInstance(caller, cons, h)，然后根据InvocationHandler实现所有方法。##### cglib动态代理（代理类不能为final类，因为是靠继承类来实现的） 单例模式双重检锁实现代码：1234567891011121314public class Singleton &#123; private volatile static Singleton singleton; private Singleton ()&#123;&#125; public static Singleton getSingleton() &#123; if (singleton == null) &#123; synchronized (Singleton.class) &#123; if (singleton == null) &#123; singleton = new Singleton(); &#125; &#125; &#125; return singleton; &#125; &#125; 第一重检锁：直接判断singleton是否为空，这个时候会直接调用字节码指令：getstatic，避免进行过多的同步浪费，提升性能；第二重检锁：在调用getstatic字节码指令把singleton对象取出来之后再判断它是否为空并不是一个原子操作；所以存在其它线程已经完成了此实例化过程；所以就需要第二次判断这个singleton是否为空。 桥接模式 定义：将抽象部分与它的实现部分分离，使它们都可以独立地变化。 也就是说 在桥接模式中存在两个维度的变化，使用组合的方式将两个变化结合起来 下面是模式结构图 从JDBC 角度理解 没有怎么理解JDBC 的两个维度的变化在哪里，在一篇文章中觉得似乎是这样的 姑且这样，以后作修改 通过图可以看出，基于JDBC的应用程序，使用JDBC的API，相当于是对数据库操作的抽象扩展，算做桥接模式的抽象部分；而具体的接口实现是由驱动来完成的，驱动就相当于桥接模式的实现部分了。而桥接的方式，不再是让抽象部分持有实现部分，而是采用了类似于工厂的做法，通过DriverManager来把抽象部分和实现部分对接起来，从而实现抽象部分和实现部分解耦。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java序列化]]></title>
    <url>%2F2018%2F05%2F12%2FJava%20%E5%9F%BA%E7%A1%80%2Fjava%E5%BA%8F%E5%88%97%E5%8C%96%2F</url>
    <content type="text"><![CDATA[为什么要序列化当我们创建一个对象后，如果程序终止那么对象就会销毁，但是存在我们需要对对象进行持久化的需求，以便在将来我们取出对象进行再次利用。序列化就是把对象变成字节码序列来实现轻量级持久化，也方便我们对其在网络上进行传输。 怎么序列化123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class Stu implements Serializable&#123; private String name; private int age; private transient String password; public Stu(String name, int age, String password) &#123; this.name = name; this.age = age; this.password = password; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125; public String getPassword() &#123; return password; &#125; public void setPassword(String password) &#123; this.password = password; &#125; public String getName() &#123; return name; &#125;&#125;public class TestSerializable &#123; public static void main(String[] args) throws IOException, ClassNotFoundException &#123; Stu stu = new Stu(&quot;May&quot;,20, &quot;123456&quot;); ObjectOutputStream ops = new ObjectOutputStream(new FileOutputStream(&quot;/home/may/Documents/temp.txt&quot;)); ops.writeObject(stu); ops.close(); ObjectInputStream ois = new ObjectInputStream(new FileInputStream(&quot;/home/may/Documents/temp.txt&quot;)); Stu stu1 = (Stu) ois.readObject(); System.out.println(stu1.getPassword()); &#125;&#125; 以上便是简单的实现对象的序列化，只需要在类上添加Serializable标记接口，然后就可以直接使用ObjectOutputStream和ObjecInputStream对对象进行序列化和反序列化。 transient关键字在序列化的时候，有些字段我们不想默认序列化，比如说用户的密码等；这个时候我们就可以使用这个关键字，对标记的字段屏蔽默认序列化。 寻找类在我们进行反序列化的时候，被序列化对象的java文件应该在同一个目录下，而且版本相同即在序列化后没有进过修改，不然在反序列化的时候会抛出ClassNotFoundException。 序列化的控制有些时候我们不想按照默认的序列化方式进行，我们想定义自己对一个对象的序列化的方式，当然上面transient是一个方式。我们还可以使用Externalizable接口，重载writeExternal和readExternal方法。 12345678910111213141516171819202122232425262728293031323334353637383940414243public class Stu implements Externalizable&#123; private String name; private int age; private transient String password; public Stu(String name, int age, String password) &#123; this.name = name; this.age = age; this.password = password; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125; public String getPassword() &#123; return password; &#125; public void setPassword(String password) &#123; this.password = password; &#125; public String getName() &#123; return name; &#125; public void writeObject(ObjectOutputStream oos) throws IOException &#123; oos.defaultWriteObject(); &#125; public void readObject(ObjectInputStream ois) throws IOException, ClassNotFoundException &#123; ois.defaultReadObject(); &#125;&#125; 这里的defaultReadObject方法就是会采用默认的对象的序列化方式。 Externalizable的替代方案直接在实现了Serialization类里面实现下面两个方法123private void WriterObject()private void readObject() 在序列化和反序列化的时候在调用ObjectOutputStream.writeObject()和ObjectInputStream.readObject()的时候会检查object是不是有自己的writeObject和readObject方法。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>序列化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nio]]></title>
    <url>%2F2018%2F05%2F05%2FIO%2Fjava%20nio%2F</url>
    <content type="text"><![CDATA[IO模式异步IO用户进程发起read操作之后，立刻就可以开始去做其它的事。而另一方面，从kernel的角度，当它受到一个asynchronous read之后，首先它会立刻返回，所以不会对用户进程产生任何block。然后，kernel会等待数据准备完成，然后将数据拷贝到用户内存，当这一切都完成之后，kernel会给用户进程发送一个signal，告诉它read操作完成了。 阻塞和非阻塞 阻塞 在等待数据就绪和复制数据阶段均阻塞。 非阻塞 在等待数据就绪阶段，如果数据未就绪 read 会立刻返回 error，不阻塞；用户需要轮询以确认数据就绪；当就绪后则复制数据，该过程阻塞。 多路复用实现非阻塞 这个概念稍有不同，它是在执行 select() 的时候，同时阻塞多个 fd 然后等到监测到某些 fd 就绪时返回。此时进程两阶段均被阻塞，但等待数据就绪阶段由 select() 阻塞，复制数据阶段由 read() 阻塞。 在BIO模型中，我们要实现非阻塞，由于不能知道什么时候可以从内核缓冲区中取数据又不想去浪费CPU资源，那么我们只能创建一个新的线程，然后使用新的线程去做接下来的事件然后等到可以取数据的时候，我们再去取。但是创建线程也是很消耗资源，而且当线程多了后切换线程也是很耗CPU资源的。所以在单线程下的IO多路复用的优点就凸显数来了，没有线程切换，只有拼命的读、写、选择事件，如果再利用好多核心进行IO那么效率还会有更大的提升 Unix五种IO模型 阻塞IO 非阻塞IO IO复用（select、poll、epoll） 信号驱动IO 异步IO Reactor和Proactor模式其实java中Selector就是Reactor模式的实现，java中的AIO就是Proactor模式的实现；它们都要实现IO的多路复用，但是在事件分发者分发给事件处理者后（内核缓冲区数据准备好了）处理事件方式不一样；前者是同步的即在当前线程下处理IO任务（将内核缓冲区数据复制到用户空间），如果这个IO任务比较耗时就会比较浪费CPU资源；后者采用的方式的创建一个新的线程给事件处理者 NIONIO与传统IO的区别 NIO面向缓冲，而传统IO面向流；传统IO面向流意味着每次从流中读一个或多个字节，直至读取所有字节，它们没有被缓存在任何地方 NIO是非阻塞的，而传统IO是阻塞的；在操作系统级别体现在当从IO设备接受数据的时候，在传统IO中当前线程需要等待设备控制器从IO设备中读取数据(虽然这个时候CPU与设备控制器是异步的)然后CPU再读取设备控制器中缓存的数据到内核内存里面；但是NIO会对前面这个过程进行异步，只有当IO设备里面的数据都到达了内核内存再通知操作系统(这里的通知的过程，我们完全可以参考后面对epoll的参考) java nio基本概念nio就是new io，是相对于传统的io模型来说的；java nio是一种基于多路复用模型的同步非阻塞的io模型 。相对于传统就一个io流就需要一个线程来进行连接处理，nio的处理方式更加的节约资源，增加系统的吞吐量。 java nio的实现 上面就是java nio的一种基本模型；一个线程对应一个selector，一个selector可以绑定多个Channel，一个Channel对应着一个Buffer。当然这只是通常的做法，一个Channel也可以对应多个Selector，一个Channel对应着多个Buffer。 selectorselector就是java nio实现多路复用的关键；在传统io中，一个socket我们必须用一个线程去管理；而在这里我们在io流和线程中间抽象出一个selector出来，selector就可以去管理多个io流连接从而实现多路链接 。 创建selector 1Selector selector = Selector.open(); 在selector上注册channel 12channel.configureBlocking(false);channel.register(selector, SelectionKey.OP_READ); 这里的channel必须是非阻塞的，这里的第二个参数是表示channel对什么事件感兴趣，只有它感兴趣的事件selector才会分发给它，这里的事件有四种： Connect：一个channel成功连接到了其它服务器 Accept： 一个ServerSocketChannel接受到了一个连接 Read： 一个channel有数据等待读 Write：一个channel准备好了写数据 这四个事件对应SelectionKey四个常量： SelectionKey.OP_CONNECT SelectionKey.OP_ACCEPT SelectionKey.OP_READ SelectionKey.OP_WRITE 需要理解SelectionKey.OP_READ、SelectionKey.OP_WRITE的使用，为什么一般情况下在读取了数据需要重新注册其感兴趣的事件为SelectionKey.OP_WRITE，因为在非阻塞的情况下，比如调用了read 就会立马返回，操作系统并行的去帮我们完成读数据这件事情，但是我们不知道什么时候完成，所以如果我们注册了SelectionKey.OP_WRITE 那么就在完成的时候得到通知 如果想表示多个感兴趣的事件可以像如下： 1int interestSet = SelectionKey.OP_READ | SelectionKey.OP_WRITE; SelectionKey 其实根据源码我们知道SelectionKey绑定了一个channel和selector，就是想表示一个事件 12345final SelChImpl channel;public final SelectorImpl selector;private int index;private volatile int interestOps;private int readyOps; 找到对应上面四种事件的SelectionKey 1234selectionKey.isAcceptable();selectionKey.isConnectable();selectionKey.isReadable();selectionKey.isWritable(); 通过SelectionKey产生selector和channel 12Channel channel = selectionKey.channel();Selector selector = selectionKey.selector(); 附加数据 123selectionKey.attach(theObject);Object attachedObj = selectionKey.attachment(); 又或者在注册的时候添加 1SelectionKey key = channel.register(selector, SelectionKey.OP_READ, theObject); 通过selector选择channel select() 阻塞到至少有一个channel已经准备好了你注册的事件 int select(long timeout）和select()差不多，但是它最多阻塞timeout milliseconds selectNow() 不阻塞，它会马上返回不管有没有channel准备好了 关于源码 selector 怎么过滤事件 123456789101112131415161718// 这是selector 监听得到的发生的感兴趣的事件protected Set&lt;SelectionKey&gt; selectedKeys = new HashSet();// 这是用户注册的通道感兴趣的事件protected HashSet&lt;SelectionKey&gt; keys = new HashSet();// 其实这两个都是上面两个的视图，read-onlyprivate Set&lt;SelectionKey&gt; publicKeys;private Set&lt;SelectionKey&gt; publicSelectedKeys;protected SelectorImpl(SelectorProvider var1) &#123; super(var1); if (Util.atBugLevel("1.4")) &#123; this.publicKeys = this.keys; this.publicSelectedKeys = this.selectedKeys; &#125; else &#123; this.publicKeys = Collections.unmodifiableSet(this.keys); this.publicSelectedKeys = Util.ungrowableSet(this.selectedKeys); &#125;&#125; 注册channel 123456789101112131415protected final SelectionKey register(AbstractSelectableChannel var1, int var2, Object var3) &#123; if (!(var1 instanceof SelChImpl)) &#123; throw new IllegalSelectorException(); &#125; else &#123; SelectionKeyImpl var4 = new SelectionKeyImpl((SelChImpl)var1, this); var4.attach(var3); Set var5 = this.publicKeys; synchronized(this.publicKeys) &#123; this.implRegister(var4); &#125; var4.interestOps(var2); return var4; &#125; &#125; 下面的代码会调用selector的以上代码 1serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT); 大致完成了 实例化了一个SelectionKey并绑定了selector和channel，并且把此SelectionKey加入到了selector中的key中 channel通道是java nio的第二个主要创新。它们既不是一个扩展也不是一项增强,而是全新、极好的 Java I/O 示例,提供与 I/O 服务的直接连接。Channel 用于在字节缓冲区和位于通道另一侧的实体(通常是一个文件或套接字)之间有效地传输数据。通道是一种途径,借助该途径,可以用最小的总开销来访问操作系统本身的 I/O 服务。 channel有四种实现 FileChannel：操作文件 DatagramChannel：在网络上读或者写数据通过UDP SocketChannel：在网络上读或者写数据通过TCP ServerSocketChannel：监听TCP的连接，就像一个web服务器；每一个连接到来都会有一个SocketChannel生成 关于channel读数据 因为在channel读数据的时候遇到了大大的坑 :angry: NIO的API是真的有点难理解，真是搞飞机 :airplane: 所以在这里总结一下 处理读事件需要自己处理下列四种情况： channel还有数据，需要继续读 channel中暂时没有数据，但channel还没有断开，这时读取到的数据个数为0，结束读，继续到select()处阻塞等待数据 另外一端channel.close()关闭连接，这时候读channel返回的读取数是-1，表示已经到了到末尾，跟读文件一样；既然已经结束了，就把对应的SelectionKey给cancel掉，表示selector不再监听这个channel上的读事件；并且关闭连接，本端channel.close(); 另一端被强制关闭,也就是channel没有close()就被强制断开了,这时候本端会抛出一个IOException:你的主机中的软件中止了一个已建立的连接的异常，要处理这个异常 关于channel使用的技巧 是否还记得，SelectionKey的四个事件，我们这里不讲SelectionKey.OP_CONNECT,其实我们控制channel就是通过register方法来修改它所感兴趣的事件来实现接下来这个channel所要去做的事件 是不是读着有点模糊，下面我结合代码来分析 1serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT); 上面这段代码，因为其作为服务端作用只有监听端口，接收连接，所以我们通过这句代码来控制它只接收 连接到来的事件，但是这句代码不能说明修改感兴趣的事件 1234567891011121314151617181920212223private String readDataFromChannel(SelectionKey selectionKey) throws IOException &#123; SocketChannel clientChannel = (SocketChannel) selectionKey.channel(); StringBuilder readStr = new StringBuilder(); int len; while ((len = clientChannel.read(buffer)) != 0 &amp;&amp; len != -1) &#123; buffer.flip(); String str = new String(buffer.array(), 0, len); readStr.append(str); buffer.clear(); &#125; clientChannel.register(selector, SelectionKey.OP_WRITE); return readStr.toString();&#125;private void sendData(SelectionKey selectionKey) throws IOException &#123; SocketChannel clientChannel = (SocketChannel) selectionKey.channel(); ByteBuffer byteBuffer = ByteBuffer.allocate(1024); byte[] bytes = response.getBytes(); byteBuffer.put(bytes); byteBuffer.flip(); clientChannel.write(byteBuffer); clientChannel.register(selector, SelectionKey.OP_READ);&#125; 上面的代码就比较典型，在接收到内容后，我们需要马上进行回复，那么就需要把该channel感兴趣的事件修改为SelectionKey.OP_WRITE；然后在回复完数据后，又要回到等待接收数据，就需要把该channel感兴趣的事件修改为SelectionKey.OP_READ Buffer一个Buffer对象是固定数量的数据的容器。其作用是一个存储器,或者分段运输区,在这里数据可被存储并在之后用于检索。缓冲区的工作与通道紧密联系。通道是 I/O 传输发生时通过的入口,而缓冲区是这些数据传输的来源或目标。对于离开缓冲区的传输,您想传递出去的数据被置于一个缓冲区,被传送到通道。 buffer的基础用法 写数据到buffer buffer.flip() 从buffer读数据 buffer.clear() 或者 buffer.compact() capacity、position、limit position、limit的含义取决于buffer是出于写模式还是读模式，capacity的含义在这两种模式下的意义都是一样的 在写模式下，position首先被置为0,limit被置为capacity，然后写一个数据类型的数据position就增加1，最大为capacity-1 当通过flip()变为读模式时，position变为0，limit变为写数据时写到最大的position位置，也就是只能从position读到limit Buffer类型 ByteBuffer MappedByteBuffer CharBuffer DoubleBuffer FloatBuffer IntBuffer LongBuffer ShortBuffer 分配Buffer 12ByteBuffer buf = ByteBuffer.allocate(48);CharBuffer buf = CharBuffer.allocate(1024); 通过Buffer传输数据 123int bytesRead = inChannel.read(buf); //read into buffer.buf.put(127); flip() 从写模式换到读模式，具体的代码实现就是，将position置为0，limit设置为上一次position的位置 下面是一段怎么将ByteBuffer里面的数据转换为utf-8数据 clear() and compact() 读完数据后可以通过clear()方法重新加入数据 当你从Buffer中没有读完数据，但是想要写数据，然后在读剩下的数据就用compact，具体实现就是把所有没有读的数据复制到buffer开始，position设置到没有读完的数据的右边 mark() and reset() 记住position 将position 设置到上一次mark记住position的位置 12345678910111213141516171819private static String getBufferString(ByteBuffer buffer)&#123; Charset charset = null; CharsetDecoder decoder = null; CharBuffer charBuffer = null; try &#123; charset = Charset.forName("UTF-8"); decoder = charset.newDecoder(); // charBuffer = decoder.decode(buffer);//用这个的话，只能输出来一次结果，第二次显示为空 charBuffer = decoder.decode(buffer.asReadOnlyBuffer()); return charBuffer.toString(); &#125; catch (Exception ex) &#123; ex.printStackTrace(); return ""; &#125;&#125; 在java nio中同步非阻塞的实现方式因为java nio是在传统io中包装过来的，所以它的本质还是同步的，而它的非阻塞就是通过channel是实现的。在代码中我们通常通过 循环selector.select()来得到连接或者待读取的通道，这里都是同步的；当得到一个连接准备写入或者读取数据的时候也就是channel的write和read方法会异步的进行，也就是在执行write方法时在还没有进行数据写进buffer之前就返回了，read同理在没有读数据到Buffer的时候就已经返回，而是通过开启一个新的线程来完成写入和读取操作。 select、poll、epoll这三者都是IO多路复用的机制。I/O多路复用就是通过一种机制，一个进程可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。 Linux的socket事件wakeup callback机制 在介绍select、poll和epoll前，有必要说说Linux（2.6+）内核的事件wakeup callback机制，这是IO多路复用机制存在的本质。Linux通过socket睡眠队列来管理所有等待socket的某个事件的进程（Process），同时通过wakeup机制来异步唤醒整个睡眠队列上等待事件的Process，通知Process相关事件发生。 select 1int select (int n, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout); select 函数监视的文件描述符分3类，分别是writefds、readfds、和exceptfds。调用后select函数会阻塞，直到有描述副就绪（有数据 可读、可写、或者有except），或者超时（timeout指定等待时间，如果立即返回设为null即可），函数返回。当select函数返回后，可以 通过遍历fdset，来找到就绪的描述符。 我大致讲一下其过程： 当调用select 函数时，会将感兴趣的所有fd_set 从用户空间复制到内核空间 当前线程会被加入到每个监控的Socket上的等待队列上面睡眠 当Socket上有事件发生的时候修改复制进来的fd_set，唤醒等待的线程，等待的线程在继续执行遍历fd_set得到发生准备好的socket select 主要有两个问题： 可监控的fds太少 只能是1024 每次都要遍历 fd_set,比较的耗时 poll 1int poll (struct pollfd *fds, unsigned int nfds, int timeout); 不同与select使用三个位图来表示三个fdset的方式，poll使用一个 pollfd的指针实现。 12345struct pollfd &#123; int fd; /* file descriptor */ short events; /* requested events to watch */ short revents; /* returned events witnessed */&#125;; pollfd结构包含了要监视的event和发生的event，不再使用select“参数-值”传递的方式。同时，pollfd并没有最大数量限制（但是数量过大后性能也是会下降）。 和select函数一样，poll返回后，需要轮询pollfd来获取就绪的描述符。 poll 只是把感兴趣事件的数据结构改了，支持监控更多的socket epoll 12345678910111213141516171819202122int epoll_create(int size)；//创建一个epoll的句柄，size用来告诉内核这个监听的数目一共有多大，调用这个方法就会产生一个如下的结构体struct eventpoll&#123; .... /*红黑树的根节点，这颗树中存储着所有添加到epoll中的需要监控的事件*/ struct rb_root rbr; /*双链表中则存放着将要通过epoll_wait返回给用户的满足条件的事件*/ struct list_head rdlist; ....&#125;;//我觉得rbr是在用户注册完需要监听的端口的所有事件后，系统在接受到一个请求后就会把此事件与这个红黑树rbr中的所有事件进行比较，如果有的话就会加入到rdlist，所以在用户不用遍历所有监听的端口而是只用遍历rdlist就可以得到所有可以读取的流int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)//创建需要监听的事件epfd epoll的句柄idop 操作即是要对fd即端口删除、增加还是修改event，所有op对应 添加EPOLL_CTL_ADD，删除EPOLL_CTL_DEL，修改EPOLL_CTL_MODfd 监听的端口对应的句柄event 进行op操作的所有事件int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout);//从内核得到事件集合，返回需要处理的事件数目 以上我们可以得出epoll相对于select和poll的优点： 没有注册描述符的限制，也就是没有监听端口的限制，也不会因为监听端口的增加而性能降低 不用去遍历所有流得到能读或者写的流，epoll已经把哪个流产生了怎样的IO事件通知了我们，我们直接取出来即可 AIO在我看来一下的两种方式其实都是通过一种方式来进行异步的：先是通过多路复用也就是Nio来实现非阻塞，然后再通过创建线程做其它事情的方式避免等待从内核缓冲区向用户空间复制数据 所以它们有一个共同点就是要先在用户空间创建buffer Future方式 12345678910111213141516171819 Path path = Paths.get("/data/code/github/java_practice/src/main/resources/1log4j.properties"); AsynchronousFileChannel channel = AsynchronousFileChannel.open(path); ByteBuffer buffer = ByteBuffer.allocate(1024); Future future = channel.read(buffer,0);// while (!future.isDone())&#123;// System.out.println("I'm idle");// &#125;//我们可以在这里做其它事情 Integer readNumber = future.get(); buffer.flip(); CharBuffer charBuffer = CharBuffer.allocate(1024); CharsetDecoder decoder = Charset.defaultCharset().newDecoder(); decoder.decode(buffer,charBuffer,false); charBuffer.flip(); String data = new String(charBuffer.array(),0, charBuffer.limit()); System.out.println("read number:" + readNumber); System.out.println(data); 因为Future的本质就是直接返回而创建新的线程运算得到结果，运算结束后自己去取结果 回调方式 12345678910111213141516171819Path path = Paths.get("/data/code/github/java_practice/src/main/resources/1log4j.properties");AsynchronousFileChannel channel = AsynchronousFileChannel.open(path);ByteBuffer buffer = ByteBuffer.allocate(1024);channel.read(buffer, 0, buffer, new CompletionHandler() &#123; @Override public void completed(Integer result, ByteBuffer attachment) &#123; System.out.println(Thread.currentThread().getName() + " read success!"); &#125; @Override public void failed(Throwable exc, ByteBuffer attachment) &#123; System.out.println("read error"); &#125;&#125;);while (true)&#123; System.out.println(Thread.currentThread().getName() + " sleep"); Thread.sleep(1000);&#125; 创建新的线程从内核取数据，所以completed方法也是在新线程上完成的 从JAVA 源码分析NIO用NIO 实现一个简单的服务器123456789101112131415161718192021222324252627282930313233public void start() throws IOException &#123; serverSocketChannel = ServerSocketChannel.open(); ServerSocket serverSocket = serverSocketChannel.socket(); serverSocket.bind(new InetSocketAddress(PORT)); selector = Selector.open(); serverSocketChannel.configureBlocking(false); serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT); while (flag) &#123; if (selector.select() &gt; 0) &#123; Set&lt;SelectionKey&gt; selectionKeys = selector.selectedKeys(); Iterator&lt;SelectionKey&gt; iterator = selectionKeys.iterator(); while (iterator.hasNext()) &#123; SelectionKey selectionKey = iterator.next(); iterator.remove(); if (selectionKey.isAcceptable()) &#123; SocketChannel client = ((ServerSocketChannel)selectionKey.channel()).accept(); client.configureBlocking(false); client.register(selector, SelectionKey.OP_READ); &#125; if (selectionKey.isReadable()) &#123; readData((SocketChannel) selectionKey.channel()); &#125; if (selectionKey.isConnectable()) &#123; System.out.println("isConnectable == true"); &#125; &#125; &#125; &#125; &#125; 接下来我们就按照代码的逻辑思考底层是怎么实现的 Selector.open()Selector 是Java NIO实现的核心，那么它是怎么怎么得到的，它是什么呢？ Selector 是通过SelectorProvider 得到的 1234567891011121314151617public static SelectorProvider provider() &#123; synchronized (lock) &#123; if (provider != null) return provider; return AccessController.doPrivileged( new PrivilegedAction&lt;SelectorProvider&gt;() &#123; public SelectorProvider run() &#123; if (loadProviderFromProperty()) return provider; if (loadProviderAsService()) return provider; provider = sun.nio.ch.DefaultSelectorProvider.create(); return provider; &#125; &#125;); &#125;&#125; SelectorProvider 是一个桥连接实现的典型 本身SelectorProvider有自己的实现方式，在Linux和Windows下实现方式不同，然后它通过组合的方式成为比如说Selector的一个属性，然后Selector又有自己的不同实现，当然还有ServerSocketChannel 下面是Windows下Selector的一种实现 123456789101112131415WindowsSelectorImpl(SelectorProvider sp) throws IOException &#123; super(sp); // pollWrapper 是多路复用实现的关键；这个对象直接操作内存，将Socket句柄和感兴趣的事件保存保存下来 pollWrapper = new PollArrayWrapper(INIT_CAP); // Pipe 是一种管道，既可以读也可以写 // wakeupPipe 的实现是为了实现唤醒阻塞等待的Selector，下面会讲是怎么实现的 wakeupPipe = Pipe.open(); wakeupSourceFd = ((SelChImpl)wakeupPipe.source()).getFDVal(); SinkChannelImpl sink = (SinkChannelImpl)wakeupPipe.sink(); (sink.sc).socket().setTcpNoDelay(true); wakeupSinkFd = ((SelChImpl)sink).getFDVal(); pollWrapper.addWakeupSocket(wakeupSourceFd, 0);&#125; pollWrapperpollWrapper用Unsafe类申请一块物理内存pollfd，存放socket句柄fdVal和events，其中pollfd共8位，0-3位保存socket句柄，4-7位保存events。 pollWrapper提供了fdVal和event数据的相应操作，如添加操作通过Unsafe的putInt和putShort实现。 serverSocketChannel.register()这个方法其实 会调用Selector.register() 12345678910111213141516171819202122232425262728293031// SelectorImpl protected final SelectionKey register(AbstractSelectableChannel ch, int ops, Object attachment) &#123; if (!(ch instanceof SelChImpl)) throw new IllegalSelectorException(); SelectionKeyImpl k = new SelectionKeyImpl((SelChImpl)ch, this); k.attach(attachment); synchronized (publicKeys) &#123; implRegister(k); &#125; // 添加感兴趣的事件 k.interestOps(ops); return k; &#125; protected void implRegister(SelectionKeyImpl ski) &#123; synchronized (closeLock) &#123; if (pollWrapper == null) throw new ClosedSelectorException(); growIfNeeded(); channelArray[totalChannels] = ski; ski.setIndex(totalChannels); fdMap.put(ski); keys.add(ski); // 添加Socket句柄 pollWrapper.addEntry(totalChannels, ski); totalChannels++; &#125; &#125; 生成SelectionKey并添加附件attachment 如果当前channel的数量totalChannels等于SelectionKeyImpl数组大小，对SelectionKeyImpl数组和pollWrapper进行扩容操作。 如果totalChannels % MAX_SELECTABLE_FDS == 0，则多开一个线程处理selector 将SelectionKey 做上Index标记，标志Socket句柄在内存上的偏移量 通过刚刚的Index属性添加 Socket句柄到对应的pollfd 通过Index属性添加感兴趣的事件到对应的pollfd的event doSelect()1234567891011121314151617181920212223242526272829303132333435363738protected int doSelect(long timeout) throws IOException &#123; if (this.channelArray == null) &#123; throw new ClosedSelectorException(); &#125; else &#123; this.timeout = timeout; this.processDeregisterQueue(); if (this.interruptTriggered) &#123; this.resetWakeupSocket(); return 0; &#125; else &#123; this.adjustThreadsCount(); this.finishLock.reset(); this.startLock.startThreads(); try &#123; this.begin(); try &#123; this.subSelector.poll(); &#125; catch (IOException var7) &#123; this.finishLock.setException(var7); &#125; if (this.threads.size() &gt; 0) &#123; this.finishLock.waitForHelperThreads(); &#125; &#125; finally &#123; this.end(); &#125; this.finishLock.checkForException(); this.processDeregisterQueue(); int var3 = this.updateSelectedKeys(); this.resetWakeupSocket(); return var3; &#125; &#125; &#125; 其中 subSelector.poll() 是select的核心，由native函数poll0实现，readFds、writeFds 和exceptFds数组用来保存底层select的结果，数组的第一个位置都是存放发生事件的socket的总数，其余位置存放发生事件的socket句柄fd。 123456789private final int[] readFds = new int [MAX_SELECTABLE_FDS + 1];private final int[] writeFds = new int [MAX_SELECTABLE_FDS + 1];private final int[] exceptFds = new int [MAX_SELECTABLE_FDS + 1];private int poll() throws IOException&#123; // poll for the main thread // 第一个参数是pollfd 数组的首地址，第二个参数就可以得到监控的所有channel,也就是Socket return poll0(pollWrapper.pollArrayAddress, Math.min(totalChannels, MAX_SELECTABLE_FDS), readFds, writeFds, exceptFds, timeout);&#125; 如果之前没有发生事件，程序就阻塞在select处，当然不会一直阻塞，因为epoll在timeout时间内如果没有事件，也会返回； 一旦有对应的事件发生，poll0方法就会返回； processDeregisterQueue方法会清理那些已经cancelled的SelectionKey； updateSelectedKeys方法统计有事件发生的SelectionKey数量，并把符合条件发生事件的SelectionKey添加到selectedKeys哈希表中，并且把SelectionKey的readyOps修改为true wakeUp()123456789101112131415161718192021222324public Selector wakeup() &#123; synchronized (interruptLock) &#123; if (!interruptTriggered) &#123; setWakeupSocket(); interruptTriggered = true; &#125; &#125; return this;&#125;// Sets Windows wakeup socket to a signaled state.private void setWakeupSocket() &#123; setWakeupSocket0(wakeupSinkFd);&#125;private native void setWakeupSocket0(int wakeupSinkFd);JNIEXPORT void JNICALLJava_sun_nio_ch_WindowsSelectorImpl_setWakeupSocket0(JNIEnv *env, jclass this, jint scoutFd)&#123; /* Write one byte into the pipe */ const char byte = 1; send(scoutFd, &amp;byte, 1, 0);&#125; 可见wakeup()是通过pipe的write 端send(scoutFd, &amp;byte, 1, 0)，发生一个字节1，来唤醒poll（）。所以在需要的时候就可以调用selector.wakeup()来唤醒selector。 epoll 实现原理epoll是Linux下的一种IO多路复用技术，可以非常高效的处理数以百万计的socket句柄。 三个epoll相关的系统调用： int epoll_create(int size)epoll_create建立一个epoll对象。参数size是内核保证能够正确处理的最大句柄数，多于这个最大数时内核可不保证效果。 int epoll_ctl(int epfd, int op, int fd, struct epoll_event event)epoll_ctl可以操作epoll_create创建的epoll，如将socket句柄加入到epoll中让其监控，或把epoll正在监控的某个socket句柄移出epoll。 int epoll_wait(int epfd, struct epoll_event events,int maxevents, int timeout)epoll_wait在调用时，在给定的timeout时间内，所监控的句柄中有事件发生时，就返回用户态的进程。 epoll内部实现大概如下： epoll初始化时，会向内核注册一个文件系统，用于存储被监控的句柄文件，调用epoll_create时，会在这个文件系统中创建一个file节点。同时epoll会开辟自己的内核高速缓存区，以红黑树的结构保存句柄，以支持快速的查找、插入、删除。还会再建立一个list链表，用于存储准备就绪的事件。 当执行epoll_ctl时，除了把socket句柄放到epoll文件系统里file对象对应的红黑树上之外，还会给内核中断处理程序注册一个回调函数，告诉内核，如果这个句柄的中断到了，就把它放到准备就绪list链表里。所以，当一个socket上有数据到了，内核在把网卡上的数据copy到内核中后，就把socket插入到就绪链表里。 当epoll_wait调用时，仅仅观察就绪链表里有没有数据，如果有数据就返回，否则就sleep，超时时立刻返回。 流和channel的不同Reactor模型(反应堆模型) 什么是Reactor 下面是来自Wiki的解释： The reactor design pattern is an event handling pattern for handling service requests delivered concurrently to a service handler by one or more inputs. The service handler then demultiplexes the incoming requests and dispatches them synchronously to the associated request handlers. 其中关键点为： 事件驱动，即由某个事件的发生触发 可以处理一个或多个输入源 通过Service Handler同步的将输入事件（Event）采用多路复用分发给相应的Request Handler（多个）处理（注意这里有两个handler,一个ServiceHandler，一个Request Handler） 需要知道的是，Reactor模式是建立在Java NIO之上的，它只是一个很好的模式去连接事件和其相关联的事件处理器；它其实是一个流程化的过程，只是在JAVA 中用面向对象思想去建立这样的模型 Reactor 在反应堆模型中有三个角色，分别是： 1231. Reactor 将IO事件分派给对应的handler2. Acceptor 处理客户端连接，并分派请求到处理器链中3. Handlers 执行非阻塞读/写 任务 单Reactor单线程模型 概述一下其过程吧： 客户端的连接会被分发器分发给accptor进行 SocketChannel的获取并将其处理器附加到SelectionKey上，以便后面事件发生的时候获取并处理 当触发的事件发生比如说SocketChannel上有可以读或者可以写的事件发生，会通过分发器去获取SelectionKey上对应的处理器去执行 下面是用代码模拟的模型： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104/** * 等待事件到来，分发事件处理 */ class Reactor implements Runnable &#123;​ private Reactor() throws Exception &#123;​ SelectionKey sk = serverSocket.register(selector, SelectionKey.OP_ACCEPT); // attach Acceptor 处理新连接 sk.attach(new Acceptor()); &#125;​ public void run() &#123; try &#123; while (!Thread.interrupted()) &#123; selector.select(); Set selected = selector.selectedKeys(); Iterator it = selected.iterator(); while (it.hasNext()) &#123; it.remove(); //分发事件处理 dispatch((SelectionKey) (it.next())); &#125; &#125; &#125; catch (IOException ex) &#123; //do something &#125; &#125;​ void dispatch(SelectionKey k) &#123; // 若是连接事件获取是acceptor // 若是IO读写事件获取是handler Runnable runnable = (Runnable) (k.attachment()); if (runnable != null) &#123; runnable.run(); &#125; &#125;​ &#125; /** * 连接事件就绪,处理连接事件 */ class Acceptor implements Runnable &#123; @Override public void run() &#123; try &#123; SocketChannel c = serverSocket.accept(); if (c != null) &#123;// 注册读写 new Handler(c, selector); &#125; &#125; catch (Exception e) &#123;​ &#125; &#125; &#125; /** * 处理读写业务逻辑 */ class Handler implements Runnable &#123; public static final int READING = 0, WRITING = 1; int state; final SocketChannel socket; final SelectionKey sk;​ public Handler(SocketChannel socket, Selector sl) throws Exception &#123; this.state = READING; this.socket = socket; sk = socket.register(selector, SelectionKey.OP_READ); sk.attach(this); socket.configureBlocking(false); &#125;​ @Override public void run() &#123; if (state == READING) &#123; read(); &#125; else if (state == WRITING) &#123; write(); &#125; &#125;​ private void read() &#123; process(); //下一步处理写事件 sk.interestOps(SelectionKey.OP_WRITE); this.state = WRITING; &#125;​ private void write() &#123; process(); //下一步处理读事件 sk.interestOps(SelectionKey.OP_READ); this.state = READING; &#125;​ /** * task 业务处理 */ public void process() &#123; //do something &#125; 因为整个过程都是在单线程下的，不能充分利用CPU的资源,且如果处理过程比较复杂会将整个过程阻塞，不能接受新的连接，所以衍生出了下面的模型 单Reactor多线程模型 在这个模型下，其实其它都没有太多改变，就是添加了一个线程池去完成对读和写的过程的处理， 其代码实现过程如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455/** * 多线程处理读写业务逻辑 */ class MultiThreadHandler implements Runnable &#123; public static final int READING = 0, WRITING = 1; int state; final SocketChannel socket; final SelectionKey sk;​ //多线程处理业务逻辑 ExecutorService executorService = Executors.newFixedThreadPool(Runtime.getRuntime().availableProcessors());​​ public MultiThreadHandler(SocketChannel socket, Selector sl) throws Exception &#123; this.state = READING; this.socket = socket; sk = socket.register(selector, SelectionKey.OP_READ); sk.attach(this); socket.configureBlocking(false); &#125;​ @Override public void run() &#123; if (state == READING) &#123; read(); &#125; else if (state == WRITING) &#123; write(); &#125; &#125;​ private void read() &#123; //任务异步处理 executorService.submit(() -&gt; process());​ //下一步处理写事件 sk.interestOps(SelectionKey.OP_WRITE); this.state = WRITING; &#125;​ private void write() &#123; //任务异步处理 executorService.submit(() -&gt; process());​ //下一步处理读事件 sk.interestOps(SelectionKey.OP_READ); this.state = READING; &#125;​ /** * task 业务处理 */ public void process() &#123; //do IO ,task,queue something &#125;&#125; 多Reactor多线程模型 该模型后面的处理流程都与前面的模型一样，在单Reactor多线程模型下，连接的处理和去执行处理器是一个线性的过程，在该模型下，把连接的注册过程分离了出来 mainReactor负责连接顺序的注册到subReactor上，subReactor管理自己的selector，对其上的SocketChannel进行监听 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111/** * 多work 连接事件Acceptor,处理连接事件 */ class MultiWorkThreadAcceptor implements Runnable &#123;​ // cpu线程数相同多work线程 int workCount =Runtime.getRuntime().availableProcessors(); SubReactor[] workThreadHandlers = new SubReactor[workCount]; volatile int nextHandler = 0;​ public MultiWorkThreadAcceptor() &#123; this.init(); &#125;​ public void init() &#123; nextHandler = 0; for (int i = 0; i &lt; workThreadHandlers.length; i++) &#123; try &#123; workThreadHandlers[i] = new SubReactor(); &#125; catch (Exception e) &#123; &#125;​ &#125; &#125;​ @Override public void run() &#123; try &#123; SocketChannel c = serverSocket.accept(); if (c != null) &#123;// 注册读写 synchronized (c) &#123; // 顺序获取SubReactor，然后注册channel SubReactor work = workThreadHandlers[nextHandler]; work.registerChannel(c); nextHandler++; if (nextHandler &gt;= workThreadHandlers.length) &#123; nextHandler = 0; &#125; &#125; &#125; &#125; catch (Exception e) &#123; &#125; &#125; &#125; /** * 多work线程处理读写业务逻辑 */ class SubReactor implements Runnable &#123; final Selector mySelector;​ //多线程处理业务逻辑 int workCount =Runtime.getRuntime().availableProcessors(); ExecutorService executorService = Executors.newFixedThreadPool(workCount);​​ public SubReactor() throws Exception &#123; // 每个SubReactor 一个selector this.mySelector = SelectorProvider.provider().openSelector(); &#125;​ /** * 注册chanel * * @param sc * @throws Exception */ public void registerChannel(SocketChannel sc) throws Exception &#123; sc.register(mySelector, SelectionKey.OP_READ | SelectionKey.OP_CONNECT); &#125;​ @Override public void run() &#123; while (true) &#123; try &#123; //每个SubReactor 自己做事件分派处理读写事件 selector.select(); Set&lt;SelectionKey&gt; keys = selector.selectedKeys(); Iterator&lt;SelectionKey&gt; iterator = keys.iterator(); while (iterator.hasNext()) &#123; SelectionKey key = iterator.next(); iterator.remove(); if (key.isReadable()) &#123; read(); &#125; else if (key.isWritable()) &#123; write(); &#125; &#125;​ &#125; catch (Exception e) &#123;​ &#125; &#125; &#125;​ private void read() &#123; //任务异步处理 executorService.submit(() -&gt; process()); &#125;​ private void write() &#123; //任务异步处理 executorService.submit(() -&gt; process()); &#125;​ /** * task 业务处理 */ public void process() &#123; //do IO ,task,queue something &#125; &#125; 参考Linux io模式、select、poll、epoll https://segmentfault.com/a/1190000003063859 https://blog.csdn.net/tianjing0805/article/details/76021440 这篇很好 Aio https://juejin.im/entry/583ec2e3128fe1006bfa6c83 NIO http://tutorials.jenkov.com/java-nio/buffers.html NIO 源码 https://www.jianshu.com/p/0d497fe5484a https://my.oschina.net/u/2337927/blog/523366 反应堆 https://blog.csdn.net/qq924862077/article/details/81026740]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ArrayList源码解析]]></title>
    <url>%2F2018%2F03%2F13%2FJava%20%E5%9F%BA%E7%A1%80%2FArrayList%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[Arrays.copyof12345public static &lt;T, U&gt; T[] copyOf(U[] original, int newLength, Class&lt;? extends T[]&gt; newType) &#123; T[] copy = newType == Object[].class ? new Object[newLength] : (Object[])Array.newInstance(newType.getComponentType(), newLength); System.arraycopy(original, 0, copy, 0, Math.min(original.length, newLength)); return copy; &#125; 函数解释：返回一个元素original数组一样的但是引用不一样的数组。 System.arraycopy123public static native void arraycopy(Object src, int srcPos, Object dest, int destPos, int length); 函数解释：从指定的源数组复制数组，从指定位置，到目标数组的制定位置。源数组为src，目标数组为dest，复制的组件数量为length，从源数组复制的位置从下标srcPos到srcPos+length-1(源数组要复制的结尾的下标)，被复制到dest数组从下标destPos到destPos+length-1(目标数组要复制的结尾的下标)的位置。 变量123456private static final int DEFAULT_CAPACITY = 10; //默认的数组容量private static final Object[] EMPTY_ELEMENTDATA = new Object[0]; //临时实例化private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = new Object[0];transient Object[] elementData; //缓存private int size;//数组大小private static final int MAX_ARRAY_SIZE = 2147483639; //MAX_ARRAY_SIZE=Integer.MAX_VALNE-8;是因为虚拟机在数组数组类型数据中保留head word字段，其会占用空间。 构造器 无参构造函数 123public ArrayList() &#123; this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA;&#125; 构造时是将空数组赋值给elementData ，但是在随后的第一个add元素的时候，会先新创建一个容量为10的初始数组。 指定容量构造函数 123456789101112public ArrayList(int initialCapacity) &#123; if (initialCapacity &gt; 0) &#123; this.elementData = new Object[initialCapacity]; &#125; else &#123; if (initialCapacity != 0) &#123; throw new IllegalArgumentException("Illegal Capacity: " + initialCapacity); &#125; this.elementData = EMPTY_ELEMENTDATA; &#125;&#125; 集合构造函数 1234567891011public ArrayList(Collection&lt;? extends E&gt; c) &#123; this.elementData = c.toArray(); if ((this.size = this.elementData.length) != 0) &#123; if (this.elementData.getClass() != Object[].class) &#123; this.elementData = Arrays.copyOf(this.elementData, this.size, Object[].class); &#125; &#125; else &#123; this.elementData = EMPTY_ELEMENTDATA; &#125;&#125; Methodadd12345678private void add(E e, Object[] elementData, int s) &#123; if (s == elementData.length) &#123; elementData = this.grow(); &#125; elementData[s] = e; this.size = s + 1;&#125; 每一次添加元素的时候都会检查缓存数组的长度是否不够，不够就会加1 grow1234567private Object[] grow() &#123; return this.grow(this.size + 1);&#125; private Object[] grow(int minCapacity) &#123; return this.elementData = Arrays.copyOf(this.elementData,this.newCapacity(minCapacity));&#125; newCapacity123456789101112131415private int newCapacity(int minCapacity) &#123; int oldCapacity = this.elementData.length; int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1);// if (newCapacity - minCapacity &lt;= 0) &#123; if (this.elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) &#123; return Math.max(10, minCapacity); &#125; else if (minCapacity &lt; 0) &#123; throw new OutOfMemoryError(); &#125; else &#123; return minCapacity; &#125; &#125; else &#123; return newCapacity - 2147483639 &lt;= 0 ? newCapacity : hugeCapacity(minCapacity); &#125;&#125; 如果指定容量大于初始容量的1.5倍，且容量为空的话就初始化容量为10，不然就是指定容量的大小；所以这里当一个空的ArrayList添加一个元素后容量都会变为10. remove123456789101112public E remove(int index) &#123; Objects.checkIndex(index, this.size); ++this.modCount; E oldValue = this.elementData(index); int numMoved = this.size - index - 1; if (numMoved &gt; 0) &#123; System.arraycopy(this.elementData, index + 1, this.elementData, index, numMoved); &#125; this.elementData[--this.size] = null; return oldValue;&#125; 把从要移除元素的下标位置开始每个元素向前移动一个位置，然后另最后一个元素为null； addAll12345678910111213141516171819202122232425public boolean addAll(int index, Collection&lt;? extends E&gt; c) &#123; this.rangeCheckForAdd(index); Object[] a = c.toArray(); ++this.modCount; int numNew = a.length; if (numNew == 0) &#123; return false; &#125; else &#123; Object[] elementData = this.elementData; int var10001 = this.elementData.length; int s = this.size; if (numNew &gt; var10001 - this.size) &#123; elementData = this.grow(s + numNew); &#125; int numMoved = s - index; if (numMoved &gt; 0) &#123; System.arraycopy(elementData, index, elementData, index + numNew, numMoved); &#125; System.arraycopy(a, 0, elementData, index, numNew); this.size = s + numNew; return true; &#125;&#125; 先扩大数组容量，然后从指定位置开始把所有元素向后面移动要添加元素数量的位置，然后再将要添加元素的从指定位置开始插入。 removeRange12345678protected void removeRange(int fromIndex, int toIndex) &#123; if (fromIndex &gt; toIndex) &#123; throw new IndexOutOfBoundsException(outOfBoundsMsg(fromIndex, toIndex)); &#125; else &#123; ++this.modCount; this.shiftTailOverGap(this.elementData, fromIndex, toIndex); &#125;&#125; 从toIndex+1以后的所有元素移动到fromIndex的位置以后，然后再另length-1-（toIndex-fromIndex）位置后的所有元素为null 一些内部类ArrayListSpliteratorjava8 并行迭代 Spliterator接口 Spliterator 是Java8 引入的新接口，顾名思义，Spliterator可以理解为Iterator的Split版本，对于Java的流API，进行并行分割迭代计算，充分利用多核CPU的优势，并行计算具有极大的辅助作用。在使用Iterator的时候，我们一般都是单线程地去顺序遍历集合的元素，但是使用Spliterator可以将集合元素分割成多份，使用多个线程 同时进行迭代，大大地提高了执行效率。 SubList相当于ArrayList的一个子视图，所以对它的操作也会反应到ArrayList上，它的工作原理就是依赖于下面三个变量 123private final ArrayList&lt;E&gt; root; // 从root里面获得子listprivate final int offset; //SubList的开始，root截断的起点private int size;//subList的大小 ItrArrayList自定义实现的容器，实现了fail-fast机制（在遍历过程中如果modCount与expectedModCount不相等，则抛出ConcurrentModificationException异常） ListItr继承自ArrayList.Itr，扩展了ListIterator的方法，能够在遍历过程中进行更多的操作。 三种元素访问 随机访问 12345String value = null;int size = list.size();for (int i=0; i&lt;size; i++) &#123; value = (String )list.get(i); &#125; 此方法是直接在缓冲数组上的通过索引访问的，速度最快 foreach访问 1234String value = null;for(String a : list)&#123; value = a;&#125; foreach访问也比随机访问要慢，但是要快于迭代器的方式（foreach是一种语法糖，在编译期间需要进行语法解析，插入额外的辅助访问的代码，会有一定的消耗） 迭代器访问 12345String value = null;Iterator iter = list.iterator();while (iter.hasNext()) &#123; value = (String )iter.next();&#125; 速度最慢，由于要保存迭代器的状态，所以性能受到损耗 一些需要注意的点 底层通过System.arraycopy将原来ArrayList的缓冲数组elementData拷贝给新的ArrayList的缓冲数组，这里是一个深克隆，操作新的数组并不会改变原来的数组的状态。 每一次影响集合结构的修改（包括增加、删除、扩容、移动元素位置，不包括修改set）ArrayList的时候都要使得modCount自增，确保感知在使用迭代器和进行序列化过程中是否发生并发修改ArrayList的情况 在子列表上的操作（如add、remove等）都会反映到原来的ArrayList上面（共用elementData），即子列表只是提供一种在原列表上的一种视图。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>源码解析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java位运算符]]></title>
    <url>%2F2018%2F03%2F12%2FJava%20%E5%9F%BA%E7%A1%80%2Fjava%E4%BD%8D%E8%BF%90%E7%AE%97%E7%AC%A6%2F</url>
    <content type="text"><![CDATA[基本运算方法binary 二进制 octal 八进制 decimal 十进制 hexaddecimal 十六进制 a = D(60) = B(001111100) b = D(13) = B(00001101) 按位右移运算符(&gt;&gt;)左操作数按位右移右操作数指定的位数 a&gt;&gt;2 = D(15) = B(1111) 对于十进制来说就是 ａ= a / 2^2 按位左移运算符(&lt;&lt;)左操作数按位左移右操作数指定的位数 a&lt;&lt;2 = D(240) = H(11110000) 对于十进制来说就是 ａ = a* 2^2 按位右移补零运算符(&gt;&gt;&gt;)a&gt;&gt;&gt;2 = D(15) = B(00001111) 与运算符(&amp;)如果相对应位都是1，则结果为1，否则为0 a&amp;b = D(12) = B(00001100) 或运算符(|)如果相对应位都是0，则结果为0，否则为1 (a|b) = D(61) = B(00111101) ##### ^运算符 如果相对应位值相同，则结果为0，否则为1 (a ^ b) = D(49) = B(00110001) ~运算符按位补运算符翻转操作数的每一位，即0变成1，1变成0。 ~a = D(-61) = B(11000011) 技巧：正数、负数、0 都是取反+1 ##### 常用位运算技巧获得int 型最大值12(1 &lt;&lt; 31) - 1~(1 &lt;&lt; 31) 获得int 型最小值121 &lt;&lt; 311 &lt;&lt; -1 乘以或除以 2的m次方1210 * 16 = 10 &lt;&lt; 410/4 = 10 &gt;&gt; 2 判断奇偶性1x &amp; 1 // 为0 是偶数；为1 是奇数 交换两个数123a = a^bb = a^ba = a^b 将一个整数的二进制最右边的1变为01(x-1) &amp; x 关于数字在计算中的表示先说几个概念： 原码：将一个数字转换为二进制，就是原码 反码：正数的反码就是其原码，负数的反码是其除符号位以外其它位置全部取反 补码：正数的补码就是其原码，负数的补码是其反码加1 在计算机中正数用其原码表示，负数用其补码表示]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>位运算</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[String源码解析]]></title>
    <url>%2F2018%2F03%2F12%2FJava%20%E5%9F%BA%E7%A1%80%2FString%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[####变化 在JDK 8之前，String的源码实现都是通过使用char数组接收字符串，但是每个char字符是由两个字符组成，因为java内部使用UTF-16实现；如果一个字符串含有英文字符，那么这些英文字符的前 8 比特都将为 0，因为一个ASCII字符都能被单个字节来表示。然而我们在使用字符串的时候只需8bit的情况占大多数。由于这种情况jvm堆空间通常很大一部分被字符串占据。 在java1.6时候引入了一个新的虚拟机参数 UseCompressedStrings；字符串将以byte数组的形式存储，代替原来的char。然而在JDK 7中被移除，主要原因在于它将带来一些如法预料的性能问题。 JDK 9中String对象的实现#####实现方式 1private final byte[] value; 用于存储String的字节编码 1234private final byte coder;static final boolean COMPACT_STRINGS = true;static final byte LATIN1 = 0;static final byte UTF16 = 1; 这些是JDK 9用于解决字符串占用内存空间大的方案的变量 每个String对象都拥有一个coder变量，它有两个值:0或者1,分别对应LATIN1和UTF16；当coder=0时表示这个String对象是用LATIN1字符集进行编码，当coder=1时表示String对象是用UTF16进行编码。 我们可以根据构造函数作为切入点进行探究 12345678910111213141516171819202122public String(char[] value) &#123; this((char[])value, 0, value.length, (Void)null);&#125;String(char[] value, int off, int len, Void sig) &#123; if (len == 0) &#123; this.value = &quot;&quot;.value; this.coder = &quot;&quot;.coder; &#125; else &#123; if (COMPACT_STRINGS) &#123; byte[] val = StringUTF16.compress(value, off, len); if (val != null) &#123; this.value = val; this.coder = 0; return; &#125; &#125; this.coder = 1; this.value = StringUTF16.toBytes(value, off, len); &#125;&#125; 从第二个构造函数我们可以很清楚的看到实现方式： 12345678910111213141516171819202122232425262728293031323334if (COMPACT_STRINGS) &#123; byte[] val = StringUTF16.compress(value, off, len); if (val != null) &#123; this.value = val; this.coder = 0; return; &#125; &#125; this.coder = 1; this.value = StringUTF16.toBytes(value, off, len); //StringUTF16的方法 public static byte[] compress(char[] val, int off, int len) &#123; byte[] ret = new byte[len]; return compress((char[])val, off, ret, 0, len) == len ? ret : null;&#125; //StringUTF16的方法public static int compress(char[] src, int srcOff, byte[] dst, int dstOff, int len）&#123; for(int i = 0; i &lt; len; ++i) &#123; char c = src[srcOff]; if (c &gt; 255) &#123; len = 0; break; &#125; dst[dstOff] = (byte)c; ++srcOff; ++dstOff; &#125; return len;&#125; 首先根据String的类变量COMPACT_STRINGS 默认为true判断是否对String对象进行压缩；根据compress()方法我们能够看出来 压缩是根据字符串是不是全部能够根据ASCII码表找对应的编码，如果有一个字符不符合，那么就会返回0，从而不进行压缩，而是直接采用UTF16进行编码。 内置的比较器1public static final Comparator&lt;String&gt; CASE_INSENSITIVE_ORDER = new String.CaseInsensitiveComparator(); 这个是String内部默认的排序方式 1234567891011121314151617181920private static class CaseInsensitiveComparator implements Comparator&lt;String&gt;, Serializable &#123; private static final long serialVersionUID = 8575799808933029326L; private CaseInsensitiveComparator() &#123; &#125; public int compare(String s1, String s2) &#123; byte[] v1 = s1.value; byte[] v2 = s2.value; if (s1.coder() == s2.coder()) &#123; return s1.isLatin1() ? StringLatin1.compareToCI(v1, v2) : StringUTF16.compareToCI(v1, v2); &#125; else &#123; return s1.isLatin1() ? StringLatin1.compareToCI_UTF16(v1, v2) : StringUTF16.compareToCI_Latin1(v1, v2); &#125; &#125; private Object readResolve() &#123; return String.CASE_INSENSITIVE_ORDER; &#125;&#125; 从代码也可以很容易看出来就是从第一个字符开始挨着挨着的比较，如果有一个字符不一样，那么就会直接比较这两个字符的大小，从而得出两个字符串的大小。 从源码可以学到的东西 检查方法参数是否正确 12345678910111213141516171819202122public String(char[] value, int offset, int count) &#123; this(value, offset, count, rangeCheck(value, offset, count));&#125; String(char[] value, int off, int len, Void sig) &#123; if (len == 0) &#123; this.value = "".value; this.coder = "".coder; &#125; else &#123; if (COMPACT_STRINGS) &#123; byte[] val = StringUTF16.compress(value, off, len); if (val != null) &#123; this.value = val; this.coder = 0; return; &#125; &#125; this.coder = 1; this.value = StringUTF16.toBytes(value, off, len); &#125;&#125; 我们可以用Void类型作为参数，接受如果运行正确的方法返回值为void的方法。 String类中存在的同步 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public boolean contentEquals(CharSequence cs) &#123; if (cs instanceof AbstractStringBuilder) &#123; if (cs instanceof StringBuffer) &#123; synchronized(cs) &#123; return this.nonSyncContentEquals((AbstractStringBuilder)cs); &#125; &#125; else &#123; return this.nonSyncContentEquals((AbstractStringBuilder)cs); &#125; &#125; else if (cs instanceof String) &#123; return this.equals(cs); &#125; else &#123; int n = cs.length(); if (n != this.length()) &#123; return false; &#125; else &#123; byte[] val = this.value; if (this.isLatin1()) &#123; for(int i = 0; i &lt; n; ++i) &#123; if ((val[i] &amp; 255) != cs.charAt(i)) &#123; return false; &#125; &#125; &#125; else if (!StringUTF16.contentEquals(val, cs, n)) &#123; return false; &#125; return true; &#125; &#125;&#125;private boolean nonSyncContentEquals(AbstractStringBuilder sb) &#123; int len = this.length(); if (len != sb.length()) &#123; return false; &#125; else &#123; byte[] v1 = this.value; byte[] v2 = sb.getValue(); if (this.coder() == sb.getCoder()) &#123; int n = v1.length; for(int i = 0; i &lt; n; ++i) &#123; if (v1[i] != v2[i]) &#123; return false; &#125; &#125; return true; &#125; else &#123; return !this.isLatin1() ? false : StringUTF16.contentEquals(v1, v2, len); &#125; &#125;&#125; 在多线程中可能存在在比较的过程中，被比较的字符串被其它县城关改变，造成运行出错。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>String对象</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[面向实习的java后台学习知识点（待完善）]]></title>
    <url>%2F2018%2F03%2F12%2F%E9%9D%A2%E5%90%91%E5%AE%9E%E4%B9%A0%E7%9A%84java%E5%90%8E%E5%8F%B0%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E7%82%B9%EF%BC%88%E5%BE%85%E5%AE%8C%E5%96%84%EF%BC%89%2F</url>
    <content type="text"><![CDATA[java基础 集合框架 hashmap、linkedlist、arraylist 线程安全 vector、concurrenthash、hashtable 线程安全 关键字： syncronized、 violate 、reenterlock jvm锁优化 自旋锁….. String 常量池：运行时常量池、静态常量池 final —-&gt; 并发 StringBUffer、StringBuilder 线程 很杂（多线程面经） 线程池 有哪些 阻塞队列 拒绝策略 io BIO NIO nio在RPC框架中的作用 object toString hushcode equals 深克隆和浅克隆 wait 和sleep() notify 和notifyall JVM 内存区域 内存分配 内存回收 (GC 和 GC算法) class文件结构 内存模型(线程) 线程实现 线程优化 类加载器 Spring IOC(很重要的点，需要了解底层) AOP（很重要的点，需要了解底层） 事务 mybaties 怎么实现事务 spring mvc SpringBeanFactory spirngMVC处理流程 springmvc容器初始化 mysql 事务（四个特性、隔离级别、读问题） 并发处理(悲观锁、乐观锁) 索引(betry，hash、全文、空间) 优化(sql优化、分库分表(mycat) ) 计算机网络 http：分层、https 数字含义 tcp：三次握手、四次挥手 udp cookie、session 操作系统 调度算法 cpu 大文件的排序 数据结构 数组(内存形式)—&gt; 链表(栈(递归调用)、队列)—&gt;树(二叉树、完全二叉树、排序二叉树、平衡二叉树(B树)、遍历过程（中序、）)—&gt;图(因为现在还没有学习数据结构，学习过后再来总结这里的大的知识点) 算法 查找 排序 动态规划(贪婪算法) 项目 RPC(三宗罪、nio) 负载均衡(无状态服务) 注册中心(nio、路由算法、缓存(雪崩、扩展、内存/jvm 缓存)) 数据库缓存集群（读写分离、分库分表、高可用高扩展） Redis了解其基本实现]]></content>
      <tags>
        <tag>学习路线</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux上安装和部署redis]]></title>
    <url>%2F2018%2F03%2F09%2FLinux%2Flinux%E4%B8%8A%E5%AE%89%E8%A3%85%E5%92%8C%E9%83%A8%E7%BD%B2%2F</url>
    <content type="text"><![CDATA[关于linux下软件通过源码的安装 主要是以下四个步骤： ./configure 这个步骤主要是为了建立MakeFile文档 make clean 主要是为了清除可能已经产生了修改却编译了的目标文件 make 使用make就是要将原始码编译成为可以被执行的可执行档，而这个可执行档会放置在目前所在的目录之下，尚未被安装到预定安装的目录中 make install 通常这就是最后的安装步骤了，make会依据Makefile这个档案里面关于install的项目，将上一个步骤所编译完成的资料给他安装到预定的目录中 redis的安装和部署1.基础知识 redis是用C语言开发的一个开源的高性能键值对（key-value）数据库。它通过提供多种键值数据类型来适应不同场景下的存储需求，目前为止redis支持的键值数据类型如下字符串、列表（lists）、集合（sets）、有序集合（sorts sets）、哈希表（hashs）2.redis的应用场景 缓存（数据查询、短连接、新闻内容、商品内容等等）。（最多使用） 分布式集群架构中的session分离。 聊天室的在线好友列表。 任务队列。（秒杀、抢购、12306等等） 应用排行榜。 网站访问统计。 数据过期处理（可以精确到毫秒）3.安装redis 下面介绍在Linux环境下，Redis的安装与部署，使用redis-3.0稳定版,因为redis从3.0开始增加了集群功能。在后面我也会分享redis集群。 1.可以通过官网下载 地址：http://download.redis.io/releases/redis-3.0.0.tar.gz 2.使用linux wget命令 1wget http://download.redis.io/releases/redis-3.0.0.tar.gz 将redis-3.0.0.tar.gz拷贝到/usr/local下 1cp redis-3.0.0.rar.gz /usr/local 解压源码 1tar -zxvf redis-3.0.0.tar.gz 进入解压后的目录进行编译 1cd /usr/local/redis-3.0.0 安装到指定目录 如 /usr/local/redis 1make PREFIX=/usr/local/redis install redis.conf是redis的配置文件，redis.conf在redis源码目录。拷贝配置文件到安装目录下进入源码目录，里面有一份配置文件 redis.conf，然后将其拷贝到安装路径下 123cd /usr/local/redismkdir confcp /usr/local/redis-3.0.0/redis.conf /usr/local/redis/bin 进入安装目录bin下 1cd /usr/local/redis/bin 此时我们看到的目录结构是这样的 redis-benchmark redis性能测试工具redis-check-aof AOF文件修复工具redis-check-rdb RDB文件修复工具redis-cli redis命令行客户端redis.conf redis配置文件redis-sentinal redis集群管理工具redis-server redis服务进程 4.启动redis 1.前端模式启动直接运行bin/redis-server将以前端模式启动，前端模式启动的缺点是ssh命令窗口关闭则redis-server程序结束，不推荐使用此方法 1./redis-server 如图 2.后端模式启动修改redis.conf配置文件， daemonize yes 以后端模式启动 1vim /usr/local/redis/bin/redis.conf 执行如下命令启动redis： 12cd /usr/local/redis./bin/redis-server ./redis.conf 连接redis 1/usr/local/redis/bin/redis-cli 5.关闭redis强行终止redis进程可能会导致redis持久化数据丢失。正确停止Redis的方式应该是向Redis发送SHUTDOWN命令，命令为： 12cd /usr/local/redis./bin/redis-cli shutdown 强行终止redis 1pkill redis-server 让redis开机自启 123vim /etc/rc.local//添加/usr/local/redis/bin/redis-server /usr/local/redis/etc/redis-conf 至此redis已经全部安装完，后面我会分享redis.conf 详细配置以及说明。 安装redis的一些问题 若出现如下提示，则说明未安装gcc，使用命令安装gcc：apt-get install gcc 12345678[root@localhost redis-2.8.17]# makecd src &amp;&amp; makeallmake[1]: Entering directory `/root/redis-2.8.17/src‘CC adlist.o/bin/sh:cc: command not foundmake[1]: *** [adlist.o] Error127make[1]: Leaving directory `/root/redis-2.8.17/src‘make: *** [all] Error2 若出现如下提示，则将make改为make MALLOC=libc，推测是因为编译库的问题。 12345678910[root@localhost redis-2.8.17]#makecd src &amp;&amp; make allmake[1]: Entering directory `/root/redis-2.8.17/src‘CC adlist.oIn file included from adlist.c:34:0:zmalloc.h:50:31: error: jemalloc/jemalloc.h: No suchfileor directoryzmalloc.h:55:2: error:#error&quot;Newer version of jemalloc required&quot;make[1]: *** [adlist.o] Error1make[1]: Leaving directory `/root/redis-2.8.17/src‘make: *** [all] Error2 ​ jekins的安装下载程序包1wget http://mirrors.jenkins.io/war/latest/jenkins.war 启动程序包1java -jarjenkins.war --httpPort=8081 这里就相当于运行java程序，并且设置端口号为8081 当运行成功后就可以 使用浏览器进行访问 至于具体使用和配置可以参数 这个链接。 ssr的搭建下载安装ssr程序安装程序 1wget -N --no-check-certificate https://raw.githubusercontent.com/ToyoDAdoubi/doubi/master/ssr.sh &amp;&amp; chmod +x ssr.sh &amp;&amp; bash ssr.sh 然后按照安装程序走就行 如果希望查看ssr信息使用下面的命令 1bash ssr.sh 使用BBR加速 12345wget --no-check-certificate https://github.com/teddysun/across/raw/master/bbr.shchmod +x bbr.sh./bbr.sh lsmod | grep bbr 如果出现tcp_bbr字样表示bbr已安装并启动成功]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux装windwos后修复MBR]]></title>
    <url>%2F2018%2F03%2F03%2FLinux%2Flinux%E8%A3%85windwos%E5%90%8E%E4%BF%AE%E5%A4%8DMBR%2F</url>
    <content type="text"><![CDATA[原因在linux系统下安装windows系统，windows系统比较霸道，会覆盖掉所有的MBR文件，所有下次启动的时候不会使你选择启动的系统而是直接进入windows系统。这个时候就需要修复引导文件。 修复引导文件 用U盘做一个linux的启动盘 用启动盘进入试用 打开命令行终端 sudo add-apt-repository ppa:yannubuntu/boot-repair &amp;&amp; sudo apt-get update sudo apt-get install -y boot-repair &amp;&amp; boot-repair 出现的界面里面选择Recommended repair 使用完成就完成了 注意 如果有些人不小心点击了Create a BootInfo summary的话，那你的开机启动界面将会出来一大堆你以前没见过的东西。 那样的话，你可以输入名令：cd /boot/grub 接着输入sudo gedit grub.cfg,打开grub.cfg文件后，通过搜索找到windows，然后把下面这些删去就和原来一样了。]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>MBR</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql相关问题]]></title>
    <url>%2F2018%2F02%2F27%2FMysql%2Fmysql%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[增加远程登录权限 本地登录mysql后执行一下命令 12grant all privileges on *.* to root@&apos;%&apos; identified by &apos;root&apos;;flush privileges;]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git命令]]></title>
    <url>%2F2018%2F02%2F27%2FGit%2Fgit%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[git reset–soft: 将Head引用指向给定提交，索引和工作目录的内容都不会表，这个功能就类似于git checkout –mixed: 将HEAD 引用指向给定提交，索引内容跟着改变，但是工作目录内容不会改变 –hard：将HEAD引用指向给定提交，索引内容和工作目录内容都跟着改变(所以这个需要慎用，因为一旦使用这个命令两个commit之间所有文件都会被删除) git rebase 和 git merge 解释 从上面的三张图就可以大致看出rebase和merge的区别：merge是在自己的分支新建一个commit而这个commit里面包含了master的所有新的提交；rebase是直接将master 的新的commit链接在当前分支的尾部 问题 git 黄金法则：绝对不要再公共分支上使用git rebase 两个命令解决冲突的方法 merge：发现冲突，提交冲突的解决，再合并 rebase：修改冲突，git add，git rebase –continue git stash该命令想要解决的是当我们一个功能写到一半的时候，但是现在出现了另外一个更加急迫的功能需要先去完成，但是因为当前功能并没有完成，我们不想直接提交，这个时候就需要用到这个命令]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux软件推荐]]></title>
    <url>%2F2018%2F02%2F26%2FLinux%2Flinux%E8%BD%AF%E4%BB%B6%E6%8E%A8%E8%8D%90%2F</url>
    <content type="text"><![CDATA[linux端的ssrgithub地址 跨平台百度网盘github地址 操作方法github上很详细 直接在命令行操作方便 #####自制webapp 首先安装appifier github地址 安装deb包 sudo dpkg -i Appifier_x.x.x_amd64.deb 安装npm包 sudo apt-get install npm 安装electron npm install electron –save-dev –save-exact 安装electron-installer-debian包 npm install -g electron-installer-debian 然后是在appifier上生成文件 然后通过以下命令生成deb包，安装(以下命令安装或者通过软件管理器安装) electron-installer-debian –src /home/jingle/Desktop/Wechat-linux-x64/ –dest /home/jingle/Desktop/wechat/ –arch amd64 dpkg -i dir 在这里可能会遇到类似错误： 123Error: No Description or ProductDescription provided at getOptions (/usr/lib/node_modules/electron-installer-debian/src/installer.js:149:11) at getDefaults.then.defaults (/usr/lib/node_modules/electron-installer-debian/src/installer.js:418:23) &apos;Error: No Description or ProductDescription provided\n at getOptions (/usr/lib/node_modules/electron-installer-debian/src/installer.js:149:11)\n at getDefaults.then.defaults (/usr/lib/node_modules/electron-installer-debian/src/installer.js:418:23)&apos; 只需要在/home/…/Desktop/Gmail-linux-x64/resources/app.asar.unpacked/package.json文件里面按照格式添加description和productDescription属性。 参考链接 http://ijingle.cc/2018/02/11/appifier-build-webapp/]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux软件</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多线程]]></title>
    <url>%2F2018%2F02%2F26%2FJava%20%E5%B9%B6%E5%8F%91%2F%E7%BA%BF%E7%A8%8B%E6%B1%A0%2F</url>
    <content type="text"><![CDATA[关于创建线程池 如果熟悉了线程池的创建过程或者说一些参数的意义那么可以直接使用下列方式进行线程池的创建 123ExecutorService executorService = Executors.newCachedThreadPool();ExecutorService executorService2 = Executors.newFixedThreadPool(int);ExecutorService executorService3 = Executors.newSingleThreadExecutor(); 讲一讲各种线程池的好坏 CachedThreadPool: 好处:在程序执行过程中通常会创建与所需数量相同的线程，然后在它回收旧线程时停止创建新线程，因此它是合理的Executor的首选； 坏处：线程最大数是Integer.MAX_VALUE，可能会创建数量非常多的线程，甚至oom； FixedThreadPool: 好处：一次性预先执行代驾高昂的线程分配，因而也就可以限制线程数量。这可以节省时间，因为你不用为每个任务都固定的付出创建线程的开销。 坏处：堆积的请求处理的队列耗费非常大的内存，甚至oom SingleThreadPool： 好处：确保任意时刻在任何线程中都只有唯一的任务在运行，在这种方式下你不需在共享资源上处理同步。 坏处：堆积的请求处理的队列耗费非常大的内存，甚至oom 在不熟悉的情况下使用ThreadPoolExecutor创建线程池，因为在这样的情况下我们可以更加明确线程池的运行规则，规避资源耗尽的风险。 用ThreadPoolExecutor创建线程池的方式： 1ExecutorService executorSeervice = new ThreadPoolExecutor(&apos;corePoolSize&apos;,&apos;maximumPoolSize&apos;,&apos;keepAliveTime&apos;,&apos;timeUnit&apos;,&apos;blockingQueue&apos;,&apos;abortPolicy&apos;) 对每个参数解释一下： corePoolSize：核心线程数量 maximumPoolSize：最大线程数量 keepAliveTime：保持活动时间，如果池中当前有多于corePoolSize，则这些多出的线程在空闲的使劲超过keepAliveTime时将会终止 BlockingQueue都可用于传输和保持提交的任务，使用此队列与池大小进行交互；如果请求任务时运行的线程数小于corePoolSize那么直接创建新的线程 运行任务；多于的话就将添加到队列里面；超出MaxPoolSize那么任务就会被拒绝，然后用abortPolicy进行任务拒绝。 排队有三种通用策略： 1231. 直接提交：工作队列的默认选项是使用SynchronousQueue，通常要求无界的maxPoolSize；2. 无界队列：如使用LinkedBlockingQueue；3. 有界队列：如 ArrayBlockingQueue 拒绝规则 有四种拒绝规则，当任务被拒绝过后就使用这些拒绝规则 ThreadPoolExecutor.AbortPolicy：用于被拒绝任务的处理程序，它将抛出 RejectedExecutionException ThreadPoolExecutor.CallerRunsPolicy:用于被拒绝任务的处理程序，它直接在 execute 方法的调用线程中运行被拒绝的任务；如果执行程序已关闭，则会丢弃该任务。 ThreadPoolExecutor.DiscardLOldestPolicy：用于被拒绝任务的处理程序，它放弃最旧的未处理请求，然后重试 execute；如果执行程序已关闭，则会丢弃该任务。 ThreadPoolExecutor.DiscardPolicy:用于被拒绝任务的处理程序，默认情况下它将丢弃被拒绝的任务。 threadPoolExecutor的其它方法： 钩子方法：用于在每个任务执行之前执行一些方法 队列维护：通过getQueue()方法方位工作队列然后通过remove（）或者purge（）取消大量已排队任务时帮助进行存储回收。 线程池的线程安全线程池是一个线程安全的类，它实现线程安全的方式是 volatile变量，CAS 操作和ReentrantLock]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[javaweb中的编码]]></title>
    <url>%2F2018%2F02%2F25%2FJavaweb%2Fjavaweb%E4%B8%AD%E7%9A%84%E7%BC%96%E7%A0%81%2F</url>
    <content type="text"><![CDATA[JavaWeb中的编码问题 编码的原因： 计算机中存储信息的最小单位是一个字节，所能表示的字符范围是0—255个 人类要表示的符号太多，无法用1个字节表示。 一些对于编码问题的总结 只要有IO流就必定有编码和解码 关于IDEA平台下的System.out.println()，它是直接将我们的经过解码的字符串的字节数组进行打印，然后操作系统用这些字符数组与字符形状表进行对比，打印出来 什么是编码解码 编码：编码的原因是把我们人类所认识的字符编码为计算机认识的0,1代码，便于存储在计算机的磁盘中或者在网络中传输；又出现了一个问题，为什么不对解码的内容直接进行存储，而非要编码为计算机认识的0，1代码？又因为地区的不一样或者甚至说不同软件之间都可能采用不同的编码，比如说记事本一般采用GBK编码而IDEA我们可以设置为UTF-8进行存储，如果我们直接对字节集解码的内容进行存储，就会不具有通用性。 解码：将计算机磁盘存储的数据或者网络IO流中的数据，按照字符集解码为对应的字节数组；有了这样的字节数组那么计算机就可以对应字符形状表显示在显示器上 常见的编码 ASCII ISO-8859-1:256个字符，涵盖大多数西欧字符； GB2312：双字节，中文编码； GBK： GB2312的扩展； GB18030：中文，单双四字节都有； UTF-16：两个字节表示一个字符； UTF-8：运用变长技术，ASCII用单字节表示，中文用三个字节表示。 Java中如何解编码 首先会根据指定的charsetName也就是你指定的编码类型，通过Charset.forName(charsetName)找到Charset类，然后根据Charset创建CharsetEncoder对象，再调用CharsetEncoder.encode对字符串编码，不同的编码类型都会对应到一个类中 ，实际的编码过程就是在这些类中完成的。 几种编码方式的比较对于中文字符由于GBK比GB2312范围更大，编码方式相同，所以GBK更好。UTf-16编码效率更高，只是把一个字节拆成两个字节就完成它的工作，所以在磁盘与内存上的操作它更适合，但是在字节容易损坏的网络上utf-8更适合，它不像utf-16顺序编码，一个字节的损坏会影响后面的字符。且编码效率上utf-8介于GBK和utf-16之间。 JavaWeb中涉及的编码 url的编解码 http://localhost:8080//examples/servlets/serlet/君山?authod=君山 sheme domin port contextPath servletPath pathInfo queryString 一般情况下pathInfo采用的是utf-8编码，然后浏览器会将非ASCII字符按照某种编码格式编码成16进制数字后将每个16进制数字表示的字节前加上%，Tomcat的设置上默认也是按照utf-8解码pathInfo；queryString是按照传输中在header中设置的contentType编码方式进行编码，然后在Tomcat中可以设置useBodyEncodingForURI=“true”将queryString的解码方式采用的也是contentType设置的编码方式。 HTTP Header 的编解码 header中只能传输ASCII字符，不能采用其他编解码方式；如果一定要传递可以先将这些字符用URIEncoder编码再添加到Header中。 Post表单上的编解码 在POST提交的时候会按照ContentType编码，tomcat也会按照ContentType解码；Tomcat在getParameter方法之前会获取contentType中的charset；但是这里有一种特殊情况，在 POST提交表单的时候默认情况下 ContentType是不会有值的就会采用默认的ISO-8859-1；而在jsp中设置的contentType中的Charset是告诉浏览器该页面该用什么解码。 HTTP body的编解码 在服务器通过response返给浏览器的时候与request给服务器的编解码过程差不多；通过设置response的contentType然后服务器和浏览器就用这个charset对body进行编解码。]]></content>
      <categories>
        <category>javaweb</category>
      </categories>
      <tags>
        <tag>javaweb编码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[生成ssh秘钥]]></title>
    <url>%2F2018%2F02%2F25%2FGit%2F%E7%94%9F%E6%88%90ssh%E7%A7%98%E9%92%A5%2F</url>
    <content type="text"><![CDATA[首先检查有没有ssh秘钥 ls -al ~/.ssh 生成秘钥 ssh-keygen -t rsa -C “your_email@example.com“]]></content>
      <tags>
        <tag>ssh秘钥</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[有关linux的命令]]></title>
    <url>%2F2018%2F02%2F25%2FLinux%2F%E6%9C%89%E5%85%B3linux%E7%9A%84%E5%91%BD%E4%BB%A4%E5%92%8C%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[比较好的linux基础命令总结 命令错误的情况sudo: add-apt-repository：找不到命令 solution：sudo apt-get install python-software-properties ​ sudo apt-get install software-properties-common 设置命令的快捷方式 vim ~/.bashrc设置别名 alias ll=’ls -al’ 如果要执行多条命令中间用分好分隔就行 source ~/.bashrc #####配置java环境变量 首先下载jdk 在linux下通过wget下载 命令示例： 1wget --no-check-certificate --no-cookies --header &quot;Cookie: oraclelicense=accept-securebackup-cookie&quot; http://download.oracle.com/otn-pub/java/jdk/8u111-b14/jdk-8u111-linux-x64.tar.gz sudo tar zxvf ./{jdk文件} -C /usr/lib cd /usr/lib sudo mv {jdk文件} jdk8 sudo vi /etc/profile 在最后加入 1234export JAVA_HOME=/usr/lib/jdk7export JRE_HOME=$&#123;JAVA_HOME&#125;/jreexport CLASSPATH=.:$&#123;JAVA_HOME&#125;/lib/tools.jar:$&#123;JRE_HOME&#125;/lib/dt.jarexport PATH=$&#123;JAVA_HOME&#125;/bin:$&#123;JAVA_HOME&#125;/jre/bin:$PATH sudo source /ect/profile 最后 通过 java -version 进行检查 #####设置系统自启动程序 rc.local自启动 在使用了systemd作为启动器的系统（如较新版的deepin）中，如果没有rc.local就自己创建，然后在文件里面写下如下内容： 123456#!/bin/bash# rc.local config file created by use把你需要执行的命令写在这里exit 0 再赋予权限 sudo chmod +x /etc/rc.local，下次重启时systemd就会自动执行rc.local里面的命令了 autostart自启动 在~/.configure/autostart 目录下添加自启动命令，以代理工具 XX-Net 为例，假定其启动脚本位于~/Documents/XX-Net-3.3.1/start。 12345678910111213141516171819[Desktop Entry]Type=ApplicationExec=&quot;~/Documents/XX-Net-3.3.1/start&quot;Hidden=falseNoDisplay=falseX-GNOME-Autostart-enabled=trueName[en_IN]=XX-NetName=XX-NetComment[en_IN]=XX-NetComment=XX-Net 系统启动时会执行 Exec所指定的命令 进程相关命令查询进程 ps命令查找与进程相关的PID号： ps a 显示现行终端机下的所有程序，包括其他用户的程序。 ps -A 显示所有程序。 ps c 列出程序时，显示每个程序真正的指令名称，而不包含路径，参数或常驻服务的标示。 ps -e 此参数的效果和指定”A”参数相同。 ps e 列出程序时，显示每个程序所使用的环境变量。 ps f 用ASCII字符显示树状结构，表达程序间的相互关系。 ps -H 显示树状结构，表示程序间的相互关系。 ps -N 显示所有的程序，除了执行ps指令终端机下的程序之外。 ps s 采用程序信号的格式显示程序状况。 ps S 列出程序时，包括已中断的子程序资料。 ps -t&lt;终端机编号&gt; 指定终端机编号，并列出属于该终端机的程序的状况。 ps u 以用户为主的格式来显示程序状况。 ps x 显示所有程序，不以终端机来区分。 最常用的方法是ps aux,然后再通过管道使用grep命令过滤查找特定的进程,然后再对特定的进程进行操作。ps aux | grep program_filter_word,ps -ef |grep tomc 杀死进程 通过PID杀死进程 1kill PID 通过进程名称杀死进程 1killall NAME ​ 网络相关指令netstat Netstat 命令用于显示各种网络相关信息，如网络连接，路由表，接口状态 (Interface Statistics)，masquerade 连接，多播成员 (Multicast Memberships) 等等。 相关参数 a (all)显示所有选项，默认不显示LISTEN相关 t (tcp)仅显示tcp相关选项 u (udp)仅显示udp相关选项 n 拒绝显示别名，能显示数字的全部转化成数字。 l 仅列出有在 Listen (监听) 的服務状态 p 显示建立相关链接的程序名 r 显示路由信息，路由表 e 显示扩展信息，例如uid等 s 按各个协议进行统计 c 每隔一个固定时间，执行该netstat命令。 提示：LISTEN和LISTENING的状态只有用-a或者-l才能看到 查看指定端口号的进程1# netstat -an | grep &apos;:80&apos; 杀死指定端口号的所有进程1kill -9 $(sudo lsof -i tcp:进程号 -t) 安装deb包 下面是一个例子： 1sudo dpkg -i Appifier_9.6.2_amd64.deb 实时跟踪tomcat的输出 进入tomcat的logs目录 例如： 1cd /usr/local/tomcat8/logs 1tail -f catalina.out linux下解压所有类型压缩类型文件的命令.tar解包：tar xvf FileName.tar打包：tar cvf FileName.tar DirName（注：tar是打包，不是压缩！）———————————————.gz解压1：gunzip FileName.gz解压2：gzip -d FileName.gz压缩：gzip FileName .tar.gz 和 .tgz解压：tar zxvf FileName.tar.gz压缩：tar zcvf FileName.tar.gz DirName———————————————.bz2解压1：bzip2 -d FileName.bz2解压2：bunzip2 FileName.bz2压缩： bzip2 -z FileName .tar.bz2解压：tar jxvf FileName.tar.bz2压缩：tar jcvf FileName.tar.bz2 DirName———————————————.bz解压1：bzip2 -d FileName.bz解压2：bunzip2 FileName.bz压缩：未知 .tar.bz解压：tar jxvf FileName.tar.bz压缩：未知———————————————.Z解压：uncompress FileName.Z压缩：compress FileName.tar.Z 解压：tar Zxvf FileName.tar.Z压缩：tar Zcvf FileName.tar.Z DirName———————————————.zip解压：unzip FileName.zip压缩：zip FileName.zip DirName———————————————.rar解压：rar x FileName.rar压缩：rar a FileName.rar DirName———————————————.lha解压：lha -e FileName.lha压缩：lha -a FileName.lha FileName———————————————.rpm解包：rpm2cpio FileName.rpm | cpio -div———————————————.deb解包：ar p FileName.deb data.tar.gz | tar zxf -——————————————— .tar .tgz .tar.gz .tar.Z .tar.bz .tar.bz2 .zip .cpio .rpm .deb .slp .arj .rar .ace .lha .lzh .lzx .lzs .arc .sda .sfx .lnx .zoo .cab .kar .cpt .pit .sit .sea解压：sEx x FileName.压缩：sEx a FileName. FileName sEx只是调用相关程序，本身并无压缩、解压功能，请注意！ gzip 命令减少文件大小有两个明显的好处，一是可以减少存储空间，二是通过网络传输文件时，可以减少传输的时间。gzip 是在 Linux 系统中经常使用的一个对文件进行压缩和解压缩的命令，既方便又好用。 语法：gzip [选项] 压缩（解压缩）的文件名该命令的各选项含义如下： -c 将输出写到标准输出上，并保留原有文件。-d 将压缩文件解压。-l 对每个压缩文件，显示下列字段： 压缩文件的大小；未压缩文件的大小；压缩比；未压缩文件的名字-r 递归式地查找指定目录并压缩其中的所有文件或者是解压缩。-t 测试，检查压缩文件是否完整。-v 对每一个压缩和解压的文件，显示文件名和压缩比。-num 用指定的数字 num 调整压缩的速度，-1 或 –fast 表示最快压缩方法（低压缩比），-9 或–best表示最慢压缩方法（高压缩比）。系统缺省值为 6。指令实例： gzip % 把当前目录下的每个文件压缩成 .gz 文件。gzip -dv % 把当前目录下每个压缩的文件解压，并列出详细的信息。gzip -l *% 详细显示例1中每个压缩的文件的信息，并不解压。gzip usr.tar% 压缩 tar 备份文件 usr.tar，此时压缩文件的扩展名为.tar.gz。 vim使用技巧使用关键字查询使用‘/’加你要查询的内容 替换需要注意的是如果是url可以将下面的’/‘换成’#’ :s（substitute）命令用来查找和替换字符串。语法如下： 1:&#123;作用范围&#125;s/&#123;目标&#125;/&#123;替换&#125;/&#123;替换标志&#125; 例如:%s/foo/bar/g会在全局范围(%)查找foo并替换为bar，所有出现都会被替换（g）。 作用范围 作用范围分为当前行、全文、选区等等。 当前行： 1:s/foo/bar/g 全文： 1:%s/foo/bar/g 选区，在Visual模式下选择区域后输入:，Vim即可自动补全为 :&#39;&lt;,&#39;&gt;。 1:&apos;&lt;,&apos;&gt;s/foo/bar/g 2-11行： 1:5,12s/foo/bar/g 当前行.与接下来两行+2： 1:.,+2s/foo/bar/g 替换标志 上文中命令结尾的g即是替换标志之一，表示全局global替换（即替换目标的所有出现）。 还有很多其他有用的替换标志： 空替换标志表示只替换从光标位置开始，目标的第一次出现： 1:%s/foo/bar i表示大小写不敏感查找，I表示大小写敏感： 123:%s/foo/bar/i# 等效于模式中的\c（不敏感）或\C（敏感）:%s/foo\c/bar c表示需要确认，例如全局查找&quot;foo&quot;替换为&quot;bar&quot;并且需要确认： 1:%s/foo/bar/gc 回车后Vim会将光标移动到每一次&quot;foo&quot;出现的位置，并提示 1replace with bar (y/n/a/q/l/^E/^Y)? 按下y表示替换，n表示不替换，a表示替换所有，q表示退出查找模式， l表示替换当前位置并退出。^E与^Y是光标移动快捷键，参考： Vim中如何快速进行光标移动。 一些插件使用技巧 NERDTree Control + W 跳转窗格 然后使用上下作用控制游标 sp可以将当前窗格进行划分 Center OS7 center os7安装后默认是安装了并启用了firewalld防火墙 所以以下是一些命令操作该防火墙基本命令，有其它需求自行在网上搜索 123456789101112启动防火墙systemctl start firewalld 禁用防火墙systemctl stop firewalld设置开机启动systemctl enable firewalld停止并禁用开机启动sytemctl disable firewalld重启防火墙firewall-cmd --reload 查看状态systemctl status firewalld或者 firewall-cmd --state ubuntu下快速构建java 环境 安装jre 1sudo apt-get install default-jre 安装jdk 1sudo apt-get install default-jdk 下面是全面的安装 1234567sudo add-apt-repository ppa:webupd8team/java sudo apt-get update sudo apt-get install oracle-java8-installer sudo apt-get install oracle-java8-set-default 关闭ubutnu下面的哔哔声 1234sudo echo "blacklist pcspkr" &gt;&gt; /etc/modprobe.d/blacklist//或者直接通过sudo su进入root//然后执行 echo "blacklist pcspkr" &gt;&gt; /etc/modprobe.d/blacklist//然后 重启电脑 关闭vim的哔哔声 1set vb t_vb= Centos 防火墙firewalld https://www.jianshu.com/p/bad33004bb4f]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux命令，环境</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux下tomcat的安装]]></title>
    <url>%2F2018%2F02%2F25%2FLinux%2Flinux%E4%B8%8Btomcat%E7%9A%84%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[下载tomcat压缩文件 tar -zxvf {tomcat文件} 移动到/usr/local 文件下 并把文件名称改为类似tomcat9 配置环境变量 vi /etc/profile 在文件最后加入 1export CATALINA_HOME=/usr/local/tomcat9 source /etc/profile 配置tomcat的catAlina.sh文件 cd $CATALINA_HOME/bin vi catalina.sh 找到OS specific support 然后在下面添加 12CATALINA_HOME=/usr/local/tomcat9JAVA_HOME=jdk文件所在位置 安装tomcat服务 cp catalina.sh /etc/init.d/tomcat chkconfig –add tomcat chkconfig tomcat on chkconfig –liist 查看tomcat是否添加服务成功 权限问题 cd $CATALINA_HOME/bin sudo chmod 777 *.sh cd /etc/init.d sudo chmod 777 tomcat]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>tomcat的安装</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于hexo]]></title>
    <url>%2F2018%2F02%2F25%2Fhexo%2F%E5%85%B3%E4%BA%8Ehexo%2F</url>
    <content type="text"><![CDATA[linux环境的准备 sudo apt-get install git sudo apt-get install nodejs sudo apt-get install npm 自己遇到的一些问题npm安装过慢 npm安装hexo过慢：用官网的npm install hexo-cli -g速度非常感人 用淘宝的npm分流，安装命令： 1npm install -g cnpm --registry=https://registry.npm.taobao.org 安装完过后用法和之前一样，只不过把npm改为cnpm 设置social链接时候可能出现的问题 在设置social链接的时候，记得一定要把social前面的#去掉，还有记得在设置什么参数的时候记得留一个空格 hexo d 时可能出现的问题 如果其他没有问题出现 ERROR Deployer not found: git问题，那么可以尝试 npm install hexo-deployer-git –save 表情插件因为hexo默认的MarkDown渲染器不支持使用表情，我们可以使用hexo-filter-github-emojis 来让其支持 具体的步骤我们可以取github插件地址去看安装步骤 我们可以使用的表情可以在这个网站去找 ####其它有用的链接 http://chitanda.me/2015/06/11/tips-for-setup-hexo/]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
</search>
